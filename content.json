{"meta":{"title":"殇花","subtitle":"殇花思密达","description":"殇花的博客","author":"殇 花","url":"https://www.shanghua.live","root":"/"},"pages":[{"title":"categories","date":"2021-06-20T13:28:52.000Z","updated":"2021-06-20T05:29:03.669Z","comments":true,"path":"categories/index.html","permalink":"https://www.shanghua.live/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-06-20T13:27:36.000Z","updated":"2021-06-20T05:27:54.528Z","comments":true,"path":"tags/index.html","permalink":"https://www.shanghua.live/tags/index.html","excerpt":"","text":""},{"title":"","date":"2021-07-08T04:54:59.481Z","updated":"2021-07-08T04:54:59.481Z","comments":true,"path":"js/demo.js","permalink":"https://www.shanghua.live/js/demo.js","excerpt":"","text":"setTimeout(() => { console.log(\"aaa\"); },0)"}],"posts":[{"title":"流媒体技术","slug":"计网/流媒体技术","date":"2021-07-08T11:02:48.000Z","updated":"2021-07-08T04:44:46.518Z","comments":true,"path":"2021/07/08/计网/流媒体技术/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/%E6%B5%81%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF/","excerpt":"","text":"流媒体技术在流媒体计数不发达的时代，数据往往是以单个文件的形式存在的，十多年前下载电影（每秒十多 k 的网速），需要等待视频下载完毕来看，往往要花废很多时间 如何将一个视频抽象成流呢？就是传输一部分即可播放一部分，在实际的操作当中，设计了一种类似目录的格式，将音视频数据进行切片，这部分能利用现有的工具 FFmpeg 就可以轻松做到 安装 FFmpeg，利用指令处理一个 MP4 文件，就可以生成很多切片和目录文件 1ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -f hls output.m3u8 上面将input.mp4切割成HTTP Live Streaming 可以播放的切片（大多数浏览器中的播放器都可以播放）。最终会生成大量的切片文件，比如说每个 256k，以及一个目录文件 output.m3u8。 下图展示的是用 FFmpeg 在我的机器上对 input.mp4 操作生成的文件清单： m3u8 文件是目录，它记录了每个视频切片文件（ts）对应的视频时间范围。用户播放视频的时候，会先下载 m3u8 文件。当用户调整视频播放滑块选择播放时间时，播放器就根据 m3u8 的内容下载对应的 ts 文件。 基于流媒体的架构flowchart LR A[视频] --&gt; B{编码} B --&gt; C[流媒体服务] C --4k--&gt; D[支持 4k 设备] C --1080p--&gt; E[支持 1080p 设备] 视频录制完成后，可能是 MP4 等格式。首先，我们将视频上传到服务器进行编码，产生上面提到的切片文件。切片文件存储到流媒体服务器中，当用户需要的时候，就从流媒体服务器中读取视频目录（上面的 m3u8 文件），然后在各个端播放。进行编码的时候，可以根据不同的清晰度编码多个版本，来应对用户在不同网络环境的情况。 直播直播技术仍然可以复用上面的这套架构。录制端不断上传视频内容，视频内容编码后流媒体服务器负责分发。如果观看人数较多，可以使用 CDN 回源到流媒体服务器。对于直播，m3u8 文件可以看作一个动态的文件，能够不断产生新的数据。因此直播技术中，可以考虑将获取 m3u8 文件设计成一个接口，不断由播放器请求新的 m3u8 文件。 其他音视频网站 将视频编码后（含切片），然后利用 CDN 分发目录和切片文件，就可以播放了 视频的编码和解码 通常视频文件较大，因此在传输前通常需要压缩 在播放前需要解码 视频的压缩技术：是针对视频的特征进行处理的压缩技术，与文件压缩技术是不同的，可以把视频看成一直连续的图片，主要是依靠的人类视觉的残留效应 ，视频的压缩也是如此，本质上是对图片的压缩 视频的前一个画面和后一个画面衔接紧密 在连续的多张图片中，也会有重复出现的事物 另外，在连续的多张图片中，也会有重复出现的事物，比如说一座桥、一间教室都可能多次出现。因此，视频压缩可以根据这些特性进行抽象。 对视频进行压缩的时候，视频文件格式也和压缩算法息息相关，我们统称为视频的编码。视频需要编码，包括如何描述目录、如何描述切片、如何存储声音，这些都是编码要考虑的。一个完整的解决方案，我们称为一套视频的编码。比如说 H264 就是国际标准化组织在推广的一种编码格式。当然，所有特性的核心是在减少视频体积（网络传输）的基础上，尽可能地提供更高的画质；另一方面就是要尽可能减少中间编码/解码的时间成本（机器资源）。 宏块在包括 H264 的很多视频编码技术中，都有一个叫作宏块的概念。宏块，就是将画面分成大小不等的区域。比如说 8x8、16x16 等。 当播放两个连续的画面的时候，你可以理解成两张图片。但是如果基于图片分析，那么播放的就是很多个宏块。在这连续的两帧画面中，并不是所有的宏块都发生了变化。特别是当你看一些教学 PPT 的讲稿时，视频前后两帧的宏块基本没有发生变化。因此往往相同画质、相同时长的教学视频体积会远小于电影视频的体积。 具体的压缩算法不在本次课程的涵盖范围之内，如果你感兴趣可以自己去查资料了解一下，参考分组、帧、预测帧等概念。 点到点视频技术在视频会议、面对面聊天等场景下，需要点到点的视频技术 flowchart LR A[Host1] --上传--&gt; B[编码] B --&gt; C[分类] C --&gt; D[分发] D --下载-解码-播放--&gt; E[Host2] 理论上说也可以使用上面的架构，一个客户端将自己本地录制的视频用二进制上传，在服务端编码然后分发到另一个端。数据在另一个端解码并播放。 这样做的缺点是链路较长，于是在实际操作的过程中如果是 1 对 1 的视频聊天，可以考虑实现点到点的服务。 flowchart LR A[Host1] &lt;-----UDP&amp;nbsp等------&gt; B[Host2] 不过不同的主机可能在私有网络 flowchart LR subgraph 内网 A[Host1] &lt;----&gt; B[NAT + 路由器] end B &lt;----&gt; Host2 你会发现如整个设计中需要一个 NAT 路由器，这样客户的数据才能回传到拉勾内网的机器。而实际情况并没有这么简单，在 NAT 通信中，往往需要在内网的主机发起连接。这个时候 NAT 模块识别发起的端口并记录。换句话说，如果某客户的机器是公网 IP，那么内网内部的主机可以找到这个客户，找到之后，双方建立连接。但是某位客户如果想主动发起向内网某台机器的连接，这其实是做不到的。 如果双方都在内网中，都需要 NAT 的场景，其实是无法通信的 flowchart RL subgraph 内网 2 direction LR C[Host2] &lt;----&gt; D[NAT + 路由器] end subgraph 内网 1 direction LR B[NAT + 路由器] &lt;----&gt;A[Host1] end B &lt;---&gt; D 上图这种情况，拉勾内网发起连接，对方的 NAT 路由会因为自己内网的机器没有发起过请求而拒绝；反之，如果客户发起请求，会被拉勾的 NAT 拒绝。这种情况类似于多线程中的“死锁”问题，无法解决。这个时候，就需要一台第三方服务器作为 NAT 模块的辅助功能，帮助双方的 NAT 模块设置本地数据，让双方的 NAT 模块都认为对方已经和自己发起过通信。这个解决方案也叫作NAT 穿透（NAT 穿墙）。 在著名的 WebRTC 协议中，可以提供网页版的在线 1 对 1 聊天，对于多数家庭到家庭的网络来说，是可以正常工作的。如果当你需要连接两个内网的机器，这个时候就需要自己架设第三方服务，或者使用某个收费的第三方服务。 对于在线会议的场景，如果人数较少的情况下，仍然可以使用点到点技术，只不过传输量会随着人数的上升而呈爆发式增长。所以在人数较多的时候，就需要更多的优化策略。当然，其中一种方案就是放弃点到点技术，而直接采用类似直播架构的中心化服务。另一种策略就是利用边缘计算，让距离相近的参会者利用共同的离自己最近的服务器交换数据。 总结视频本质上是一张张图片在播放，因此非常适合流传输。要知道，流是随着时间产生的数据。通常在一个网络中，等价成本下吞吐量、丢包率和延迟 3 者不能兼得。也就是说，像直播这种吞吐量非常大的视频应用，可能就要牺牲延迟。比如之前 B 站直播没有优化前，用户看到的直播画面会比真实的时间会慢近半分钟。 另一方面，像在线会议这类对延迟要求较高的场景，就可能需要降低视频质量，或者部署边缘服务。如果是内网视频会议，或者跨地区的公司视频会议，很容易找到边缘节点帮助交换数据和计算；如果是来自天南地北的用户，那么就需要投入更多成本。对于社交网站而言，需要维护几个人同时语音、视频聊天，因为人数较少，就可以使用点对点技术（但是要解决 NAT 穿墙的问题）。 直播是如何实现的？ 录制端：负责录制直播视频，用流的形式上传。 计算集群：专门负责编码上传的流数据，然后进行压缩、转码、切片等工作。 对象存储：存储原始视频和转码后的视频（相当于 CDN 的源，回源用）。 CDN：将转码后的内容分发到离用户较近的节点，方便用户获取。 直播 App：给用户看直播时使用。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"爬虫和反爬虫","slug":"计网/爬虫和反爬虫","date":"2021-07-08T11:02:48.000Z","updated":"2021-07-08T05:55:25.822Z","comments":true,"path":"2021/07/08/计网/爬虫和反爬虫/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/%E7%88%AC%E8%99%AB%E5%92%8C%E5%8F%8D%E7%88%AC%E8%99%AB/","excerpt":"","text":"爬虫和反爬虫早期一些购票网站起家的时候，就大量使用爬虫技术爬取航空公司的数据，为了不让航空公司屏蔽，特意用了很多个人电脑做爬虫端，让航空公司无法分清哪些是爬虫、哪些是用户一些相互竞争的电商、外卖公司，内部甚至会设立专门的数据爬取小组，用户监控竞品的数据，并且实时地调整业务的竞争策略—-如补贴、签约等黑产利用招聘网站的漏洞，爬取并出售简历数据，再出售给不法分子 爬取数据违法吗首先，爬取一个网站的数据，很可能是违法行为。通常一个网站，会在自己根路径下的 robots.txt 中定义自己网页中哪些数据是可以用来爬取的。从理论上讲，如果你想爬取一个网站的数据，应该先获取它根目录下的 robots.txt 文件，查阅文件内容，看自己要爬取的数据是否被允许。 下面是 bilibili 的 robots.txt 的内容： 12345678910111213141516171819202122User-agent: YisouspiderAllow: /User-agent: ApplebotAllow: /User-agent: bingbotAllow: /User-agent: Sogou inst spiderAllow: /User-agent: Sogou web spiderAllow: /User-agent: 360SpiderAllow: /User-agent: GooglebotAllow: /User-agent: BaiduspiderAllow: /User-agent: BytespiderAllow: /User-agent: PetalBotAllow: /User-agent: *Disallow: / 可以看到，如果你是谷歌、苹果、360、百度等搜索引擎，那么 B 站是欢迎你爬取内容的。如果你是其他的个人或者组织，比如说你想爬取 B 站上所有大 V 的数据，然后将分析结果出售给其他人（比如某个 MCN 平台），实际上是触犯法律的。依据我国的刑法，你可能会被判处非法获取计算机信息系统数据罪，情节严重的可能会被判处 3 年以上的有期徒刑并处罚金。 助点机器人在没有允许的情况下爬取对方的数据是违法行为。但是 这里衍生出一个问题，比如说，你是一个拉勾的付费用户，你觉得拉勾的界面不够智能，于是你自己写了一个程序，只针对自己的账号范围实现某个功能，对拉勾的简历进行筛选，从而找到合适的求职者，这是违法行为吗？ 这个行为不是违法行为。这个行为可以归结成你自己做的一个辅助自己工作的机器人，但是如果你将这个工具提供给其他人，这是违法行为吗？其实也不是违法行为。但是如果其他人将这个工具用作黑产，比如说爬取用户的数据然后进行简历信息的买卖，这就构成了违法行为，构成犯罪的是买卖简历信息。如果你是拉勾的竞品，你使用大量账号这样做，还会构成非法竞争。 换一个例子，有人觉得 Github 不够智能，然后做了一个插件，帮助大家浏览 Github 中文件代码的目录树，本质上这个工具也需要用到爬虫的部分技术——需要爬取这个目录树。但这不是违法行为，但若有人利用类似的工具，将 Github 全部代码都拿走，在淘宝上打包售卖，这就是违法行为了。 爬虫的原理本质上就是一次网络请求，然后将返回的数据保存下来对于搜索引擎的爬虫而言，通常会在请求头上加上自己的标识，比如百度会加上 baidu 字符串,这样方便网站服务器识别 爬虫如果是非法的，往往就需要伪装成浏览器。通常会用到浏览器内核去模拟发出网络请求，比如用 Chromium（Chrome 的开源内核）就可以提供这样的能力。 当你用 Chromium 发起请求的时候，对于服务提供方的反爬虫系统，你的请求就变成了一次标准的用户行为。如果对方网站需要登录才能爬取数据，这个时候，不法分子还会模拟登陆行为。如果仅仅是输入用户名和密码，那这个网站登录行为会非常容易模拟，只需要找到对方对应的接口，把用户名和密码传过去，就可以拿到访问资源的令牌。这就是大部分网站登录时需要你用手机验证码登录、微信扫描、或填写图片验证码的原因。 对于一些获取数据还需要付费的网站，比如说视频网站或拉勾这样的招聘网站，用户需要付费才能获取核心的数据，这个时候不法分子可能会购买大量的账号。为了防止不法分子获得大量的账号，现在国家已经在严打销售手机卡号的行为。所以请你记住，使用其他人的身份去注册账号，这也是一种违法行为。 关于验证码当被爬取的网站登录接口有验证码时，爬虫的设计者通常会有两种手段。一种是破解验证码，在现在这个人工智能的时代，想要破解验证码只需要获得足够多的验证码图片样本，然后用 tensorflow 分析一下，基本上都可以做到一定的识别率，可以高于 80% 以上。所以现在的网站往往不会使用简单的图片验证码，比如说要拖动一个滑块、选中几张图片、算一道数学题等来增加破解成本。我见过最变态的网站验证码是一道化学题，我花了两个小时才注册成功。 所以你的网站如果还在使用普通的图形验证码，而你网站被攻克的代价也很高的话，请你务必早点更换验证码——更换成更难破解的，甚至多种验证码的混合。 模拟用户动作对于一个爬取数据用的浏览器内核，往往还提供了模拟用户行为的功能。比如说点击按钮，滚动一下页面，输入一行文字。所以千万不要觉得，爬虫模拟不了这些用户行为，对于爬虫的设计者，这些都是基础操作。 数据的提取当数据被下载下来之后，爬虫会尝试将原始数据存储，然后再进行离线分析。当然有的爬虫爬取了数据之后就马上进行分析。如果要爬取网页数据，后续会用到 HTML 的解析器（Parser），这个在 Github上 可以找到很多的开源实现。如果是爬取的接口数据，通常就是分析 Json。有的网页数据是由 JavaScript 渲染的，这种网页，通常爬虫会模拟浏览器的行为，在页面加载完成几秒之后才开始下载网页内容。 反追踪对于黑产的爬虫，还会进行 IP 的反追踪。所谓 IP 的反追踪，就是利用代理，增加追踪的成本。比如黑客在从事犯罪活动时通过多次代理，跨了多个国家，那么一个国家的警方力量就很难追踪到他。在爬虫领域有很多人会购买 IP 代理，比如说一个非法的去 B 站收集统计数据的爬虫，为了防止 B 站的追诉以及防止 B 站安全策略的屏蔽，可能会购买大量的 IP，然后模拟成几百个用户在使用 B 站。你要注意，临时租用大量 IP 地址的价格低廉，这也大大降低了犯罪的成本。 反爬虫接下来，我们说说有关反爬虫的一些基本的操作。 robots.txt在反爬虫的时候，第一步我们要先从法律上告诉爬虫哪些页面是不可以爬取的。所以我们要先写好自己的 robots.txt，并放到网站的根目录。 用户的识别接下来我们对于高频访问的 IP 要予以关注。当然，仅仅通过 IP 来判断是不可取的。因为有的时候一家公司会共用一个 IP 出口地址。举个例子：一家猎头公司下面的几百个猎头，可能会每天疯狂的使用拉勾，因此从拉勾的数据上，你会看到大量的重复 IP 访问。这个时候我问你个问题，你禁不禁用这些 IP？当然不能禁用，这些都是付费用户。 那么这个时候有一件非常值得做的事情，就是使用设备的指纹。对于一个设备，它的 CPU 数量、CPU 序列号、屏幕的分辨率、手机的厂商等，通常是固定的。这样可以结合 IP 地址做精细去重。这项技术被称为设备指纹，就是利用设备上的信息，生成一个具有唯一性的字符串，因为这种生成算法是非标准化的，因此不同的数据安全团队会有自己的算法。 有了对用户的识别，就可以根据唯一用户设置数据安全策略，比如访问频次、黑名单等。 字体加密再介绍一种方法是自己实现字符编码和字体文件，增加爬虫爬取数据的成本。 爬虫爬取的通常就是用户本身可以看到的内容。如果自己实现一套自己的字符编码。比如将 UTF8 编码中的汉字打乱顺序，然后再将字体文件中对应的数据换序，得到字体文件。显示简历的时候，使用自己根据这个字符集生成的字体文件。 这样，爬虫下载到网页数据后，中文会乱码，这是因为爬虫无法理解我们创造的非标准字符集编码。当用户看到网页的时候，可以看到正确的内容，这是因为字体文件起了作用。即便爬虫将字体文件打开，和编码对应上，也是非常复杂的一个体力劳动。然后我们每天更换一次顺序，就可以给黑产增加相当大的爬取成本。 加密传输对于移动端 App 中的数据，如果可以加密传输，也能大大增加爬取成本。因为 App 不是浏览器，想要模拟一个 App 是非常困难的。那么 App 的数据抓取就依赖于 App 数据传输使用的标准协议，比如一个用 HTTPS 协议传输数据的 App，爬虫可以在 App 端安装证书，然后再利用代理实现中间人抓包。但如果数据用自己的协议加密，那么爬虫抓包的同时，还必须能够破解这个加密协议。 总结非法爬取数据是不可能完全杜绝的，我们只能提高非法爬取数据的成本。但是一定要有数据安全的意识。在互联网的世界里，数据是第一生产力，也是生命线。在完成开发工作之余，利用自己的专业知识适当提高爬取数据的成本是非常有必要的。 如果自己被公司要求写一个爬虫爬取竞品数据，请你先阅读下竞品的 robots.txt 文件，看看允不允许你这样做。如果这是一个违法行为，那么也可以适当提醒下有这样想法的决策者。 国家对网络信息安全犯罪的打击，只会越来越严。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"HTTP 协议","slug":"计网/HTTP协议","date":"2021-07-08T09:02:56.000Z","updated":"2021-07-08T02:03:23.189Z","comments":true,"path":"2021/07/08/计网/HTTP协议/","link":"","permalink":"https://www.shanghua.live/2021/07/08/%E8%AE%A1%E7%BD%91/HTTP%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"HTTP 协议1990 年蒂姆·伯纳斯·李开发了第一个浏览器，书写了第一个 Web 服务器程序和第一张网页。网页用的语言后来被称作超文本标记语言（HTML），而在服务器和客户端之间传输网页的时候，伯纳斯·李没有直接使用传输层协议，而是在 TCP 的基础上构造了一个应用层协议，这个就是超文本传输协议 HTTP。 万维网（World Wide Web，WWW）是博纳斯·李这一系列发明，包括 Web 服务、HTTP 协议、HTML 语言等一个体系的综合 请求响应和长连接HTTP 协议采用请求/返回模型。客户端（通常是浏览器）发起 HTTP 请求，然后 Web 服务端收到请求后将数据回传。 HTTP 的请求和响应都是文本，你可以简单认为 HTTP 协议利用 TCP 协议传输文本。当用户想要看一张网页的时候，就发送一个文本请求到 Web 服务器，Web 服务器解析了这段文本，然后给浏览器将网页回传。 Web 服务器内部就设置一个定时器。在一定范围的时间内，如果客户端继续发送请求，那么服务器就会重置定时器。如果在一定范围的时间内，服务器没有收到请求，就会将连接断开。这样既防止浪费握手、挥手的资源，同时又避免一个连接占用时间过长无法回收导致内存使用效率下降。 我们可以利用 HTTP 协议头进行配置，列如 Keep-Alive: timeout=5s 会告诉 Web 服务器连接的持续时间是 5s，如果 5s 内没有请求，那么连接就会断开 在最初版本是并没有 Keep-Alive 的，随着版本升级，在 HTTP 1.1 才最终支持 Keep-Alive HTTP 2.0 多路复用当一个网站需要加载的资源较多时，浏览器会尝试并发发送请求（利用多线程技术），浏览器会限制同时发送并发请求的数量，通常是 6 个，这样做一方面是对用户本地体验的一种保护，防止浏览器抢占太多网络资源，另一方面也是对站点服务的保护，防止瞬时流量过大 在 HTTP 2.0 之后，增加了多路复用能力。与 RPC 多路复用类似，请求、返回会被拆分成切片，然后混合传输。这样请求、返回之间就不会阻塞。在 HTTP 1.1 的 Keep-Alive 设计中，第二个请求，必须等待第一个请求返回。如果第一个请求阻塞了，那么后续所有的请求都会阻塞。而 HTTP 2.0 的多路复用，将请求返回都切分成小片，这样利用同一个连接，请求相当于并行的发出，互相之间不会有干扰。 HTTP 方法和 RestFul 架构RestFul 是三个单词的缩写 re（Representational）、St（State）、Ful（Transfer） 在 RestFul 架构中，状态仅仅存在于服务端，前端无状态。状态（State）可以理解为业务的状态，这个状态是由服务端管理的。这个无状态和服务端目前倡导的无状态设计不冲突，现在服务端倡导的无状态设计指的是容器内的服务没有状态，状态全部存到合适的存储中去。所以 Restful 中的 State，是服务端状态。 HTTP 方法在 Restful 架构中，除了约定了上述整体架构方案之外，还约束了一些实现细节，比如用名词性的接口和 HTTP 方法来设计服务端提供的接口。 我们使用 GET 获取数据，或者进行查询,如下代码的作用就是获取订单为 123 的订单数据 1GET /order/123 GET 是 HTTP 方法，/order 是一种名词性质的命名，这样设计语义非常清晰，这个接口是获取订单的数据，也就是订单的 Representation 用的 对于更新数据的场景，可以使用 PUT 方法，根据 HTTP 协议规定，PUT 是一种幂等的更新行为，POST 是一种非幂等的更新行为。 12PUT /order/123 &#123;...订单数据&#125; 上面使用 PUT 更新订单，如果订单 123 还没有创建，那么这个接口就会创建订单。如果 123 已经存在，那么这个接口会更新订单 123 的数据，因为 PUT 代表幂等，对于一个幂等的接口，请求多少遍最终的状态是一致的，也就是说操作的都是同一笔订单 如果换成 POST 更新订单： 12POST /order&#123;...订单数据&#125; POST 代表非幂等的设计，像上面这种用 POST 提交表单的接口，调用多次往往会产生多个订单。也就是非幂等的设计每次调用结束后都会产生新的状态。 另外在 HTTP 协议中，还约定了 DELETE 方法用于删除数据。其实还有几个方法，请大家自行查找相关资料，比如 OPTIONS PATCH 缓存在 HTTP 的使用中，我们经常会遇到两种缓存，强制缓存和协商缓存，接下来我举两个场景来说明。 强制缓存你的公司用版本号管理某个对外提供的 JS 文件。比如说 libgo.1.2.3.js，就是 libgo 的 1.2.3 版本。其中 1 是主版本，2 是副版本，3 是补丁编号。每次你们有任何改动，都会更新 libgo 版本号。在这种情况下，当浏览器请求了一次 libgo.1.2.3.js 文件之后，还需要再请求一次吗？ 整理下我们的需求，浏览器在第一次进行了GET /libgo.1.2.3.js这个操作后，如果后续某个网页还用到了这个文件（libgo.1.2.3.js），我们不再发送第二次请求。这个方案要求浏览器将文件缓存到本地，并且设置这个文件的失效时间（或者永久有效）。这种请求过一次不需要再次发送请求的缓存模式，在 HTTP 协议中称为强制缓存。当一个文件被强制缓存后，下一次请求会直接使用本地版本，而不会真的发出去。 使用强制缓存时要注意，千万别把需要动态更新的数据强制缓存。一个负面例子就是小明把获取用户信息数据的接口设置为强制缓存，导致用户更新了自己的信息后，一直要等到强制缓存失效才能看到这次更新。 协商缓存我们再说一个场景：小明开发了一个接口，这个接口提供全国省市区的 3 级信息。先问你一个问题，这个场景可以用强制缓存吗？小明一开始觉得强制缓存可以，然后突然有一天接到运营的通知，某市下属的两个县合并了，需要调整接口数据。小明错手不急，更新了接口数据，但是数据要等到强制缓存失效。 为了应对这种场景，HTTP 协议还设计了协商缓存。协商缓存启用后，第一次获取接口数据，会将数据缓存到本地，并存储下数据的摘要。第二次请求时，浏览器检查到本地有缓存，将摘要发送给服务端。服务端会检查服务端数据的摘要和浏览器发送来的是否一致。如果不一致，说明服务端数据发生了更新，服务端会回传全部数据。如果一致，说明数据没有更新，服务端不需要回传数据。 从这个角度看，协商缓存的方式节省了流量。对于小明开发的这个接口，多数情况下协商缓存会生效。当小明更新了数据后，协商缓存失效，客户端数据可以马上更新。 和强制缓存相比，协商缓存的代价是需要多发一次请求。 总结目前 HTTP 协议已经发展到 2.0 版本，不少网站都更新到 HTTP 2.0 大部分浏览器、CDN 也支持 HTTP 2.0 HTTP 3.0 也在建设当中，HTTP 3.0 对 HTTP 2.0 兼容，主要调整发生在网络底层","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"CDN 内容分发网络","slug":"计网/CDN内容分发网络","date":"2021-07-06T10:36:01.000Z","updated":"2021-07-08T01:01:18.022Z","comments":true,"path":"2021/07/06/计网/CDN内容分发网络/","link":"","permalink":"https://www.shanghua.live/2021/07/06/%E8%AE%A1%E7%BD%91/CDN%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91%E7%BD%91%E7%BB%9C/","excerpt":"","text":"今天使用的电商、直播、社交工具、视频网站中都含有大量的图片、视频、文档等，这些资源需要分发给用户。对于一些体量较大的应用来说，如果把大量资源集中到单一节点进行分发，恐怕很难有某个机房可以支撑得住这么大的流量。例如一个日活在 100W 的小型互联网产品，如果每次请求需要 1M 的数据，那就刚好是近 1TB 数据。对于这样的数据规模而言，完全由单一节点进行分发是不现实的。因此现在互联网应用在分发内容的时候，并不是从自己架设的服务器上直分发内容，而是走一个叫作内容分发网络（Content Dilivery Network）的互联网底层建设。 CDN 是什么内容分发网络（Content Dilivery Network，CDN） 一个专门分发内容的分布式应用，CDN 构建在现有的互联网之上，通过在各地部署数据中心，让不同地域的用户可以就近获取内容这里的内容指的就是 文件、图片、视频、声音、应用程序安装包 为什么不能提供这些资源呢？这和域名系统的 DNS 记录不能集中提供是一个道理，需要考虑到流量、单点故障、延迟等因素。在离用户更近的地理位置提供资源，可以减少延迟。按照地理位置分散提供资源，也可以降低中心化带来的服务压力 因此，CDN 的服务商会选择在全球布点，或者在某个国家布点。具体要看 CDN 服务提供商的服务范围。目前国内的阿里云、腾讯云等也在提供 CDN 业务。 内容的分发 当一个用户请求一个网络资源时，用户请求的是 CDN 提供的资源 当用户请求一个资源时，首先会接触到一个类似域名系统中目录的服务，这个服务会告诉用户究竟去哪个 IP 获取这个资源 很多大型的应用，会吧 DNS 解析作为一种负载均衡的手段 当一个用户请求一个一个网址的时候，会从该网络提供的智能 DNS 中获取网站的 IP。具体请求哪个 IP，是由智能 DNS 中的服务决定的。域名系统允许网站自己为自己的产品提供 DNS 解析，可以参考 DNS 域名解析系统 介绍的 NS 记录 当用户请求一个静态资源的时候，首先会触发域名系统的解析。域名系统会将解析的责任交由 CDN 提供商来处理，CDN 的智能 DNS 服务会帮助用户选择离自己距离最近的节点，返回这个节点的 A（或 AAAA）记录。然后客户端会向 CDN 的资源节点发起请求，最终获得资源。 在上面整个过程当中，CDN 的智能 DNS 还充当了负载均衡的作用。如果一个节点压力过大，则可以将流量导向其他的节点。 回溯CDN 主要用途是提供分发静态资源，那么静态资源提供者如何将资源提供到 CDN 呢？手动上传、接口推送，还是其他别的方式呢？ 你可以把 CDN 想象成一个分布式的分级缓存，再加上数据库的两层设计，用户请求先到达缓存层，如果缓存被穿透，才到达最终的存储层。缓存的设计是分布式的，因为绝大多数的资源使用都会发生在缓存上，只有极少数的请求才会穿透到底层的存储，通常这种设计缓存至少需要挡住 99% 的流量，那么实际的数据存储可以交由源站点完成 单一数据源（Single Souce of Truth，SSOT）在程序设计中，应该尽可能的去减少数据的来源，最好每个数据来源都只有单独一份这样能够避免大量的数据不一致以及同步数据的问题。基于这样的设计，谁来提供资源的存储呢？如果 CDN 提供一份资源的存储不就有两个数据源了吗? 而且只有服务的提供者才能更好的维护这个资源仓库。 在 CDN 的设计当中，CDN 实际上提供的是数据的缓存。而原始数据，则由服务的提供者提供。举个例子，当用户请求某个拉勾网站的静态图片，实际上如果你是要 DIG 命令查看这个网址，会看到如下图所示的结果列如 dig www.lgstatic.com ，就可以看到下面的结果 12345678910111213141516171819202122$ dig www.lgstatic.com ; &lt;&lt;&gt;&gt; DiG 9.16.1-Ubuntu &lt;&lt;&gt;&gt; www.lgstatic.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 59409;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 65494;; QUESTION SECTION:;www.lgstatic.com. IN A;; ANSWER SECTION:www.lgstatic.com. 20 IN CNAME www.lgstatic.com.wswebpic.com.www.lgstatic.com.wswebpic.com. 30 IN A 111.7.109.98www.lgstatic.com.wswebpic.com. 30 IN A 111.7.109.87;; Query time: 32 msec;; SERVER: 127.0.0.53#53(127.0.0.53);; WHEN: 三 7月 07 17:24:28 CST 2021;; MSG SIZE rcvd: 117 上面的结果中，拉勾网的静态资源域名 www.lgstatic.com 被 CNAME 到了 www.lgstatic.com.wswebpic.com. 说明当用户请求 www.lgstatic.com 的资源时，实例请求的是 CDN 服务提供商的域名。当用户向 CDN 请求资源的时候，CDN 的智能 DNS 服务就会帮助用户选最优的节点（比如地理上最临近，或者当前比较空闲的）。如果 CDN 节点资源已经存在了用户请求的资源，那么直接返回资源给用户。如果 CDN 中尚未缓存这个资源，此时 CDN 节点就会向拉勾请求资源。也就是说，拉勾网需要有所有的原始数据，并提供出来可以让 CDN 服务访问。 如下图所示，整个过程是 4 个层级。用户请求静态资源通常用自己的域名（防止跨域和一些安全问题）。为了让用户请求的是自己的网站，而使用的是 CDN 的服务，这里会使用 CNAME 让自己的域名作为 CDN 域名的一个别名。当请求到 CDN 服务的时候，会首先由 CDN 的 DNS 服务帮助用户选择一个最优的节点，这个 DNS 服务还充当了负载均衡的作用。接下来，用户开始向 CDN 节点请求资源。如果这个时候资源已经过期或者还没有在 CDN 节点上，就会从源站读取数据，这个步骤称为回溯 flowchart LR A[请求拉勾的图片] --通常伴随 CNAME--&gt; B[CDN 的 DNS 服务] B --负载均衡--&gt; C[CDN 资源节点] C --回溯--&gt; 拉勾服务器 CDN 上缓存的资源通常也会伴随失效时间的设置，当失效之后同样会触发回源，可以通过开发 API 或者 CDN 管理后台直接删除缓存（让资源失效），这个操作后，同样会触发回源 总结CDN 是一种网络应用，作用是分发互联网上的资源。CDN 服务的提供商，会在世界（或国家）范围内设立数据中心，帮助分发资源。用户请求的资源会被 CDN 分发到最临近的节点获取。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"DNS 域名解析系统","slug":"计网/DNS域名解析系统","date":"2021-07-04T17:31:49.000Z","updated":"2021-07-04T11:45:16.776Z","comments":true,"path":"2021/07/05/计网/DNS域名解析系统/","link":"","permalink":"https://www.shanghua.live/2021/07/05/%E8%AE%A1%E7%BD%91/DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"DNS 域名解析系统DNS 和统一资源定位服 (URL) 域名系统本质是定位资源 这是一个完整的 URL（Uniform Resource Locator） https://www.example.com:8080/books?id=1000#Good https:// 对应 Scheme：协议，Scheme 有 https、ftp、ssh 等 www.example.com 对应 Host Host 代表站点 8080 对应 端口，代表提供服务的应用 /books 对应 Path，代表资源在服务中的路径 id=1000 对应 Query，查询条件，代表需要的是资源中的某一个部分 #Good 对应 Fragment 代表 二级查询条件，通常不在服务端响应，而是用于前端展示定位内容 统一资源定位符 URL（Uniform Resource Locator）,这样我们就可以通过一个字符串定位互联网资源总的来说，URL 是一种树状的设计， Host 代表主机（对应的 IP 地址由 DNS 服务提供）；Port 代表应用；Path 代表资源在应用中的路径；Query 代表对资源的查询条件。通过这种设计，互联网中万亿级别的资源都可以得到有效区分。 在计算机中，树状结构在计算机中非常常见，比如目录的设计，源代码块的嵌套设计 JSON 和 XML 的设计，都是树桩关系这源于人类的思考方式天然地喜欢把事物放到互斥的分类当中。 不过需要注意的是，树状的分类解决不了一个东西在多个类别的情况，而这种情况在多数时候却是真实存在的。真实世界中事物是普遍联系的，所以本质上事物之间的联系应该是图。但是通常情况下，我们会用树处理某一个方面的诉求。比如用 URL 描述资源的位置，然后用搜索引擎通过关键字反查 URL（另一个方面，维度等）。 域名系统DNS（Domain Name System，域名系统） 一个域名和 IP 地址相互映射的分布式服务，比如你想访问 shangghua.live 的 IP 地址，就需要通过 DNS 服务获得，这样凡是访问本博客的用户，就不需要在浏览器中输入博客的 IP 地址，而是通过一个方便人们记忆的域名 根域名服务器DNS 本身是一个出色的分布式架构 位于最顶层的是根域名服务器（Root Name Server）。人们在全世界范围内搭建了多台根域名服务器，2016 年的统计数据中，全世界目前有 13 台 IPv4 根服务器，25 台 IPv6 根服务器。 根域名服务器存储的不是域名和 IP 的映射关系，而是一个目录，如果将所有的域名记录都存放到根域名服务器，从存储量上来说，不会非常巨大但是如果全世界所有的 DNS 请求都集中到少量的根服务器上，这个访问流量就会过于巨大，。而且一旦发生故障，很容易导致大面积瘫痪。而且因为根服务器较少，所以如果全部都走根服务器，不同客户端距离根服务器距离不同，感受到的延迟也不一样，这样对用户来说不太友好。 因此，因为流量、防止单点故障、平衡地理分布等问题，根域名服务器只是一个目录，并不提供具体的数据。 域名分级和数据分区根服务器提供的目录有一定的索引规则，在域名的世界中，通过分级域名的策略建立索引我们知道中文字典可以按照偏旁部首以及拼音索引，和字典类似，根服务器提供的目录也有一定的索引规则 平时我们看到的.com.cn.net等，称为顶级域名。比如对于 www.shanghua.live 这个网址来说，com是顶级域名，shanghua是二级域名，www是三级域名。域名分级当然是为了建立目录和索引，并对数据存储进行分区。 graph TD A[根 DNS 服务器] --&gt; B[com DNS 服务器] B --&gt; baidu B --&gt; taobao A --&gt; C[net DNS 服务器] A --&gt; D[org DNS 服务] A --&gt; E[...] 顶部第一级是根 DNS 存储，存储的是顶级域的目录，被称作根 DNS 服务器 第二级是顶级域存储，存储的是二级域的目录，被称作顶级域 DNS 服务器（Top Level DNS，TLD） 最后一级是叶子节点，存储的是具体的 DNS 记录，也被称作权威 DNS 服务器。 DNS 查询过程 用户自己的路由器中的 DNS 缓存 小区的 DNS 服务器 ISP 的 DNS 服务器 graph TD A[请求 www.shanghua.live] --1--&gt; B[本地 DNS 服务器] B --2--&gt; C[根 DNS 服务器] C --3--&gt; B B --4--&gt; D[TLS DNS 服务器] D --5--&gt; B B --6--&gt; E[权威 DNS 服务器] E --7--&gt; B B --8--&gt; A 本地 DNS 是一系列 DNS 的合集，比如 ISP 提供的 DNS、公司网络提供的 DNS 本地 DNS 是一个代理，将 DNS 请求转发到 DNS 网络中 如果本地 DNS 缓存中找到了对应的 DNS 条目，就会直接返回，而跳过之后的步骤 客户端根据请求根 DNS 服务器。如果本地 DNS 中没有对应的记录，那么请求就会被转发到根 DNS 服务器，根 DNS 服务器只解析顶级域名,也就是 com 的部分 根 DNS 服务器返回顶级 DNS 服务器的 IP。 客户端请求顶级 DNS 服务器，顶级 DNS 服务器中是具体域名的目录。 顶级 DNS 服务器返回权威 DNS 服务器的 IP。 客户端请求权威 DNS 服务器。在权威 DNS 服务器上存有具体的 DNS 记录。以 lagou 为例，权威 DNS 服务器中可能有和 lagou.com 相关的上百条甚至更多的 DNS 记录，会根据不同的 DNS 查询条件返回 权威 DNS 服务器返回 DNS 记录到本地 DNS 服务器。 本地 DNS 服务器返回具体的 DNS 记录给客户端。 在上述 8 个过程全部结束后，客户端通过 DNS 记录中的 IP 地址，可以找到请求服务的主机。从而获得 Web 服务。浏览器会缓存 DNS，操作系统、路由器、本地 DNS 服务器也会绝大数情况，请求不会到达 DNS 服务器 关于缓存如果在某个时刻同一区域内有一个用户触发过上述 1 ~ 8 的过程，另一个同区域的用户就可以在本地 DNS 服务器中获得 DNS 记录，而不需要再走到根 DNS 服务器这种设计我们称之为 分级缓存策略在分级缓存策略中，每一层都会进行缓存，经过一层层的缓存，最终命中根 DNS 服务、顶级 DNS 服务器以及权威 DNS 服务的请求少之又少 DNS 记录一个 DNS 记录具体的样子 1www.example.com. IN A 16.162.59.31; IN 代表记录用于互联网，是 Intenet 的缩写 www.example.com 代表要解析的域名 A 代表记录的类型,代表这是一条解析 IPv4 的记录 16.162.59.31 是记录的值 ; 分号是语句块的结尾，也是注释 除了 A 记录，DNS 记录的类型非常多，有 30 多种，其中比较常见的有 A、AAAA、CNAME、MX，以及 NS 等 CNAMECNAME (CANONICAL Name Record) 用于定义域名的别名 1a.example.com. IN CNAME b.example.com; 这条 DNS 记录定义了 a.example.com 是 b.example.com 的别名，在浏览器中输入 a.example.com 后浏览器就能查找 a.example.com 为 b.example.com 的别名，就回去查找 b.example.com 的 A 记录 这样用户如果在浏览器输入 a.example.com 实际打开的就是 b.example.com。因为走的是 DNS 查询的路径，速度更快（因为有缓存）不需要 HTTP 重定向等操作 当你想把一个网站迁移到新的域名，旧的域名仍然保留的时候 当你想将自己的静态资源放到 CDN 上的时候，CNAME 就非常有用 AAAA 记录AAAA 记录与 A 记录类似，不过 A 记录记录的是 域名与 IPv4 的关系，AAAA 记录是 域名与 IPv6 的关系 MX 记录MX 记录是邮件记录，用来描述邮件服务器的域名。在工作中，我们经常会发邮件到某个同事的邮箱。比如说，发送一封邮件到 &#x78;&#x69;&#97;&#111;&#109;&#x69;&#110;&#x67;&#64;&#x73;&#104;&#x61;&#x6e;&#103;&#104;&#117;&#97;&#x2e;&#108;&#105;&#x76;&#x65;，那么如何知道哪个 IP 地址是邮件服务器呢？这时候就可以添加一条 MX 记录 1IN MX mail.shanghua.live 这样凡是 @shanghua 的邮件都会发送到 mail.shanghua.live 中，而 mail.shanghua.live 的 IP 地址，可以通过 mail.shanghua.live 的 A 记录 和 AAAA 记录获得 NS 记录NS（Name Server）记录是描述 DNS 服务器网址从 DNS 的存储结构上，Name Server 中含有权威 DNS 服务的目录NS 记录指定哪台 Server 是回答 DNS 查询的权威服务器，当一个 DNS 查询看到 NS 记录的时候，会再去 NS 记录配置的 DNS 服务器查询，得到最终结果 12a.com. IN NS ns1.a.coma.com. IN NS ns2.a.com 当解析 a.com 地址时，我们看到 a.com 有两个 NS 记录，所以确定最终 a.com 的记录在 ns1.a.com 和 ns2.a.com 上。从设计上看，ns1 和 ns2 是网站 a.com 提供的智能 DNS 服务器，可以提供负载均衡、分布式 Sharding 等服务。比如当一个北京的用户想要访问 a.com 的时候，ns1 看到这是一个北京的 IP 就返回一个离北京最近的机房 IP。 上面代码中 a.com 配置了两个 NS 记录。通常 NS 不会只有一个，这是为了保证高可用，一个挂了另一个还能继续服务。通常数字小的 NS 记录优先级更高，也就是 ns1 会优先于 ns2 响应。 配置了上面的 NS 记录后，如果还配置了 a.com 的 A 记录，那么这个 A 记录会被 NS 记录覆盖。 总结CNAME 记录的作用是？ CNAME 是一种 DNS 记录，作用是将一个域名映射到另一个域名，域名解析的时候，如果看到 CNAME 记录，则会从映射目标重新开始查询","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"RPC 框架","slug":"计网/RPC框架","date":"2021-07-03T10:42:57.000Z","updated":"2021-07-04T12:27:24.053Z","comments":true,"path":"2021/07/03/计网/RPC框架/","link":"","permalink":"https://www.shanghua.live/2021/07/03/%E8%AE%A1%E7%BD%91/RPC%E6%A1%86%E6%9E%B6/","excerpt":"","text":"RPCRPC（Remote Procedure Call）远程过程调用 在远程必选先定义这个方法，然后才可以通过 RPC 框架调用该方法，远程调用不仅可以传入参数、获取到返回值还可以捕捉调用过程中的异常 RPC 让远程调用就像本地调用一样 假设实现一个 rpc 对象，其中的 invode 方法可以实现远程调用 1var result = rpc.invode(&quot;greetings&quot;,arg1,arg2...) 这段程序将本地看作 一个 RPC 的客户端，将远程看作一个 RPC 的服务端。如下图所示： flowchart RL B[服务 B] --返回--&gt; D[RPC 服务端] D --本地方法调用--&gt; B A[服务 A] --远程方法调用--&gt; C[RPC 客户端] C --返回--&gt; A D &lt;--TCP&#x2F;UDP&#x2F;HTTP--&gt; C 服务 A 发起远程方法调用，RPC 客户端通过某种协议将请求发送给服务 B服务 B 解析请求，进行本地方法的调用，将结果返回到服务 B 的 RPC 服务端最终返回到服务 A。如果程序员没有意识到这是一次远程方法调用，就可能写出下面这段程序 123for(int i = 0;i &lt; 1000000;i++)&#123; rpc.invoke(...)&#125; 之所以可能写出，是因为你（程序员）没有意识到 rpc.invoke 是一次远程调用。在实际的操作过程中，rpc.invoke 可能被封装到某个业务方法中，程序员调用的时候便容易忽视这是一次远程操作。所以 RPC 调用时就要求你（程序员）对性能有清晰的认识 多路复用的优化RPC 提供的是远程方法的调用 本质上是数据的传递，传递数据有一个最基本的问题要处理，就是提高吞吐量 (单位时间传递的数据量)如果为每个远程调用（请求）建立一个连接，就会造成资源的浪费，因此通常我们会考虑多个请求复用一个连接叫做多路复用 在具体实现多路复用的时候，也会有不同的策略。假设要发送数据 A、B、C、D，那么一种方法是建立一个连接依次将 A、B、C、D 发过去，就像下面这样 —&gt; | &nbsp; A &nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 子这种结构中，利用一个连接顺序发送 A、B、C、D 将多个请求放入一个连接的方式，节省了多次握手、挥手的时间，但是由于 ABCD 不是并行发送，而是顺序发送，当其中某个请求的体积较大时，容易阻塞其他请求，如下 —&gt; | &nbsp;&nbsp;&nbsp;&nbsp; A &nbsp;&nbsp;&nbsp;&nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 在 A 较大的时候，B，C，D 就只能等 A 完全传送完成才能发生传送。这样模型对于 RPC 请求/响应大小不平均的网络不太友好体积小的请求/响应可能会因为一些大体积的请求/响应而延迟因此还有另一种常见的多路复用方案，就是将 A、B、C、D 切片一起传输，如下 顺序传输方案 —&gt; | &nbsp;&nbsp;&nbsp;&nbsp; A &nbsp;&nbsp;&nbsp;&nbsp; | &nbsp; B &nbsp; | &nbsp; C &nbsp; | &nbsp; D &nbsp; | —&gt; 上图中，用不同的块,代表不同的传输任务。采用顺序传输方案将 A、B、C、D 用一个连接传输节省了握手，挥手成本。切片传输的方案在这之上，将数据切片可以保证大、小任务并行，不会因为大任务阻塞小任务 另外还有一个需要考虑的点，单个 TCP 连接的极限传输速度是受到窗口大小，缓冲区等因素的制约，不一定可以用满网络资源。如果传输量特别大的时候，有可能需要考虑提供多个连接，每个连接再去考虑多路复用的情况 调用约定和命名远程调用一个函数 命名空间 + 类名 + 方法名 比如调用一个支付服务对象 Payservice 的 pay 方法 命名空间（trade.payment） 对象名称是（PayServer） 方法名称是（Pay） 例如用 ＃ 分割: trade.payment#PayService#Pay 在进行远程调用的时候，给远程方法命名是调用约定的一部分，通过调用命名下完整的名称调用远getName程方法 常用的做法是先不具体指定调用的方法，而是先创建一个远程对象的实例，比如上方 PayService 对象的实例这里会用到一些特别的编程技巧，比如代理设计模式、动态接口生成等。 不过归根结底，我们调用的本质就是字符串名称。而实现这个调用，你需要知道两件事情 IP 是多少，也就是方法在哪个机器上调用 端口是多少，也就是哪个服务提供这个调用 注册和发现调用的时候我们需要通过 字符串 获取 IP和端口（机器和服务 ） 在网络的时间中，需要的只是网络接口和 IP 地址，而操作系统区分应用需要的是端口在调用过程中，需要的是注册表，存储了字符串和 IP + 端口的对应关系我们可以使用 Redis 的 hash 对象存储这个对应关系 当我们上线一个服务的时候，就在 Redis 的某个 hash 对象中存储它和它对应的 IP 地址 + 端口列表通常，将写这个 hash 对象的过程称之为注册我们远程调用一个 RPC 服务的时候，调用端提供的是 RPC 服务的名称（例如：命名空间+对象+方法）根据名称查找到提供服务的 IP + 端口清单并指定某个 IP + 端口的过程称作为发现 但是并不能简单的这样理解为，注册就是写一个 Hash 表，发现就是查哈希表再决定服务的响应者在实际的设计中，需要考虑很多东西，例如基于 Redis 的实现如果所有 ROC 调用都需要去 Redis 查询，会造成负责发现的中间件压力较大RPC 调用者会缓存上一次调用的 IP + 端口，但是缓存又会造成数据会和注册表之间产生数据不一致的问题可以考虑由分布式共识服务比如 Zookeeper 提供订阅，让 RPC 调用者订阅到服务地址的变更，及时更新自己的缓存 负载均衡的设计在设计 RPC 框架的时候，负载均衡的设计往往需要和 RPC 框架一起考虑，因为 RPC 框架提供了注册、发现的能力，提供发现能力的模块本省就是一个负载均衡器，因此负载均衡可以看作发现模块的一个子组件。请求到达 RPC 的网关（或某个路由程序）后，发现组件会提供服务对应的所有实例（IP + 端口），然后负载均衡算法会指定其中一个响应这个请求。 可用性和容灾 当一个服务实例崩溃的时候（不可用），因为有发现模块的存在，可以及时从注册表中删除这个服务实例，只要服务本身有足够度的实例那么完全不可用的风险会大大降低，当然，可用性 百分之百 是不可能实现的。 注册表和 RPC 调用者之间必然存在不一致的现象，而且注册表的更新本身也可能滞后 如果遇到临时访问量剧增，需要扩容的场景，可以自动启动服务注册即可，这块可以用自动化脚本衔接。 总结设计一个 RPC 框架最基础的能力就是实现远程方法的调用。这里需要一个调用约定，比如怎么描述一个远程的方法，发送端怎么传递参数接收方如何解析参数，发生异常如何处理，具体来说，这些事情都不难实现，只是比较烦琐。其实不仅仅在 RPC 调用时有调用约定，编译器在实现函数调用的时候，也会有调用约定。另外，还有一些在 RPC 基础上建立起来的更复杂、更体系化的约定，比如说面向服务架构（SOA）。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"BIO、NIO 和 AIO","slug":"计网/网络IO模型","date":"2021-07-01T16:43:55.000Z","updated":"2021-07-01T09:56:19.019Z","comments":true,"path":"2021/07/02/计网/网络IO模型/","link":"","permalink":"https://www.shanghua.live/2021/07/02/%E8%AE%A1%E7%BD%91/%E7%BD%91%E7%BB%9CIO%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"BIO、NIO 和 AIO 有什么区别？从本质来说，讨论 BIO、NIO、AIO 的区别，就是讨论 I/O 的模型，我们可以从三个方面思考 变成模型：合理设计 API，让程序写得更舒服 数据的传输和转化成本：比如减少数据拷贝次数，合理压缩数据等。 高效的数据结构：利用好缓冲区、红黑树等 I/O 编程模型BIOBIO（Blocking I/O，阻塞I/O），API 的设计会阻塞程序调用 12// 程序会在这个地方阻塞，直到收到数据byte a = readKey() 假设 readKey 方法会从键盘中读取一个用户的按键，如果是阻塞 I/O 的设计，readKey 会阻塞当前用户线程直到用户按键阻塞态的线程如果要恢复执行，就要进行排队，也就是线程的上下文切换（Context Switch）：从一个线程切换到另一个线程 NIONIO （None Blocking I/O 非阻塞 IO），API 的设计不会阻塞程序的调用 1byte a = readKey() 假设 readKey 方法从键盘读取一个按键，如果是非阻塞 I/O 的设计，readKey 不会阻塞当前的线程，哪如果没有按键会怎么办， 在阻塞 I/O 的设计中，如果用户没有按键线程会阻塞等待用户按键 在非阻塞 I/O 的设计中，线程不会阻塞，没有按键会返回一个空值 AIOAIO（Asynchronous I/O,异步 I/O），API 的设计会多创造一条时间线 1234function callBackFuntion(byte keyCode)&#123; // 处理按键&#125;readKey(callBackFuntion) 在异步 I/O 中，readKey 方法会直接返回，但是没有结果，结果需要回调一个函数callBackFunction 去接受异步：时间线上无法同步的现象，不知道 callbackFunction 何时会执行 但是 异步 I/O 会产生回调地狱的问题，本质来说是因为 异步程序的时间线错乱导致维护成本较高，如下 123456789request(&quot;/order/123&quot;, (data1) -&gt; &#123; //.. request(&quot;/product/456&quot;, (data2) -&gt; &#123; // .. request(&quot;/sku/789&quot;, (data3) -&gt; &#123; //... &#125;) &#125;)&#125;) 一般情况我们会提供一种异步转换为同步程序的语法。如下 12345678Future future1 = request(&quot;/order/123&quot;)Future future2 = request(&quot;/product/456&quot;)Future future3 = request(&quot;/sku/789&quot;)// ...// ...order = future1.get()product = future2.get()sku = future3.get() request 函数是一次网络请求调用，请求订单 ID=123 的订单数据。本身 request 函数不会阻塞，会马上执行完成，而网络是一次异步请求，调用不会在 request(“/order/123”) 下一行结束，而是会在未来某个时间结束，因此我们用一个 Future对象封装这个异步操作，future.get() 是一个阻塞操作，会阻塞直到网络调用返回 在 request 和 future.get 之间，我们还可以进行别的操作，比如发送更多的请求，Future 这样能够将异步操作再同步主时间线的操作，我们称之为异步转同步，也叫做异步编程，通常一门语言如果能提供异步编程的能力，指的就是提供异步转同步的能力同步程序看起来更直观，并且更好维护 数据的传输和转化成本无论是那种 I/O 模型都要从数据从网卡拷贝到用户程序（接收），或者将数据从用户程序传输到网卡（发送） 有的数据需要编码解码，比如 JSON 格式的数据 有的数据需要进行压缩和解码 graph LR A[网卡] --&gt; B[内核] B --&gt; C[用户程序] 数据到网卡到内核到用户程序是两次传输。将数据从内存中的一个区域拷贝到另一个区域。这是一个 CPU 密集型操作数据的拷贝归根结底需要一个字节一个字节去做 从网卡到内核空间的这步操作，可以用 DMA （Direct Memory Access）技术控制。DMA 是一种小型设备，用 DMA 拷贝数据可以不使用 CPU，从而节省计算资源。通常我们写程序的时候，不能直接控制 DMA，因此 DMA 仅仅用于设备传输数据到内存中。不过，从内核到用户空间这次拷贝，可以用内存映射技术，将内核空间的数据映射到用户空间。 无论 I/O 的编程模型如何选择，数据传输和转化成本是逃不掉的，通过 DMA 技术和内存映射技术，就可以节省成本减少数据传输、数据压缩解压、数据编码解码 总结BIO、NIO 和 AIO 有什么区别？ 这三者是三个 I/O 的编程模型 BIO 接口设计会直接导致当前线程阻塞 NIO 的设计不会触发当前线程的阻塞 AIO 为 I/O 提供了异步能力；将 I/O 的响应程序放到一个独立的时间线去执行 通常 AIO 的提供者会提供异步编程模型，就是实现一种对异步计算封装的数据结构，并且提供将数据计算同步会主线的能力 这三种 API 都会伴随 I/O 多路复用 如果底层用红黑树管理注册的文件描述服和事件，可以在很小的开销内由内核将 I/O 消息发送给指定的线程","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"缓冲区 flip","slug":"计网/缓冲区flip","date":"2021-07-01T13:03:27.000Z","updated":"2021-07-01T08:42:23.061Z","comments":true,"path":"2021/07/01/计网/缓冲区flip/","link":"","permalink":"https://www.shanghua.live/2021/07/01/%E8%AE%A1%E7%BD%91/%E7%BC%93%E5%86%B2%E5%8C%BAflip/","excerpt":"","text":"缓冲区的 flip在计算机中，数据往往会被抽象陈流，然后传输。比如读取一个文件，数据会被抽象成文件流；播放一个视频，视频被抽象成视频流，处理节点为了防止过载，又会使用缓冲区削峰（减少瞬间压力）在传输协议中，应用往往先把数据放入缓冲区，然后再将缓冲区通过给发送数据的程序，发送数据的程序从缓冲区读取数据，然后进行发送。 流代表数据，具体来说是随着时间产生的数据，类比自然界的河流读取文件的时候，文件被抽象成流流的内部构造，决定了你每次能从文件中读取多少数据，从流中读取数据的操作，本质上是一种迭代器流的内部构造决定了迭代器每次能读取的数据规模 为什么需要缓冲区因为从文件读取数据这个操作，是一次磁盘的 I/O 操作，非常耗时。内核从文件系统读取到的数据是确定的，但里面的有效数据是不确定的。而无论读取打一个字节还是读取对个字节，都应该适配内核的底层行为，也就是说，每次流对象读取一个字节，内核可能会读取 2k、4k 的数据。这样的行为才能真的做到减少磁盘I/O 操作 哪为什么不直接读取几兆或者更大的数据呢？ 两个原因 如果是高并发场景下，并发读取数据时内存使用是根据并发数翻倍的，如果同时读取的数据量过大，可能会导致内存不足 读取 2k/4k 大很多倍的数据，比如 1M/2M 这种远远大于内存分页大小的数据，并不能提升性能 缓冲区缓冲区就是一块用来做缓冲的内存区域，为了应对频繁的字节读取，我们在内存中设置一个 2k 大小的缓冲区。这样读取 2048 次才会真正发生一次读取。 不仅仅如此，比如做一个秒杀系统，如果同时到达的流量过高，也可以使用缓冲区将用户请求先存储下来，再进行处理这个操作我们称之为削锋，削去流量的峰值缓冲区的数据通常具有朴素的公平，先进先出（FIFO）。从数据结构的设计上，缓冲区像一个队列。在实际的使用场景中缓冲区有自己的特别的需求 graph LR A[文件流] --&gt; B[缓冲区] B --&gt; C[网络流] 缓冲区需要支持两种操作： 写入数据 读取数据 清空（应对下一次请求） 那么具体怎么设计这个缓冲区？首先，数据可以考虑存放到一个数组中， 1| | | | | | | | 写入数据的时候，需要一个指针指向可以写入的位置 123 | | | | | | | | |position 每次写入数据，position 增加 1,比如写入 a,b,c,d 后 123| a | b | c | d | | | | | position 那么这个时候需要切换读状态怎么做呢？我们可以增加一个 limit 指针，随着写入指针一起增长 12345 limit | | a | b | c | d | | | | | position 当需要切换到读取状态时候，将 position 设置为 0，limit 不变即可 12345 limit | | a | b | c | d | | | | |position 我们将 position 设置为 0，limit 不变的操作称为 flip 操作，flip 本意是翻转，在这个场景中是读，写状态的切换读取操作可以循环从 position 一直读取到 limit 这样就可以读取 a,b,c,d 那么如果要继续写入应该怎么操作呢，这个时候就需要 clear 操作，这个操作会清空缓冲区。具体来说 clear 会将 position，limit 都设置为 0，就可以做到重复利用缓冲区了 写过程从 position = 0 开始，position 和 limit 一起自增。读取时，用 flip 操作切换缓冲区读写状态，读取数据完毕，用 clear重置缓冲区状态 总结流是随着时间产生的数据。数据抽象成流，是因为客观世界存在这样的现象。数据被抽象成流后，我们不需要把所有的数据都读取到内存中进行计算和迭代，而是每次处理或者计算一个缓冲区的数据。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"EPoll 红黑树","slug":"计网/EPoll","date":"2021-06-29T17:16:25.000Z","updated":"2021-07-01T04:18:04.798Z","comments":true,"path":"2021/06/30/计网/EPoll/","link":"","permalink":"https://www.shanghua.live/2021/06/30/%E8%AE%A1%E7%BD%91/EPoll/","excerpt":"","text":"Socket 是什么flowchart TB subgraph one 客户端 &lt;--&gt; Socket对象1 end subgraph two 服务端 &lt;--&gt; Socket对象2 end Socket对象1 &lt;--&gt; three Socket对象2 &lt;--&gt; three subgraph three TCP&#x2F;IP end Socket 是一种文件，准确的来说是一种双线管道文件 管道文件：管道会将一个程序的输入，导向另一个程序的输入 双向管道文件：双向管道文件连接的程序是对等的，都可以作为输入和输出 服务端程序 12var serverSocket = new ServerSocket();serverSocket.bind(new InetSocketAddress(80)); 这里看起来是我们创建的是一个服务端 Socket 对象，但单纯看这个对象，它代表着什么呢？如果从管道文件来理解，就容易些 其一，这是一个文件 其二，它里面存的是所有客户端 Socket 文件的文件描述符 当一个客户端连接到服务端的时候，操作系统就会创建一个客户端的 Socket 文件。然后操作系统对这个文件的文件描述写入服务端程序创建的服务端 Socket 中，服务端 Socket 文件，是一个管道文件，如果读取这个文件的内容，就相当于从管道中取走了客户端的文件描述符 graph LR 硬件 --&gt; os((OS)) os --- data[Data 客户端 Socket] os --- file[文件描述符 服务端 Socket] Thread ---&gt; file 当线程想要读取客户端传来的数据时，就从客户端 Socket 文件中读取数据当线程想要发送数据到客户端时，就向客户端 Socket 文件中写入数据 服务端 Socket 的绑定比如 Nginx 监听 80 端口 Node 监听 3000 端口 SSH 监听 22 端口 Tomcat 监听 8080 端口 端口监听不能冲突，不然客户端连接进来创建客户端 Socket 文件文件描述服就不知道写入哪个服务端 Socket 文件服务端监听的本质，是将服务端 Socket 文件和端口绑定，这个操作也称为 bind。有时候我们不仅仅绑定端口，还需要绑定 IP 地址。这是因为有时候我们只允许指定 IP 访问我们的服务器程序 扫描和监听对于服务端程序，可以定期扫描服务端 Socket 文件的变更，来了解哪些客户端想要连接进来如果在客户端 Socket 文件中读取到一个客户端的文件描述服，就可以将这个文件描述符实例成一个 Socket 对象 graph LR ServerSocket --客户端 Socket 文件描述服--&gt; 服务端程序 服务端程序 --定期读取--&gt; ServerSocket 服务端程序 --Socket对象--&gt; s((客户端 Socket 集合)) 之后，服务端可以将这个 Socket 对象加入一个容器（集合），通过定期遍历所有的客户端 Socket 对象，查看背后 Socket 文件的状态从而确定是否有新的数据从客户端传输过来这样通过一个线程来响应多个客户端的计数，也被称作 I/O 多路复用技术 响应式 （Reactive）服务端程序（线程）需要维护一个 Socket 的集合，然后定期遍历这个集合 命令式的程序：遍历一个 Socket 集合看看有没有发生写入 graph LR 线程指挥官 --主动观察--&gt; Socket对象1 线程指挥官 --主动观察--&gt; Socket对象2 线程指挥官 --主动观察--&gt; Socket对象3 线程指挥官 --主动观察--&gt; Socket对象4 线程指挥官 --主动观察--&gt; Socket对象5 线程指挥官 --主动观察--&gt; Socket对象6 线程去遍历 Socket 对象，若 Sokcet 对象过多，会导致负担过重，吞吐量下降 响应式就不会有这样的情况 graph LR Socket对象1 --被动响应--&gt; 线程指挥官 Socket对象2 --被动响应--&gt; 线程指挥官 Socket对象3 --被动响应--&gt; 线程指挥官 Socket对象4 --被动响应--&gt; 线程指挥官 Socket对象5 --被动响应--&gt; 线程指挥官 Socket对象6 --被动响应--&gt; 线程指挥官 在响应式程序中，Socket 会主动通知指挥官，所以应该是有某个观察者观察到 Socket 文件状态的变化，从而通知处理线程响应。线程不需要遍历 Socket 集合，而是观察程序的通知当然最适合观察者其实是操作系统本身。在实现这个模型时，有几个事情需要主机 线程需要告诉中间的观察者自己要观察什么，或者说什么情况下才响应？比如具体到某个 Socket 发生了什么事件？是读写还是其他事情？这一步我们通常称为注册 中间的观察者需要实现一个高效的数据结构（通常情况下是基于红黑树的二叉搜索树），这是因为中间的观察者不仅仅是某个服务于某个线程，而是服务于很多的线程。当一个 Socket 文件发生变化的时候，中间的观察者需要知道，究竟是哪个线程需要这个信息，而不是将所有线程都遍历一边 总结 Socket 既是一种编程模型，或者说是一段程序，同时也是一个文件，一个双向管道文件。 一个线程可以通过读取服务端 Socket 文件中的内容拿到所有的客户端 Socket 这样一个线程就可以负责响应所有客户端的 I/O这种技术称为 I/O 多路复用 主动式的 I/O 多路复用，对负责 I/O 的线程压力过大，通常会设计一个 I/O 事件的观察者，线程通过订阅来被动响应，也就是响应式模型 操作系统内核为我们提供响应式实现 Linux 的设计中有三种典型的 I/O 多路复用模型 select 主动模型，需要线程通过一个集合存放所有的 Socket，然后发生 I/O 变化的时候遍历 poll 更优质的编程接口，本质与 select 相同，千级别下的 I/O 可以考虑 select 和 poll epoll 在操作系统内核提供了一个中间数据结构，这个中间数据结构会提供事件监听注册，以及快速判断消息关联到哪个线程的能力","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"Java UDP Socket","slug":"计网/JavaUDPSocket","date":"2021-06-29T12:42:45.000Z","updated":"2021-06-29T05:04:06.492Z","comments":true,"path":"2021/06/29/计网/JavaUDPSocket/","link":"","permalink":"https://www.shanghua.live/2021/06/29/%E8%AE%A1%E7%BD%91/JavaUDPSocket/","excerpt":"","text":"Java 创建 UDP socket创建 UDP ServerHello我们可以用 Java 中的 DatagramSocket 创建一个 UDP Server 1234567891011121314151617181920212223public class UdpEchoServer &#123; // 端口号 private static final int port = 8421; public static void main(String[] args) throws IOException &#123; // 创建 UDP socket DatagramSocket socket = new DatagramSocket(port); while (true) &#123; // 创建数据包 DatagramPacket packet = new DatagramPacket(new byte[512], 512); // 接受数据 socket.receive(packet); // 拼接收到的数据 String msg = new String(packet.getData(), 0, packet.getLength(), StandardCharsets.UTF_8); System.out.println(packet.getAddress() + &quot;:&quot; + packet.getPort() + &quot;&gt;&quot; + msg); // 将收到的数据加上 “server” 头 packet.setData((&quot;server:&quot; + msg).getBytes(StandardCharsets.UTF_8)); // 返回数据 socket.send(packet); &#125; &#125;&#125; Java 创建 UDP Client同样的使用 DatagramSocket 创建客户端 123456789101112131415161718192021222324252627282930313233public class UdpEchoClient &#123; private static final int remotePort = 8421; private static InetAddress remoteIp = null; static &#123; try &#123; // 获取本地 IP remoteIp = InetAddress.getLocalHost(); &#125; catch (UnknownHostException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws IOException &#123; // 创建 UDP socket DatagramSocket socket = new DatagramSocket(); // 创建消息 byte[] outputMsg = &quot;hello Server&quot;.getBytes(); // 打包消息 DatagramPacket outputPacket = new DatagramPacket(outputMsg,outputMsg.length,remoteIp,remotePort); // 发送消息 socket.send(outputPacket); // 接受消息 DatagramPacket inputPacket = new DatagramPacket(new byte[512],512); socket.receive(inputPacket); // 将接受到的数据转换成 String String msg = new String(inputPacket.getData(),0,inputPacket.getLength(), StandardCharsets.UTF_8); System.out.println(msg); // 关闭连接 socket.close(); &#125;&#125; 运行首先运行 UdpEchoServer，运行后会监听本地 8421 端口，再运行 UdpEchoClient 向服务端发送消息可以看到服务端先打印了 /127.0.0.1:45793&gt;hello Server然后客户端打印 server:hello Server 使用 Wireshark 抓包如果客户端与服务端都运行在本地，需要在 Wireshark 选择网卡页面选择 Loopback:io 本地回环，来抓取本地数据包 在过滤窗口输入 udp.port == 8421 ,过滤 udp 协议 8421 端口，运行 UdpEchoServer 之后运行 UdpEchoClient 即可看到 udp 数据包，如图 客户端发往服务端数据包 服务器发往客户端的数据包 可以看到 UDP 数据包只有一来一回两个数据包，不像 TCP 协议需要先三次握手建立连接，每次收到数据都要发送给 ACK 断开连接需要四次挥手，非常麻烦","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"数据包抓包","slug":"计网/数据包抓包","date":"2021-06-27T15:09:52.000Z","updated":"2021-06-29T04:56:53.972Z","comments":true,"path":"2021/06/27/计网/数据包抓包/","link":"","permalink":"https://www.shanghua.live/2021/06/27/%E8%AE%A1%E7%BD%91/%E6%95%B0%E6%8D%AE%E5%8C%85%E6%8A%93%E5%8C%85/","excerpt":"","text":"WiresharkWireshark 是世界上应用最广泛的网络协议分析器，它让我们在微观层面上看到整个网络正在发生的事情。可以去 Wireshark 官网下载 Wireshark 官网 Wireshark 具有丰富的功能集 深入检查数百个协议，并不断添加更多协议 事实捕捉和离线分析 支持 Windows、Linux、MacOs、Solaris、等多种操作系统 提供 GPU 浏览、也可以通过 TTY 支持 VOIP 支持 Gzip 支持 IPSec 打开 WiresharkLinux 打开 Wireshark 如下界面 这里列出了电脑的网卡，你可以选择抓包的网卡，这里我的电脑是有限上网，所以选择 enp1s0，点击后会进入捕获页面 在这里可以看到非常多的数据包，有发送的，以及接受的数据包。页面没列以此是 序号（No）是 Wireshark 分配的一个从捕获开始的编号 时间（Time）是从捕获开始过去的时间戳，可以从在上方菜单栏 视图 -&gt; 时间显示格式 修改显示的格式 源地址和目标地址（Source 和 Destination）是 IP 协议，注意这里有 IPv6 的地址，也有 IPv4 的地址 协议可能有很多种，比如 TCP/UDP/ICMP 等，ICMP 是 IP 协议之上搭建的一个消息控制协议（Internet Conetol Message Protocol）比如 Ping 命令用的就是 ICMP； 还有 ARP 协议（Address Resolution Protocol）用来在局域网广播自己的 MAC 地址 Length 是消息的长度（Bytes） Info 是根据不同协议显示的数据，比如你可以看到 TCP 协议上看到 Seq 和 ACK。这里的 Seq 和 ACK 已经简化过了，正常情况是一个大随机数 观察 TCP 协议查看捕获页面的单个 TCP 协议 然后下方可以观察到详细内容 可以看到详细信息是从不同层面捕获的。从传输层看是 TCP 段；从网络层看是 IP 封包；从链路层看是 Frame 点开不同的层面观察 TCP 段，就可以获得对它更具体的认识，例如下图是从 TCP 层面理解这次捕获 可以看出这次是一次 ACK，从 80 端口发送到 60478，下方还有二进制窗口，可以看到此次消息的 16 进制形式 再来张全家图 Whireshark 追溯的是最底层网卡传输的 Frame（帧），可以追溯到数据的链路层。因此对我们二进制的解读，也就是消息试图也要分层。因为对同样的数据，不同层的解读是不同的 最上面是 Frame 数据，主要是关注数据的收发时间和大小 接着是数据链路层数据，关注的是设备的传递。你可以看到源 MAC 地址和目标 MAC 地址。 然后是网络层数据，IP层数据。这里有 IP 地址（源 IP 地址和目标 IP 地址）；也有头部 Checksum 最下面是传输层数据。也就是 TCP 协议。关注的是源端口，目标端口，Seq、ACK 等 有的传输层上还有一个 TLS 协议，这是因为用 HTTPS 请求了数据。TLS 也是传输层。TLS 是建立在 TCP 之上，复用了 TCP 的逻辑 观察 HTTP 协议 可以看到，Wireshark 不仅仅捕获了应用层，还可以看到这次 HTTP 捕获对应的传输层、网络层和链路层数据。 过滤和筛选Wireshark 还提供了捕获的过滤，我们只需要输入过滤条件，就可以只看符合条件的捕获。 首先我们通过 ping 命令查看百度的 IP 地址，如下图 在 Wireshark 中输入表达式 ip.addr == 39.156.66.18 ，如下图 这样就可以看到所有与 baidu 相关的连接。上图刚好是一次建立 TCP 连接（3 次握手），到 HTTPS 协议传输握手的完整过程。你可以只看到 192.168.1.109 到 39.156.66.18 的请求 首先是从客户端（192.168.1.5）发出的 SYN 和百度返回的 SYN-ACK，如下图所示： 然后是客户端返回给百度一个 ACK： 接下来是 HTTPS 协议开始工作 可以看到 HTTPS 协议通过 TLSv1.2 发送了 Client Hello 到服务端。接下来是 Server 返回给客户端 ACK，然后再发送给客户端一个 Server Hello： 之后百度回传了证书，握手结束 报文颜色在抓包过程中，黑色报文代表各类报文错误；红色代表出现异常；其他颜色代表正常传输 注意，红色是深红色，并不是此图中的粉红色","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"计算机网络入门 局域网-NAT","slug":"计网/局域网NAT","date":"2021-06-27T13:47:14.000Z","updated":"2021-06-27T07:09:04.290Z","comments":true,"path":"2021/06/27/计网/局域网NAT/","link":"","permalink":"https://www.shanghua.live/2021/06/27/%E8%AE%A1%E7%BD%91/%E5%B1%80%E5%9F%9F%E7%BD%91NAT/","excerpt":"","text":"NAT 是如何工作的当一个公司申请到一个公网 IP，会在公司内部设置一个局域网，这个局域网中通常 IP 地址，会以 192.168 开头当一个员工使用 UDP 协议发送信息向王者荣耀服务器，可是员工的 IP 地址是一个内网 IP，数据到王者荣耀服务器可以通过寻址和路由找到目的地但是数据从王者荣耀服务器回来的时候，王者荣耀服务器如何知道 192.168 开头的地址应该如何寻址呢？ 局域网数据交换（MAC 地址）设备间通讯的本质：设备拥有的网络接口（网卡）间的通信 为了区别每个网络接口，互联网工程任务组（IETF）要求每个设备拥有一个唯一的编号 MAC 地址 IP 地址不是唯一的吗?并不是的，如果你将电脑搬到另一个城市 IP 地址就会改变，电脑网卡的 MAC 地址不会发生变化数据交换，必须经过交换机，毕竟线路是由网卡连接交换机的 数据发送方将本身的 MAC 地址，以及目的地的 MAC 地址，Frame 或者封包，发送给交换机，交换机根据地址转发给目的地或者目的地的网卡这个 Frame，并不是 IP 协议的分组链路层的数据交换，支持 IP 协议工作，是网络层的底层如果 IP 协议要传输数据，就要将数据转换为链路层的分组，然后才可以在链路层传输，链路层的大小受限于链路层的网络设备、线路以及使用了链路层协议的设计MTU（Maximun Transmission Unit）最大传输单元 链路层网络允许的最大传输数据分组的大小MSS（Maximun Segment Size，最大段大小） TCP 段 TCP 分组（TCP Packet）的最大大小MSS 是传输层概念，MTU 是链路层概念MTU = MSS + TCP Header + IP HeaderTCP 传输的数据大于 MSS，就拆包，每个封包上加上 TCP Header，之后经过 IP 协议，再加上 IP Header，于是这个加上 IP 头的分组（Packet）不能超过 MTU 对于一个 网络接口，它如何能知道目标接口的 MAC 地址呢？ 地址解析协议（Address Resoulution Protocol，ARP）发送接口会发送一个广播查询给交换机，交换机将查询转发给所有接口，如果某个接口发现自己就是对方要查下的接口，则会将自己的 MAC 地址回传然后再交换机增加缓存条目，缓存采用的是逐级缓存的设计减少 ARP 请求（发送接口先查询本地的 ARP 表，如何本地没有数据，然后广播 ARP 查询） ARP 表是一种缓存，缓存需要考虑 失效时间、更新策略、数据接口 考虑使用 TTL（Time To Live）的设计，为每个缓存条目增加一个失效时间 更新策略可以考虑利用老化（Aging）算法模拟 LRU 家用设备会提供局域网 具备交换机的能力，又具有路由器的能力 当 ARP 表很大的时候，需要专门的、能够承受大量网络接口的交换设备 连接内网有时候，公司内部有多个子网，这个时候一个子网如果要访问另一个子网，就需要通过路由器也就是说。路由器其实充当了两个子网通讯的桥梁。发送接口并不能通过 MAC 地址发送数据到接收接口，因为两个子网之间只有路由器相连，子网1 的交换机不知道子网2 的交换机。这个时候发送方需要通过 IP 协议，将数据发送到路由器，再由路由器转发信息到子网2 的交换机子网2 的交换机通过 查询 ARP 表来找到 IP 地址的接口 连接外网（网络地址转换技术，NAT）flowchart LR; A[192.168.0.1] &lt;--私有网络--&gt; B[NAT + 路由器] &lt;--互联网--&gt; C[服务 22.22.22.22] 寻找目标 IP 地址 22.22.22.22 是一个公网 IP，可以通过正常的寻址 + 路由算法定位，当 22.22.22.22 寻找 192.168.0.1 的时候，是寻找一个私网 IP，这个时候是找不到的。这个时候就需要使用网络地址转换技术，NAT 技术转换的是 IP 地址，私有 IP 通过 NAT 转换为公网 IP 发送到服务区。服务器的响应通过 NAT转换为私有 IP，返回给客户端，通过这种方式就解决了内网和外网通讯的问题 总结 链路层发送数据靠的是 MAC 地址 交换机（链路层交换机）：不断接受数据，然后转发数据 地址解析协议（ARP）: 已知 IP 地址，找到 MAC 地址的协议 网络和网络的衔接，必须要有路由器（等价的设备）","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"IPv4 协议","slug":"计网/IP协议","date":"2021-06-23T17:37:43.000Z","updated":"2021-06-23T11:43:17.253Z","comments":true,"path":"2021/06/24/计网/IP协议/","link":"","permalink":"https://www.shanghua.live/2021/06/24/%E8%AE%A1%E7%BD%91/IP%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"什么是 IP 协议IP 协议，是一个处于垄断地位的网络层协议，IPv4 就是 IP 协议的地 4 个版本，是目前互联网的主要网络层协议IPv4 是目前互联网的主要网络层协议。IPv4 为传输层提供 Host-To-Host 的能力，IPv4 需要底层数据链路层的支持IP 协议并不负责数据的可靠性，传输数据时，IP 协议还会对数据进一步拆分。进行两次拆分是为了适配底层的设备 可靠性是要保证数据无损传输到目的地，是由 IP 协议上方，Host-To-Host 协议保证了，TCP 通过应答机制，窗口等保证IP 协议自身不能保证可靠性。比如 IP 协议可能面临下面几个问题 封包损坏（数据传输过程中被损坏） 丢包（数据发送过程中丢失） 重发（数据被重发，比如中间设备通过 2 个路径传递数据） 乱序（到达目的地时数据与发送数据不一致） IP 协议并不会去处理这些问题，因为网络层只专注解决网络层的问题，而且不同特性的应用在不同场景下需要解决的问题不一样对于网络层，有三个问题需要解决 延迟 吞吐量 丢包率 IP 协议的工作原理IP 协议接受 IP 协议上方的 Host-To-Host 协议来传输数据，然后进行拆分，这个能力叫作切片（Fragmentation）IP 协议为每个片段（Fragmentation）增加一个 IP 头（Header），组成一个 IP 封包（Datagtam）。之后 IP 协议调用底层的局域网（数据链路层）传输数据。最后 IP 协议通过寻址和路由能力最终把封包送达目的地。 分片是吧数据切分成片IP 协议通过局域网（链路层）传输数据，因此需要适配底层传输网络的传输能力如果底层（链路层）发现一个未经过封包的数据，又没有能力传输时，就直接丢弃数据包在网络环境中往往存在多条路径，一条路径断了，说不定其他路径可能连通 增加协议头（IP Header） 分为四个部分 最重要的是原地址和目标地址。IPv4 的地址是4组8位的数字，总共是32位。 Type of Service 服务的类型是为了响应不同的用户诉求，用来选择延迟、吞吐量和丢包率之间的关系。 IML（Internet Header Length）用来描述 IP 协议头的大小。所以 IP 协议头的大小是可变的。IHL 只有4位，最大值 1111 = 15 最大是 15 个双字（15*4 字节 = 60 字节） Total Length 定义报文（封包 Datagram）的长度。 Identification（报文的 ID），发送方分配，代表顺序。 Fragment offset 描述要不要分包（拆分），以及如何拆分 Time To Live（TTL） 描述封包的存货时间。因此每个 IP 封包发送出去后，就开始销毁倒计时。如果倒计时为0就会销毁。比如中间的路由器看到一个 TTL 为0 的封包，就直接丢弃 Protcol 描述上层的协议，比如 TCP = 6，UDP = 17 Options 代表可选项 Checksum 用来检验封包的正确性，类似 UDP，如果 Checksum 不对，就要丢弃这个封包 Type of Service 延迟（Latency）指的是 1 bit 的数据从网络的一个终端传送到另一个终端需要的时间 吞吐量（Throughput）吞吐量指单位时间内可以传输的平均数据量 丢包率（Packet loss）指的是发送出去的封包没有到达指定目的地的比例 Type of Service 有4个选项低延迟，高吞吐量，地丢包率，低成本 寻址（Addressing）地址想要表达的是一个东西在哪里。寻址要做的就是：给一个地址，然后找到这个东西。IPv4 协议的寻址过程是逐级寻址。 IPv4 地址IPv4 地址是4个8位（Octet）排列而成，总共可以编址43亿个地址 103.16.3.1 103 16 3 1 01100111 0010000 00000011 001001 寻址过程 找到顶层网络比如 103.16.3.1 最顶层的网络号可以和 225.0.0.0 （子网掩码）做位运算得到103.16.3.1 &amp; 255.0.0.0 = 103.0.0.0因此103.0.0.0就是103.16.3.1所在的顶层网络。255.0.0.0.称作子网掩码。子网掩码的作用就是帮助根据 IP 地址找到对应子网。子网掩码是很多个1接着很多个0，和 IP 地址一起使用。 找到下一层网络接下来要找到下一层网络，就需要 IP 地址和下一级的子网掩码做位与运算103.16.3.1 &amp; 255.255.0.0 = 103.16.0.0其中 103.16.0.0 就是下一级的网络号 再下一级网络通过子网掩码 255.255.255.0 子网掩码找到下一级网络 103.16.3.0 定位设备设备就在子网 103.16.3.0 中，最终找到的设备号是 1当然子网掩码也不一定都是255，比如这个子网掩码255.240.0.0也是可以的。但通常我们把 IPv4 的网络分成这样 4 层。 路由（Routing）在寻址过程中，数据总是存在于某个局域网中。如果目的地在局域网中，就可以直接定位设备了。如果目的地不在局域网中，这个时候就需要再去往其他网络假设，我们要前往 IP 地址为 14.215.177.38 寻址，当前的路由器所在的网络编号是 16.0.0.0。那么我们就需要知道前往 14.0.0.0 网络的 Gateway IP 地址在当前网络执行 route 查看路由表，可能看到一条下面这样的记录。 Destination:14.0.0.0 Gateway:16.12.1.100 Mask:255.0.0.0 Iface:16.12.1.1 这条记录就表示如果你要去 14.0.0.0 网络，IP 地址，14.215.177.38 先要和 255.0.0.0,进行位运算然后查表 看到 14.0.0.0 得知去往 Gateway 的网卡（IFace） 是 16.12.1.1 总结 IP 协议会讲数据进行分片，将上游数据拆分成一个个的封包（Datagram），然后封包增加 IP 头部。封包发送出去后，就开始可寻址过程。寻址就是找到 IP 地址对应的设备，在同一局域网内，如果找不到设备，就需要路由。路由就是找打数据应该往哪里发送。最后通过层层路由定位到具体的设备。","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"IPv6 协议","slug":"计网/IPv6协议","date":"2021-06-23T17:37:43.000Z","updated":"2021-06-27T05:47:19.654Z","comments":true,"path":"2021/06/24/计网/IPv6协议/","link":"","permalink":"https://www.shanghua.live/2021/06/24/%E8%AE%A1%E7%BD%91/IPv6%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"IPv4 用 32 位整数描述地址，最多支持 43 亿设备，显然不够用 可以拆分子网来解决 IPv4 不够用的问题，内外网数据交互，需要网络地址转换协议（NAT 协议），增加传输成本多级网络会增加数据的路由和传输链路，降低网络的速度 IPv62019 年据中国互联网络中心（CNNIC）统计，IPv6 协议目前在我国普及率 60%，已经位居时间首位 什么是 Tunnel 技术 IPv4 与 IPv6 相似点 IPv6：切片（Segmentation）、增加封包头、路由（寻址） IPv6：接受上方主机到主机（Host-To-Host）协议传递来的数据 最核心的能力：确保数据可以从发送主机到达接收主机 不相同点 IPv4地址是 4 个 8 位（octeat），共 32 位 IPv6 8 个 16 位（hextet），共 128 位 IPv4 使用 . 点分割 如 103.28.7.35 IPv6 使用 : 冒号分割 0123:4567:89ab:cdef:0123:4567:89ab:cdef 也可以省略前 64 字节简写为 0123:4567::0123:4567:0000:cdef:: 只能出现一次，相当于省略了若干个 0000。比如 1111::2222 相当于中间省略了 6 组 0000。如果出现两个 1111::2222::3333 就无法得知 0000 是如何分部的。开头的 0 也可以简写为 123:4567::123:4567:0:cdef还有一种情况，如果我们想后面都填 0 比如 3c4d::/16,这代表只有前 16 位有数据，后面是 0 IPv6 寻址寻址的目的：找到设备，以及规划到设备途径的路径，最核心的内容，对网络进行划分 全局单播寻址，1 对 1 寻址 本地单播 类似 IPv4 内部网络，开头必须是 fe80 分组多播（Group Multicast） 广播 任意播 特殊方式 全局单薄将消息从一个设备传到另一个设备全局单薄地址：目标就是定位网络中的设备IPv6 地址太多，因此不再需要子网掩码，而是直接将 IPv6 的地址分区即可 在全局单播中，IPv6 分为 3 部分 站点前缀（Site Prefix）48 bit，一般是由 ISP （Internet Service Providor，运营商）或者 RIR （Regional Internet Registry，地区性互联网注册机构），RIR 将 IP 地址分配给运营商 子网好（Subnet ID），16bit 用于站点内部区分子网 接口号（Interface），64bit，用于站点内部区分设备 因此 IPv6 也是树状结构，站点前缀需要一定资质，子网号与接口号内部定义。IPv6 的寻址过程就是先通过站点前缀找到站点，然后追踪子网；每个子网中，还可以用 64 位整数表示设备。 本地单播在局域网中，实现设备到设备的通讯虽然 IPv6 可以给每个设备一个 IP 地址，但是有些情况还是需要一个局域网络的 1234Format | Link-Locl prefix| 0 | Interface ID | | 10 bits | 64 bit | 54 bits|Example : fe80::123e:456d 分组多播实现广播：将消息同时发送给多个接收者 当 IP 地址以 8 个 1 开头，也就是 ff00 开头，后面会跟上一个分组的编号，就是在进行分组多播 任意播任意播：将消息发送给多个接收方，并选择一条最优的路径 在一个网络中有多个接收方，这些授时服务都共享了一个任播地址当一个客户端想要获取时间，就可以讲请求发送到这个任意播地址，客户端的请求扩散出去后，可能会找到授时服务中的一个或者多个，但是距离最近的往往会被先发现。这个时候，客户端使用它第一次收到的授时信息修正自己的时间 IPv4 和 IPv6 兼容两种情况 情况1：一个 IPv4 的网络和一个 IPv6 的网络通讯 首先 客户端去 DNS64（提供的一种解决 IPv4 和IPv6 兼容问题的 DNS 服务），这个查询服务会吧 IPv4 地址和 IPv6 地址同事返回 DNS64 服务器返回含 IPv4 地址的 AAAA 记录。 客户端将对应的 IPv4 地址请求发送给一个 NAT64 路由器 由这个 NAT64 路由器将 IPv6 地址转换为 IPv4 地址，从而访问 IPv4 网络，并收集结果 消息返回到客户端 情况2：一个 IPv6 的网络和一个 IPv6 的网络通讯，但是中间需要经过一个 IPv4 的网络 隧道的本质：在两个 IPv6 的网络出口网关处，实现一段地址转换的程序 总结 IPv6 IPv6 解决的是地址耗尽的问题, 减少了子网，更小的封包头部体积，提升了性能 Tunnel 技术是什么？ Tunnel 就是隧道，隧道不是只有一辆车通过，而是每天都有大量的车辆来来往往 两个网络，用隧道连接，位于两个网络中的通讯设备，都可以使用这个隧道","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"最大连接测试","slug":"计网/最大连接测试","date":"2021-06-23T15:09:52.000Z","updated":"2021-06-23T09:26:43.487Z","comments":true,"path":"2021/06/23/计网/最大连接测试/","link":"","permalink":"https://www.shanghua.live/2021/06/23/%E8%AE%A1%E7%BD%91/%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%B5%8B%E8%AF%95/","excerpt":"","text":"Java 创建 Socket 连接一台内存在 8G 左右的服务器，可以同时维护多少连接？ 连接是内存中的状态对象，从理论上分析，连接本身不太占用内存。不同语言连接对象大小不等，但是通常很小。我们可以写个 Java 程序测试一下 Server 端 12345678910111213141516public class ServerDemo &#123; public static void main(String[] args) throws IOException &#123; var serverSocket = new ServerSocket(); // 3001 端口 var address = new InetSocketAddress(3001); serverSocket.bind(address); var list = new LinkedList&lt;&gt;(); while (true)&#123; // 监听连接 var client = serverSocket.accept(); list.add(client); System.out.println(list.size()); &#125; &#125;&#125; Client 端 123456789101112public class ClientDemo &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; var clients = new LinkedList&lt;&gt;(); // 循环 一百万次 for (int i = 0; i &lt; 1000000; i++) &#123; // 连接 3001 端口 var client = new Socket(&quot;127.0.0.1&quot;,3001); clients.add(client); &#125; TimeUnit.SECONDS.sleep(100); &#125;&#125; 创建 100W 连接速度不快，说明 TCP 连接创建有成本 用 jps 找到对应的进程 id，用 sudo cat /proc/{进程ID}/status | grep VmHWM 查看占用内存 执行 jps 命令,我们可以看到输出 1234538931 Main42676 Launcher42679 Server39259 RemoteMavenServer3642734 Jps Server 就是我们启动的进程， 进程 ID 为 42679执行 bash 命令 1sudo cat /proc/42679/status | grep VmHWM 输出 VmHWM: 42636 kB,可以看到随着连接创建，占用不停增长当单机建立太多链接，会爆出 Cannot assign requested address 异常，这是由于没建立一个连接，操作系统就会为客户端分配端口号，端口号很快就被占用用尽 所以核心问题是，通信需要缓冲区，通讯需要 I/O 。这是因为通讯占用资源，连接本身占用资源少。 有哪些 好用的压力测试工具？压力测试最常用的工具是 Apache Benchmark （简称 AB） linux 可执行以下命令安装 123yum install httpd-tools// orapt-get install apache2-utils 还有一款更好用的 Java 生态工具 JMeter, 安装 Java 运行环境就可使用 具体用法有空我再做一篇笔记","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP 和 UDP","slug":"计网/TCP和UDP","date":"2021-06-20T17:00:01.000Z","updated":"2021-06-23T04:43:16.057Z","comments":true,"path":"2021/06/21/计网/TCP和UDP/","link":"","permalink":"https://www.shanghua.live/2021/06/21/%E8%AE%A1%E7%BD%91/TCP%E5%92%8CUDP/","excerpt":"","text":"TCP 可靠性 HTTP 协议 1.1 和 2.2 UDP 灵活 HTTP 协议 3.0 UDP 协议UDP 在数据传输，网络控制，音视频，Web 技术UDP (User Datagram Protocol) 目标是在传输层提供直接发送报文(Datagram)的能力 Datagram 是数据传输的最小单位 UDP 协议不会帮助拆分数据，它的目标只有一个，就是发送报文 为什么不用 IP 协议呢 graph LR; A[应用层] --&gt; B[传输层] --&gt; C[IP协议层] 传输层 (端口号，每个端口代表不同的应用) IP 协议 (将数据从主机传输到主机) UDP 的封包格式 Soure Port(源端口号) Destination(目标端口号) Length(消息体长度) Checksum(校验和) Data octets。。。(一个一个字节数据) 校验和 (Checksum) 机制：校验数据在传输过程中有没有丢失、损坏。是一个普遍需求 简单的校验和程序 checksum=(a+b+c+d) ^ 0xff 接收方可以用同样的算法检查，不过还是可能碰撞 UDP 与 TCP 的区别 TCP (提供可靠的网络传输) UDP (在提供报文交换能力基础上尽可能地简化协议，轻装上阵)只管发送数据包，不管是否发送成功 TCP 是一个面向连接的协议(Connection-oriented Protocol) UDP 无连接协议 (Connection-less Protocol) TCP 流控技术(在发送缓冲区中存储数据，并在接受缓冲区中接受数据) UDP 没有流控，不过 UDP 协议简化，没有连接，可靠性检查等，速度更快 TCP 不适合高速传输数据场景(视频，游戏) UDP(Ping 和 DNSLookup，只需要一次简单的请求/返回，不需要建立连接) TCP 无损传输文件 UDP 传输数据更快 TCP HTTP 协议 UDP HTTP 3.0 理论上来讲，任何一个用 TCP 协议构成的成熟应用层协议，都可以用 UDP 重构 TCP 的场景 远程控制 File Transfer Protocol(FTP) 邮件(SMTP，IMAP)等 点对点文件传出(微信等) UDP 场景 网络游戏 音视频传输 DNS Ping 直播 模糊地带 HTTP (目前以 TCP 为主) 文件传输 UDP 不提供可靠性，不代表不能解决可靠性 UDP 的核心价值：灵活、轻便，构造了最小版本的传输层协议我们可以为 UDP 实现连接 (Connection)，实现会话 (Session),实现可靠性 (Reliability) … 总结 TCP 协议可以培养思维的缜密性 （序号的设计，滑动窗口的设计，快速重发的设计，内在状态机的设计） UDP 协议可以带动我们反思自己的技术架构 报文传输 - 可靠性 - 流量控制 - 连接和会话 TCP 最核心的价值就是提供好了一套解决可靠性的优秀方案 TCP 在确保吞吐量、延迟、丢包率的基础上，保证可靠性 UDP 提供了最小版的实现，只支持 Checksum UDP 最核心的价值：灵活、轻量、传输速度快","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP-滑动窗口-流速控制","slug":"计网/TCP-滑动窗口-流速控制","date":"2021-06-20T15:53:20.000Z","updated":"2021-06-21T08:26:55.771Z","comments":true,"path":"2021/06/20/计网/TCP-滑动窗口-流速控制/","link":"","permalink":"https://www.shanghua.live/2021/06/20/%E8%AE%A1%E7%BD%91/TCP-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3-%E6%B5%81%E9%80%9F%E6%8E%A7%E5%88%B6/","excerpt":"","text":"!! 此篇博客内容来自 拉勾教育 作为一个传输层协议，最核心的能力是传输，传输需要保证可靠性，还需要控制流速，这两个核心均由滑动窗口提供 请求/响应模型每一个请求收到响应之后，再发送下一个请求，吞吐量会很低。因为这样的设计，会产生网络的空闲时间，说白了，就是浪费带宽。带宽没有用满，意味着可以同时发送更多的请求，接收更多的响应。 一种改进的方式，就是让发送方有请求就发送出去，而不是等待响应。通过这样的处理方式，发送的数据连在了一起，响应的数据也连在了一起，吞吐量就提升了。 排队（Queuing）在这种情况下，我们通常会考虑排队机制 这样做就需要多个队列，我们要将未发送的数据从队列中取出，加入发送中的队列。然后再将发送中的数据，收到 ACK 的部分取出，放入已接收的队列。而发送中的封包，何时收到 ACK 是一件不确定的事情，这样使用队列似乎也有一定的问题。 滑动窗口（Sliding Window） 深绿色代表已经收到 ACK 的段 浅绿色代表发送了，但是没有收到 ACK 的段 白色代表没有发送的段 紫色代表暂时不能发送的段 这个时候滑动窗口可以向右滑动，如下图所示： 重传如果发送过程中，部分数据没能收到 ACK 会怎样呢？这就可能发生重传。如果发生下图这样的情况，段 4 迟迟没有收到 ACK。 这个时候滑动窗口只能右移一个位置，如下图所示： 在这个过程中，如果后来段 4 重传成功（接收到 ACK），那么窗口就会继续右移。如果段 4 发送失败，还是没能收到 ACK，那么接收方也会抛弃段 5、段 6、段 7。这样从段 4 开始之后的数据都需要重发。 快速重传在 TCP 协议中，如果接收方想丢弃某个段，可以选择不发 ACK。发送端超时后，会重发这个 TCP 段。而有时候，接收方希望催促发送方尽快补发某个 TCP 段，这个时候可以使用快速重传能力。例如段 1、段 2、段 4 到了，但是段 3 没有到。 接收方可以发送多次段 3 的 ACK。如果发送方收到多个段 3 的 ACK，就会重发段 3。这个机制称为快速重传。这和超时重发不同，是一种催促的机制。为了不让发送方误以为段 3 已经收到了，在快速重传的情况下，接收方即便收到发来的段 4，依然会发段 3 的 ACK（不发段 4 的 ACK），直到发送方把段 3 重传。 流速控制假设 RTT = 1ms, 带宽是 1mb/s如果窗口大小为 1kb，那么 1ms 可以发送一个 1kb 段数据（含 TCP 头）1s 就可以发送 1mb 的数据，刚好可以将带宽用慢如果 RTT 再慢一些，比如 RTT = 10ms ,这样的设计就只能用完 1/10 的带宽 总结有了窗口，发送方利用滑动窗口算法发送消息；接收方构造缓存区接受消息，并给发送方 ACK 滑动窗口是 TCP 协议控制可靠性的核心，发送方将数据拆包，变成多个分组，然后讲数据放入一个拥有滑动窗口的数组，依次发出，然后遵循，先入先出（FIFO）的顺序单数窗口中的分组会一次性发送。窗口中序号最小的分组如果收到 ACK ，窗口就会发生滑动，如果最小序号的分组长时间没有收到 ACK，就会触发整个窗口的数据重新发送","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"TCP-封包-拆包","slug":"计网/TCP-封包-拆包","date":"2021-06-20T13:16:22.000Z","updated":"2021-06-21T08:26:53.271Z","comments":true,"path":"2021/06/20/计网/TCP-封包-拆包/","link":"","permalink":"https://www.shanghua.live/2021/06/20/%E8%AE%A1%E7%BD%91/TCP-%E5%B0%81%E5%8C%85-%E6%8B%86%E5%8C%85/","excerpt":"","text":"TCP 封包 TCP 协议是如何恢复数据的顺序的 ? 拆包和粘包的作用是什么 ? TCP 是一个传输协议，会讲数据进行拆分进行发送，为什么不分批发送？ 为了稳定性，一次性发送的数据越多，出错的概率越大 为了效率，拆分的数据包就能更好的利用这些并行的路径 发送和接受数据都有缓冲区，缓存区是在内存中开辟的一块区域，目的是缓冲 在传输层封包不能太大以缓存区大小为单位 TCP 协议： 会将数据拆分成不超过缓冲区大小的一个个部分 每个部分都有一个独特的名称，叫做 TCP 段（TCP Segment） 拆包：将数据拆分成多个 TCP 段传输 粘包：将多个数据合并成一个 TCP 段发送 TCP SegmentTCP 分组格式示意图 Source Port/DestinationPort 描述的事发送端口号和目标端口号，代表发送数据的应用程序和接受数据的应用程序 Sequence Number 和 Achnowlendgment Number 是保证可靠性的两个关键 Data Offset 是一个偏移量，原因：TCP Header 部分的长度可变，需要一个数值来描述数据从哪个字节开始 Reserved 是很多协议设计会保留的一个区域，用于日后扩展能力 URG/ACK/PSH/PST/SYN/FIN 是几个标志位，用来描述 TCP 段的行为 URG 代表一个紧急数据（比如终结程序） ACK 代表响应 PSH 代表数据的推送，传输数据 SYN 同步请求，申请握手 FIN 终止请求，挥手 这五个标志位一个占一个 bit 可同时使用 Window 也是 TCP 保证稳定性并进行流量控制的工具 Checksum 是校验和，用来校验 TCP 段有没有损坏 Urgent Poninter 指向最后一个紧急数据的序号（Sequece Number） Option 中存储了一些可选字段 MSS （Maxiumun Segment Size）(长度不固定) Padding 存在的意义是因为 Option 的长度不固定，需要 Pading 进行对齐 Sequece Number 和 Achnowlendgment Number拆包：数据被分成很多个部分，部分增加了协议头合并成一个 TCP 段，进行传输TCP 段经过复杂的网络结构，由底层的 IP 协议，负责传输到目的地，然后进行重组 稳定性要求是数据无损地传输（拆包获得的数据，又需要恢复到原来的样子）数据虽然是顺序发送的，但不能保证是顺序接受的发送的每一个 TCP 段都需要有序号 – Sequence Number（Seq） 发送数据的时候，为每一个 TCP 段分配一个自增的 Sequence Number 接受数据的时候，可以通过 Sequence Number 为乱序的 TCP 段进行排序 接收方回复发送方，也需要 seq，而网络的两个终端，去同步一个自增的序号是非常困难的 对于任何一个接收方，如果知道了发送者发送某个 TCP 段时，已经发送了多少个字节的数据，那么就可以确认发送者发送数据的顺序如果接收方也向发送者发送了数据请求，接收方就不知道发送者发送的数据到底对应哪一条自己发送的数据？每一个 TCP 段发送时，发送方已经接受了多少数据 Achnowlendgment（ACK） 无论是 Seq 和 ACK 都是针对 “对方” 而言的 MSS （Maxiumun Sequence Size） 重要的 TCP Header 中的可选择（Options） 可选性控制 TCP 段的大小，它是一个协商字段（Negotiate） 协商是双方都要遵循的标准，配置不能由单方决定，需要双方协商 TCP 段的大小（MSS）涉及发送、接收缓存区的大小设置 双方实际发送接受封包的大小，对拆包和粘包的过程有知道作用 设置的过大会降低性能 用户占用服务器太多的资源，意味着其他的用户就需要等待或者降低他们的服务质量 支持 TCP 协议工作的 IP 协议，工作效率会下降 IP 协议为什么需要拆包呢？ 在网络中，每次传输的数据不能太大，受限于具体的网络传输设备（物理特性） IP 协议拆分太多的封包并没有意义 可能会导致属于同个 TCP 段的封包被不同的网络线传输，加大延迟 拆包需要消耗硬件和计算资源 是不是 MSS 越小越好呢？ MSS 太小的情况，会浪费传输资源（降低吞吐量） 无法获得完美的解决方案需要实验测试她 总结 TCP 协议是如何恢复数据的顺序的，TCP 拆包和粘包的作用是什么 TCP 拆包的作用，将任务拆分处理，降低整体任务出错的概率，以及减小底层网络处理的压力，粘包过程需要保证数据经过网络的传输，又能恢复到原来的数据 需要数学提供保证顺序的理论依据，TCP 利用 （发送字节数，接受字节数）的唯一性来确认封包直接的顺序关系 TODO 本篇文章未完成","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"计算机网络入门-TCP/UDP","slug":"计网/计网-入门","date":"2021-06-19T11:23:11.000Z","updated":"2021-06-21T08:26:51.799Z","comments":true,"path":"2021/06/19/计网/计网-入门/","link":"","permalink":"https://www.shanghua.live/2021/06/19/%E8%AE%A1%E7%BD%91/%E8%AE%A1%E7%BD%91-%E5%85%A5%E9%97%A8/","excerpt":"为什么 TCP 握手三次，挥手却四次","text":"为什么 TCP 握手三次，挥手却四次 TCP 传输层协议，提供给 Host-To-Host 数据的可靠性传输，支持全双工，是一个连接导向的协议这里主要涉及到，主机到主机、连接、会话、双工/单工及可靠性 主机到主机（Host-To-Host）提供的是 Host-To-Host 传输，一台主机通过 TCP 发送数据到另一台主机可以是电脑-手机-平板TCP 协议往上上 应用到应用 (Application-To-Application) 的协议微信的聊天协议想要工作，就需要一个主机到主机的工具互联网协议群（TCP/IP 协议群） graph LR; A[应用层] --&gt; B[传输层] --&gt; C[网络层] --&gt; D[数据链路层] --&gt; E[物理层] 网络层 提供地址到地址的通讯，不负责信号在具体两个设备传递主机到主机为应用提供应用间通讯的能力 连接（Connection）连接数网络行为状态的记录通讯双方的一个约定，目标是让两个在通讯的程序之间产生一个默契，保证两个程序都在线而且尽快的响应对象的请求两个应用会维护一个关联的对象，比如双方 IP 和 端口 是多少？现在发送了多少数据了，状态健康吗，传输速度如何 双工/单工问题 问题名称 概念 需要几条线路 单工 在任何时刻，如果数据只能单向发送 只需 1 条 半双工 在任何时刻数据可以向一个方向传输 也可以在另一个反方向传输，而且交替进行 至少一条 全双工 如果任何时刻数据都可以双向收发 大于 1 条 线路，是一个抽象的概念，你可以并发的处理信号，达到模拟双工的目的TCP 一个双工协议，数据任何时候都可以双向传输客户端和服务的在 TCP 协议中有一个平等的名词 Host（主机） 可靠性 可靠性（数据保证无损传输）如果发送方按照顺序发送，然后数据无序地主网络间传输，就必须有一种算法在接受方将数据恢复原有的顺序 多播情况如果有一个消息到达任何一个接受者，那么所有接受者都必须收到这个消息 TCP 的握手和挥手TCP 是一个连接导向的协议，设计有建立连接（握手）和断开连接（挥手的过程） 如果一个 Host 主动向另一个 Host 发起连接，被称为 SYN （Synchronization），请求同步 如果一个 Host 主动断开请求，称之为 FIN （Finish），请求完成 如果一个 Host 给另一个 Host 发送数据，成为 PSH （Push），数据推送 接收方接受到数据后，都需要给发送方一个 ACK（Acknowledgement） 响应，如果不响应，发送方会以为需要重发请求保持连接的可靠性约束，TCP 协议要保证每一条发出的数据必须给返回 建立连接的过程（三次握手）sequenceDiagram 客户端-&gt;&gt;服务端:1.客户端发送消息给服务端（SYN） [一次握手] note over 服务端: 2. 服务端准备好进行连接 note right of 服务端: [服务端的准备，不算握手] 服务端-&gt;&gt;客户端: 3. 服务端针对客户端的 SYN 给一个 ACK [三四是同时发生的，算一次握手，第二次握手] 服务端-&gt;&gt;客户端: 4. 服务端发送一个 SYN 给客户端 [三四可以合并成一个 SYN-RCVD 作为一条响应] note over 客户端: 5. 客户端准备好进行连接 note left of 客户端: 客户端准备 不算握手 客户端-&gt;&gt;服务端: 6.客户端针对 SYN 给服务端一个 ACK [第三次握手] 为 TCP 协议增加协议头，在协议头中取对个位（bit），其中 SYN，ACK，PSH 都占有一个位 断开连接的过程（四次挥手） 客户端要求断开连接，发送一个断开的请求，这个叫做 （FIN） 服务端收到请求，然后给客户端一个 ACK，作为 FIN 的响应。 不能像握手一样马上穿回 FIN 回去，因为断开连接要处理的问题比较多，比如说客服务的还有发送出去的消息没有得到 ACK；也可能自己有资源要释放，因此不能将两条消息合并。所以客户端经过等待确认可以关闭连接了，再发生一条 FIN 给客户端 sequenceDiagram 客户端-&gt;&gt;服务端: FIN 请求断开连接 服务端-&gt;&gt;客户端: ACK 响应 客户端 FIN note over 服务端: 服务端处理完事情 服务端-&gt;&gt;客户端: FIN 请求断开连接 客户端-&gt;&gt;服务端: ACK 响应 服务端 FIN 总结 TCP 提供连接（Connection），让双法的传输更加的稳定、安全 TCP 没有直接提供会话，因为应用对会话的需求多种多样，比如聊天程序会话会保持双方的聊天记录，电商程序会话会保持购物车、订单一致，所以会话通常在 TCP 连接上进一步封装 TCP 是一个面相连接的协议（Connection-orented Protocol），说的就是 TCP 协议参与的双方（Host）在收发数据之前会先建立连接。 UDP 是一个面向报文（Datagramo-oriented） 的协议双方不需要建立连接，直接传送报文（数据） 最后，连接 u 要消耗更多的资源；比如说，在传输数据前，必须先协商建立连接，因此，不是每种场景都应该用连接导向的协议。比如视频播放的场景，如果使用连接导向的协议，服务端没向客户端推送一帧视频，客户端都要给服务端响应这是不合理的","categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"mybatis-源码分析","slug":"mybatis/mybatis-源码分析","date":"2020-07-28T00:00:00.000Z","updated":"2021-06-20T05:10:29.862Z","comments":true,"path":"2020/07/28/mybatis/mybatis-源码分析/","link":"","permalink":"https://www.shanghua.live/2020/07/28/mybatis/mybatis-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"传统 JDBC 的问题","text":"传统 JDBC 的问题 数据库配置信息存在硬编码问题 解决方法: 1,配置文件 频繁创建释放数据库连接 2,数据库连接池 sql、设置参数,获取结果集均存在硬编码问题 ３，配置文件 手动封装返回结果集，比较繁琐 4,反射，内省 自定义持久层框架设计思路 使用端：（项目）：引入自定义持久层的 jar 包 提供了两部分配置信息：数据库配置信息，sql 配置信息：sql 语句，参数类型，返回值类型 使用配置文件提供这两部分信息 sql Ｍ apConfig.xml 存放数据库配置信息，存放 mapper.xml 的全路径 mapper.xml: 存放 sql 配置信息 自定义持久从逛街本身：（工程）：本质就是对 JDBC 代码进行了封装 加载配置文件：根据配置文件的路径，加载配置文件成字符输入流，存储在内存中 创建 Resource 类 方法 InputStream getResourceAsStream(String path) 创建两个 JavaBean:(容器对象)：存放的就是配置文件解析出来的内容 Configuration:核心配置类：存放 sqlMapConfig.xml 解析的内容 MappedStatement：映射配置类：存放 mapper.xml 解析出来的内容 解析配置文件：dom4j 创建一个类：SqlSessionFactoryBuilder 方法: build (InputStream in) 第一 : 使用 dom4j 解析配置文件，将解析出来的内容封装到容器对象中 第二创建 SqlSessionFactory 对象;生产 sqlSession ：会话对象(工厂模式) 创建 SqlSessionFactory 接口实现类 DefaultSqlSessionFactory 第一 openSession():生产 sqlSession 创建 SqlSession 接口及实现类 DefaultSqlSession 定义对数据库的 crud 操作：selectList(),selectOne(),update(),delete() 创建 Executor 接口及实现类 SimpleExecutor query(Configuration,MappedStatement,Object…params) 执行的就是 JDBC 代码","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"}]},{"title":"mybatis-源码学习","slug":"mybatis/mybatis-源码学习","date":"2020-07-26T00:00:00.000Z","updated":"2021-06-20T05:10:29.989Z","comments":true,"path":"2020/07/26/mybatis/mybatis-源码学习/","link":"","permalink":"https://www.shanghua.live/2020/07/26/mybatis/mybatis-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/","excerpt":"传统 JDBC 弊端","text":"传统 JDBC 弊端 JDBC 底层没有用连接池,操作数据库需要频繁创建和关联链接.消耗很大的资源. 原生 jdbc 代码在 java 中,一旦我们需要修改 sql 的话,java 需要整体编译,不利于系统维护. 使用 PreparedStatement 预编译的话对变量进行设置 123 数字,这样的序号不利于维护. 返回 result 结果集也需要硬编码. mybatis 配置方式 使用 xml 方式并不需要创建 Mapper Class 文件 使用 注解方式需要创建 Mapper Class 文件 mybatis 核心概念 名称 意义 Configuration 管理 mysql-config.xml 全局配置关系类 SqlSessionFactory Session 管理工厂接口 Session SqlSession 是一个面向用户（程序员）的接口。SqlSession 提供了很多操作数据库的方法 Executor 执行其是一个接口（基于执行器、缓存执行器）作用: SqlSession 内部通过执行器操作数据库 MappendStatement 底层封装对象 作用: 对操作数据库存储封装,包括 sql 语句、输入输出 StatementHandler 具体操作数据库相关的 handler 接口 ResultSetHandler 具体操作数据库返回结果的 handler 接口","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"}]},{"title":"vim 入门","slug":"Linux/vim-入门","date":"2020-07-24T00:00:00.000Z","updated":"2021-06-20T05:12:40.753Z","comments":true,"path":"2020/07/24/Linux/vim-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/24/Linux/vim-%E5%85%A5%E9%97%A8/","excerpt":"vim 常用快捷键移动光标","text":"vim 常用快捷键移动光标 h j k l 控制上下作用,也可以使用方向键 ctrl + b 屏幕往后移动一页 f 屏幕往前移动一页 u 屏幕往后移动半页 d 屏幕往前移动半页 shift + g == G 移动文章到最后 4 == $ 移动到所在行的行尾 6 == ^ 移动到光标所在行首 w 光标跳到下一个单词开头 e 光标跳到下一个单词的词尾 b 光标回到上个字的开头 :1 跳到第数字行 gg 进入到文本的开始 常用命令 :nu 显示当前行数 :set nu 显示所有行数 :set expandtab tab 为 4 个空格 :set autoindent 保持当前缩进 复制粘贴 yy 复制光标当前行 p 粘贴到当前光标下一行","categories":[],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://www.shanghua.live/tags/Vim/"}]},{"title":"maven-入门","slug":"maven/maven-入门","date":"2020-07-20T00:00:00.000Z","updated":"2021-06-20T05:10:44.642Z","comments":true,"path":"2020/07/20/maven/maven-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/20/maven/maven-%E5%85%A5%E9%97%A8/","excerpt":"maven 使用简介","text":"maven 使用简介 maven 使用,在项目目录创建 pom.xml 文件,格式是 12345678910111213141516&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wang&lt;/groupId&gt; &lt;artifactId&gt;shanghua-maven&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt;&lt;/project&gt; maven 使用一种约定大于配置的模式,所以项目必须严格按照 maven 的约定进行开发 maven 目录结构 src/main/java 内放如 java 源代码 src/main/resource 资源目录 src/test pom.xml maven 文件 maven 常用命令 mvn clean 清楚打包内容 mvn compile 编译项目 maven 测试 测试文件必须放入到 src/test/java,类名以 Test 开头,方法名以 test 开头 执行 mvn test 即可 执行所以 test 开头方法 编译好的 test 文件 在 target/test-classes 下 测试结果在 target/surefire-reports 下 使用 junit 进行测试,在 pom.xml 内加入 123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 加入后必须在需要执行的方法上加上 @Test 注解才会运行 maven 仓库 本地仓库 可通过修改本地 maven 配置文件 settings.xml &lt;localRepository&gt; 修改仓库目录 远程仓库可通过添加 mirror 节点添加. maven 项目依赖 依赖一个框架的时候,会同时依赖此项目的所以依赖 依赖优先原则 下方的依赖会覆盖上方的依赖 相同路径下的,配置在前优先 依赖范围 &lt;scope&gt; 配置在 &lt;dependency&gt; 下限制依赖范围 compile: 默认,编译范围,编译和打包都会依赖 provided:提供范围,编译时依赖,但不会打包进去,如 server-api.jar runtime: 运行时范围,打包时依赖,编译不会,如 mysql-connector.jar test: 测试范围,运行测试用例依赖,如 junit.jar, test jar 包只有 src/test 内的文件才能引用 system: 表示由系统中的 CLASSPATH 指定,编译时依赖,不会打包进去,配合 &lt;systemPath&gt; 一起使用,如 java.home 下的 tool.jar maven 依赖管理 父类内可声明 &lt;dependencyManagement&gt; 内部可写 &lt;dependencies&gt; 子类依赖父类后,并不会直接依赖父类 &lt;dependencyManagement&gt; 内声明的内容,只有声明后才会依赖,依赖可省略版本号 maven 默认属性 $&#123;basedir&#125; 项目根目录 $&#123;version&#125; 项目版本 $&#123;project.basedir&#125; 同 $&#123;basedir&#125; $&#123;project.version&#125; 同 $&#123;version&#125; $&#123;project.build.directory&#125; 构建目录,缺省为 target $&#123;project.build.sourcceEncoding&#125; 表示主源码的编码格式 $&#123;project.build.sourceDirectory&#125; 表示主源码路径 $&#123;project.build.finalName&#125; 表示输出文件名称 $&#123;project.build.outputDirectory&#125; 构建过程输出目录,缺省 target/classes 默认属性可在 resource 目录下配置文件 以及 pom.xml 内使用, 属性还可以通过 执行 mvn 命令是加入 -D 参数添加 项目生命周期123graph LRA[预编译] --&gt;B[编译] --&gt; C[编译测试类] --&gt; D[构建] --&gt; G[jar 包构建] --&gt; F[部署]D --&gt; H[war 包构建] --&gt; F[部署] maven 生命周期 clean : 清理生命周期,用于清理项目 default:默认生命周期,用于编译,打包,测试,部署等 site: 站点文档生成,用于构建站点文档 当执行下面生命周期的目录时,会将上方的生命周期走一边 maven 生命周期命令大部分是由插件完成的,例如 test 就是由 maven-surefire-plugin","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"}]},{"title":"maven-插件","slug":"maven/maven-插件","date":"2020-07-20T00:00:00.000Z","updated":"2021-06-20T05:10:44.547Z","comments":true,"path":"2020/07/20/maven/maven-插件/","link":"","permalink":"https://www.shanghua.live/2020/07/20/maven/maven-%E6%8F%92%E4%BB%B6/","excerpt":"maven 命令 mvn dependency:tree 可查看插件的依赖关系","text":"maven 命令 mvn dependency:tree 可查看插件的依赖关系 mvn archetype:generate 使用 maven 生成项目 mvn help:effective-pom maven 插件绑定 生命周期的阶段可以绑定具体的插件及目标 不同配置下同一阶段可以对应多个插件和目标 maven 绑定插件的目录在 MAVEN_HOME\\lib\\maven-core.jar\\META-INF\\plexus\\default-bindings.xml maven 插件使用示例 123456789101112131415161718192021222324&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;!-- 在执行 package后 将依赖复制到 $&#123;project.build.directory&#125;/alternateLocation 目录下--&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;!-- 指定 goal 执行位置--&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- 指定配置文件--&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/alternateLocation&lt;/outputDirectory&gt; &lt;overWriteReleases&gt;false&lt;/overWriteReleases&gt; &lt;overWriteSnapshots&gt;false&lt;/overWriteSnapshots&gt; &lt;overWriteIfNewer&gt;true&lt;/overWriteIfNewer&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 插件使用第二种方法 mvn groupId:artifactId:version:goal -D{参数名} 插件开发流程 创建 maven 插件项目 设定 packaging 为 maven-plugin 添加插件依赖 编写插件实现逻辑 打包构建插件 插件 pom 配置 创建 maven 项目 定义&lt;packaging&gt;maven-plugin&lt;/packaging&gt; 引入 maven-plugin-api maven-plugin-annotations 依赖 插件方法类继承 org.apache.maven.plugin.AbstractMojo 实现 execute 方法 可在全局变量上方加上 org.apache.maven.plugins.annotations.Parameter 注解,获取 maven 参数 maven nexus 私服 搭建完成后可通过添加 repositories 制定 maven 服务器 也可通过修改 maven setting.xml 中的 mirrors 全局指定服务器 如需要 deploy jar 包到私服,需要在 pom.xml 下的 distributionManagement 下制定私服地址,并在 setting.xml 文件下添加 server 节点添加用户获取权限,并且 server 下的 id 需要与 distributionManagement 下的 id 对应","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"}]},{"title":"git-入门","slug":"Git/git-入门","date":"2020-07-17T00:00:00.000Z","updated":"2021-06-20T05:11:51.904Z","comments":true,"path":"2020/07/17/Git/git-入门/","link":"","permalink":"https://www.shanghua.live/2020/07/17/Git/git-%E5%85%A5%E9%97%A8/","excerpt":"git 存储文件时候会将一个文件存储到一个数据库中","text":"git 存储文件时候会将一个文件存储到一个数据库中 git 常用命令 git init ./目录名 初始化，初始化后会创建一个 .git 文件夹 元数据存储在 objects 中 git add 将文件存储到暂存取 -A 将所有文件存储到暂存取 git rm –cached 将文件从暂存区删除，本地文件并不会被删除 git commit filename -m ‘first commit’ 将暂存区文件提交到本地仓库 git push -u origin master 将本地仓库提交到远程仓库 master git config –list 查看 git 配置环境 git show 查看最后一次提交 git 分支相关命令 git branch 默认查看分支 -avv 查看所有分支 -d 删除分支 git branch 分支名 父分支名 创建一个分支 git gc 当强制删除一个分支的时候，分支内的信息还是存在的，通过这个命令可打包项目信息，跳过删除的信息 git 解决冲突 当远程仓库内容被修改，pull 的时候由于本地仓库与远程仓库文件冲突，会进入到一个解决冲突的分支，需要解决冲突后，重新执行 add commit push 操作解决冲突 git 远程仓库 git remote add origin url 指定远程仓库 git remote add origin2 url 添加远程仓库 git remote origin set-url url 修改远程地址 git remote temove 分支名 删除远程仓库 git push –set-upstream origin master 上传至远程分支 git branch –track git tag git tag 查看当前 tag git tag tag 名 创建 tag git 日志管理 git log 查看日志 –oneline 简单查看 –graph 图形网络 git log 分支名 查看某个分支的日志 git log dev..master 查看多少个 master 没有提交到 dev 内 git 底层原理 git 存储对象(hashMap) find .git/objects/ -type f 查找所有 git 对象 git hash-object -w filename 存储一个文件，并返回 hash，相当与 git add git cat-file -p hash 通过 hash 查看文件内容，我们并不知道文件内容属于哪个文件 git cat-file -p master^{tree} 查看一个提交的文件的信息，包含文件名 git commit 提交会包含一个 commit 对象，对象包含一个文件对象，包含文件名以及对应的 keycommit 对象 还包含一个 src 树对象 书对象包含 层级目录对象，直至目录中的文件，文件包含文件名以及 key 通过 git log 可查看 commit 对象包含的 keygit cat-file -p key 可查看 commit 包含的内容内容包含一个 tree 对象以及一个树对象一个新 commit 产生的时候 改变的文件会将 上级的 key 改变 直到 commit key git 创建中央仓库 git init –bare shanghua.git 创建裸项目，只要能访问这个目录就能进行开发，甚至是共享文件夹 git clone root@ip:项目目录 通过这条命令可访问上一条命令在远程仓库创建的项目，通过 ssh 协议搭建 中央仓库 通过 nginx 搭建 http 中央仓库 http(dump) 协议 1234567server&#123; listen 80; server_name git.shanghua.com; location / &#123; root /data/git-repository; # 仓库地址 &#125;&#125; 重命名钩子mv hooks/post-update.sample hooks/post-update 本地克隆 git clone http://git.shanghua.com/shanghua.git 通过 git 协议搭建远程仓库 git 协议 123nohup git daemon --reuseaddr --base-path=&#x27;项目目录&#x27; &#x27;项目目录&#x27;默认端口是 9418git clone git://ip:9418/shanghua.git shanghua git 服务器搭建git gogs 服务器 gogs 官网 https://gogs.io/ 下载安装包 解压进入 gogs 目录 ./gogs web 即可运行 浏览器访问本地 ip:3000 即可初始化项目 gogs 可配置 邮箱服务器 gogs 备份 ./gogs backup -h 查看备份相关参数 ./gogs backup 默认备份,备份在当前目录 ./gogs backup –target=’输出目录’ –database-only –exclude-repos ./gogs restore –from=’备份文件’ 备份恢复","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://www.shanghua.live/tags/git/"}]},{"title":"IDEA 破解教程","slug":"Java/idea-破解","date":"2020-05-08T10:38:00.000Z","updated":"2021-06-20T05:09:17.259Z","comments":true,"path":"2020/05/08/Java/idea-破解/","link":"","permalink":"https://www.shanghua.live/2020/05/08/Java/idea-%E7%A0%B4%E8%A7%A3/","excerpt":"下载破解 jar 包 下载地址 下载后解压","text":"下载破解 jar 包 下载地址 下载后解压 打开 IDEA 在试用模式下点击 Help –&gt; Edit Custom VM Option 第一次点击会让创建一个文件，点击确定 在最后一行加入 -javaagent:你解压后jar包的位置 重启 IDEA IDEA 启动后点击 Help –&gt; Register –&gt; License server 在 Server address 内输入 http://fls.jetbrains-agent.com 点击 ACTIVATE 成功后点击 CONTINUE DONE 使用方法来自 https://zhile.io/2018/08/25/jetbrains-license-server-crack.html","categories":[],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://www.shanghua.live/tags/IDEA/"}]},{"title":"可转债","slug":"股市/可转债","date":"2020-04-28T20:16:00.000Z","updated":"2021-06-20T05:12:09.575Z","comments":true,"path":"2020/04/29/股市/可转债/","link":"","permalink":"https://www.shanghua.live/2020/04/29/%E8%82%A1%E5%B8%82/%E5%8F%AF%E8%BD%AC%E5%80%BA/","excerpt":"打新可转债 判断新债 https://www.jisilu.cn/data/cbnew/#pre","text":"打新可转债 判断新债 https://www.jisilu.cn/data/cbnew/#pre 先价比转股甲 先价比转股价 &gt; 95% 评级 AA、AA+、AAA 可转债说明可转换是一张可以转化成股票的公司债券 可转债 债券 在可转债到期后公司需要连本带息还钱 100￥ + 利息 &gt; 100￥ 在 &lt; 100人民币 买入可保本 可转换为股票 可转债会随着股票的价格增长而增长 尽可能购买评级高的股票 防御性买入法（慢） 买入价格 &lt; 100￥ 评级 AA 级以上 进攻型买入法（快） 溢价率低于 20% 上市满足半年 价格低于 110 评级至少为 至少AA 怎么卖 上涨不卖 最高点 跌 10 元卖出","categories":[],"tags":[]},{"title":"elasticsearch 与 Head 插件","slug":"other/elasticsearch","date":"2020-04-08T00:00:00.000Z","updated":"2021-06-20T05:13:06.480Z","comments":true,"path":"2020/04/08/other/elasticsearch/","link":"","permalink":"https://www.shanghua.live/2020/04/08/other/elasticsearch/","excerpt":"","text":"基础命令 查询 进入 Head 插件 复合查询 http://localhost:9200/ _analyze POST Body &#123;&quot;analyzer&quot;:&quot;ik_smart&quot;,&quot;text&quot;:&quot;php java&quot;&#125;","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.shanghua.live/tags/elasticsearch/"}]},{"title":"MongoDB 的安装和使用","slug":"other/MongoDB","date":"2020-04-03T15:44:15.000Z","updated":"2021-06-20T05:13:06.830Z","comments":true,"path":"2020/04/03/other/MongoDB/","link":"","permalink":"https://www.shanghua.live/2020/04/03/other/MongoDB/","excerpt":"安装 MongoDB 进入到 https://www.mongodb.com/download-center/community 即可选择符合你操作系统的安装包 按照安装包指示的流程安装即可 安装完成后将安装后的 bin 目录加入到系统 path 环境变量中","text":"安装 MongoDB 进入到 https://www.mongodb.com/download-center/community 即可选择符合你操作系统的安装包 按照安装包指示的流程安装即可 安装完成后将安装后的 bin 目录加入到系统 path 环境变量中 使用 MongoDB 创建目录 打开命令提示符 创建存放数据的目录 md d:\\data 启动服务 mongod ‐‐dbpath=d:\\data 连接 mongo 192.168.184.134 常用命令 创建数据库 use 数据库名 数据库不存在则会自动创建 use spit 插入数据 db.数据库名.insert(数据); db.spit.insert(&#123;content:&quot;aaa&quot;,userid:&quot;1011&quot;,nickname:&quot;小雅&quot;,visits:NumberInt(902)&#125;); 查询数据 db.集合名称.find(); db.spit.find(); 可以发现，每个数据库文档都会自动创建一个 _id 字段，相当于数据库的主键，我们可以插入支持的类型值替换 db.spit.insert(&#123;_id:&quot;1&quot;,content:&quot;aaa&quot;,userid:&quot;1012&quot;,nickname:&quot;小明&quot;,visits:NumberInt(2020)&#125;); 条件查询 db.spit.find(&#123;userid:&#39;1011&#39;&#125;) 查询一个 db.spit.findOne(&#123;userid:&#39;1013&#39;&#125;) 指定条数 db.spit.find().limit(3) 修改数据 db.集合名称.update(条件,修改后的数据) 修改 _id 为 1 的记录 db.spit.update(&#123;_id:&quot;1&quot;&#125;,&#123;visits:NumberInt(1000)&#125;) 修改后除了 visits 字段其他字段都不见了，我们可以使用 $set 解决 db.spit.update(&#123;_id:&quot;2&quot;&#125;,&#123;$set:&#123;visits:NumberInt(2000)&#125;&#125;) 删除数据 db.集合名称.remove(条件) 入过没条件则全部删除 慎用！ db.集合名称.remove(&#123;visits:1000&#125;) 删除 visits 为 100 的值 统计条数 db.spit.count() db.spit.count(&#123;userid:&quot;1012&quot;&#125;) 统计 userid 为 1012 的数量\\ 模糊查询 /模糊查询字符串/ db.spit.find(&#123;content:/流量/&#125;) db.spit.find(&#123;content:/^加班/&#125;) 大于 小于 不等于 db.集合名称.find(&#123; &quot;field&quot; : &#123; $gt: value &#125;&#125;) // 大于: field &gt; value db.集合名称.find(&#123; &quot;field&quot; : &#123; $lt: value &#125;&#125;) // 小于: field &lt; value db.集合名称.find(&#123; &quot;field&quot; : &#123; $gte: value &#125;&#125;) // 大于等于: field &gt;= value db.集合名称.find(&#123; &quot;field&quot; : &#123; $lte: value &#125;&#125;) // 小于等于: field &lt;= value db.集合名称.find(&#123; &quot;field&quot; : &#123; $ne: value &#125;&#125;) // 不等于: field != value 包含与不包含 db.spit.find(&#123;userid:&#123;$in:[&quot;1013&quot;,&quot;1014&quot;]&#125;&#125;) 查询 useid 字段包含 1013 和 1014 的文档 db.spit.find(&#123;userid:&#123;$nin:[&quot;1013&quot;,&quot;1014&quot;]&#125;&#125;) 查询 useid 字段不包含 1013 和 1014 的文档 条件连接 $and:[ &#123; &#125;,&#123; &#125;,&#123; &#125; ] 相当于 SQL 中的 AND db.spit.find(&#123;$and:[ &#123;visits:&#123;$gte:1000&#125;&#125; ,&#123;visits:&#123;$lt:2000&#125; &#125;]&#125;) 查询 visits 大于 1000 并且小于 2000 的文档 $or:[ &#123; &#125;,&#123; &#125;,&#123; &#125; ] 相当于 SQL 中的 OR db.spit.find(&#123;$or:[ &#123;userid:&#123;$gte:&quot;1013&quot;&#125;&#125; ,&#123;visits:&#123;$lt:2000&#125; &#125;]&#125;) 查询 userid 等于 1013 并且 visits 小于 2000 的文档 列值增长 db.spit.update(&#123;_id:&quot;2&quot;&#125;,&#123;$inc:&#123;visits:NumberInt(1)&#125;&#125;)","categories":[],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.shanghua.live/tags/MongoDB/"}]},{"title":"K8s(kubernetes) 简介","slug":"other/k8sAbout","date":"2020-03-30T20:50:23.000Z","updated":"2021-06-20T05:13:06.663Z","comments":true,"path":"2020/03/31/other/k8sAbout/","link":"","permalink":"https://www.shanghua.live/2020/03/31/other/k8sAbout/","excerpt":"kubernetes容器编排工具，是一个开源的平台，可以实现容器集群的自动化部署，自动扩缩容，维护等功能","text":"kubernetes容器编排工具，是一个开源的平台，可以实现容器集群的自动化部署，自动扩缩容，维护等功能 快速部署应用 快速扩展应用 无缝对接新的应用功能 节省资源，优化硬件资源应用 特点 可移植 支持公有云（阿里云，腾讯云），私有云（OpenStack），混合云，多重云（多个公有云） 可扩展 模块化，插件化，可挂载，可组合 自动化 自动部署，自动重启，自动复制，自动伸缩/扩展 kubernetes 的目标是促进完善组件和工具的生态系统，已减轻应用程序在公有云或私有云运行的负担","categories":[],"tags":[{"name":"k8","slug":"k8","permalink":"https://www.shanghua.live/tags/k8/"}]},{"title":"使用 SSH 连接 Ubuntu","slug":"Linux/ubuntu-ssh","date":"2020-03-30T20:27:22.000Z","updated":"2021-06-20T05:11:39.044Z","comments":true,"path":"2020/03/31/Linux/ubuntu-ssh/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Linux/ubuntu-ssh/","excerpt":"软件准备FinalShell 软件官网 http://www.hostbuf.com/ 因为我们之前安装系统的时候已经安装过 SSH 了，这里我们直接连接就好了","text":"软件准备FinalShell 软件官网 http://www.hostbuf.com/ 因为我们之前安装系统的时候已经安装过 SSH 了，这里我们直接连接就好了 第一步查看 IP 地址，在命令行输入 ifconfig 123456789shanghua@ubuntu:~$ ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.1.103 netmask 255.255.255.0 broadcast 192.168.1.255 inet6 fe80::20c:29ff:fe32:75e2 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:32:75:e2 txqueuelen 1000 (Ethernet) RX packets 29766 bytes 43406394 (43.4 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 3187 bytes 257063 (257.0 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 这里我的 IP 地址就是 192.168.1.103 打开 FinalShell 并新建一个连接 点击确定，这样我们就连接成功了 12345连接成功To run a command as administrator (user &quot;root&quot;), use &quot;sudo &lt;command&gt;&quot;.See &quot;man sudo_root&quot; for details.shanghua@ubuntu:~$ 这里我们就获得了一个 shell 就可以直接操作虚拟机里的系统了 设置 ROOT 用户12345shanghua@ubuntu:~$ sudo passwd root[sudo] password for shanghua:Enter new UNIX password:Retype new UNIX password:passwd: password updated successfully 先输入当前用户密码，然后再输入两次 ROOT 账户密码，这样就设置成功了 切换到 ROOT 用户123shanghua@ubuntu:~$ suPassword:root@ubuntu:/home/shanghua# 我们输入 su 命令，然后再输入我们刚刚设置的 ROOT 密码就可以切换到 ROOT 用户了，我们可以从命令行看到，用户从 shanghua 变成了 root 配置 SSH 允许 ROOT 用户远程连接1root@ubuntu:/home/shanghua# vi /etc/ssh/sshd_config 12#PermitRootLogin prohibit-passwordPermitRootLogin yes 修改 SSH 配置文件，将 PermitRootLogin 后面的 prohibit-password 修改为 yes 重启 SSH 服务1root@ubuntu:/home/shanghua# service ssh restart 重启后 ssh 配置文件才会生效哦 编辑 FinalShell 连接改为 root 用户 记得改密码哦，修改完成点击确定，然后打开这个连接 12连接成功root@ubuntu:~# 这样就会发现连接上后就是 root 用户了","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"}]},{"title":"python 换源","slug":"Python/python换源","date":"2020-03-30T20:27:21.000Z","updated":"2021-06-20T05:12:32.389Z","comments":true,"path":"2020/03/31/Python/python换源/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Python/python%E6%8D%A2%E6%BA%90/","excerpt":"环境 平台 Windows 10python 3","text":"环境 平台 Windows 10python 3 临时换源1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple 永久换源在 %HOMEPATH%\\pip 目录下新建 pip.ini 文件，内容如下(如果没有 pip 文件夹，新建一个即可 ) 1234[global]timeout = 6000index-url = https://mirrors.aliyun.com/pypi/simple/trusted-host = mirrors.aliyun.com","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.shanghua.live/tags/Python/"}]},{"title":"java - 算法","slug":"Java/java-算法","date":"2020-03-30T20:27:15.000Z","updated":"2021-06-20T05:09:18.567Z","comments":true,"path":"2020/03/31/Java/java-算法/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E7%AE%97%E6%B3%95/","excerpt":"排序算法分类 计算复杂度：最佳、最坏以及平均复杂度","text":"排序算法分类 计算复杂度：最佳、最坏以及平均复杂度 内存使用：空间复杂度 递归算法：排序算法中是否用到了递归 稳定性：当相同的健存在时，经过排序后，其值也保持相对的顺序（不发生变化） 比较排序：集合中的两个元素比较排序 串行或并行：是否运用串行或并行排序 时间复杂度表达式（Time Complexity） 表达式：Big O notation 常量时间：T(n) = O(1)(数组随机访问) 线性时间：T(n) = O(n)(在未排序数组中找最值) 对数时间：T(n) = O(n)(二级制搜索) 指数时间：T(n) = O(n^c)(冒泡排序、插入排序) 比较排序 冒泡排序(Bubble Sort)：最佳 O(n)、平均 O(n^2)、最坏 O(n^2) 插入排序(Insertion Sort)：最佳 O(n)、平均 O(n^2)、最坏 O(n^2) 快速排序(Quick Sort)：最佳 O(nlogn)、平均 O(nlong)、最坏 O(n^2) 合并排序(Merge Sort)：最佳 O(nlogn)、平均 O(nlong)、最坏 O(nlong) Tim 排序(Tim Sort)：最佳 O(n)、平均 O(nlong)、最坏 O(nlong) 内建实现 冒泡排序(Bubble Sort)：无 插入排序(Insertion Sort)：java.util.Arrays#megeSort （当排序集合数量小于 7 时） 快速排序(Quick Sort)：java.util.DualPivotQuicksort#sort（Since 1.7） 合并排序(Merge Sort)：java.util.Arrays#megeSort （1.7 之后需要激活） Tim 排序(Tim Sort)：java.util.TimSort （Since 1.7）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"算法","slug":"算法","permalink":"https://www.shanghua.live/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"java 面向对象设计二","slug":"Java/java 面向对象设计二","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.375Z","comments":true,"path":"2020/03/31/Java/java 面向对象设计二/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E4%BA%8C/","excerpt":"Java 泛型设计泛型使用场景 编译时强类型转换 避免类型强转 实现通用算法","text":"Java 泛型设计泛型使用场景 编译时强类型转换 避免类型强转 实现通用算法 泛型类型A generic type is a generic class or interface that is parameterized over types. 调用泛型类型 实例化泛型 java 7 Diamond 类型参数命名约定 类型参数命名约定 E: 表示集合元素（Element） V: 表示数值（Value） K: 表示键（Key） T: 表示类型 可以参考 java.util.function.BiConsumer 类的写法 泛型有界类型参数 单界限 多界限 泛型方法和有界类型参数","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 函数式设计","slug":"Java/java-函数式设计","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.859Z","comments":true,"path":"2020/03/31/Java/java-函数式设计/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E5%87%BD%E6%95%B0%E5%BC%8F%E8%AE%BE%E8%AE%A1/","excerpt":"@Functionallnterface用于函数式接口类型声明的信息注解类型，这些接口的实例被 Lambda 表示式、方法引用或构造器引用创建。函数时接口只能有一个抽象方法，","text":"@Functionallnterface用于函数式接口类型声明的信息注解类型，这些接口的实例被 Lambda 表示式、方法引用或构造器引用创建。函数时接口只能有一个抽象方法，并排除默认方法以及声明中覆盖 Object 的公开方法的统计。同时 @Functionallnterface 不能标注在注解，类以及枚举上。如果违背以上规则，那么接口不能视为函数式接口，当标注 @Functionallnterface 后，会引起编译错误。 不过，如果任意接口满足以上函数式接口的要求，无论接口生命中是否标注 @Functionallnterface ，均能被编译器视作函数式接口。 函数式接口类型 提供类型 - Supplier&lt;T&gt; 消费类型 - Consumer&lt;T&gt; 转换类型 - Function&lt;T,R&gt; 断定类型 - Predicate&lt;T&gt; 隐藏类型 - Action 函数式接口设计Supplier&lt;T&gt; 接口定义 基本特点：只进不出 编程范式：作为方法/构造参数，方法的返回值 使用场景：数据来源，代码替代接口 Function&lt;T,R&gt; 接口定义 基本特点：有进有出 编程范式：作为方法/构造器参数 使用场景：类型转换、业务处理 Predicate&lt;T&gt; 接口定义 基本特点：boolean 类型判断 编程范式：作为方法/构造参数 使用场景：过滤、对象比较等 Stream API 设计Stream 基本操作 转换：Stream#map(Function) 过滤：Stream#filter(Predicate) 排序 Stream#sorted() Stream#sorted(Comparator) Stream 高级操作 Collect 操作 分组操作 聚合操作 flatMap 操作 reduce 操作 Stream 类型 串行 Stream（默认类型） 并行 Stream 转换并行 Stream：Stream#parallel() 是否并行 Stream：Stream#isParallel()","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 并发理论基础","slug":"Java/java-并发理论基础","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:17.488Z","comments":true,"path":"2020/03/31/Java/java-并发理论基础/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E5%B9%B6%E5%8F%91%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/","excerpt":"同步实现 信号量 (Semaphores)：Linux、Solaris 屏障（Barriers）：Linux、Pthreads","text":"同步实现 信号量 (Semaphores)：Linux、Solaris 屏障（Barriers）：Linux、Pthreads 互斥（Mutex）：Linux、Pthreads 条件变量（Condition Variables）：Solaris、Pthreads 自旋锁（Spinlock）：Windows、Linux、Pthreads 读-写锁（Reader-Writer Lock）：Linux、Solaris、Pthreads 同步原语 - synchronized 锁定对象：对象（Object）和类（Class） 修饰范围：方法（Method）、代码块（Block） 特点：重进入（Reentrant） 方法 flages：ACC_SYNCHRONIZED 字节码：monitorenter 和 monitorexit 锁实现：Thin Lock、Inflated、HeavyWeight 实战演示 Java 线程死锁（Dead Lock） Java 线程集合（Starvation）","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 模块化设计","slug":"Java/java-模块化设计","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:18.488Z","comments":true,"path":"2020/03/31/Java/java-模块化设计/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E6%A8%A1%E5%9D%97%E5%8C%96%E8%AE%BE%E8%AE%A1/","excerpt":"java -verbose:class Java Compact 模块路径模块路径可能是单个 artiface，或者是多个 artiface 的目录，存在于宿主机器上。","text":"java -verbose:class Java Compact 模块路径模块路径可能是单个 artiface，或者是多个 artiface 的目录，存在于宿主机器上。 类路径（Class Path）的脆弱性 通过 artifaces 的 Class Path 区分类型 无法区分 artifaces 无法提前通知 artifaces 缺少 允许不同的 artifaces 定义在相同的 packages 定义类型 模块路径的差异性 定位整个模块而非类型 无论是运行时，还是编译时，在同一个目录下不允许出现同名模块 可读性（Readability）模块 com.foo.app 依赖 模块 com.foo.bar 和 java.sql，说明 java.sql 对 com.foo.app 是可读的。同时，java.sql 依赖 java.xml 和 java.logging 模块，然而这并不意味着 java.xml 或 java.logging 对 com.foo.app 可读。简言之，可读性无法跨层模块之家生效 Java 模块化迁移 非命名模块（Unnamed moudule） 类型加载于 ClassPath，而非具体模块，如遗留 jar 文件，暴露所有的 packages。 命名模块（Named modules） 所有正常的 Java 模块，packages 暴露受限于 exports – 自动模块（automatic module） 假设我们需要使用 Spring ListenableFuture API，它来自于 org.springframework:spring-core，由于该 jar 文件属于非命名模块，并且其 artifactid 为 spring-core，该 ID 命名的方式对于模块化名词是非法的。 我们能够在模块路径下能后使用”自动模块”替代 spring-core-*.jar 即使有 spring.core 模块 迁移分析 需要明确应用实现依赖的 JDK 模块 需要明确二方或三方 jar 所依赖的 JDK 模块 需要微服务化应用 迁移建议 凡是定义 module-info.java(module-info.class) 属于命名模块（java 9 + 模块化 artiface） java 9 之前的 artiface 属于命名模块 自动化模块 如果在 MANIFEST.MF 定义了 Automatic-Module-Name 属性，那么采用该属性值作为模块名称 否则，使用 jar 文件的名称(如果存在 “-“ 将其替换为”.”) Java 模块反射获取模块 获取模块 - Class#getModule() 模块接口 - Module 模块描述文件接口 - ModuleDescriptor","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 面向对象设计一","slug":"Java/java-面向对象设计一","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:09:18.234Z","comments":true,"path":"2020/03/31/Java/java-面向对象设计一/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E4%B8%80/","excerpt":"Java 接口设计通用设计","text":"Java 接口设计通用设计 类/接口名 模式：（形容词） + 名词 举例 单名词：java.lang.String 双名词：java.util.ArrayList 形容词+名词：java.util.LinkedList 可访问性 public：开放 API 使用场景 举例：java.lang.String (默认)：仅在当前 package 下使用，属于私有 API 举例：java.io.FileSystem 四种修饰符 public (default) protected : 不能用于修饰最外层 class private : 不能用于修饰最外层 class 可继承性 final：final 不具备继承性，仅用于实现类，不能与 abstract 关键字同时修饰类 举例：java.lang.String 非 final：最常见/默认的设计手段，可继承性依赖于可访问性 举例：java.io.FileSystem 具体类设计常见场景 功能组件 HashMap 接口/抽象类实现 HashMap &lt;- AbstractMap &lt;- Map 数据对象 POJO 工具辅助 *Utils ViewHelper Helper 命名模式 前缀模式：”Default”、”Generic”、”Common”、”Basic” 后缀模式：”impl” 抽象类设计抽象类常见场景 接口通用实现（模板模式） Spring *Template AbstractList AbstractSet AbstractMap 状态/行为继承 工具类 常见模式 抽象程序介于类与接口之间（java 8+ 可完全由接口替换） 以 “Abstract” 或 “Base” 类名前缀 java.util.AbstractCollection javax.sql.rowset.BaseRowSet 接口设计接口设计常见场景 上下游系统（组件）通讯契约 API RPC 常量定义 Serializable Cloneable AutoCloseable EventListener 接口设计常见模式 无状态（Stateless） 完全抽象（&lt; Java 8） 局部抽象（Java 8+） 单一抽象（Java 8 函数式接口） 内置类设计内置类常见场景 临时数据存储类：java.lang.ThreadLocal.ThreadMap 特殊用途的 API 实现：java.util.Collection.UnmodifiableCollection Builder 模式（接口）：java.util.stream.Stream.Builder Java 枚举设计“枚举类” 枚举(enum)实际是 final class， 枚举(成员)修饰符为 public static final values 是 java 编译器做的字节码提升 场景：Java 枚举（enum）引入之前的模拟枚举实现类 模式： 成员用常量表示，并且类型为当前类型 常用关键字 final 修饰 非 public 构造器 枚举基本特性 类结构（强类型） 继承 java.lang.Enum 不可显示地继承和被继承","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"进程-线程-协程","slug":"Java/进程-线程-协程","date":"2020-03-30T20:27:00.000Z","updated":"2021-06-20T05:11:08.745Z","comments":true,"path":"2020/03/31/Java/进程-线程-协程/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/%E8%BF%9B%E7%A8%8B-%E7%BA%BF%E7%A8%8B-%E5%8D%8F%E7%A8%8B/","excerpt":"进程指计算机中已运行的程序。进程为曾经是分时系统的基本运作单位。在面向进程设计的系统中，进程是程序的基本执行实体；在面向线程设计的系统中，进程本身不是基本运行单位，而是线程的容器。程序本身只是指令、数据以及其组织形式的描述，进程才是程序的真正运行实例","text":"进程指计算机中已运行的程序。进程为曾经是分时系统的基本运作单位。在面向进程设计的系统中，进程是程序的基本执行实体；在面向线程设计的系统中，进程本身不是基本运行单位，而是线程的容器。程序本身只是指令、数据以及其组织形式的描述，进程才是程序的真正运行实例 线程操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程的实际操作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程可以并发多个线程，每条线程并行执行不同的任务。在Unix System V 及 SunOS 中也被称为轻量进程，但轻量进程更多指内核线程，而把用户线程称为线程 Java 线程Green Thread （绿色线程）java 1.2 之前的 Java Thread 实现，模拟多线程并发 Native OS Thread （原生 OS 线程）java 1.2 之后 Java Thread 实现，基于 OS 线程实现，数量映射 1:1 Java 线程编程模型 &lt; Java 5：Thread、Runnable Java 5：Executor、Future、Callable Java 7：ForkJoin Java 8：CompletionStage、CompletableFuture Java 9：Flow（Publisher、Subscriber、Subscription、Processor） Java 线程池 &lt; Java 5：自定义 Thread Pool Java 5+：ExecutorService ThreadPoolExecutor ScheduledThreadPoolExecutor Java 7+ ForkJoinPool Java 并发框架 Java 5：Java Util Concurrent Java 7：Fork/Join Java 8：CompletabFuture、RxJava、Reactor Java 9：Flow API、Reactive Streams 同步最常见的编程手段，是指任务发起和执行方在同一线程完成 异步常见的提升吞吐手段，是指任务发起方和执行方在不同线程中完成 非阻塞一种编程模型，由通知状态被动的回调执行，同步或异步执行均可 POSIX 线程POSIX 线程（英文：POSIX Threads，常被缩写为 Pthreads）是 POSIX 的线程标准，定义了创建和操纵线程的一套 API 实现 POSIX 线程标准的库常被称作 Pthreads，一般用于 Unix-like POSIX 系统，如 Linux Solaris。但是 Microsoft Windows 上的实现也存在，例如直接使用 Windows API 实现的第三方库 pthreads-w32；而利用 Windows 的 SFU/SUA 子系统，则可以直接使用微软提供的一部分原生 POSIX API - https://sourceware.org/pthreads-win32/ Java 线程状态API - java.lang.Thread.State（Since 1.5） NEW：线程已创建，尚未启动 RUNNABLE：表示线程处于可运行状态，不代表一定运行 BLOCKED：被 Monitor 锁阻塞，表示当前线程在同步锁的场景运作 WAITTING：线程处于等待状态，由 Object#wait()、Thread#join() 或 LockSupport#park() TIMED_WAITTING：线程处于规定时间内的等待状态 TERMINATED：线程执行结束 使用场景线程堆栈 工具 - jstack JMX - java.lang.management.ThreadMXBean#dumpAllThreads(boolean,boolean) API - java.lang.Thread#dumpStack() 生命周期方法 启动 - java.lang.Thread#start() 停止 - java.lang.Thread#stop() 暂停 - java.lang.Thread#suspend() 恢复 - java.lang.Thread#resume() “中止” - java.lang.Thread#interrupt()、java.lang.Thread#isInterrupted()","categories":[],"tags":[]},{"title":"Java 进程管理","slug":"Java/java-进程管理","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:18.156Z","comments":true,"path":"2020/03/31/Java/java-进程管理/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"管理当前 JVM 进程 获取当前 JVM 进程 ID 获取当前 JVM 进程启动时间","text":"管理当前 JVM 进程 获取当前 JVM 进程 ID 获取当前 JVM 进程启动时间 获取当前 JVM 进程线程数量 获取当前 JVM 内存使用情况 退出当前 JVM 进程 管理子进程 启动子进程 进程 API 主子进程 I/O 交互 阻塞进程 退出进程","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 集合便利实现","slug":"Java/java-集合便利实现","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:17.970Z","comments":true,"path":"2020/03/31/Java/java-集合便利实现/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9B%86%E5%90%88%E4%BE%BF%E5%88%A9%E5%AE%9E%E7%8E%B0/","excerpt":"接口类型 单例集合接口（Collections.singleton*） 空集合接口（Collections.empty*） 转换集合接口（Collections.*、Arrays.*） 列举集合接口（*.of(…)）","text":"接口类型 单例集合接口（Collections.singleton*） 空集合接口（Collections.empty*） 转换集合接口（Collections.*、Arrays.*） 列举集合接口（*.of(…)） 单例集合接口 List: Collections.singletonList(T) Set: Collections.singleton(T) Map: Collections.singletonMap(K,V) 设计原则：不变集合（Immutable Collection）空集合接口（Collections.empty*） 枚举：Collections.emptyEnumeration() 迭代器：emptyIterator()、emptyListIterator() List：emptyList() Set：emptySet()、emptySortedSet、emptyNavigableSet() Map：emptyMap、emptySortedMap、emptyNavigableSet() 转换集合接口（Collections.*、Arrays.*） Enumeration：Collections.enumeration(Collection) List: Collections.list(Enumeration&lt;T&gt;)、Arrays.asList(T…) Set：Collections.newSetFromMap(Map&lt;E,Boolean&gt;) Queue：Collections.asLifoQueue(Deque&lt;T&gt;) HashCode：Arrays.hashCode(…) String：Arrays.toString(…) 列举集合接口 (*.of(…)) java.util.BitSet.valueOf(…) java.util.EnumSet.valueOf(…)(Since 1.5) java.util.Stream.valueOf(…) (Since 1.8) java.util.List.valueOf(…) (Since 9) java.util.Set.valueOf(…) (Since 9) java.util.Map.valueOf(…) (Since 9) 包装接口类型 同步包装接口（java.util.Collections.synchronized*） 只读包装接口（java.util.Collections.unmodifiable*) 类型安全包装接口（java.util.Collections.checked*） JAVA 集合 特殊实现 基本介绍为特殊场景设计实现，这些实现表现出非标准性能特性，使用限制或行为。 示例说明 弱引用 Map java.util.WeakHashMap java.lang.ThreadLocal.ThreadLocalMap 对象鉴定 Map java.util.identityHashMap","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 集合框架基础","slug":"Java/java-集合框架基础","date":"2020-03-30T20:26:00.000Z","updated":"2021-06-20T05:09:18.051Z","comments":true,"path":"2020/03/31/Java/java-集合框架基础/","link":"","permalink":"https://www.shanghua.live/2020/03/31/Java/java-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80/","excerpt":"基本组成 Collection interfaces（集合接口）","text":"基本组成 Collection interfaces（集合接口） Infrastructure（基础设施） General-purppose implementations（通用实现） Abstract implementations（抽象实现） Legacy implementations（遗留实现） Convenience implementations（便利实现） Wrapper implementations（包装实现） Special-purpose implementations（特殊实现） Array Utilities（数组工具类） java.utils.Collection 接口通用接口 java.util.List java.util.Set java.util.SortedSet java.util.NavigableSet(since java 1.6) 集合实现遗留实现 java.util.Vector java.util.Stack java.util.HashTable java.util.En","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"Java 并发锁","slug":"Java/java-并发锁","date":"2019-09-18T11:57:00.000Z","updated":"2021-06-20T05:09:17.610Z","comments":true,"path":"2019/09/18/Java/java-并发锁/","link":"","permalink":"https://www.shanghua.live/2019/09/18/Java/java-%E5%B9%B6%E5%8F%91%E9%94%81/","excerpt":"","text":"并发锁 重进入锁 - ReentrantLock 重进入读写锁 - ReentrantReadWriteLock 邮票锁 - StampedLock","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 函数式基础","slug":"Java/java-函数式基础","date":"2019-08-29T11:40:00.000Z","updated":"2021-06-20T05:09:17.738Z","comments":true,"path":"2019/08/29/Java/java-函数式基础/","link":"","permalink":"https://www.shanghua.live/2019/08/29/Java/java-%E5%87%BD%E6%95%B0%E5%BC%8F%E5%9F%BA%E7%A1%80/","excerpt":"匿名内部类使用场景Java 作为一门面向对象的静态语言，其封装性能够屏蔽数据结构的细","text":"匿名内部类使用场景Java 作为一门面向对象的静态语言，其封装性能够屏蔽数据结构的细 节，从而更加关注模块的功能性。其静态性也确保了 Java 强类型的特性。随着模块功能的提升，伴随而来的是复杂度的增加，代码的语义清晰依赖与开发人员抽象和命名类的或方法的能力。尽管编程思想和设计模式能够促使编程风格趋于统一，然而大多数业务系统属于面共享过程的方式，这与面向对象编程在一定程度上存在一些冲突。Java 编程语言为了解决这个问题，引入了匿名内部类的方案。 匿名内置类基本特性 无名词类 声明位置（执行模块）： static block 实例 block 方法 构造器 并非特殊类 类名称：${package}.${declared_class}.${num}.class 基本特点 基于多态（多数基于接口编程） 实现类无需名称 允许多个抽象方法 编程局限 代码臃肿 强类型约束 接口方法升级","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 模块化基础","slug":"Java/java-模块化基础","date":"2019-08-22T12:04:00.000Z","updated":"2021-06-20T05:09:18.401Z","comments":true,"path":"2019/08/22/Java/java-模块化基础/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/java-%E6%A8%A1%E5%9D%97%E5%8C%96%E5%9F%BA%E7%A1%80/","excerpt":"Java 9 模块化收益 提升平台伸缩性 提升平台完整性","text":"Java 9 模块化收益 提升平台伸缩性 提升平台完整性 提升性能 模块化强封装性 并非所有 public class 都可以被运用，需要 exports 来配合 exports 所配置的 package 下必须要有 Class 负面问题 对人的要求很高（对 Class 透明化） 必须了解相关的 module-info.java 需要了解某些类的依赖 需要了解某些类的职责 个人观点 收益不大，代价不小 对团队要求极高，容易出现互喷的情况 java 9 之前采用 jar 文件管理，java 9 模块化之后，变成了 module-info.java 管理，还需要考虑与 Maven 依赖管理如何配合","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"java 面向过程","slug":"Java/java-面向过程","date":"2019-08-22T12:04:00.000Z","updated":"2021-06-20T05:09:18.333Z","comments":true,"path":"2019/08/22/Java/java-面向过程/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/java-%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B/","excerpt":"核心要素 数据结构：原生类型、对象类型、数组类型、集合类型","text":"核心要素 数据结构：原生类型、对象类型、数组类型、集合类型 方法调用：访问性、返回类型、方法参数、异常等 执行流程：赋值、逻辑、迭代（循环）、递归等JAVA 中只有原生类型、对象类型 面向对象基本特性 封装性 派生性 多态性 面向对象设计模式 GOF 23：构建、结构、行为 方法设计：名称、访问性、参数、返回类型、异常 泛型设计：类级别、方法级别 异常设计：层次性、传播性 方法设计 单元：一个类或者一组类（组件） 类采用名词结构 动词过去式+名词 ContextRefreshedEven 动词 ing+名词 linitializingBean 形容词+名称 ConfigurableApplicationContext 执行：某个方法 方法命名：动词 execute callback run 方法参数：名词 异常： 根（顶层）异常 Throwable check 类型：Execption uncheck 类型：RuntimeException 不常见：Error java 1.4 java.lang.StackTraceElement 添加异常的原因（cause） 反模式：吞掉某个异常 性能：注意 fillInStackTrace() 方法开销,避免异常咱掉的深度 方法 1：JVM 参数控制栈深度（物理屏蔽） 方法 2：logback 日志框架控制堆栈输出深度（逻辑屏蔽） 泛型设计java 泛型属于编译时处理，运行时擦写。如果确认了泛型的类型，则用 T，否则用 ?","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"JsonSon 实体类与 json 字符串不匹配","slug":"Java/json2Pojo","date":"2019-08-21T23:07:15.000Z","updated":"2021-06-20T05:09:18.633Z","comments":true,"path":"2019/08/22/Java/json2Pojo/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/json2Pojo/","excerpt":"字段名与属性名不匹配","text":"字段名与属性名不匹配 在字段上加 JsonProperty 注解 value 对应 json 字符串 12@JsonProperty(value = &quot;isebookon&quot;)private Integer ebookon; 类字段缺少 json 字符串对应的列在类上添加 @JsonIgnoreProperties 注解 12@JsonIgnoreProperties(ignoreUnknown = true)public class TbUser&#123;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Json","slug":"Json","permalink":"https://www.shanghua.live/tags/Json/"}]},{"title":"Lambda 表达式","slug":"Java/lambda","date":"2019-08-21T23:07:00.000Z","updated":"2021-06-20T05:12:17.304Z","comments":true,"path":"2019/08/22/Java/lambda/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Java/lambda/","excerpt":"基本特点 流程编排清晰 函数类型编程","text":"基本特点 流程编排清晰 函数类型编程 改善代码臃肿 兼容接口升级 编程局限Contents 单一抽象方法 Lambda 调试苦难 Stream API 操作能力有限 函数式接口基本特性 所有函数式接口都引用一段执行代码 函数式接口没有固定的类型，固定模式(SCFP = Supplier + Consumer + Function + Predicate) + Action 利用方法引用来实现模型匹配","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"}]},{"title":"Ubuntu Server 18.04 X64 安装","slug":"Linux/Ubuntu-install","date":"2019-08-21T22:50:24.000Z","updated":"2021-06-20T05:11:38.603Z","comments":true,"path":"2019/08/22/Linux/Ubuntu-install/","link":"","permalink":"https://www.shanghua.live/2019/08/22/Linux/Ubuntu-install/","excerpt":"安装准备","text":"安装准备 1.Ubuntu 镜像准备，下载地址 这里使用的是阿里镜像站的镜像地址 开始安装选择语言 直接回车，选择 English 选择键盘布局 这里直接默认 Done 选择系统类型选择系统类型，第一个是安装 Ubuntu 另外两个是附带云功能的，我们不需要 直接回车，选择第一个 选择网卡我这里是 ens33，其他电脑可能有不同，不过都是 en 开头的 直接回车 选择 IP 代理 这里直接回车，不用填 选择镜像地址 这里我们可以输入阿里云镜像地址，这样后面下载东西会快很多 1http://mirrors.aliyun.com/ubuntu/ 把默认值删掉，输入阿里地址。输入后变成这样 Done 下一步 文件系统设置 这里一定要选择第二个，带 LVM （逻辑卷管理） 的，回车 选择安装磁盘 只有一个，直接回车下一步 磁盘分区，这里需要注意一下 这里有一个 14.996G free space，这怎么行，我们选择 ubuntu-lv 回车选择 Edit 然后将其改为 18.996G，也就是 max 后面的值 然后选择 save 回车，然后我们就会发现 free space 没得了，完美 然后 done 回车，这时候会弹出一个框，我们选择 continue 即可 填写用户名密码 填写完成，shanghua 是我的网名 这里密码一定要记住，不然忘记了就完蛋了 SSH 设置 这里按一下空格选中安装 SSH 服务 Done 不知道是什么页面 不用管直接 Done 最后然后等一小会就会出来这个页面 这里选择 Reboot Now 重启就完成了，重启就进入系统了","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"}]}],"categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"https://www.shanghua.live/tags/%E8%AE%A1%E7%BD%91/"},{"name":"Java","slug":"Java","permalink":"https://www.shanghua.live/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://www.shanghua.live/tags/Mybatis/"},{"name":"Vim","slug":"Vim","permalink":"https://www.shanghua.live/tags/Vim/"},{"name":"Maven","slug":"Maven","permalink":"https://www.shanghua.live/tags/Maven/"},{"name":"git","slug":"git","permalink":"https://www.shanghua.live/tags/git/"},{"name":"IDEA","slug":"IDEA","permalink":"https://www.shanghua.live/tags/IDEA/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://www.shanghua.live/tags/elasticsearch/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.shanghua.live/tags/MongoDB/"},{"name":"k8","slug":"k8","permalink":"https://www.shanghua.live/tags/k8/"},{"name":"Linux","slug":"Linux","permalink":"https://www.shanghua.live/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.shanghua.live/tags/Ubuntu/"},{"name":"Python","slug":"Python","permalink":"https://www.shanghua.live/tags/Python/"},{"name":"算法","slug":"算法","permalink":"https://www.shanghua.live/tags/%E7%AE%97%E6%B3%95/"},{"name":"Json","slug":"Json","permalink":"https://www.shanghua.live/tags/Json/"}]}